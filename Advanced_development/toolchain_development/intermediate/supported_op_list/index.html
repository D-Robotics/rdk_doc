<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Advanced_development/toolchain_development/intermediate/supported_op_list" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">模型算子支持列表 | RDK DOC</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://developer.d-robotics.cc/rdk_doc/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://developer.d-robotics.cc/rdk_doc/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://developer.d-robotics.cc/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="模型算子支持列表 | RDK DOC"><meta data-rh="true" name="description" content="supportedoplistandrestrictions}"><meta data-rh="true" property="og:description" content="supportedoplistandrestrictions}"><link data-rh="true" rel="icon" href="/rdk_doc/img/logo.png"><link data-rh="true" rel="canonical" href="https://developer.d-robotics.cc/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list"><link data-rh="true" rel="alternate" href="https://developer.d-robotics.cc/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://developer.d-robotics.cc/rdk_doc/en/Advanced_development/toolchain_development/intermediate/supported_op_list" hreflang="en"><link data-rh="true" rel="alternate" href="https://developer.d-robotics.cc/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"7. 进阶开发","item":"https://developer.d-robotics.cc/rdk_doc/Advanced_development"},{"@type":"ListItem","position":2,"name":"7.4 算法工具链开发指南","item":"https://developer.d-robotics.cc/rdk_doc/04_toolchain_development"},{"@type":"ListItem","position":3,"name":"7.4.2 进阶指南","item":"https://developer.d-robotics.cc/rdk_doc/Advanced_development/toolchain_development/intermediate/"},{"@type":"ListItem","position":4,"name":"模型算子支持列表","item":"https://developer.d-robotics.cc/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list"}]}</script><script src="https://hm.baidu.com/hm.js?24dd63cad43b63889ea6bede5fd1ab9e" async></script><link rel="stylesheet" href="/rdk_doc/assets/css/styles.0fbd7d27.css">
<script src="/rdk_doc/assets/js/runtime~main.08819509.js" defer="defer"></script>
<script src="/rdk_doc/assets/js/main.bd17a3ee.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a href="https://d-robotics.cc/" target="_blank" rel="noopener noreferrer" class="navbar__brand"><div class="navbar__logo"><img src="/rdk_doc/img/logo.png" alt="地瓜机器人社区 logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/rdk_doc/img/logo.png" alt="地瓜机器人社区 logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">D-Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/rdk_doc/RDK">RDK X3 / X5</a><a class="navbar__item navbar__link" href="/rdk_doc/rdk_s/RDK">RDK S100</a><a href="https://developer.d-robotics.cc/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Community<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/D-Robotics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>CN</a><ul class="dropdown__menu"><li><a href="/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-Hans">CN</a></li><li><a href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/supported_op_list" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">EN</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="切换浅色/暗黑模式（当前为system mode）"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/rdk_doc/RDK">D-Robotics RDK套件</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/Quick_start">1. 快速开始</a><button aria-label="展开侧边栏分类 &#x27;1. 快速开始&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/System_configuration">2. 系统配置</a><button aria-label="展开侧边栏分类 &#x27;2. 系统配置&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/Basic_Application">3. 基础应用开发</a><button aria-label="展开侧边栏分类 &#x27;3. 基础应用开发&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/Basic_Development">4. 算法应用开发</a><button aria-label="展开侧边栏分类 &#x27;4. 算法应用开发&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/Robot_development">5. 机器人应用开发</a><button aria-label="展开侧边栏分类 &#x27;5. 机器人应用开发&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/Application_case">6. 应用开发指南</a><button aria-label="展开侧边栏分类 &#x27;6. 应用开发指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/rdk_doc/Advanced_development">7. 进阶开发</a><button aria-label="折叠侧边栏分类 &#x27;7. 进阶开发&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rdk_doc/hardware_development">7.1 硬件开发指南</a><button aria-label="展开侧边栏分类 &#x27;7.1 硬件开发指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rdk_doc/linux_development">7.2 Linux开发指南</a><button aria-label="展开侧边栏分类 &#x27;7.2 Linux开发指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rdk_doc/03_multimedia_development">7.3 RDK X3 多 媒体开发指南</a><button aria-label="展开侧边栏分类 &#x27;7.3 RDK X3 多媒体开发指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/rdk_doc/04_toolchain_development">7.4 算法工具链开发指南</a><button aria-label="折叠侧边栏分类 &#x27;7.4 算法工具链开发指南&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/rdk_doc/Advanced_development/toolchain_development/overview">7.4.1 简介</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/rdk_doc/Advanced_development/toolchain_development/intermediate/">7.4.2 进阶指南</a><button aria-label="折叠侧边栏分类 &#x27;7.4.2 进阶指南&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/rdk_doc/Advanced_development/toolchain_development/intermediate/environment_config">环境安装</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/rdk_doc/Advanced_development/toolchain_development/intermediate/ptq_process">PTQ原理及步骤详解</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list">模型算子支持列表</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/rdk_doc/Advanced_development/toolchain_development/intermediate/runtime_sample">模型上板运行应用开发说明</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rdk_doc/Advanced_development/toolchain_development/expert/">7.4.3 高阶指南</a><button aria-label="展开侧边栏分类 &#x27;7.4.3 高阶指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/FAQ">8. 常见问题</a><button aria-label="展开侧边栏分类 &#x27;8. 常见问题&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/Appendix">9. 附录</a><button aria-label="展开侧边栏分类 &#x27;9. 附录&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/rdk_doc/Release_Note/release_note">10. 版本发布</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/rdk_doc/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/rdk_doc/Advanced_development"><span>7. 进阶开发</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/rdk_doc/04_toolchain_development"><span>7.4 算法工具链开发指南</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/rdk_doc/Advanced_development/toolchain_development/intermediate/"><span>7.4.2 进阶指南</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">模型算子支持列表</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>模型算子支持列表</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="使用限制说明">使用限制说明<a href="#使用限制说明" class="hash-link" aria-label="使用限制说明的直接链接" title="使用限制说明的直接链接">​</a></h2>
<p>本章节主要介绍D-Robotics 处理器支持的 <code>Caffe</code> 和 <code>ONNX</code> 算子情况，其他未列出的算子因D-Robotics 处理器 bpu硬件限制，暂不支持。</p>
<p><strong>术语概念：</strong></p>
<ul>
<li>
<p>BPU加速   ：D-Robotics 处 理器可以进行加速的算子（一定约束条件下），如果不满足约束条件，则会在CPU进行计算</p>
</li>
<li>
<p>CPU计算   ：当前已经在D-Robotics ARM CPU上进行优化的算子，支持onnx opset10与opset11。</p>
</li>
<li>
<p>CPU计算※   ：暂时未集成的CPU算子。</p>
</li>
</ul>
<p><strong>其他注意事项：</strong></p>
<ul>
<li>
<p>RDK X3所有BPU上运行的算子均遵守一般限制：input_batch ≤ 128。</p>
</li>
<li>
<p>RDK Ultra 和 RDK X5所有BPU上运行的算子均遵守一般限制：1. 输入输出维度均为4，对于支持非四维情况的op，会在约束中显性标识； 2. shape：H,W,C ∈ [1, 65536]，<code>N &lt;= 4096；3. N x C x H x W &lt;= 1G bytes</code>。</p>
</li>
<li>
<p>支持 <code>Caffe 1.0</code> 基础算子以及常用扩展算子，支持onnx <code>opset10</code> 和 <code>opset11</code> 算子，对于无法满足BPU加速约束条件的算子将会退化到ARM CPU进行计算。</p>
</li>
<li>
<p><code>Cast</code> , <code>Constant</code> , <code>Dropout</code> , <code>Reshape</code> , <code>Squeeze</code> , <code>Unsqueeze</code> , <code>Shape</code> 这些算子(OP)无法直接运行在BPU上，但在一些情况下（常量折叠）算法工具链会将其优化掉进而实现支持的效果。</p>
</li>
<li>
<p>标记为PyTorch的算子(OP)为官方的opset11不包含的算子，D-Robotics 算法工具链提供了导出脚本可以将其从PyTorch导出到D-Robotics 自定义的onnx OP中。</p>
</li>
<li>
<p>基于tensorlfow-onnx（<a href="https://github.com/onnx/tensorflow-onnx%EF%BC%89%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7%EF%BC%8C%E6%94%AF%E6%8C%81%E5%B0%86" target="_blank" rel="noopener noreferrer">https://github.com/onnx/tensorflow-onnx）转换工具，支持将</a> <code>tensorlfow1.*</code> 版本的算子稳定的转换到opset6-opset11版本的ONNX模型格式，但是 <code>Tensroflow2.*</code> 当前支持还属于实验版本。</p>
</li>
<li>
<p>关于OP主动量化被动量化的说明：一个符合  本章节约束条件的OP仍然运行在CPU的主要原因是该OP属于被动量化OP，算法工具链会根据OP的计算特性和BPU底层逻辑等多方面考虑设计量化逻辑，当前量化逻辑分为：主动量化，被动量化，手动量化。量化逻辑更多信息请阅读：<a href="https://developer.d-robotics.cc/forumDetail/118364000835765793" target="_blank" rel="noopener noreferrer"><strong>算法工具链中的主动量化和被动量化逻辑</strong></a> 章节。</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-x3支持的caffe算子列表">RDK X3支持的Caffe算子列表<a href="#rdk-x3支持的caffe算子列表" class="hash-link" aria-label="RDK X3支持的Caffe算子列表的直接链接" title="RDK X3支持的Caffe算子列表的直接链接">​</a></h2>
<table><thead><tr><th><strong>caffe算子名称</strong></th><th><strong>CPU计算/BPU加速</strong></th><th><strong>X3 BPU支持约束</strong></th><th><strong>CPU支持约束</strong></th></tr></thead><tbody><tr><td>Convolution</td><td>BPU加速</td><td>Kernel宽高取值范围：HxW=[1,7]x[1,7] <br> 输入输出Channel取值范围 <code>(one group) &lt;= 2048</code>（对于非dilated、group、depthwise conv等普通卷积，可以放宽至 <code>&lt;=4096</code>）。<br> stride无限制。<br> Dilation取值范围：只支持设置为2的幂次方，且必须能够被stride整除。<br> h_dilated 和 w_dilated 可以不同但要求 <code>h_diated &lt;= w_dilated</code>。<br> 单个 Kernel 总体大小限制：<code>HxWxC &lt;= 32768</code>。<br> 不支持配置axis，默认为1</td><td>仅支持4维Conv计算。<br> auto_pad 属性不支持。<br> type约束支持：float, int32, int8。<br> pads 属性约束``[Hstart, Wstart, Hend, Wend]`（pads长度等于4）并且 Hstart == Hend，Wstart == Wend。</td></tr><tr><td>Deconvolution</td><td>BPU加速</td><td>Kernel 宽高取值范围：HxW=[2,14]x[2,14]。  <br> 输入输出Channel数值取值范围：<code>C &lt;= 2048</code>。  <br>Padding宽高取值范围： <br>HxW=[0,(Kernel_H-1)/2]x[0,(Kernel_W-1)/2] 。 <br>Stride取值范围：Stride ∈ <!-- -->4<!-- --> 。 <br> <code>stride_h ≦ stride_w</code> 。 <br>Dilation ∈ <!-- -->1<!-- -->。  <br>不支持配置axis属性。</td><td>不支持output_shape和output_padding参数；  <br>auto_pad参数只支持NOTSET模式；  <br>不支持axis</td></tr><tr><td>MaxUnpool</td><td>CPU计算</td><td>---</td><td>from_type支持：   <br>- X：type约束：仅支持float类型。  <br>- I：Tensor（int64）。  <br>to_type支持：type约束：仅支持float类型。</td></tr><tr><td>Pooling</td><td>BPU加速</td><td>共有四种Pooling算子即MaxPooling，AveragePooling，GlobalMaxPooling，GlobalAveragePooling。 <br>对四种Pooling的约束分别为：   <br>MaxPooling： <br> Kernel宽高的取值范围为：[1,64]x[1,64] 。 <br>Stride取值范围为：[1,185]。 <br> Padding值需要大于等于零。 <br>AveragePooling： <br> Kernel HxW=[1, 7]x[1, 7], Stride ∈<!-- -->185<!-- -->。  <br>GlobalAveragePooling：  <br>假设输入shape为NCHW， 则输入宽高需满足 <code>HxW &lt;= 8192</code> 。 <br>GlobalMaxPooling：  <br>假设输入shape为NCHW，则输入宽高取值范围为HxW=[1,1024]x[1,1024]。</td><td>无</td></tr><tr><td>SPP</td><td>CPU计算</td><td>不支持</td><td>支持pyramid_height，2^n 次pooling, <code>n&lt;7</code> ; <br> pooling kernel 小于等于 255；  <br> 支持pool，配置可选值为 <code>{0，1}</code></td></tr><tr><td>InnerProduct</td><td>BPU加速</td><td>InnerProduct将被转化为Conv实现。  <br>假设InnerProduct的输入feature map的shape为NCHW ： <br>1. 如果HW均小于等于7，则Gemm的限制等同于Conv。  <br>2. 如果H和W均为1，那么C的限制为<code> &lt;= 16384</code>；否则 C的大小限制为 <code>&lt;= 2048</code>。  <br>3. 如果Gemm后是一个BPU支持的节点，Gemm会进行低精度int8输出，此时的输入宽高限制为: H x W/8 x C/4 <code>&lt;=</code> 1024。  <br>4.  如果Gemm后是一个非BPU支持的节点，Gemm会进行高精度int32输出，此时的输入宽高限制为: H x W/8 x C/4 &lt; 2048 。 <br> 不支持配置axis属性</td><td>无</td></tr><tr><td>LRN</td><td>CPU计算</td><td>不支持</td><td>local_size 支持、 <br>alpha支持、 <br>beta 支持、 <br>norm_region 支持，配置可选值<code>{ACROSS_CHANNELS, WITHIN_CHANNEL }</code>、 <br>k 支持</td></tr><tr><td>MVN</td><td>CPU计算</td><td>不支持</td><td>normalize_variance支持，配置可选值为<!-- -->1<!-- -->、 <br>across_channels支持，配置可选值为<!-- -->1<!-- -->、 <br>仅支持Float32类型的计算。</td></tr><tr><td>BatchNorm</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>ELU</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>BNLL</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>PReLU</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>ReLU/LeakyRelu</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>Sigmoid</td><td>BPU加速</td><td>对于一个输入维度为1CHW的tensor，仅支持min(8W4C对齐后的shape，32C对齐后的shape) <code>&lt;=8192</code>的情况。 <br>8W4C：实际运行时tensor的W维度padding至8的整数倍，C维度padding至4的整数倍。 <br>32C：实际运行时tensor的C维度padding至32的整数倍。 <br>在两个对齐方式中取对齐后shape最小值，判断是否<code>&lt;=8192</code>。</td><td>无</td></tr><tr><td>TanH</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>Eltwise</td><td>BPU加速</td><td>operation目前支持Add和Mul，暂不支持减。  <br>Add：  <br>输入channel大小 <code>M&lt;= 2048</code>  <br>支持以下几种情况： <br> 1. Add的两个输入shape为NCHW和NCHW；  <br>2. Add的两个输入shape为NCHW和NC11（Add的两个输入都需要是其它op的输出） <br> Mul： <br> Mul的两个输入都需要是四维并且C的大小需要 <code>&lt;= 2048</code>。 <br> 同时仅支持如下shape的相乘：  <br>1. (1xCxHxW vs 1xCxHxW)。  <br>2. (1xCxHxW vs 1xCx1x1)。  <br>3. (1xCxHxW vs 1x1x1x1)。</td><td>无</td></tr><tr><td>Bias</td><td>BPU加速</td><td>参考Eltwise等于Add的情况</td><td>无</td></tr><tr><td>Scale</td><td>BPU加速</td><td>参考Eltwise等于Mul的情况</td><td>无</td></tr><tr><td>AbsVal</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Exp</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>Log</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Power</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>Threshold</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Reduction</td><td>CPU计算</td><td>不支持</td><td>operation 支持 SUM、ASUM、 SUMSQ、MEAN ； <br>axis 支持；  <br> 仅支持Float32类型的计算。</td></tr><tr><td>Softmax</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>ArgMax</td><td>BPU加速</td><td>仅支持 <code>axis=1，c&lt;=64</code> 。 <br>不支持配置top_k != 1</td><td>无</td></tr><tr><td>Concat</td><td>BPU加速</td><td>输入输出Channel：<code>C&lt;=2048 </code></td><td>无</td></tr><tr><td>Split</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>Slice</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>Reshape</td><td>CPU计算</td><td>不支持（一些场景下可以融合）</td><td>shape 支持[1,4]个 shape_dim 配置 ； <br> axis 支持[-4,3]范围内可配，不支 持 N 维度，默认值 0，遵循 caffe 规则 ； <br> num_axes 支持[-1,3]范围内可配，默认 值-1 表示对 axis 起始的所有 轴进行变换</td></tr><tr><td>Flatten</td><td>CPU计算</td><td>不支持（一些场景下可以融合）</td><td>axis 取值范围[-4,3]，默认值 为 1，-4 与 0 含义相同。  <br>只支持End_axis == -1。</td></tr><tr><td>Crop</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Dropout</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>LSTM</td><td>BPU加速</td><td>仅支持batch=1</td><td>--</td></tr><tr><td>Normalize</td><td>CPU计算</td><td>不支持</td><td>type约束：仅支持float类型。</td></tr><tr><td>PassThrough</td><td>BPU加速</td><td>支持mode=DCR 和 mode=CRD。 <br>仅支持H和W方向的重新排列，并且仅支持blocksize=2的重排列。 <br>举例：NxCxHxW -&gt; Nx(4C)x(H/2)x(W/2)。</td><td>type约束：仅支持float类型。</td></tr><tr><td>CReLU</td><td>CPU计算</td><td>不支持</td><td>type约束：仅支持float类型。</td></tr><tr><td>RReLU</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Permute</td><td>CPU计算</td><td>不支持</td><td>- 支持nhwc2nchw，perm：[0, 3, 1, 2]。  <br> - 支持nchw2nhwc，perm：[0, 2, 3, 1]。 <br> - 支持指定perm维度转换，数据类型仅支持float，int8，int32。</td></tr><tr><td>MatMul</td><td>BPU加速</td><td>对于两个输入分别为featuremap和weight的场景（即featuremap与常量相乘） <br> 其中第一个输入是featuremap，第二个输入是weight，以下几种场景均可优化到BPU上运行： <br>- K vs KxN、K vs 1xKxN、K vs 1x1xKxN  <br>- MxK vs K、MxK vs KxN、MxK vs 1x1xKxN  <br>- 1xMxK vs K、1xMxK vs 1xKxN  <br>- 1x1xMxK vs K、1x1xMxK vs 1xKxN、1x1xMxK vs 1x1xKxN  <br>- BxMxK vs KxN （B&gt;=1）  <br>- 1xBxMxK vs KxN （B&gt;=1） <br>- AxBxMxK vs KxN (A&gt;1，B&gt;1)  <br>- 其中第一个输入是weight，第二个输入是featuremap，以下场景可优化到BPU上运行： <br>- 1xBxMxK vs 1x1xKxN (B&gt;1)  <br>对于两个输入均为featuremap的场景（即两个featuremap相乘），以下场景可优化到BPU上运行： <br>- 1xBxMxK vs 1x1xKxN （B&gt;=1）</td><td>type约束：仅支持float类型。</td></tr><tr><td>Upsample</td><td>BPU加速</td><td>输入featuremap需为四维NCHW，并且只支持在H和W维度上进行resize；  <br> 放大系数factor支持2的幂数倍如2，4，8，16，32等； <br> 支持H维度和W维度的放大系数不同但需要满足 <code>H_factor &lt;= W_factor</code></td><td>无</td></tr><tr><td>ROIPooling</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>PSROIPooling</td><td>CPU计算</td><td>不支持</td><td>无</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-x3支持的onnx算子列表">RDK X3支持的ONNX算子列表<a href="#rdk-x3支持的onnx算子列表" class="hash-link" aria-label="RDK X3支持的ONNX算子列表的直接链接" title="RDK X3支持的ONNX算子列表的直接链接">​</a></h2>
<table><thead><tr><th><strong>ONNX算子名称</strong></th><th><strong>CPU计算/BPU加速</strong></th><th><strong>X3 BPU支持约束</strong></th><th><strong>CPU支持约束</strong></th></tr></thead><tbody><tr><td>Abs</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Acos</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Acosh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Add</td><td>BPU加速</td><td>输入channel大小 <code>M&lt;= 2048</code> 支持以下几种情况： <br> 1. Add的两个输入shape为NCHW和NCHW；  <br>2. Add的两个输入shape为NCHW和NC11（Add的两个输入都需要是其它op的输出）； <br>3.作为resnet中的short-cut子结构的Add，会被融合到上一个conv中加速计算。</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>And</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>ArgMax</td><td>BPU加速</td><td>1. 输入维度为四维输入NCHW。  <br>2. 仅支持沿C维度进行argmax，即axis=1。 <br> 3. <code>C &lt;= 64 </code></td><td>type约束：仅支持float类型。</td></tr><tr><td>ArgMin</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型  。</td></tr><tr><td>Asin</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Asinh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Atan</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Atanh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>AveragePool</td><td>BPU加速</td><td>Kernel HxW=[1, 7]x[1, 7], Stride ∈<!-- -->185</td><td>auto_pad 属性不支持。 <br>仅支持四维Tensor计算。</td></tr><tr><td>BatchNormalization</td><td>BPU加速</td><td>优化阶段会被融合到上一个conv中支持</td><td>type约束：仅支持float类型。  <br>支持第1个维度是channel的数据排布方式计算。</td></tr><tr><td>BitShift</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Cast</td><td>CPU计算</td><td>--</td><td>from_type支持double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8。<br>to_type支持double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8。</td></tr><tr><td>Ceil</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Clip</td><td>BPU加速</td><td>无限制。</td><td>type约束：仅支持float类型。 <br>仅有2个输入时，默认为min参数。</td></tr><tr><td>Compress</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Concat</td><td>BPU加速</td><td>输入输出Channel：<code>C&lt;=2048</code>。</td><td>--</td></tr><tr><td>ConcatFromSequence</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Constant</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>目前不支持sparse_tensor属性。 <br> type约束：仅支持float类型。</td></tr><tr><td>ConstantOfShape</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>type约束支持：float,int32,int8。</td></tr><tr><td>Conv</td><td>BPU加速</td><td>Kernel宽高取值范围：HxW=[1,7]x[1,7]。 <br> 输入输出Channel取值范围<code>(one group) &lt;= 2048</code>（对于非dilated、group、depthwise conv等普通卷积，可以放宽至<code>&lt;=4096</code>）。 <br> stride无限制，，但对于Conv后接Add(resnet shortcut-connecting) Stride取值范围为：<!-- -->2<!-- -->。 <br> Dilation取值范围：只支持设置为2的幂次方，且必须能够被stride整除。 <br>h_dilated和w_dilated可以不同但要求<code>h_diated&lt;=w_dilated</code> 。 <br> 单个Kernel总体大小限制: <code>HxWxC &lt;= 32768</code></td><td>仅支持4维Conv计算。 <br>auto_pad 属性不支持。 <br>type约束支持：float,int32,int8。 <br>pads属性约束：[Hstart, Wstart, Hend, Wend]（pads长度等于4）并且Hstart==Hend，Wstart==Wend。</td></tr><tr><td>ConvInteger</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>ConvTranspose</td><td>BPU加速</td><td>Kernel 宽高取值范围：HxW=[2,14]x[2,14]。 <br> 输入输出Channel数值取值范围：<code>C &lt;= 2048</code> 。 <br> Padding宽高取值范围：HxW=[0,(Kernel_H-1)/2]x[0,(Kernel_W-1)/2]。 <br> Stride取值范围：<code>Stride ∈ {2, 4}</code>。 <br> <code>stride_h ≦ stride_w</code>。 <br> <code>Dilation ∈ {(1, 1)}</code></td><td>auto_pad属性不支持。  <br>type约束支持：float,int32,int8。</td></tr><tr><td>Cos</td><td>BPU加速</td><td>对于一个输入维度为1CHW的tensor，仅支持 <code>CxHxW &lt;= 8192</code>的情况</td><td>type约束：仅支持float类型。</td></tr><tr><td>Cosh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>CumSum</td><td>CPU计算</td><td>--</td><td>from_type： <br>x：type约束仅支持float类型。 <br>axis：type约束仅支持int32类型。 <br>to_type：type约束仅支持float类型。</td></tr><tr><td>DepthToSpace</td><td>BPU加速</td><td>支持mode=DCR 和 mode=CRD。 <br> 仅支持H和W方向的重新排列，并且仅支持blocksize=2的重排列。  <br>举例：NxCxHxW -&gt; Nx(C/4)x(2H)x(2W)</td><td>from_type支持： <br>- type约束仅支持float类型。 <br>- 仅支持4维度Tensor计算。 <br>to_type支持： <br>- type约束仅支持float类型。 <br>- 仅支持4维度Tensor计算。</td></tr><tr><td>DequantizeLinear</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Det</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Div</td><td>BPU加速</td><td>1. 只支持两个输入均为featuremap（不支持输入来自于常量）；  <br>2. 对input shape的约束请参考Mul算子</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Dropout</td><td>BPU加速</td><td>该算子推理阶段不参加计算， 会被移除优化</td><td>--</td></tr><tr><td>Einsum</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Elu</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Equal</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Erf</td><td>CPU计算</td><td>--</td><td>type约束：支持float、double数据类型。</td></tr><tr><td>Exp</td><td>BPU加速</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Expand</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>EyeLike</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Flatten</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Floor</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>GRU</td><td>CPU计算</td><td>--</td><td>- direction属性仅支持forward类型。 <br>- type约束：仅支持float类型。 <br>- 仅支持输入个数是3、4、6。 <br>- 输出个数是2。</td></tr><tr><td>Gather</td><td>CPU计算</td><td>--</td><td>from_type支持： <br>- input：type约束支持： <br>float,int64,int32,int8,uint64,uint32,uint8。 <br>- indices：type约束支持int32, int64。  <br>to_type支持：type约束支持： <br>float,int64,int32,int8,uint64,uint32,uint8。</td></tr><tr><td>GatherElements</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>GatherND</td><td>CPU计算</td><td>--</td><td>from_type支持： <br>- input：type约束支持float,int32,int8。 <br>- indices：tensor(int64)。 <br>to_type支持：type约束支持float,int32,int8。</td></tr><tr><td>Gemm</td><td>BPU加速</td><td>Gemm将被转化为Conv实现。 <br> 假设Gemm的输入feature map的shape为NCHW： <br> 1. 如果HW均小于等于7，则Gemm的限制等同于Conv。 <br> 2. 如果H和W均为1，那么C的限制为 <code>&lt;= 16384</code>；否则 C的大小限制为 <code>&lt;= 2048</code>。 <br> 3. 如果Gemm后是一个BPU支持的节点，Gemm会进行低精度int8输出，此时的输入宽高限制为: <code>H x W/8 x C/4 &lt;= 1024</code>。 <br> 4. 如果Gemm后是一个非BPU支持的节点，Gemm会进行高精度int32输出，此时的输入宽高限制为: <code>H x W/8 x C/4 &lt; 2048</code>。</td><td>type约束：仅支持float类型。</td></tr><tr><td>GlobalAveragePool</td><td>BPU加速</td><td>假设输入shape为NCHW， 则输入宽高需满足 <code>HxW &lt;= 8192 </code></td><td>无</td></tr><tr><td>GlobalLpPool</td><td>CPU计算</td><td>--</td><td>- type约束：支持float和double类型。 <br> - 仅支持四维Tensor计算。</td></tr><tr><td>GlobalMaxPool</td><td>BPU加速</td><td>假设输入shape为NCHW， 则输入宽高取值范围为HxW=[1,1024]x[1,1024]</td><td>- type约束仅支持float类型。 <br>- 仅支持四维Tensor。</td></tr><tr><td>Greater</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>HardSigmoid</td><td>CPU计算</td><td>--</td><td>type约束仅支持float类型。</td></tr><tr><td>Hardmax</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Identity</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>If</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>InstanceNormalization</td><td>CPU计算</td><td>--</td><td>- type约束仅支持float类型。 <br>- 支持第1个维度是channel的数据排布方式计算。</td></tr><tr><td>IsInf</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>IsNaN</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>LRN</td><td>CPU计算</td><td>--</td><td>- type约束仅支持float类型。 <br>- 仅支持四维Tensor。</td></tr><tr><td>LSTM</td><td>BPU加速</td><td>仅支持batch_size=1</td><td>- 不支持属性设置。 <br>- type约束仅支持float类型。 <br>- 仅支持输入个数是3、4、8。 <br>- 输出个数是2。</td></tr><tr><td>LeakyRelu</td><td>BPU加速</td><td>无</td><td>无</td></tr><tr><td>Less</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>LessOrEqual</td><td>CPU计算</td><td></td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Log</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>LogSoftmax</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Loop</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>LpNormalization</td><td>CPU计算</td><td>--</td><td>- p范数仅支持1或者2。 <br>- type约束支持double类型和float类型。</td></tr><tr><td>LpPool</td><td>CPU计算</td><td>--</td><td>- auto_pad属性不支持。 <br>- type约束支持double类型和float类型。 <br>- 仅支持4维计算。</td></tr><tr><td>MatMulInteger</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>MatMul</td><td>BPU加速</td><td>对于两个输入分别为featuremap和weight的场景（即featuremap与常量相乘） <br> 其中第一个输入是featuremap，第二个输入是weight，以下几种场景均可优化到BPU上运行： <br>- K vs KxN、K vs 1xKxN、K vs 1x1xKxN  <br>- MxK vs K、MxK vs KxN、MxK vs 1x1xKxN  <br>- 1xMxK vs K、1xMxK vs 1xKxN  <br>- 1x1xMxK vs K、1x1xMxK vs 1xKxN、1x1xMxK vs 1x1xKxN  <br>- BxMxK vs KxN （B&gt;=1）  <br>- 1xBxMxK vs KxN （B&gt;=1） <br>- AxBxMxK vs KxN (A&gt;1，B&gt;1)  <br>- 其中第一个输入是weight，第二个输入是featuremap，以下场景可优化到BPU上运行： <br>- 1xBxMxK vs 1x1xKxN (B&gt;1)  <br>对于两个输入均为featuremap的场景（即两个featuremap相乘），以下场景可优化到BPU上运行： <br>- 1xBxMxK vs 1x1xKxN （B&gt;=1）</td><td>type约束：仅支持float类型。</td></tr><tr><td>Max</td><td>CPU计算</td><td>--</td><td>- 支持1-∞个输入。 <br>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>MaxPool</td><td>BPU加速</td><td>Kernel宽高的取值范围为：[1, 64]x[1, 64]。 <br> Stride取值范围为：[1,185]。 <br>Padding值需要大于等于零。 <br>MaxPool不支持dilation。</td><td>1. dilation只支持1x1。 <br>2. 只支持数据行优先存储。 <br>3. auto_pad属性不支持。 <br>4. storage_order属性不支持。 <br>5. 仅支持四维Tensor计算。</td></tr><tr><td>MaxRoiPool</td><td>CPU计算</td><td>--</td><td>无</td></tr><tr><td>Mean</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Min</td><td>CPU计算</td><td>--</td><td>- 支持1-∞个输入。 <br>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Mod</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Mul</td><td>BPU加速</td><td>Mul的两个输入都需要是四维并且C的大小需要 <code>&lt;= 2048</code>。  <br>同时仅支持如下shape的  相乘：  <br>1. (1xCxHxW vs 1xCxHxW)。  <br>2. (1xCxHxW vs 1xCx1x1)。 <br> 3. (1xCxHxW vs 1x1x1x1) 。 <br>注意：输入的取值不能为0。</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Multinomial</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Neg</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>NonZero</td><td>CPU计算</td><td>--</td><td>- type约束支持：float,int32,int8。 <br>- 支持1维计算。 <br>- 支持4维计算。</td></tr><tr><td>Not</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>OneHot</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Or</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。  <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>PRelu</td><td>BPU加速</td><td>--</td><td>- type约束支持：仅支持float类型。 <br>- from_type：X和slope。 <br>- to_type：Y。 <br>- X的shape为data_shape，slope的为slope_shape ，shape约束如下：   <br>- data_shape == slope_shape。    <br>- slope_shape.ProdSize() == 1。    <br>- X和slope仅支持NCHW排布的4维度计算，并且N、C维度值相等。      <br>- HxW 与1x1（ slope_shape ）。      <br>- HxW与Hx1（ slope_shape ）。      <br>- HxW与1xW（ slope_shape ）。  <br>- X是4维度 &amp;&amp; slope是3维度 &amp;&amp; data_shape[1] == slope_shape [0] &amp;&amp; slope_shape [1] == 1 &amp;&amp; slope_shape [2] == 1。</td></tr><tr><td>Pad</td><td>BPU加速</td><td>支持mode = Constant。 <br>仅支持H，W维度的pad。</td><td>Pad-10： <br>- type约束仅支持float类型。 <br>- 仅支持NCHW排布的4维Tensor。 <br>- 属性pads的约束如下：   <br>- len(pads) == 8 &amp;&amp; pads[i] &gt;=0 &amp;&amp; pads[0] == 0 &amp;&amp; pads[1] == 0 &amp;&amp; pads[4] == 0 &amp;&amp; pads[5] == 0。  <br>Pad-11： <br>- from_type支持：   <br>- data：type约束仅支持float类型。   <br>- pads : tensor(int64)。   <br>- constant_value (optional)：type约束仅支持float类型。 <br>- to_type支持：type约束仅支持float类型。 <br>- 仅支持4维Tensor。 <br>- 仅支持2/3维度填充。</td></tr><tr><td>Pow</td><td>BPU加速</td><td>只支持第二个输入（exponent）为单个值。</td><td>- type约束支持：double, float，int64, int32。 <br>- 支持相同输入shape的计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。 <br>- 仅支持X和Y相同type。</td></tr><tr><td>QLinearConv</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>QLinearMatMul</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>QuantizeLinear</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>RNN</td><td>CPU计算</td><td>--</td><td>- type约束：仅支持float类型。 <br>- 属性约束：direction属性仅支持forward。 <br>- 输入约束：仅支持X、W、R输入，不支持可选输入B、sequence_lens、initial_h设置。  <br>- 输出约束：仅支持Y_h的输出，shape [num_directions, batch_size, hidden_size]。</td></tr><tr><td>RandomNormal</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>RandomNormalLike</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>RandomUniform</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>RandomUniformLike</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Range</td><td>CPU计算</td><td>--</td><td>type约束支持：float,int64,int32,int16。</td></tr><tr><td>Reciprocal</td><td>BPU加速</td><td>--</td><td>--</td></tr><tr><td>ReduceL1</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceL2</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceLogSum</td><td>CPU计算</td><td>--</td><td>仅支持float、double数据类型</td></tr><tr><td>ReduceLogSumExp</td><td>CPU计算</td><td>--</td><td>type约束支持float、double数据类型。</td></tr><tr><td>ReduceMax</td><td>CPU计算</td><td>--</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>ReduceMean</td><td>BPU加速</td><td>input featuremap需为四维，并且axes=[2, 3]</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>ReduceMin</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceProd</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceSum</td><td>CPU计算</td><td>--</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>ReduceSumSquare</td><td>CPU计算</td><td>--</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>Relu</td><td>BPU加速</td><td>会被融合到前一个conv中</td><td>type约束：仅支持float类型。</td></tr><tr><td>Reshape</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Resize</td><td>BPU加速</td><td>1. 输入featuremap需为四维NCHW，并且只支持在H和W维度上进行resize，onnx opset=11时支持roi输入（pytorch转换的模型需手动修改算子添加roi输入，roi只支持常量输入），roi输入只支持H和W维度，roi输入只在tf_crop_and_resize模式下起作用。 <br>2. 属性mode支持nearest和linear两种模式。 <br>3. 支持放大和缩小。 <br>4. 对于mode=nearest，放大系数factor支持2的幂数倍如2，4，8，16，32等；支持H维度和W维度的放大系数不同但需要满足 <code>H_factor &lt;= W_factor</code>。 <br>5. 对于onnx opset=11，属性coordinate_transformation_mode支持half_pixel，pytorch_half_pixel, asymmetric，align_corners和tf_crop_and_resize，当coordinate_transformation_mode=tf_crop_and_resize时，需要保证roi输入转换得到的边界坐标为整数。</td><td>resize-10  <br>- 输入等于2时，使用opset10。 <br>- 输入数据是4维Tensor。  <br>resize-11   <br>- 输入大于2时，使用opset11。 <br>- 输入数据是4维Tensor。 <br>- coordinate_transformation_mode在nearest, linear模式下支持half_pixel, asymmetric, align_corners和pytorch_half_pixel四种，在cubic模式下只支持half_pixel。 <br>- extrapolation_value属性不支持。</td></tr><tr><td>ReverseSequence</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>RoiAlign</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Round</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Scan</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Scatter (deprecated)</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>ScatterElements</td><td>CPU计算</td><td>--</td><td>from_type支持： <br>- data：type约束支持：float,int32,int8。 <br>- indices：type约束仅支持int32类型。 <br>- updates：type约束支持：float,int32,int8。 <br>to_type支持：type约束支持：float,int32,int8。</td></tr><tr><td>ScatterND</td><td>CPU计算</td><td>--</td><td>from_type支持： <br>- data：type约束支持：float,int32,int8。 <br>- updates : type约束支持：float,int32,int8。 <br>to_type支持：type约束支持：float,int32,int8。</td></tr><tr><td>Selu</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>SequenceAt</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceConstruct</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceEmpty</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceErase</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceInsert</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceLength</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Shape</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>--</td></tr><tr><td>Shrink</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Sigmoid</td><td>BPU加速</td><td>对于一个输入维度为1CHW的tensor，仅支持min(8W4C对齐后的shape，32C对齐后的shape) <code>&lt;=8192</code>的情况。 <br>8W4C：实际运行时tensor的W维度padding至8的整数倍，C维度padding至4的整数倍。 <br>32C：实际运行时tensor的C维度padding至32的整数倍。 <br>在两个对齐方式中取对齐后shape最小值，判断是否<code>&lt;=8192</code>。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Sign</td><td>CPU计算</td><td>--</td><td>无</td></tr><tr><td>Sin</td><td>BPU加速</td><td>对于一个输入维度为1CHW的tensor，仅支持<code>CxHxW &lt;= 8192</code>的情况</td><td>type约束：仅支持float类型。</td></tr><tr><td>Sinh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Size</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>--</td></tr><tr><td>Slice</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>Softmax</td><td>BPU加速</td><td>默认运行在CPU上，当该op输入为四维且axis=1，并且作为模型输出节点时，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Softplus</td><td>BPU加速</td><td>对于一个输入维度为1CHW的tensor，仅支持<code>CxHxW &lt;= 8192</code>的情况</td><td>type约束：仅支持float类型。</td></tr><tr><td>Softsign</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>SpaceToDepth</td><td>BPU加速</td><td>支持mode=DCR 和 mode=CRD。 <br> 仅支持H和W方向的重新排列，并且仅支持blocksize=2的重排列。  <br>举例：NxCxHxW -&gt; Nx(4C)x(H/2)x(W/2)</td><td>type约束：仅支持float类型。</td></tr><tr><td>Split</td><td>BPU加速</td><td>1. 只支持输入大小为NCHW；  <br>2. 原始输入的长度必须是每个被切分的tensor长度的倍数；  <br>3. 只支持沿着C，H，W维度的切分，也就是axis支持等于1，2，3；  <br>4. split数应可以整除</td><td>type约束：仅支持float类型。</td></tr><tr><td>SplitToSequence</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Sqrt</td><td>BPU加速</td><td>对于一个输入维度为1CHW的tensor，仅支持<code>CxHxW &lt;= 8192</code> 的情况</td><td>type约束：仅支持float类型。</td></tr><tr><td>Squeeze</td><td>CPU计算</td><td>如果该op出现在模型中的常量计算子结构中，会被常量折叠优化删除掉，不参与推理</td><td>--</td></tr><tr><td>StringNormalizer</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Sub</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Sum</td><td>BPU加速</td><td>限制条件等同于Add</td><td>type约束：仅支持float类型。</td></tr><tr><td>Tan</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Tanh</td><td>BPU加速</td><td>对于一个输入维度为1CHW的tensor，仅支持<code>CxHxW &lt;= 8192</code>的情况</td><td>type约束：仅支持float类型。</td></tr><tr><td>TfIdfVectorizer</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>ThresholdedRelu</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Tile</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float,int64,int32,uint64,uint32类型。</td></tr><tr><td>TopK</td><td>CPU计算</td><td>--</td><td>- type约束：仅支持float类型。  <br>- 仅支持opset-10。</td></tr><tr><td>Transpose</td><td>CPU计算</td><td>--</td><td>- 支持nhwc2nchw，perm：[0, 3, 1, 2]。 <br>- 支持nchw2nhwc，perm：[0, 2, 3, 1]。 <br>- 支持指定perm维度转换，数据类型仅支持float，int8，int32。</td></tr><tr><td>Unique</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Unsqueeze</td><td>CPU计算</td><td>如果该op出现在模型中的常量计算子结构中，会被常量折叠优化删除掉，不参与推理</td><td>--</td></tr><tr><td>Upsample (resize替代)</td><td>BPU加速</td><td>--</td><td>Upsample-(resize-10)  <br>- 输入等于2时，使用opset10。 <br>- 输入数据是4维Tensor。  <br>Upsample-(resize-11)   <br>- 输入大于2时，使用opset11。 <br>- 输入数据是4维Tensor。 <br>- coordinate_transformation_mode在nearest, linear模式下支持half_pixel, asymmetric, align_corners和pytorch_half_pixel四种，在cubic模式下只支持half_pixel。 <br>- extrapolation_value属性不支持。</td></tr><tr><td>Where</td><td>CPU计算</td><td>--</td><td>type约束支持float和int64类型。 <br> condition的shape为cond_shape，X的shape为x_shape，Y的shape为y_shape ，output的shape为o_shape，shape约束如下： <br>- 仅支持cond_shape == o_shape情况下：   <br>- x_shape == o_shape的broadcast。   <br>- y_shape == o_shape的broadcast。 <br>- 仅支持cond_shape.NDim() == 4 &amp;&amp; o_shape.NDim() == 4 &amp;&amp; N维度值相同 &amp;&amp; C维度值相同：   <br>- 1x1（cond_shape）与HxW （o_shape）。   <br>- Hx1（cond_shape）与HxW（o_shape）。   <br>- 1xW（cond_shape）与HxW（o_shape）。</td></tr><tr><td>Xor</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Function</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Celu</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>DynamicQuantizeLinear</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>GreaterOrEqual</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。 <br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>MeanVarianceNormalization</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>GridSample（PyTorch）</td><td>CPU计算※</td><td>--</td><td></td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-x5支持的caffe算子列表">RDK X5支持的Caffe算子列表<a href="#rdk-x5支持的caffe算子列表" class="hash-link" aria-label="RDK X5支持的Caffe算子列表的直接链接" title="RDK X5支持的Caffe算子列表的直接链接">​</a></h2>
<table><thead><tr><th><strong>caffe算子名称</strong></th><th><strong>CPU计算/BPU加速</strong></th><th><strong>X5 BPU支持约束</strong></th><th><strong>CPU支持约束</strong></th></tr></thead><tbody><tr><td>Convolution</td><td>BPU加速</td><td>限制条件等同于 ONNX Conv</td><td>支持conv1d、conv2d、conv3d。<br>type约束支持：float，int32，int8。<br>auto_pad属性不支持。<br>pads属性约束：<br> - conv1d： [Dstart，Dend]，pads长度等于2，并且Dstart = Dend。<br> - conv2d：[Hstart，Wstart，Hend，Wend]，pads长度等于4 ，并且Hstart==Hend，Wstart==Wend。<br>- conv3d：[Dstart，Hstart，Wstart，Dend，Hend，Wend]，pads长度等于6 ，并且Dstart = Dend，Hstart==Hend，Wstart==Wend。</td></tr><tr><td>Deconvolution</td><td>BPU加速</td><td>限制条件等同于 ONNX ConvTranspose</td><td>shape约束：仅支持4维Tensor计算。 <br>type约束：仅支持float类型。 <br>attribute约束：<br>- 仅支持dilations、group、output_padding、 pads 、strides 属性。<br>- pads属性约束：[hstart, wstart, hend, wend]必须满足(hstart==hend and wstart==wend)。</td></tr><tr><td>MaxUnpool</td><td>CPU计算</td><td>---</td><td>from_type支持：  <br>- X：type约束：仅支持float类型。<br>- I：Tensor（int64）。<br>to_type支持：type约束：仅支持float类型。</td></tr><tr><td>Pooling</td><td>BPU加速</td><td>共有四种Pooling算子即MaxPooling，AveragePooling，GlobalMaxPooling，GlobalAveragePooling。对四种Pooling的约束分别为：<br>- MaxPooling：<br>该算子支持int16输入输出。<br>kernel <code>&lt;=</code> 256；<br>stride <code>&lt;=</code> 256；<br>padding <code>&lt;=</code> 256。<br>MaxPooling不支持dilation。<br>- AveragePooling：<br>限制条件等同于 ONNX AveragePool <br>- GlobalAveragePooling：<br>无限制。<br>- GlobalMaxPooling：<br>H, W ∈ [1, 256]。</td><td>无</td></tr><tr><td>SPP</td><td>CPU计算</td><td>不支持</td><td>支持pyramid_height，<code>2^n</code> 次pooling, n <code>&lt; 7</code>;<br>pooling kernel 小于等于 255； <br>支持pool，配置可选值为 <code>{0，1}</code></td></tr><tr><td>InnerProduct</td><td>BPU加速</td><td>InnerProduct将被转化为Conv实现，边界约束参考Conv。 <br>不支持配置axis属性。</td><td>无</td></tr><tr><td>LRN</td><td>CPU计算</td><td>不支持</td><td>local_size 支持。<br>alpha支持。<br>beta 支持。<br>norm_region 支持，配置可选值<code>{ACROSS_CHANNELS, WITHIN_CHANNEL }</code>。<br>k 支持。</td></tr><tr><td>MVN</td><td>CPU计算</td><td>不支持</td><td>normalize_variance支持，配置可选值为<!-- -->1<!-- -->。<br>across_channels支持，配置可选值为<!-- -->1<!-- -->。<br>仅支持Float32类型的计算。</td></tr><tr><td>BatchNorm</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>ELU</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>无</td></tr><tr><td>BNLL</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>PReLU</td><td>BPU计算</td><td>1. 该算子仅支持int8输入输出。<br> 2. 输入输出仅支持4维。</td><td>- type约束支持：仅支持float类型。<br>- from_type：X和slope。<br>- to_type：Y。<br>- X的shape为data_shape，slope的为slope_shape ，shape约束如下：<br>  - data_shape == slope_shape 。<br>  - slope_shape.ProdSize() == 1 。<br>  - X和slope仅支持NCHW排布的4维度计算，并且N、C维度值相等。 <br>    - HxW 与1x1（ slope_shape ）。 <br>    - HxW与Hx1（ slope_shape ）。 <br>    - HxW与1xW（ slope_shape ） 。<br>  - X是4维度 &amp;&amp; slope是3维度 &amp;&amp; data_shape[1] == slope_shape [0] &amp;&amp; slope_shape [1] == 1 &amp;&amp; slope_shape [2] == 1。</td></tr><tr><td>ReLU/LeakyRelu</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>无</td></tr><tr><td>Sigmoid</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>无</td></tr><tr><td>TanH</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>无</td></tr><tr><td>Eltwise</td><td>BPU加速</td><td>目前支持的operation包括Add、Sub、Mul。<br>1. 该算子支持int16输入输出。<br>2. 输入类型支持featurmap和常量，且最多支持一个常量输入。<br>3. 支持所有维度的广播，支持两个输入之间的互相广播，例如NH1C和N1WC。<br>4. 输入输出维度支持1-10维，大小为一般限制（见备注）。支持两个输入维度不同，输入大于4维时可通过合并相邻维度降维到4维（包括N），合并规则是：<br>(1)将输出dim为1的维度去除，例如[1, 2, 3, 4] [1, 2, 1, 4]-&gt;[1, 2, 3, 4]可看为[2, 3, 4],[2, 1, 4]-&gt;[2, 3,4]。<br>(2)相邻的非广播维度可以合并，如[2, 5, 4, 5, 3] [2, 5, 1, 5, 3], 2, 5可以合并。<br>(3)相邻的同一Tensor的广播维度可以合并: 如[2, 5, 4, 5, 2] [1, 1, 1, 5, 2] 2，5，4可以合并。<br>(4)广播维度不能和相邻非广播维度合并，如[2, 5, 4, 5, 2] [2, 1, 4, 1, 2]不能合并；非同一Tensor的广播维度不能合并 [2, 1, 4, 1, 2] [1, 5, 1, 5, 1]。</td><td>无</td></tr><tr><td>Bias</td><td>BPU加速</td><td>参考Eltwise等于Add的情况</td><td>无</td></tr><tr><td>Scale</td><td>BPU加速</td><td>参考Eltwise等于Mul的情况</td><td>无</td></tr><tr><td>AbsVal</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>无</td></tr><tr><td>Exp</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>无</td></tr><tr><td>Log</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>无</td></tr><tr><td>Power</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维<br>3. 第二个输入只支持标量。</td><td>无</td></tr><tr><td>Threshold</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Reduction</td><td>CPU计算</td><td>不支持</td><td>operation 支持 SUM、ASUM、 SUMSQ、MEAN、Max、LogSum、Min、Prod； <br>axis 支持； <br> 仅支持Float32类型的计算。</td></tr><tr><td>Softmax</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 默认运行在CPU上，当该op输入为四维并且axis=1,2,3时，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>无</td></tr><tr><td>ArgMax</td><td>BPU加速</td><td>1. 仅支持 axis=1，c<code>&lt;=</code>64。<br>2. 不支持配置top_k != 1。<br>3. 该算子支持int16输入输出。</td><td>无</td></tr><tr><td>Concat</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 不支持N维度concat。</td><td>无</td></tr><tr><td>Split</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 原始输入的长度必须是每个被切分的tensor长度的倍数。<br>3. 支持除N维度以外的任意维度。<br>4. split数应可以整除。<br>5. 支持非四维输入输出。</td><td>无</td></tr><tr><td>Slice</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 无限制，支持非四维输入输出。</td><td>无</td></tr><tr><td>Reshape</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 支持1-10维输入输出。</td><td>shape 支持<code>[1,4]</code>个 shape_dim 配置 ；<br> axis 支持<code>[-4,3]</code>范围内可配，不支 持 N 维度，默认值 0，遵循 caffe 规则 ；<br> num_axes 支持<code>[-1,3]</code>范围内可配，默认 值 -1 表示对 axis 起始的所有 轴进行变换</td></tr><tr><td>Flatten</td><td>CPU计算</td><td>不支持（一些场景下可以融合）</td><td>axis 取值范围<code>[-4,3]</code>，默认值 为 1，-4 与 0 含义相同。 <br>只支持End_axis == -1。</td></tr><tr><td>Crop</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Dropout</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>LSTM</td><td>BPU加速</td><td>仅支持batch=1</td><td>--</td></tr><tr><td>Normalize</td><td>CPU计算</td><td>不支持</td><td>type约束：仅支持float类型。</td></tr><tr><td>PassThrough</td><td>BPU加速</td><td>支持mode=DCR 和 mode=CRD。<br>仅支持H和W方向的重新排列，并且仅支持blocksize=2的重排列。<br>举例：NxCxHxW -&gt; Nx(4C)x(H/2)x(W/2)。</td><td>type约束：仅支持float类型。</td></tr><tr><td>CReLU</td><td>CPU计算</td><td>不支持</td><td>type约束：仅支持float类型。</td></tr><tr><td>RReLU</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Permute</td><td>BPU加速</td><td>1. 支持任意输入维度。<br>2. 除batch维度（第一维）以外，支持任意其它维度的转换。</td><td>- 支持nhwc2nchw，perm：[0, 3, 1, 2]。 <br> - 支持nchw2nhwc，perm：[0, 2, 3, 1]。<br> - 支持指定perm维度转换，数据类型仅支持float，int8，int32。</td></tr><tr><td>MatMul</td><td>BPU加速</td><td>C = MatMul(A，B)，对输入A和输入B有以下维度限制：<br>- A和B均支持非四维输入但需满足约束：<br>  - A和B的维度必须相同。<br>  - A和B的最低两个维度M, K ∈ [1, 8192]，其他更高维度∈[1, 4096]。    <br>  注：HDMK vs HDKN，MK/KN即为最低两个维度。<br>- 支持的broadcast需满足以下条件：<br>  - A 跟B两个输入，除开最低两维的其他维度全是1或者全是不需要广播的值。<br>    - 此场景支持的例子：HDMK vs H1KN<br>    - 此场景不支持反例：H1MK vs 1DKN<br>  - A除了最低两个维度，其他维度不能即有需要广播的值也有不需要广播的值。<br>    - 此场景支持的例子：11MK vs HDKN<br>    - 此场景不支持反例：H1MK vs HDKN<br>  - B除了最低两个维度，如果其他维度即有需要广播的值也有不需要广播的值，那么不需要广播的值只能在连续的高维度上。<br>    - 此场景支持的例子：BHDMK vs B11KN<br>    - 此场景不支持反例：BHDMK vs B1DKN  <br>  注：需要广播的值和不需要广播的值：<br>   <br>- 如果A和B在对应维度轴上的两个值，一个为1，另一个为非1，那么1就是需要广播的值，非1就是不需要广播的值；<br>    - 如果A和B在对应维度轴上的两个值相等，那么这两个值都是不需要广播的值（如HDMK vs H1KN，1是需要广播的值，H是不需要广播的值）。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Upsample</td><td>BPU加速</td><td>输入featuremap需为四维NCHW，并且只支持在H和W维度上进行resize； <br> 放大系数factor不能同时小于2。</td><td>无</td></tr><tr><td>ROIPooling</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>PSROIPooling</td><td>CPU计算</td><td>不支持</td><td>无</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-x5支持的onnx算子列表">RDK X5支持的ONNX算子列表<a href="#rdk-x5支持的onnx算子列表" class="hash-link" aria-label="RDK X5支持的ONNX算子列表的直接链接" title="RDK X5支持的ONNX算子列表的直接链接">​</a></h2>
<table><thead><tr><th><strong>ONNX算子名称</strong></th><th><strong>CPU计算/BPU加速</strong></th><th><strong>X5 BPU支持约束</strong></th><th><strong>CPU支持约束</strong></th></tr></thead><tbody><tr><td>Abs</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>Acos</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束支持float和double类型。</td></tr><tr><td>Acosh</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束支持float和double类型。</td></tr><tr><td>Add</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入类型支持featurmap和常量，且最多支持一个常量输入。<br>3. 支持所有维度的广播，支持两个输入之间的互相广播，例如NH1C和N1WC。<br>4. 输入输出维度支持1-10维，大小为一般限制（见备注）。支持两个输入维度不同，输入大于4维时可通过合并相邻维度降维到4维（包括N），合并规则是：<br>(1)将输出dim为1的维度去除，例如[1, 2, 3, 4] [1, 2, 1, 4]-&gt;[1, 2, 3, 4]可看为[2, 3, 4],[2, 1, 4]-&gt;[2, 3,4]。<br>(2)相邻的非广播维度可以合并，如[2, 5, 4, 5, 3] [2, 5, 1, 5, 3], 2, 5可以合并。<br>(3)相邻的同一Tensor的广播维度可以合并: 如[2, 5, 4, 5, 2] [1, 1, 1, 5, 2] 2，5，4可以合并。<br>(4)广播维度不能和相邻非广播维度合并：如[2, 5, 4, 5, 2] [2, 1, 4, 1, 2]不能合并；非同一Tensor的广播维度不能合并 [2, 1, 4, 1, 2] [1, 5, 1, 5, 1]。<br>5. 作为resnet中的short-cut子结构的Add，会被融合到上一个conv中加速计算。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>And</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>ArgMax</td><td>BPU加速</td><td>1. 输入维度为四维输入NCHW。<br>2. N ∈ [1, 4096]，H,W ∈ [1, 65536] ，C ∈ [1, 8191]。<br>3. 该算子支持int16输入输出。<br>4. 仅支持沿C维度进行argmax/argmin，即axis=1。</td><td>type约束：仅支持float类型。</td></tr><tr><td>ArgMin</td><td>BPU加速</td><td>1. 输入维度为四维输入NCHW。<br>2. N ∈ [1, 4096]，H,W ∈ [1, 65536] ，C ∈ [1, 8191]。<br>3. 该算子支持int16输入输出。<br>4. 仅支持沿C维度进行argmax/argmin，即axis=1。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Asin</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维。</td><td>type约束支持float和double类型。</td></tr><tr><td>Asinh</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维。</td><td>type约束支持float和double类型。</td></tr><tr><td>Atan</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维。</td><td>type约束支持float和double类型。</td></tr><tr><td>Atanh</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维。</td><td>type约束支持float和double类型。</td></tr><tr><td>AveragePool</td><td>BPU加速</td><td>kernel: H,W ∈ [1, 256] <br> H * W <code>&lt;=</code> 8192 ，H * W &gt; 1 <br>stride: H,W ∈ [1, 256]&lt; br/&gt;padding: H,W ∈ [0, 255]</td><td>输入和输出支持4维和5维。</td></tr><tr><td>BatchNormalization</td><td>BPU加速</td><td>无限制。</td><td>type约束：仅支持float类型。 <br>支持第1个维度是channel的数据排布方式计算。</td></tr><tr><td>BitShift</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Cast</td><td>CPU计算</td><td>--</td><td>from_type支持double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8。<br>to_type支持double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8。</td></tr><tr><td>Ceil</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束支持double类型和float类型。</td></tr><tr><td>Clip</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>opset6: <br>min, max作为属性值，dtype仅支持float类型;<br>opset11: <br>min, max作为输入，仅有两个输入时，第二个为min；dtype支持float, double类型。</td></tr><tr><td>Compress</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Concat</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 不支持N维度concat。</td><td>--</td></tr><tr><td>ConcatFromSequence</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Constant</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>目前不支持sparse_tensor属性。</td></tr><tr><td>ConstantOfShape</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>type约束支持：float,int32,int8。</td></tr><tr><td>Conv</td><td>BPU加速</td><td>支持四维输入（conv2d）和五维输入（conv3d）。<br>四维输入（conv2d）：<br>Kernel shape范围：N,C ∈ [1, 8192]; H,W ∈ [1, 31]。C * H * W &lt; = 32767。<br>输入输出Channel取值范围(one group) <code>&lt;=</code> 8192，如果Conv是量化子图的最后一个算子，取值范围<code>&lt;=</code> 65536。<br>stride取值范围：H,W ∈ [1, 256]，但对于Conv后接Add(resnet shortcut-connecting) Stride取值范围为：<!-- -->2<!-- -->，对dilated&gt;1的conv，stride只支持=1。<br>Dilation取值范围：H,W∈ [1, 16]，H或W大于1时，只支持输出int8，且输入Tensor的H必须能被dilation的H整除，输入Tensor的W必须能被dilation的W整除。<br>padding取值范围：H,W ∈ [0, 256]。<br>五维输入（conv3d）：<br>输入大小NCDHW：N ∈ [1, 128]; H,W,D,C ∈ [1, 65536]。<br>kernel大小NCDHW：N,C ∈ [1, 65536]; H,W ∈ [1, 31], D ∈ [1, 8191]。<br>padding大小DHW：H,W ∈ [0, 256], D ∈ [0, kernel_d/2]。<br>stride取值范围：H, W同为1或H, W同为2。<br>group，dilation暂不支持。<br>Size: 1G bytes；当D * C &gt; 4096时, H * alignCeil(W, 256) * D * C &lt; 1G。<br>weight的D * 输入的C <code>&lt;=</code> 8192。</td><td>支持conv1d、conv2d、conv3d。<br>type约束支持：float，int32，int8。<br>auto_pad属性不支持。<br>pads属性约束：<br>- conv1d： [Dstart，Dend]，pads长度等于2，并且Dstart = Dend。<br>- conv2d：[Hstart，Wstart，Hend，Wend]，pads长度等于4 ，并且Hstart==Hend，Wstart==Wend。<br>- conv3d：[Dstart，Hstart，Wstart，Dend，Hend，Wend]，pads长度等于6 ，并且Dstart = Dend，Hstart==Hend，Wstart==Wend。</td></tr><tr><td>ConvInteger</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>ConvTranspose</td><td>BPU加速</td><td>输入输出featuremap大小限制：<br>N ∈ [1, 128]。<br>H,W ∈ [1, 65536]。 <br>C ∈ [1, 2048] 。<br>Size: 1G bytes。<br>weight大小限制：<br>N,C ∈ [1, 2048]。 <br>H,W ∈ [1, 14]且HW不同时为1。<br>Size: <br>psh = padding.h % stride.h;<br>psw = padding.w % stride.w;<br>ksh = (kernel.h - 1 + psh) / stride.h +1<br>ksw = (kernel.w - 1 + psw) / stride.w + 1<br>group_num = fout.c / kernel.c<br>ksc = fin.c / group_num<br>kernel_size = ksh * ksw * ksc<br>kernel_size ∈ [1, 32767] <br>padding取值范围：<br>stride为奇数时，H,W ∈ [0, kernel / stride)。<br>stride为偶数，H,W ∈ [0, kernel / stride]。<br>out_pad取值范围：H,W ∈ <!-- -->1<!-- -->。<br>stride &gt;= 1 &amp;&amp; stride <code>&lt;=</code>14 但不支持stride_h和stride_w同时等于1。<br>Dilation ∈ <!-- -->1<!-- -->。</td><td>shape约束：仅支持4维Tensor计算。<br>type约束：仅支持float类型。<br>attribute约束：<br>- 仅支持dilations、group、output_padding、 pads 、strides 属性。<br>- pads属性约束：[hstart, wstart, hend, wend]必须满足(hstart==hend and wstart==wend)。</td></tr><tr><td>Cos</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束支持float类型。</td></tr><tr><td>Cosh</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束支持float类型。</td></tr><tr><td>CumSum</td><td>CPU计算</td><td>--</td><td>axis：type约束仅支持int32类型。</td></tr><tr><td>DepthToSpace</td><td>BPU加速</td><td>该算子支持int16输入输出。<br> 支持mode=DCR 和 mode=CRD。<br> 仅支持H和W方向的重新排列，并且仅支持blocksize=2的重排列。 <br>举例：NxCxHxW -&gt; Nx(C/4)x(2H)x(2W) 输出的channel必须是4的倍数。</td><td>from_type支持：<br>- type约束仅支持float类型。<br>- 仅支持4维度Tensor计算。<br>to_type支持：<br>- type约束仅支持float类型。<br>- 仅支持4维度Tensor计算。</td></tr><tr><td>DequantizeLinear</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Det</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Div</td><td>BPU加速</td><td>对input shape的约束请参考Mul算子。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>Dropout</td><td>BPU加速</td><td>该算子推理阶段不参加计算， 会被移除优化</td><td>--</td></tr><tr><td>Einsum</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Elu</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>Equal</td><td>BPU加速</td><td>1. 该算子支持int16输入。<br>2. 支持所有维度的广播，支持fin0或fin1其中一个输入的广播，不能支持互相广播。<br>3. 输入输出维度支持1-10维，大小为一般限制（见备注）。输入大于4维时可通过合并相邻维度降维到4维（包括N），合并规则是：<br>(1)将输出dim为1的维度去除，例如[1, 2, 3, 4] [1, 2, 1, 4]-&gt;[1, 2, 3, 4]可看为[2, 3, 4],[2, 1, 4]-&gt;[2, 3,4]。<br>(2)相邻的非广播维度可以合并，如[2, 5, 4, 5, 3] [2, 5, 1, 5, 3], 2, 5可以合并。<br>(3)相邻的同一Tensor的广播维度可以合并: 如[2, 5, 4, 5, 2] [1, 1, 1, 5, 2] 2，5，4可以合并。<br>(4)广播维度不能和相邻非广播维度合并：如[2, 5, 4, 5, 2] [2, 1, 4, 1, 2]不能合并。<br>4. 默认运行在CPU上，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>Erf</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：支持float数据类型。</td></tr><tr><td>Exp</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>Expand</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，输入与输出仅支持有一个维度上的数值不同。<br>3. 输入与输出仅允许有一个维度上数值不同。</td><td>--</td></tr><tr><td>EyeLike</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Flatten</td><td>BPU加速</td><td>限制条件等同于Reshape。</td><td>--</td></tr><tr><td>Floor</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>GRU</td><td>CPU计算</td><td>--</td><td>- direction属性仅支持forward类型。<br>- type约束：仅支持float类型。</td></tr><tr><td>Gather</td><td>BPU加速</td><td>1. input/output/indices 的rank都要小于等于4。<br>2. indices支持：<br>    - indices是feature（其他op输出）时，type约束仅支持int32类型。<br>    - indices是weight（模型保存的常量）时，type约束支持int32和int64类型。</td><td>from_type支持：<br>- input：type约束支持：<br>float,int64,int32,int8,uint64,uint32,uint8。<br>- indices：type约束支持int32, int64。 <br>to_type支持：type约束支持：<br>float,int64,int32,int8,uint64,uint32,uint8。</td></tr><tr><td>GatherElements</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. input/indices/output维度支持1-10维。<br>3. 当输入维度 i != axis时，要求indices.shape[i] <code>&lt;=</code> input.shape[i]。</td><td>--</td></tr><tr><td>GatherND</td><td>CPU计算</td><td>--</td><td>from_type支持：<br>- input：type约束支持float,int32,int8。<br>- indices：tensor(int64)。<br>to_type支持：type约束支持float,int32,int8。</td></tr><tr><td>Gemm</td><td>BPU加速</td><td>Gemm将被转化为Conv实现，边界约束参考Conv。</td><td>type约束：仅支持float类型。</td></tr><tr><td>GlobalAveragePool</td><td>BPU加速</td><td>无限制。</td><td>- type约束：仅支持float类型。<br>- 仅支持四维Tensor。</td></tr><tr><td>GlobalLpPool</td><td>CPU计算</td><td>--</td><td>- type约束：支持float和double类型。<br> - 仅支持四维Tensor计算。</td></tr><tr><td>GlobalMaxPool</td><td>BPU加速</td><td>H, W ∈ [1, 256]。</td><td>- type约束仅支持float类型。<br>- 仅支持四维Tensor。</td></tr><tr><td>Greater</td><td>BPU加速</td><td>1. 该算子支持int16输入。<br>2. 支持所有维度的广播，支持fin0或fin1其中一个输入的广播，不能支持互相广播。<br>3. 输入输出维度支持1-10维，大小为一般限制（见备注）。输入大于4维时可通过合并相邻维度降维到4维（包括N），合并规则是：<br>(1)将输出dim为1的维度去除，例如[1, 2, 3, 4] [1, 2, 1, 4]-&gt;[1, 2, 3, 4]可看为[2, 3, 4],[2, 1, 4]-&gt;[2, 3,4]。<br>(2)相邻的非广播维度可以合并，如[2, 5, 4, 5, 3] [2, 5, 1, 5, 3], 2, 5可以合并。<br>(3)相邻的同一Tensor的广播维度可以合并：如[2, 5, 4, 5, 2] [1, 1, 1, 5, 2] 2，5，4可以合并。<br>(4)广播维度不能和相邻非广播维度合并：如[2, 5, 4, 5, 2] [2, 1, 4, 1, 2]不能合并。<br>4. 默认运行在CPU上，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>HardSigmoid</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束仅支持float类型。</td></tr><tr><td>Hardmax</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Identity</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>If</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>InstanceNormalization</td><td>CPU计算</td><td>--</td><td>- type约束仅支持float类型。<br>- 支持第1个维度是channel的数据排布方式计算。</td></tr><tr><td>IsInf</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>IsNaN</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>LRN</td><td>CPU计算</td><td>--</td><td>- type约束仅支持float类型。<br>- 仅支持四维Tensor。</td></tr><tr><td>LSTM</td><td>BPU加速</td><td>仅支持batch_size=1，如果需要配置多batch，需要在导出onnx时保证LSTM的batch为1并在yaml中配置参数input_batch=1。</td><td>- type约束仅支持float类型。<br>- 属性约束：direction属性仅支持forward。<br>- 输入约束：<br>   - 支持X、W、R输入配置；<br>   - 支持X、W、R、B输入配置（sequence_lens为空或默认值）；<br>   -  支持X、W、R、B、sequence_lens、initial_h、initial_c、P输入配置（sequence_lens为空或者默认值）。</td></tr><tr><td>LeakyRelu</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>Less</td><td>BPU加速</td><td>1. 该算子支持int16输入。<br>2. 支持所有维度的广播，支持fin0或fin1其中一个输入的广播，不能支持互相广播。<br>3. 输入输出维度支持1-10维，大小为一般限制（见备注）。输入大于4维时可通过合并相邻维度降维到4维（包括N），合并规则是：<br>(1)将输出dim为1的维度去除，例如[1, 2, 3, 4] [1, 2, 1, 4]-&gt;[1, 2, 3, 4]可看为[2, 3, 4],[2, 1, 4]-&gt;[2, 3,4]。<br>(2)相邻的非广播维度可以合并，如[2, 5, 4, 5, 3] [2, 5, 1, 5, 3], 2, 5可以合并。<br>(3)相邻的同一Tensor的广播维度可以合并：如[2, 5, 4, 5, 2] [1, 1, 1, 5, 2] 2，5，4可以合并。<br>(4)广播维度不能和相邻非广播维度合并：如[2, 5, 4, 5, 2] [2, 1, 4, 1, 2]不能合并。<br>4. 默认运行在CPU上，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>LessOrEqual</td><td>BPU加速</td><td>opset11 不支持单个LessOrEqual算子，支持拆分后的算子Greater+Not运行在BPU上，限制条件与Greater相同。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>Log</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>LogSoftmax</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Loop</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>LpNormalization</td><td>CPU计算</td><td>--</td><td>- p范数仅支持1或者2。<br>- type约束支持float类型。</td></tr><tr><td>LpPool</td><td>CPU计算</td><td>--</td><td>- auto_pad属性不支持。<br>- type约束支持float类型。<br>- 仅支持4维计算。</td></tr><tr><td>MatMulInteger</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>MatMul</td><td>BPU加速</td><td>C = MatMul(A，B)，对输入A和输入B有以下维度限制：<br>- A和B均支持非四维输入但需满足约束：<br>  - A和B的维度必须相同。<br>  - A和B的最低两个维度M, K∈[1, 8192]，其他更高维度∈[1, 4096]。    <br>  注：HDMK vs HDKN，MK/KN即为最低两个维度。<br>- 支持的broadcast需满足以下条件：<br>  - A跟B两个输入，除开最低两维的其他维度全是1或者全是不需要广播的值。<br>    - 此场景支持的例子：HDMK vs H1KN<br>    - 此场景不支持反例：H1MK vs 1DKN<br>  - A除了最低两个维度，其他维度不能即有需要广播的值也有不需要广播的值。<br>    - 此场景支持的例子：11MK vs HDKN<br>    - 此场景不支持反例：H1MK vs HDKN<br>  - B除了最低两个维度，如果其他维度即有需要广播的值也有不需要广播的值，那么不需要广播的值只能在连续的高维度上。<br>    - 此场景支持的例子：BHDMK vs B11KN<br>    - 此场景不支持反例：BHDMK vs B1DKN  <br>  注：需要广播的值和不需要广播的值：<br>    - 如果A和B在对应维度轴上的两个值，一个为1，另一个为非1，那么1就是需要广播的值，非1就是不需要广播的值；<br>    - 如果A和B在对应维度轴上的两个值相等，那么这两个值都是不需要广播的值（如HDMK vs H1KN，1是需要广播的值，H是不需要广播的值）</td><td>type约束：仅支持float类型。</td></tr><tr><td>Max</td><td>BPU加速</td><td>1.该算子支持int16输入输出。<br>2.支持所有维度的广播，支持两个输入之间的互相广播，例如NH1C和N1WC。<br>3.输入输出维度支持1-10维，大小为一般限制（见备注）。支持两个输入维度不同，输入大于4维时可通过合并相邻维度降维到4维（包括N），合并规则是：<br>(1)将输出dim为1的维度去除，例如[1, 2, 3, 4] [1, 2, 1, 4]-&gt;[1, 2, 3, 4]可看为[2, 3, 4],[2, 1, 4]-&gt;[2, 3,4]。<br>(2)相邻的非广播维度可以合并，如[2, 5, 4, 5, 3] [2, 5, 1, 5, 3], 2, 5可以合并。<br>(3)相邻的同一Tensor的广播维度可以合并：如[2, 5, 4, 5, 2] [1, 1, 1, 5, 2] 2，5，4可以合并。<br>(4)广播维度不能和相邻非广播维度合并：如[2, 5, 4, 5, 2] [2, 1, 4, 1, 2]不能合并；非同一Tensor的广播维度不能合并 [2, 1, 4, 1, 2] [1, 5, 1, 5, 1]。</td><td>- 支持1-∞个输入。<br>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>MaxPool</td><td>BPU加速</td><td>该算子支持int16输入输出。<br>kernel <code>&lt;=</code> 256。<br>stride <code>&lt;=</code> 256。<br>padding <code>&lt;=</code> 256。<br>MaxPool不支持dilation。</td><td>1. dilation只支持1x1。<br>2. 只支持数据行优先存储。<br>3. auto_pad属性不支持。<br>4. storage_order属性不支持。<br>5. 输入和输出支持4维和5维。</td></tr><tr><td>MaxRoiPool</td><td>CPU计算</td><td>--</td><td>无</td></tr><tr><td>Mean</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Min</td><td>BPU加速</td><td>1.该算子支持int16输入输出。<br>2.支持所有维度的广播，支持两个输入之间的互相广播，例如NH1C和N1WC。<br>3.输入输出维度支持1-10维，大小为一般限制（见备注）。支持两个输入维度不同，输入大于4维时可通过合并相邻维度降维到4维（包括N），合并规则是：<br>(1)将输出dim为1的维度去除，例如[1, 2, 3, 4] [1, 2, 1, 4]-&gt;[1, 2, 3, 4]可看为[2, 3, 4],[2, 1, 4]-&gt;[2, 3,4]。<br>(2)相邻的非广播维度可以合并，如[2, 5, 4, 5, 3] [2, 5, 1, 5, 3], 2, 5可以合并。<br>(3)相邻的同一Tensor的广播维度可以合并：如[2, 5, 4, 5, 2] [1, 1, 1, 5, 2] 2，5，4可以合并。<br>(4)广播维度不能和相邻非广播维度合并：如[2, 5, 4, 5, 2] [2, 1, 4, 1, 2]不能合并；非同一Tensor的广播维度不能合并 [2, 1, 4, 1, 2] [1, 5, 1, 5, 1]。<br>4. 默认运行在CPU上，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>- 支持1-∞个输入。<br>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>Mod</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Mul</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2.输入类型支持featurmap和常量，且最多支持一个常量输入。<br>3. 支持所有维度的广播，支持两个输入之间的互相广播，例如NH1C和N1WC。<br>4. 输入输出维度支持1-10维，大小为一般限制（见备注）。支持两个输入维度不同，输入大于4维时可通过合并相邻维度降维到4维（包括N），合并规则是：<br>(1)将输出dim为1的维度去除，例如[1, 2, 3, 4] [1, 2, 1, 4]-&gt;[1, 2, 3, 4]可看为[2, 3, 4],[2, 1, 4]-&gt;[2, 3,4]。<br>(2)相邻的非广播维度可以合并，如[2, 5, 4, 5, 3] [2, 5, 1, 5, 3], 2, 5可以合并。<br>(3)相邻的同一Tensor的广播维度可以合并: 如[2, 5, 4, 5, 2] [1, 1, 1, 5, 2] 2，5，4可以合并。<br>(4)广播维度不能和相邻非广播维度合并：如[2, 5, 4, 5, 2] [2, 1, 4, 1, 2]不能合并；非同一Tensor的广播维度不能合并 [2, 1, 4, 1, 2] [1, 5, 1, 5, 1]。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>Multinomial</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Neg</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Not</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>OneHot</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Or</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>PRelu</td><td>BPU加速</td><td>1. 该算子仅支持int8输入输出。<br>2. 输入输出仅支持4维。</td><td>- type约束支持：仅支持float类型。<br>- from_type：X和slope。<br>- to_type：Y。<br>- X的shape为data_shape，slope的为slope_shape ，shape约束如下：  <br>- data_shape == slope_shape。   <br>- slope_shape.ProdSize() == 1。   <br>- X和slope仅支持NCHW排布的4维度计算，并且N、C维度值相等。     <br>- HxW 与1x1（ slope_shape ）。     <br>- HxW与Hx1（ slope_shape ）。     <br>- HxW与1xW（ slope_shape ）。 <br>- X是4维度 &amp;&amp; slope是3维度 &amp;&amp; data_shape[1] == slope_shape [0] &amp;&amp; slope_shape [1] == 1 &amp;&amp; slope_shape [2] == 1。</td></tr><tr><td>Pad</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 支持mode = Constant。<br>3. 支持所有维度的Pad。</td><td>Pad-10：<br>- type约束仅支持float类型。<br>- 仅支持NCHW排布的4维Tensor。<br>- 属性pads的约束如下：  <br>- len(pads) == 8 &amp;&amp; pads[i] &gt;=0 &amp;&amp; pads[0] == 0 &amp;&amp; pads[1] == 0 &amp;&amp; pads[4] == 0 &amp;&amp; pads[5] == 0。 <br>Pad-11：<br>- from_type支持：  <br>- data：type约束仅支持float类型。  <br>- pads : tensor(int64)。  <br>- constant_value (optional)：type约束仅支持float类型。<br>- to_type支持：type约束仅支持float类型。<br>- 输入和输出支持4维，仅支持2/3维度填充。<br>- 输入和输出支持5维，仅支持2/3/4维度填充。</td></tr><tr><td>Pow</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维 <br>3. 第二个输入只支持标量。</td><td>- type约束支持：double, float，int64, int32。<br>- 支持相同输入shape的计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。<br>- 仅支持X和Y相同type。</td></tr><tr><td>QLinearConv</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>QLinearMatMul</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>QuantizeLinear</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>RNN</td><td>CPU计算</td><td>--</td><td>- type约束：仅支持float类型。<br>- 属性约束：direction属性仅支持forward。<br>- 输入约束：仅支持X、W、R输入，不支持可选输入B、sequence_lens、initial_h设置。 <br>- 输出约束：仅支持Y_h的输出，shape [num_directions, batch_size, hidden_size]。</td></tr><tr><td>RandomNormal</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>RandomNormalLike</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>RandomUniform</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>RandomUniformLike</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Range</td><td>CPU计算</td><td>--</td><td>type约束支持：float,int64,int32,int16。</td></tr><tr><td>Reciprocal</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>--</td></tr><tr><td>ReduceL1</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceL2</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceLogSum</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceLogSumExp</td><td>CPU计算</td><td>--</td><td>type约束支持float、double数据类型。</td></tr><tr><td>ReduceMax</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入支持2-5维，需要指定axes属性，指定的axes数量为1，不支持沿大于1个维度进行reduce操作。<br>3. reduce维度对应的轴的size ∈ [1, 8192]。<br>4. 仅支持keepdims == 1。</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>ReduceMean</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入支持2-5维，需要指定axes属性，指定的axes数量为1，不支持沿大于1个维度进行reduce操作。<br>3. 当reduce维度=2时，支持同时沿HW维度进行reduce。<br>4. 仅支持keepdims == 1。</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>ReduceMin</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceProd</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceSum</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入支持2-5维，需要指定axes属性，指定的axes数量为1，不支持沿大于1个维度进行reduce操作。</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>ReduceSumSquare</td><td>CPU计算</td><td>--</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>Relu</td><td>BPU加速</td><td>无限制</td><td>type约束：仅支持float类型。</td></tr><tr><td>Reshape</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 支持1-10维输入输出。</td><td>--</td></tr><tr><td>Resize</td><td>BPU加速</td><td>1. 输入featuremap需为四维NCHW，并且只支持在H和W维度上进 行resize，onnx opset=11时支持roi输入（pytorch转换的模型需手动修改算子添加roi输入，roi只支持常量输入），roi输入只支持H和W维度，roi输入只在tf_crop_and_resize模式下起作用。<br>2. 属性mode支持nearest和linear两种模式。<br>3. 支持放大和缩小。<br>4. 对于mode=nearest，放大系数factor支持2的幂数倍如2，4，8，16，32等；支持H维度和W维度的放大系数不同但需要满足H_factor <code>&lt;=</code> W_factor。<br>5. 对于onnx opset=11，属性coordinate_transformation_mode支持half_pixel，pytorch_half_pixel, asymmetric，align_corners和tf_crop_and_resize，当coordinate_transformation_mode=tf_crop_and_resize时，需要保证roi输入转换得到的边界坐标为整数。</td><td>resize-10 <br>- 输入等于2时，使用opset10。<br>- 输入数据是4维Tensor。 <br>resize-11  <br>- 输入大于2时，使用opset11。<br>- 输入数据是4维Tensor。<br>- coordinate_transformation_mode在nearest, linear模式下支持half_pixel, asymmetric, align_corners和pytorch_half_pixel四种，在cubic模式下只支持half_pixel。<br>- extrapolation_value属性不支持。</td></tr><tr><td>ReverseSequence</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>RoiAlign</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Round</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维。</td><td>--</td></tr><tr><td>Scan</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Scatter (deprecated)</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>ScatterElements</td><td>CPU计算</td><td>--</td><td>from_type支持：<br>- data：type约束支持：float,int32,int8。<br>- indices：type约束仅支持int32类型。<br>- updates：type约束支持：float,int32,int8。<br>to_type支持：type约束支持：float,int32,int8。</td></tr><tr><td>ScatterND</td><td>CPU计算</td><td>--</td><td>from_type支持：<br>- data：type约束支持：float,int32,int8。<br>- updates : type约束支持：float,int32,int8。<br>to_type支持：type约束支持：float,int32,int8。</td></tr><tr><td>Selu</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维。</td><td>type约束：仅支持float类型。</td></tr><tr><td>SequenceAt</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceConstruct</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceEmpty</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceErase</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceInsert</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceLength</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Shape</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>--</td></tr><tr><td>Shrink</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Sigmoid</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>Sign</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>Sin</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束支持float和double类型。</td></tr><tr><td>Sinh</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束支持float类型。</td></tr><tr><td>Size</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>--</td></tr><tr><td>Slice</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 无限制，支持非四维输入输出。</td><td>无</td></tr><tr><td>Softmax</td><td>BPU加速</td><td>- 该算子支持int16输入输出。<br>- 默认运行在CPU上，由于onnx::softmax和pytorch::softmax计算存在区别，分以下两种情况：<br>1. 对于onnx::softmax，当该op输入为四维并且axis=3时，可以通过run_on_bpu指定该节点将其运行在BPU上。<br>2. 对于pytorch::softmax, 当该op输入为四维并且axis=1,2,3时，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Softplus</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>Softsign</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>SpaceToDepth</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 支持mode=DCR 和 mode=CRD。<br> 仅支持H和W方向的重新排列，并且仅支持blocksize=2的重排列。 <br>举例：NxCxHxW -&gt; Nx(4C)x(H/2)x(W/2)</td><td>type约束：仅支持float类型。</td></tr><tr><td>Split</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 原始输入的长度必须是每个被切分的tensor长度的倍数。<br>3. 支持除N维度以外的任意维度。<br>4. split数应可以整除。<br>5. 支持非四维输入输出。</td><td>type约束：仅支持float类型。</td></tr><tr><td>SplitToSequence</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Sqrt</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>Squeeze</td><td>BPU加速</td><td>该op会被转换成Reshape，BPU约束详见Reshape op。</td><td>--</td></tr><tr><td>StringNormalizer</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Sub</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入类型支持featurmap和常量，且最多支持一个常量输入。<br>3. 支持所有维度的广播，支持两个输入之间的互相广播，例如NH1C和N1WC。<br>4. 输入输出维度支持1-10维，大小为一般限制（见 备注）。支持两个输入维度不同，输入大于4维时可通过合并相邻维度降维到4维（包括N），合并规则是：<br>(1)将输出dim为1的维度去除，例如[1, 2, 3, 4] [1, 2, 1, 4]-&gt;[1, 2, 3, 4]可看为[2, 3, 4],[2, 1, 4]-&gt;[2, 3,4]。<br>(2)相邻的非广播维度可以合并，如[2, 5, 4, 5, 3] [2, 5, 1, 5, 3], 2, 5可以合并。<br>(3)相邻的同一Tensor的广播维度可以合并: 如[2, 5, 4, 5, 2] [1, 1, 1, 5, 2] 2，5，4可以合并。<br>(4)广播维度不能和相邻非广播维度合并：如[2, 5, 4, 5, 2] [2, 1, 4, 1, 2]不能合并；非同一Tensor的广播维度不能合并 [2, 1, 4, 1, 2] [1, 5, 1, 5, 1]。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是8。</td></tr><tr><td>Sum</td><td>BPU加速</td><td>限制条件等同于Add</td><td>type约束：仅支持float类型。</td></tr><tr><td>Tan</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：支持float类型。</td></tr><tr><td>Tanh</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维</td><td>type约束：仅支持float类型。</td></tr><tr><td>TfIdfVectorizer</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>ThresholdedRelu</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Tile</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入与输出仅允许有一个维度上数值不同。</td><td>type约束：仅支持float,int64,int32,uint64,uint32类型。</td></tr><tr><td>TopK</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. input/indices/output维度支持1-10维。<br>3. indices type约束支持int16/int32/int64。<br>4. 参数sorted只支持true。</td><td>- type约束：仅支持float类型。</td></tr><tr><td>Transpose</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 支持任意输入维度。</td><td>- 支持nhwc2nchw，perm：[0, 3, 1, 2]。<br>- 支持nchw2nhwc，perm：[0, 2, 3, 1]。<br>- 支持指定perm维度转换，数据类型仅支持float，int8，int32。</td></tr><tr><td>Unique</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Unsqueeze</td><td>BPU加速</td><td>该op会被转换成Reshape，BPU约束详见Reshape op。</td><td>--</td></tr><tr><td>Upsample (resize替代)</td><td>BPU加速</td><td>--</td><td>Upsample-(resize-10) <br>- 输入等于2时，使用opset10。<br>- 输入数据是4维Tensor。 <br>Upsample-(resize-11)  <br>- 输入大于2时，使用opset11。<br>- 输入数据是4维Tensor。<br>- coordinate_transformation_mode在nearest, linear模式下支持half_pixel, asymmetric, align_corners和pytorch_half_pixel四种，在cubic模式下只支持half_pixel。<br>- extrapolation_value属性不支持。</td></tr><tr><td>Where</td><td>CPU计算</td><td>--</td><td>type约束支持float和int64类型。<br> condition的shape为cond_shape，X的shape为x_shape，Y的shape为y_shape ，output的shape为o_shape，shape约束如下：<br>- 仅支持cond_shape == o_shape情况下：  <br>- x_shape == o_shape的broadcast。  <br>- y_shape == o_shape的broadcast。<br>- 仅支持cond_shape.NDim() == 4 &amp;&amp; o_shape.NDim() == 4 &amp;&amp; N维度值相同 &amp;&amp; C维度值相同：  <br>- 1x1（cond_shape）与HxW （o_shape）。  <br>- Hx1（cond_shape）与HxW（o_shape）。  <br>- 1xW（cond_shape）与HxW（o_shape）。</td></tr><tr><td>Xor</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Function</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Celu</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>DynamicQuantizeLinear</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>GreaterOrEqual</td><td>BPU加速</td><td>opset11 不支持单个GreaterOrEqual算子，支持拆分后的算子Less+Not运行在BPU上，限制条件与Less相同。</td><td>- 支持相同输入shape计  算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>MeanVarianceNormalization</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>GridSample（PyTorch）</td><td>BPU加速</td><td>1. 输入维度仅支持四维，第一个输入需满足N ∈ [1, 4096]； C ∈ [1, 65536]； H,W ∈ [1, 1024] 且 H * W <code>&lt;=</code> 512 * 512。<br>2. mode只支持&#x27;bilinear&#x27;、&#x27;nearest&#x27;。<br>3. padding_mode只支持&#x27;zeros&#x27;、&#x27;border&#x27;。<br>4. 该算子为opset16的onnx算子，为在opset11支持，工具链以自定义算子的方式提供导出，导出包含该算子的onnx模型请使用horizon_nn.torch.export_onnx接口替换torch.onnx.export，接口传参相同，示例代码如下：<br>from horizon_nn.torch import export_onnx<br>    ...    <br>    export_onnx(...)</td><td></td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-ultra支持的caffe算子列表">RDK Ultra支持的Caffe算子列表<a href="#rdk-ultra支持的caffe算子列表" class="hash-link" aria-label="RDK Ultra支持的Caffe算子列表的直接链接" title="RDK Ultra支持的Caffe算子列表的直接链接">​</a></h2>
<table><thead><tr><th><strong>caffe算子名称</strong></th><th><strong>CPU计算/BPU加速</strong></th><th><strong>RDK Ultra BPU支持约束</strong></th><th><strong>CPU支持约束</strong></th></tr></thead><tbody><tr><td>Convolution</td><td>BPU加速</td><td><code>Kernel宽高限制：&lt;=32</code>。 <br> 输入输出Channel取值范围<code>(one group) &lt;= 8192</code>，如果Conv是量化子图的最后一个算子，取值范围<code>&lt;= 65536</code>。 <br> stride无限制，但对于Conv后接Add(resnet shortcut-connecting) Stride取值范围为：<!-- -->2<!-- -->。 <br> Dilation取值限制：<code>&lt;=16</code>。<br>当dilation != 1时，stride只支持为1。 <br> 不支持配置axis，默认为1。</td><td>仅支持4维Conv计算。<br>auto_pad 属性不支持。<br>type约束支持：float,int32,int8。<br>pads属性约束：[Hstart, Wstart, Hend, Wend]（pads长度等于4）并且Hstart==Hend，Wstart==Wend。</td></tr><tr><td>Deconvolution</td><td>BPU加速</td><td>kernel &gt;= stride。 <br>输入输出<code>featuremap大小 &lt;= 2048</code>。 <br> <code>pad &lt;= kernel / stride</code>。<br> <code>out_pad &lt; 2</code> 。<br><code>stride &gt;= 1 &amp;&amp; stride &lt;=14</code> 但不支持stride_h和stride_w同时等于1。 <br>不支持配置axis属性。</td><td>shape约束：仅支持4维Tensor计算。 <br>type约束：仅支持float类型。 <br>attribute约束：<br>- 仅支持dilations、group、output_padding、 pads 、strides 属性。<br>- pads属性约束：[hstart, wstart, hend, wend]必须满足(hstart==hend and wstart==wend)。</td></tr><tr><td>MaxUnpool</td><td>CPU计算</td><td>---</td><td>from_type支持：  <br>- X：type约束：仅支持float类型。 <br>- I：Tensor（int64）。 <br>to_type支持：type约束：仅支持float类型。</td></tr><tr><td>Pooling</td><td>BPU加速</td><td>共有四种Pooling算子即MaxPooling，AveragePooling，GlobalMaxPooling，GlobalAveragePooling。<br>对四种Pooling的约束分别为：  <br>MaxPooling：<br> 该算子支持int16输入输出。<br><code>kernel &lt;= 256；stride &lt;= 256；padding &lt;= 256</code>。 <br> MaxPooling不支持dilation。<br>AveragePooling：<br> <code>kernel &lt;= 256; stride &lt;= 256；padding &lt;= 256</code>。 <br>GlobalAveragePooling： <br>无限制。<br>GlobalMaxPooling： <br>H, W ∈ [1, 256]。</td><td>无</td></tr><tr><td>SPP</td><td>CPU计算</td><td>不支持</td><td>支持pyramid_height，2^n 次pooling, <code>n&lt;7</code>;<br>pooling kernel 小于等于 255； <br>支持pool，配置可选值为<code>{0，1}</code></td></tr><tr><td>InnerProduct</td><td>BPU加速</td><td>InnerProduct将被转化为Conv实现，边界约束参考Conv。 <br>假不支持配置axis属性。</td><td>无</td></tr><tr><td>LRN</td><td>CPU计算</td><td>不支持</td><td>local_size 支持。<br>alpha支持。<br>beta 支持。<br>norm_region 支持，配置可选值<code>{ACROSS_CHANNELS, WITHIN_CHANNEL }</code>。<br>k 支持。</td></tr><tr><td>MVN</td><td>CPU计算</td><td>不支持</td><td>normalize_variance支持，配置可选值为<!-- -->1<!-- -->。<br>across_channels支持，配置可选值为<!-- -->1<!-- -->。<br>仅支持Float32类型的计算。</td></tr><tr><td>BatchNorm</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>ELU</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>无</td></tr><tr><td>BNLL</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>PReLU</td><td>CPU计算</td><td>不支持</td><td>- type约束支持：仅支持float类型。<br>- from_type：X和slope。<br>- to_type：Y。<br>- X的shape为data_shape，slope的为slope_shape ，shape约束如下：<br>  - data_shape == slope_shape 。<br>  - slope_shape.ProdSize() == 1 。<br>  - X和slope仅支持NCHW排布的4维度计算，并且N、C维度值相等。 <br>    - HxW 与1x1（ slope_shape ）。 <br>    - HxW与Hx1（ slope_shape ）。 <br>    - HxW与1xW（ slope_shape ） 。<br>  - X是4维度 &amp;&amp; slope是3维度 &amp;&amp; data_shape[1] == slope_shape [0] &amp;&amp; slope_shape [1] == 1 &amp;&amp; slope_shape [2] == 1。</td></tr><tr><td>ReLU/LeakyRelu</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>无</td></tr><tr><td>Sigmoid</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>无</td></tr><tr><td>TanH</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>无</td></tr><tr><td>Eltwise</td><td>BPU加速</td><td>目前支持的operation包括Add、Sub、Mul。<br>1. 该算子支持int16输入输出。<br>2. 输入类型支持featurmap和常量，且最多支持一个常量输入；<br>3. 支持除第一维外的广播，支持两个输入之间的互相广播，例如NH1C和N1WC；<br>4. 输入输出维度支持2维、3维、4维和5维，大小为一般限制（见备注）。支持两个输入维度不同，输入为5维时需要满足以下限制：<br>(1)首先可以通过合并相邻维度降维到4维，例如NHWD1和N1WDC可以合并W维和D维来降维；<br>(2)其次广播的维度不能和相邻维度合并，例如NHWD1和N11DC因为H维、W维和C维都是广播的维度，无法通过合并相邻维度降维，所以无法支持。</td><td>无</td></tr><tr><td>Bias</td><td>BPU加速</td><td>参考Eltwise等于Add的情况</td><td>无</td></tr><tr><td>Scale</td><td>BPU加速</td><td>参考Eltwise等于Mul的情况</td><td>无</td></tr><tr><td>AbsVal</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>无</td></tr><tr><td>Exp</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>无</td></tr><tr><td>Log</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>无</td></tr><tr><td>Power</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。<br>3. 第二个输入只支持标量。</td><td>无</td></tr><tr><td>Threshold</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Reduction</td><td>CPU计算</td><td>不支持</td><td>operation 支持 SUM、ASUM、 SUMSQ、MEAN、Max、LogSum、Min、Prod； <br>axis 支持； <br> 仅支持Float32类型的计算。</td></tr><tr><td>Softmax</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 默认运行在CPU上，当该op输入为四维并且axis=1,2,3时，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>无</td></tr><tr><td>ArgMax</td><td>BPU加速</td><td>1. 仅支持 axis=1，<code>c&lt;=64</code>。<br>2. 不支持配置top_k != 1。<br>3. 该算子支持int16输入输出。</td><td>无</td></tr><tr><td>Concat</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 不支持N维度concat。</td><td>无</td></tr><tr><td>Split</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 原始输入的长度必须是每个被切分的tensor长度的倍数。<br>3. 支持除N维度以外的任意维度。<br>4. split数应可以整除。<br>5. 支持非四维输入输出。</td><td>无</td></tr><tr><td>Slice</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 无限制，支持非四维输入输出。</td><td>无</td></tr><tr><td>Reshape</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 支持1-10维输入输出。</td><td>shape 支持[1,4]个 shape_dim 配置 ；<br> axis 支持[-4,3]范围内可配，不支 持 N 维度，默认值 0，遵循 caffe 规则 ；<br> num_axes 支持[-1,3]范围内可配，默认 值-1 表示对 axis 起始的所有 轴进行变换</td></tr><tr><td>Flatten</td><td>CPU计算</td><td>不支持（一些场景下可以融合）</td><td>axis 取值范围[-4,3]，默认值 为 1，-4 与 0 含义相同。 <br>只支持End_axis == -1。</td></tr><tr><td>Crop</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Dropout</td><td>BPU加速</td><td>无限制</td><td>无</td></tr><tr><td>LSTM</td><td>BPU加速</td><td>仅支持batch=1</td><td>--</td></tr><tr><td>Normalize</td><td>CPU计算</td><td>不支持</td><td>type约束：仅支持float类型。</td></tr><tr><td>PassThrough</td><td>BPU加速</td><td>支持mode=DCR 和 mode=CRD。<br>仅支持H和W方向的重新排列，并且仅支持blocksize=2的重排列。<br>举例：NxCxHxW -&gt; Nx(4C)x(H/2)x(W/2)。</td><td>type约束：仅支持float类型。</td></tr><tr><td>CReLU</td><td>CPU计算</td><td>不支持</td><td>type约束：仅支持float类型。</td></tr><tr><td>RReLU</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>Permute</td><td>BPU加速</td><td>1. 支持任意输入维度。<br>2. 除batch维度（第一维）以外，支持任意其它维度的转换。</td><td>- 支持nhwc2nchw，perm：[0, 3, 1, 2]。 <br> - 支持nchw2nhwc，perm：[0, 2, 3, 1]。<br> - 支持指定perm维度转换，数据类型仅支持float，int8，int32。</td></tr><tr><td>MatMul</td><td>BPU加速</td><td>C = MatMul(A，B)，对输入A和输入B有以下维度限制：<br>- A和B均支持非四维输入但需满足约束：<br>  - A和B的维度必须相同。<br>  - A和B的最低两个维度M, K ∈ [1, 8192]，其他更高维度∈[1, 4096]。    <br>  注：HDMK vs HDKN，MK/KN即为最低两个维度。<br>- 支持的broadcast需满足以下条件：<br>  - A 跟B两个输入，除开最低两维的其他维度全是1或者全是不需要广播的值。<br>    - 此场景支持的例子：HDMK vs H1KN<br>    - 此场景不支持反例：H1MK vs 1DKN<br>  - A除了最低两个维度，其他维度不能即有需要广播的值也有不需要广播的值。<br>    - 此场景支持的例子：11MK vs HDKN<br>    - 此场景不支持反例：H1MK vs HDKN<br>  - B除了最低两个维度，如果其他维度即有需要广播的值也有不需要广播的值，那么不需要广播的值只能在连续的高维度上。<br>    - 此场景支持的例子：BHDMK vs B11KN<br>    - 此场景不支持反例：BHDMK vs B1DKN  <br>  注：需要广播的值和不需要广播的值：<br>   <br>- 如果A和B在对应维度轴上的两个值，一个为1，另一个为非1，那么1就是需要广播的值，非1就是不需要广播的值；<br>    - 如果A和B在对  应维度轴上的两个值相等，那么这两个值都是不需要广播的值（如HDMK vs H1KN，1是需要广播的值，H是不需要广播的值）。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Upsample</td><td>BPU加速</td><td>输入featuremap需为四维NCHW，并且只支持在H和W维度上进行resize； <br> 放大系数factor不能同时小于2。</td><td>无</td></tr><tr><td>ROIPooling</td><td>CPU计算</td><td>不支持</td><td>无</td></tr><tr><td>PSROIPooling</td><td>CPU计算</td><td>不支持</td><td>无</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-ultra支持的onnx算子列表">RDK Ultra支持的ONNX算子列表<a href="#rdk-ultra支持的onnx算子列表" class="hash-link" aria-label="RDK Ultra支持的ONNX算子列表的直接链接" title="RDK Ultra支持的ONNX算子列表的直接链接">​</a></h2>
<table><thead><tr><th><strong>ONNX算子名称</strong></th><th><strong>CPU计算/BPU加速</strong></th><th><strong>RDK Ultra BPU支持约束</strong></th><th><strong>CPU支持约束</strong></th></tr></thead><tbody><tr><td>Abs</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Acos</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Acosh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Add</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入类型支持featurmap和常量，且最多支持一个常量输入。<br>3. 支持除第一维外的广播，支持两个输入之间的互相广播，例如NH1C和N1WC。<br>4. 输入输出维度支持2维、3维、4维和5维，大小为一般限制（见备注）。支持两个输入维度不同，输入为5维时需要满足以下限制：<br>(1)首先可以通过合并相邻维度降维到4维，例如NHWD1和N1WDC可  以合并W维和D维来降维；<br>(2)其次广播的维度不能和相邻维度合并，例如NHWD1和N11DC因为H维、W维和C维都是广播的维度，无法通过合并相邻维度降维，所以无法支持。<br>5. 作为resnet中的short-cut子结构的Add，会被融合到上一个conv中加速计算。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>And</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>ArgMax</td><td>BPU加速</td><td>1. 输入维度为四维输入NCHW。 <br>2. 仅支持沿C维度进行argmax，即axis=1。<br> 3. <code>C &lt;= 64</code> 。 <br>4. 该算子支持int16输入输出。</td><td>type约束：仅支持float类型。</td></tr><tr><td>ArgMin</td><td>BPU加速</td><td>1. 输入维度为四维输入NCHW。 <br>2. 仅支持沿C维度进行argmax，即axis=1。<br> 3. <code>C &lt;= 64</code> 。 <br>4. 该算子支持int16输入输出。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Asin</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Asinh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Atan</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Atanh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>AveragePool</td><td>BPU加速</td><td><code>kernel &lt;= 256</code>。<br><code>stride &lt;= 256</code>。<br><code>padding &lt;= 256</code>。</td><td>auto_pad 属性不支持。<br>仅支持四维Tensor计算。</td></tr><tr><td>BatchNormalization</td><td>BPU加速</td><td>无限制。</td><td>type约束：仅支持float类型。 <br>支持第1个维度是channel的数据排布方式计算。</td></tr><tr><td>BitShift</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Cast</td><td>CPU计算</td><td>--</td><td>from_type支持double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8。<br>to_type支持double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8。</td></tr><tr><td>Ceil</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Clip</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>opset6: <br>min, max作为属性值，dtype仅支持float类型;<br>opset11: <br>min, max作为输入，仅有两个输入时，第二个为min；dtype支持float, double类型。</td></tr><tr><td>Compress</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Concat</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 不支持N维度concat。</td><td>--</td></tr><tr><td>ConcatFromSequence</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Constant</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>目前不支持sparse_tensor属性。</td></tr><tr><td>ConstantOfShape</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>type约束支持：float,int32,int8。</td></tr><tr><td>Conv</td><td>BPU加速</td><td>支持四维输入（conv2d）和五维输入（conv3d）。<br>四维输入（conv2d）：<br>Kernel shape范围：<code>N,C ∈ [1, 8192]</code>; <code>H,W ∈ [1, 31]</code>。<code>C*H*W &lt; = 65535</code>。<br>输入输出Channel取值范围 <code>(one group) &lt;= 8192</code>，如果Conv是量化子图的最后一个算子，取值范围 <code>&lt;= 65536</code>。<br>stride取值范围：<code>H,W ∈ [1, 256]</code>，但对于Conv后接Add(resnet shortcut-connecting) Stride取值范围为：<code>{1, 2}</code>，对dilated&gt;1的conv，stride只支持=1。<br>Dilation取值范围：<code>H,W∈ [1, 16]</code>，H或W大于1时，只支持输出int8，且输入Tensor的H必须能被dilation的H整除，输入Tensor的W必须能被dilation的W整除。<br>padding取值范围：<code>H,W ∈ [0, 256]</code>。<br>五维输入（conv3d）：<br>输入大小NCDHW：<code>N ∈ [1, 128]</code>; <code>H,W,D,C ∈ [1, 65536]</code>。<br>kernel大小NCDHW：<code>N,C ∈ [1, 65536]; H,W ∈ [1, 31], D ∈ [1, 8191]</code>。<br>padding大小DHW：<code>H,W ∈ [0, 256]</code>, <code>D ∈ [0, kernel_d/2]</code>。<br>stride取值范围：H, W同为1或H, W同为2。<br>group，dilation暂不支持。<br> Size: 1G bytes；当 <code>D * C &gt; 4096</code>时, <code>H * alignCeil(W, 256) * D * C &lt; 1G</code>。<br>weight的D * 输入的<code>C &lt;= 8192</code>。</td><td>仅支持4维Conv计算。<br>auto_pad 属性不支持。<br>type约束支持：float,int32,int8。<br>pads属性约束：[Hstart, Wstart, Hend, Wend]（pads长度等于4）并且Hstart==Hend，Wstart==Wend。</td></tr><tr><td>ConvInteger</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>ConvTranspose</td><td>BPU加速</td><td>输入输出featuremap大小限制：<br>N ∈ [1, 128]。<br>H,W ∈ [1, 65536]。 <br>C ∈ [1, 2048] 。<br>Size: 1G bytes。<br>weight大小限制：<br>N,C ∈ [1, 2048]。 <br>H,W ∈ [1, 14]且HW不同时为1。<br>Size: [1, 65535]。<br>padding取值范围：<br>stride为奇数时，<code>H,W ∈ [0, kernel / stride)</code>。<br>stride为偶数，H,W ∈ [0, kernel / stride]。<br>out_pad取值范围：H,W ∈ <!-- -->1<!-- -->。<br>stride &gt;= 1 &amp;&amp; <code>stride &lt;=14 </code>但不支持stride_h和stride_w同时等于1。<br><code>Dilation ∈ {(1, 1)}</code>。</td><td>shape约束：仅支持4维Tensor计算。<br>type约束：仅支持float类型。<br>attribute约束：<br>- 仅支持dilations、group、output_padding、 pads 、strides 属性。<br>- pads属性约束：[hstart, wstart, hend, wend]必须满足(hstart==hend and wstart==wend)。</td></tr><tr><td>Cos</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Cosh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>CumSum</td><td>CPU计算</td><td>--</td><td>axis：type约束仅支持int32类型。</td></tr><tr><td>DepthToSpace</td><td>BPU加速</td><td>支持mode=DCR 和 mode=CRD。<br> 仅支持H和W方向的重新排列，并且仅支持blocksize=2的重排列。 <br>举例：NxCxHxW -&gt; Nx(C/4)x(2H)x(2W) 输出的channel必须是4的倍数。</td><td>from_type支持：<br>- type约束仅支持float类型。<br>- 仅支持4维度Tensor计算。<br>to_type支持：<br>- type约束仅支持float类型。<br>- 仅支持4维度Tensor计算。</td></tr><tr><td>DequantizeLinear</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Det</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Div</td><td>BPU加速</td><td>1. 只支持两个输入均为featuremap（不支持输入来自于常量）； <br>2. 对input shape的约束请参考Mul算子</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Dropout</td><td>BPU加速</td><td>该算子推理阶段不参加计算， 会被移除优化</td><td>--</td></tr><tr><td>Einsum</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Elu</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Equal</td><td>BPU加速</td><td>1. 该算子支持int16输入。<br>2. 输入输出维度支持2-5维。<br>3. 支持所有维度的广播，支持fin0或fin1其中一个输入的广播，不能支持互相广播，5维广播时有以下限制：<br>（1）需要能够合并相邻维度降到4维（包括维度N），例如NHWDC和NH1D1可以合并NH维来降维。<br>（2）广播的维度不能和相邻维度合并，例如NHWDC和N1W1C因为无法合并相邻维度，所以无法支持。<br>4. 默认运行在CPU上，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Erf</td><td>CPU计算</td><td>--</td><td>type约束：支持float、double数据类型。</td></tr><tr><td>Exp</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Expand</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，输入与输出仅支持有一个维度上的数值不同。<br>3. 输入与输出仅允许有一个维度上数值不同。</td><td>--</td></tr><tr><td>EyeLike</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Flatten</td><td>BPU加速</td><td>限制条件等同于Reshape。</td><td>--</td></tr><tr><td>Floor</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>GRU</td><td>CPU计算</td><td>--</td><td>- direction属性仅支持forward类型。<br>- type约束：仅支持float类型。</td></tr><tr><td>Gather</td><td>BPU加速</td><td>1. input/output/indices 的rank都要小于等于4。<br>2. indices支持：<br>    - indices是feature（其他op输出）时，type约束仅支持int32类型。<br>    - indices是weight（模型保存的常量）时，type约束支持int32和int64类型。</td><td>from_type支持：<br>- input：type约束支持：<br>float,int64,int32,int8,uint64,uint32,uint8。<br>- indices：type约束支持int32, int64。 <br>to_type支持：type约束支持：<br>float,int64,int32,int8,uint64,uint32,uint8。</td></tr><tr><td>GatherElements</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. input/indices/output维度支持1-10维。<br>3. indices type约束支持int16/int32/int64。</td><td>--</td></tr><tr><td>GatherND</td><td>CPU计算</td><td>--</td><td>from_type支持：<br>- input：type约束支持float,int32,int8。<br>- indices：tensor(int64)。<br>to_type支持：type约束支持float,int32,int8。</td></tr><tr><td>Gemm</td><td>BPU加速</td><td>Gemm将被转化为Conv实现，边界约束参考Conv。</td><td>type约束：仅支持float类型。</td></tr><tr><td>GlobalAveragePool</td><td>BPU加速</td><td>无限制。</td><td>- type约束：仅支持float类型。<br>- 仅支持四维Tensor。</td></tr><tr><td>GlobalLpPool</td><td>CPU计算</td><td>--</td><td>- type约束：支持float和double类型。<br> - 仅支持四维Tensor计算。</td></tr><tr><td>GlobalMaxPool</td><td>BPU加速</td><td>H, W ∈ [1, 256]。</td><td>- type约束仅支持float类型。<br>- 仅支持四维Tensor。</td></tr><tr><td>Greater</td><td>BPU加速</td><td>1. 该算子支持int16输入。<br>2. 输入输出维度支持2-5维。<br>3. 支持所有维度的广播，支持fin0或fin1其中一个输入的广播，不能支持互相广播，5维广播时有以下限制：<br>（1）需要能够合并相邻维度降到4维（包括维度N），例如NHWDC和NH1D1可以合并NH维来降维。<br>（2）广播的维度不能和相邻维度合并，例如NHWDC和N1W1C因为无法合并相邻维度，所以无法支持。<br>4. 默认运行在CPU上，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>-  支持broadcast计算，最大维度是5。</td></tr><tr><td>HardSigmoid</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束仅支持float类型。</td></tr><tr><td>Hardmax</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Identity</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>If</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>InstanceNormalization</td><td>CPU计算</td><td>--</td><td>- type约束仅支持float类型。<br>- 支持第1个维度是channel的数据排布方式计算。</td></tr><tr><td>IsInf</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>IsNaN</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>LRN</td><td>CPU计算</td><td>--</td><td>- type约束仅支持float类型。<br>- 仅支持四维Tensor。</td></tr><tr><td>LSTM</td><td>BPU加速</td><td>仅支持batch_size=1，如果需要配置多batch，需要在导出onnx时保证LSTM的batch为1并在yaml中配置参数input_batch=1。</td><td>- type约束仅支持float类型。<br>- 属性约束：direction属性仅支持forward。<br>- 输入约束：<br>   - 支持X、W、R输入配置；<br>   - 支持X、W、R、B输入配置（sequence_lens为空或默认值）；<br>   -  支持X、W、R、B、sequence_lens、initial_h、initial_c、P输入配置（sequence_lens为空或者默认值）。</td></tr><tr><td>LeakyRelu</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Less</td><td>BPU加速</td><td>1. 该算子支持int16输入。<br>2. 输入输出维度支持2-5维。<br>3. 默认运行在CPU上，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维  度是5。</td></tr><tr><td>LessOrEqual</td><td>BPU加速</td><td>opset11 不支持单个LessOrEqual算子，支持拆分后的算子Greater+Not运行在BPU上，限制条件与Greater相同。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Log</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>LogSoftmax</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Loop</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>LpNormalization</td><td>CPU计算</td><td>--</td><td>- p范数仅支持1或者2。<br>- type约束支持double类型和float类型。</td></tr><tr><td>LpPool</td><td>CPU计算</td><td>--</td><td>- auto_pad属性不支持。<br>- type约束支持double类型和float类型。<br>- 仅支持4维计算。</td></tr><tr><td>MatMulInteger</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>MatMul</td><td>BPU加速</td><td>C = MatMul(A，B)，对输入A和输入B有以下维度限制：<br>- A和B均支持非四维输入但需满足约束：<br>  - A和B的维度必须相同。<br>  - A和B的最低两个维度M, K∈[1, 8192]，其他更高维度∈[1, 4096]。    <br>  注：HDMK vs HDKN，MK/KN即为最低两个维度。<br>- 支持的broadcast需满足以下条件：<br>  - A跟B两个输入，除开最低两维的其他维度全是1或者全是不需要广播的值。<br>    - 此场景支持的例子：HDMK vs H1KN<br>    - 此场景不支持反例：H1MK vs 1DKN<br>  - A除了最低两个维度，其他维度不能即有需要广播的值也有不需要广播的值。<br>    - 此场景支持的例子：11MK vs HDKN<br>    - 此场景不支持反例：H1MK vs HDKN<br>  - B除了最低两个维度，如果其他维度即有需要广播的值也有不需要广播的值，那么不需要广播的值只能在连续的高维度上。<br>    - 此场景支持的例子：BHDMK vs B11KN<br>    - 此场景不支持反例：BHDMK vs B1DKN  <br>  注：需要广播的值和不需要广播的值：<br>    - 如果A和B在对应维度轴上的两个值，一个为1，另一个为非1，那么1就是需要广播的值，非1就是不需要广播的值；<br>    - 如果A和B在对应维度轴上的两个值相等，那么这两个值都是不需要广播的值（如HDMK vs H1KN，1是需要广播的值，H是不需要广播的值）</td><td>type约束：仅支持float类型。</td></tr><tr><td>Max</td><td>BPU加速</td><td>1.该算子支持int16输入输出。<br>2.输入输出维度支持2-5维。<br>3.支持所有维度的广播，支持fin0或fin1其中一个输入的广播，不能支持互相广播，5维广播时有以下限制：<br>（1）需要能够合并相邻维度降到4维（包括维度N），例如NHWDC和NH1D1可以合并NH维来降维。<br>（2）广播的维度不能和相邻维度合并，例如NHWDC和N1W1C因为无法合并相邻维度，所以无法支持。</td><td>- 支持1-∞个输入。<br>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>MaxPool</td><td>BPU加速</td><td>该算子支持int16输入输出。<br><code>kernel &lt;= 256</code>。<br><code>stride &lt;= 256</code>。<br><code>padding &lt;= 256</code>。<br>MaxPool不支持dilation。</td><td>1. dilation只支持1x1。<br>2. 只支持数据行优先存储。<br>3. auto_pad属性不支持。<br>4. storage_order属性不支持。<br>5.仅支持四维Tensor计算。</td></tr><tr><td>MaxRoiPool</td><td>CPU计算</td><td>--</td><td>无</td></tr><tr><td>Mean</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Min</td><td>BPU加速</td><td>1.该算子支持int16输入输出。<br>2.输入输出维度支持2-5维。<br>3.支持所有维度的广播，  支持fin0或fin1其中一个输入的广播，不能支持互相广播，5维广播时有以下限制：<br>（1）需要能够合并相邻维度降到4维（包括维度N），例如NHWDC和NH1D1可以合并NH维来降维。<br>（2）广播的维度不能和相邻维度合并，例如NHWDC和N1W1C因为无法合并相邻维度，所以无法支持。<br>4. 默认运行在CPU上，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>- 支持1-∞个输入。<br>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Mod</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Mul</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2.输入类型支持featurmap和常量，且最多支持一个常量输入。<br>3.支持除第一维外的广播，支持两个输入之间的互相广播，例如NH1C和N1WC。<br>4.输入输出维度支持2维、3维、4维和5维，大小为一般限制（见备注）。支持两个输入维度不同，输入为5维时需要满足以下限制：<br>(1)首先可以通过合并相邻维度降维到4维，例如NHWD1和N1WDC可以合并W维和D维来降维；<br>(2)其次广播的维度不能和相邻维度合并，例如NHWD1和N11DC因为H维、W维和C维都是广播的维度，无法通过合并相邻维度降维，所以无法支持。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Multinomial</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Neg</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Not</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>OneHot</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Or</td><td>CPU计算</td><td>--</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。 <br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>PRelu</td><td>CPU计算</td><td>--</td><td>- type约束支持：仅支持float类型。<br>- from_type：X和slope。<br>- to_type：Y。<br>- X的shape为data_shape，slope的为slope_shape ，shape约束如下：  <br>- data_shape == slope_shape。   <br>- slope_shape.ProdSize() == 1。   <br>- X和slope仅支持NCHW排布的4维度计算，并且N、C维度值相等。     <br>- HxW 与1x1（ slope_shape ）。     <br>- HxW与Hx1（ slope_shape ）。     <br>- HxW与1xW（ slope_shape ）。 <br>- X是4维度 &amp;&amp; slope是3维度 &amp;&amp; data_shape[1] == slope_shape [0] &amp;&amp; slope_shape [1] == 1 &amp;&amp; slope_shape [2] == 1。</td></tr><tr><td>Pad</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 支持mode = Constant。<br>3. 支持所有维度的Pad。</td><td>Pad-10：<br>- type约束仅支持float类型。<br>- 仅支持NCHW排布的4维Tensor。<br>- 属性pads的约束如下：  <br>- len(pads) == 8 &amp;&amp; pads[i] &gt;=0 &amp;&amp; pads[0] == 0 &amp;&amp; pads[1] == 0 &amp;&amp; pads[4] == 0 &amp;&amp; pads[5] == 0。 <br>Pad-11：<br>- from_type支持：  <br>- data：type约束仅支持float类型。  <br>- pads : tensor(int64)。  <br>- constant_value (optional)：type约束仅支持float类型。<br>- to_type支持：type约束仅支持float类型。<br>- 仅支持4维Tensor。<br>- 仅支持2/3维度填充。</td></tr><tr><td>Pow</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。<br>3. 第二个输入只支持标量。</td><td>- type约束支持：double, float，int64, int32。<br>- 支持相同输入shape的计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。<br>- 仅支持X和Y相同type。</td></tr><tr><td>QLinearConv</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>QLinearMatMul</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>QuantizeLinear</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>RNN</td><td>CPU计算</td><td>--</td><td>- type约束：仅支持float类型。<br>- 属性约束：direction属性仅支持forward。<br>- 输入约束：仅支持X、W、R输入，不支持可选输入B、sequence_lens、initial_h设置。 <br>- 输出约束：仅支持Y_h的输出，shape [num_directions, batch_size, hidden_size]。</td></tr><tr><td>RandomNormal</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>RandomNormalLike</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>RandomUniform</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>RandomUniformLike</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Range</td><td>CPU计算</td><td>--</td><td>type约束支持：float,int64,int32,int16。</td></tr><tr><td>Reciprocal</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>--</td></tr><tr><td>ReduceL1</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceL2</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceLogSum</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceLogSumExp</td><td>CPU计算</td><td>--</td><td>type约束支持float、double数据类型。</td></tr><tr><td>ReduceMax</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入支持2-5维，需要指定axes属性，指定的axes数量为1，不支持沿大于1个维度进行reduce操作。<br>3. reduce维度对应的轴的size ∈ [1, 8192]。<br>4. 仅支持keepdims == 1。</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>ReduceMean</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入支持2-5维，需要指定axes属性，指定的axes数量为1，不支持沿大于1个维度进行reduce操作。<br>3. 当reduce维度=2时，支持同时沿HW维度进行reduce。<br>4. 仅支持keepdims == 1。</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>ReduceMin</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceProd</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>ReduceSum</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入支持2-5维，需要指定axes属性，指定的axes数量为1，不支持沿大于1个维度进行reduce操作。</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>ReduceSumSquare</td><td>CPU计算</td><td>--</td><td>axes支持0, 1或者等于输入数据的维数</td></tr><tr><td>Relu</td><td>BPU加速</td><td>无限制</td><td>type约束：仅支持float类型。</td></tr><tr><td>Reshape</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 支持1-10维输入输出。</td><td>--</td></tr><tr><td>Resize</td><td>BPU加速</td><td>1. 输入featuremap需为四维NCHW，并且只支持在H和W维度上进行resize，onnx opset=11时支持roi输入（pytorch转换的模型需手动修改算子添加roi输入，roi只支持常量输入），roi输入只支持H和W维度，roi输入只在tf_crop_and_resize模式下起作用。<br>2. 属性mode支持nearest和linear两种模式。<br>3. 支持放大和缩小。<br>4. 对于mode=nearest，放大系数factor支持2的幂数倍如2，4，8，16，32等；支持H维度和W维度的放大系数不同但需要满足<code>H_factor &lt;= W_factor</code>。<br>5. 对于onnx opset=11，属性coordinate_transformation_mode支持half_pixel，pytorch_half_pixel, asymmetric，align_corners和tf_crop_and_resize，当coordinate_transformation_mode=tf_crop_and_resize时，需要保证roi输入转换得到的边界坐标为整数。</td><td>resize-10 <br>- 输入等于2时，使用opset10。<br>- 输入数据是4维Tensor。 <br>resize-11  <br>- 输入大于2时，使用opset11。<br>- 输入数据是4维Tensor。<br>- coordinate_transformation_mode在nearest, linear模式下支持half_pixel, asymmetric, align_corners和pytorch_half_pixel四种，在cubic模式下只支持half_pixel。<br>- extrapolation_value属性不支持。</td></tr><tr><td>ReverseSequence</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>RoiAlign</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Round</td><td>CPU计算</td><td>--</td><td>--</td></tr><tr><td>Scan</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Scatter (deprecated)</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>ScatterElements</td><td>CPU计算</td><td>--</td><td>from_type支持：<br>- data：type约束支持：float,int32,int8。<br>- indices：type约束仅支持int32类型。<br>- updates：type约束支持：float,int32,int8。<br>to_type支持：type约束支持：float,int32,int8。</td></tr><tr><td>ScatterND</td><td>CPU计算</td><td>--</td><td>from_type支持：<br>- data：type约束支持：float,int32,int8。<br>- updates : type约束支持：float,int32,int8。<br>to_type支持：type约束支持：float,int32,int8。</td></tr><tr><td>Selu</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>SequenceAt</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceConstruct</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceEmpty</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceErase</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceInsert</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>SequenceLength</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Shape</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>--</td></tr><tr><td>Shrink</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Sigmoid</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Sign</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Sin</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Sinh</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Size</td><td>BPU加速</td><td>会通过常量折叠将其优化为数值存储</td><td>--</td></tr><tr><td>Slice</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 无限制，支持非四维输入输出。</td><td>无</td></tr><tr><td>Softmax</td><td>BPU加速</td><td>- 该算子支持int16输入输出。<br>- 默认运行在CPU上，由于onnx::softmax和pytorch::softmax计算存在区别，分以下两种情况：<br>1. 对于onnx::softmax，当该op输入为四维并且axis=3时，可以通过run_on_bpu指定该节点将其运行在BPU上。<br>2. 对于pytorch::softmax, 当该op输入为四维并且axis=1,2,3时，可以通过run_on_bpu指定该节点将其运行在BPU上。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Softplus</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Softsign</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>SpaceToDepth</td><td>BPU加速</td><td>支持mode=DCR 和 mode=CRD。<br> 仅支持H和W方向的重新排列，并且仅支持blocksize=2的重排列。 <br>举例：NxCxHxW -&gt; Nx(4C)x(H/2)x(W/2)</td><td>type约束：仅支持float类型。</td></tr><tr><td>Split</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 原始输入的长度必须是每个被切分的tensor长度的倍数。<br>3. 支持除N维度以外的任意维度。<br>4. split数应可以整除。<br>5. 支持非四维输入输出。</td><td>type约束：仅支持float类型。</td></tr><tr><td>SplitToSequence</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Sqrt</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>Squeeze</td><td>BPU加速</td><td>该op会被转换成Reshape，BPU约束详见Reshape op。</td><td>--</td></tr><tr><td>StringNormalizer</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Sub</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入类型支持featurmap和常量，且最多支持一个常量输入。<br>3. 支持除第一维外的广播，支持两个输入之间的互相广播，例如NH1C和N1WC。<br>4. 输入输出维度支持2维、3维、4维和5维，大小为一般限制（见备注）。支持两个输入维度不同，输入为5维时需要满足以下限制：<br>(1)首先可以通过合并相邻维度降维到4维，例如NHWD1和N1WDC可以合并W维和D维来降维；<br>(2)其次广播的维度不能和相邻维度合并，例如NHWD1和N11DC因为H维、W维和C维都是广播的维度，无法通过合并相邻维度降维，所以无法支持。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>Sum</td><td>BPU加速</td><td>限制条件等同于Add</td><td>type约束：仅支持float类型。</td></tr><tr><td>Tan</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Tanh</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入输出支持1-10维，最高维 ∈ [1, 4096]，其它维 ∈ [1, 65536]。</td><td>type约束：仅支持float类型。</td></tr><tr><td>TfIdfVectorizer</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>ThresholdedRelu</td><td>CPU计算</td><td>--</td><td>type约束：仅支持float类型。</td></tr><tr><td>Tile</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 输入与输出仅允许有一个维度上数值不同。</td><td>type约束：仅支持float,int64,int32,uint64,uint32类型。</td></tr><tr><td>TopK</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. input/indices/output维度支持1-10维。<br>3. indices type约束支持int16/int32/int64。<br>4. 参数sorted只支持true。</td><td>- type约束：仅支持float类型。</td></tr><tr><td>Transpose</td><td>BPU加速</td><td>1. 该算子支持int16输入输出。<br>2. 支持任意输入维度。</td><td>- 支持nhwc2nchw，perm：[0, 3, 1, 2]。<br>- 支持nchw2nhwc，perm：[0, 2, 3, 1]。<br>- 支持指定perm维度转换，数据类型仅支持float，int8，int32。</td></tr><tr><td>Unique</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Unsqueeze</td><td>BPU加速</td><td>该op会被转换成Reshape，BPU约束详见Reshape op。</td><td>--</td></tr><tr><td>Upsample (resize替代)</td><td>BPU加速</td><td>--</td><td>Upsample-(resize-10) <br>- 输入等于2时，使用opset10。<br>- 输入数据是4维Tensor。 <br>Upsample-(resize-11)  <br>- 输入大于2时，使用opset11。<br>- 输入数据是4维Tensor。<br>- coordinate_transformation_mode在nearest, linear模式下支持half_pixel, asymmetric, align_corners和pytorch_half_pixel四种，在cubic模式下只支持half_pixel。<br>- extrapolation_value属性不支持。</td></tr><tr><td>Where</td><td>CPU计算</td><td>--</td><td>type约束支持float和int64类型。<br> condition的shape为cond_shape，X的shape为x_shape，Y的shape为y_shape ，output的shape为o_shape，shape约束如下：<br>- 仅支持cond_shape == o_shape情况下：  <br>- x_shape == o_shape的broadcast。  <br>- y_shape == o_shape的broadcast。<br>- 仅支持cond_shape.NDim() == 4 &amp;&amp; o_shape.NDim() == 4 &amp;&amp; N维度值相同 &amp;&amp; C维度值相同：  <br>- 1x1（cond_shape）与HxW （o_shape）。  <br>- Hx1（cond_shape）与HxW（o_shape）。  <br>- 1xW（cond_shape）与HxW（o_shape）。</td></tr><tr><td>Xor</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Function</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>Celu</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>DynamicQuantizeLinear</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>GreaterOrEqual</td><td>BPU加速</td><td>opset11 不支持单个GreaterOrEqual算子，支持拆分后的算子Less+Not运行在BPU上，限制条件与Less相同。</td><td>- 支持相同输入shape计算。<br>- 支持输入1是标量或者输入2是标量的计算。<br>- 支持broadcast计算，最大维度是5。</td></tr><tr><td>MeanVarianceNormalization</td><td>CPU计算※</td><td>--</td><td>--</td></tr><tr><td>GridSample（PyTorch）</td><td>BPU加速</td><td>1. 输入维度仅支持四维，第一个输入需满足N ∈ [1, 4096]； C ∈ [1, 65536]； H,W ∈ [1, 1024] 且 <code>H*W &lt;= 720*1024</code>。<br>2. mode只支持&#x27;bilinear&#x27;、&#x27;nearest&#x27;。<br>3. padding_mode只支持&#x27;zeros&#x27;、&#x27;border&#x27;。<br>4. 该算子为opset16的onnx算子，为在opset11支持，工具链以自定义算子的方式提供导出，导出包含该算子的onnx模型请使用horizon_nn.torch.export_onnx接口替换torch.onnx.export，接口传参相同，示例代码如下：<br>from horizon_nn.torch import export_onnx    <br>...    <br>    export_onnx(...)</td><td></td></tr></tbody></table></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">最后<!-- -->于 <b><time datetime="2025-09-01T17:16:54.000Z" itemprop="dateModified">2025年9月1日</time></b> <!-- -->更新</span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/rdk_doc/Advanced_development/toolchain_development/intermediate/ptq_process"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">PTQ原理及步骤详解</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/rdk_doc/Advanced_development/toolchain_development/intermediate/runtime_sample"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">模型上板运行应用开发说明</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#使用限制说明" class="table-of-contents__link toc-highlight">使用限制说明</a></li><li><a href="#rdk-x3支持的caffe算子列表" class="table-of-contents__link toc-highlight">RDK X3支持的Caffe算子列表</a></li><li><a href="#rdk-x3支持的onnx算子列表" class="table-of-contents__link toc-highlight">RDK X3支持的ONNX算子列表</a></li><li><a href="#rdk-x5支持的caffe算子列表" class="table-of-contents__link toc-highlight">RDK X5支持的Caffe算子列表</a></li><li><a href="#rdk-x5支持的onnx算子列表" class="table-of-contents__link toc-highlight">RDK X5支持的ONNX算子列表</a></li><li><a href="#rdk-ultra支持的caffe算子列表" class="table-of-contents__link toc-highlight">RDK Ultra支持的Caffe算子列表</a></li><li><a href="#rdk-ultra支持的onnx算子列表" class="table-of-contents__link toc-highlight">RDK Ultra支持的ONNX算子列表</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">友情链接</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.guyuehome.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">古月居<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">联系我们</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/D-Robotics" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://space.bilibili.com/437998606" target="_blank" rel="noopener noreferrer" class="footer__link-item">BiLiBiLi<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 D-Robotics.</div></div></div></footer></div>
</body>
</html>