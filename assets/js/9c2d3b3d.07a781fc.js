"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[28019],{28453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>s});var i=t(96540);const o={},r=i.createContext(o);function a(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),i.createElement(r.Provider,{value:e},n.children)}},72173:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>_,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"Advanced_development/toolchain_development/expert/user_guide","title":"\u5f00\u53d1\u6307\u5357","description":"\u6d6e\u70b9\u6a21\u578b\u7684\u8981\u6c42","source":"@site/docs/07_Advanced_development/04_toolchain_development/expert/user_guide.md","sourceDirName":"07_Advanced_development/04_toolchain_development/expert","slug":"/Advanced_development/toolchain_development/expert/user_guide","permalink":"/rdk_doc/Advanced_development/toolchain_development/expert/user_guide","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1757664965000,"sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"\u5feb\u901f\u4e0a\u624b","permalink":"/rdk_doc/Advanced_development/toolchain_development/expert/quick_start"},"next":{"title":"\u6df1\u5165\u63a2\u7d22","permalink":"/rdk_doc/Advanced_development/toolchain_development/expert/advanced_content"}}');var o=t(74848),r=t(28453);const a={sidebar_position:3},s="\u5f00\u53d1\u6307\u5357",l={},c=[{value:"\u6d6e\u70b9\u6a21\u578b\u7684\u8981\u6c42",id:"\u6d6e\u70b9\u6a21\u578b\u7684\u8981\u6c42",level:2},{value:"symbolic_trace",id:"symbolic_trace",level:3},{value:"\u4ec5\u652f\u6301\u90e8\u5206\u7b97\u5b50",id:"\u4ec5\u652f\u6301\u90e8\u5206\u7b97\u5b50",level:3},{value:"\u6784\u5efa\u91cf\u5316\u53cb\u597d\u6a21\u578b",id:"\u6784\u5efa\u91cf\u5316\u53cb\u597d\u6a21\u578b",level:3},{value:"qconfig \u8be6\u89e3",id:"qconfig-\u8be6\u89e3",level:2},{value:"\u4ec0\u4e48\u662f qconfig",id:"\u4ec0\u4e48\u662f-qconfig",level:3},{value:"\u5982\u4f55\u83b7\u53d6 qconfig",id:"\u5982\u4f55\u83b7\u53d6-qconfig",level:3},{value:"\u5982\u4f55\u8bbe\u7f6e qconfig",id:"\u5982\u4f55\u8bbe\u7f6e-qconfig",level:3},{value:"qconfig \u6a21\u677f",id:"qconfig-\u6a21\u677f",level:3},{value:"Calibration \u6307\u5357",id:"Calibration",level:2},{value:"\u6d41\u7a0b\u548c\u793a\u4f8b",id:"\u6d41\u7a0b\u548c\u793a\u4f8b",level:3},{value:"\u5e38\u7528\u7b97\u6cd5\u4ecb\u7ecd",id:"\u5e38\u7528\u7b97\u6cd5\u4ecb\u7ecd",level:3},{value:"\u8c03\u53c2\u6280\u5de7",id:"\u8c03\u53c2\u6280\u5de7",level:3},{value:"Observer \u53c2\u6570\u6587\u6863",id:"observer-\u53c2\u6570\u6587\u6863",level:3},{value:"\u91cf\u5316\u8bad\u7ec3\u6307\u5357",id:"quantization",level:2},{value:"\u6d41\u7a0b\u548c\u793a\u4f8b",id:"\u6d41\u7a0b\u548c\u793a\u4f8b-1",level:3},{value:"prepare_qat_fx",id:"prepare_qat_fx",level:4},{value:"\u52a0\u8f7d Calibration \u6a21\u578b\u53c2\u6570",id:"\u52a0\u8f7d-calibration-\u6a21\u578b\u53c2\u6570",level:4},{value:"\u8bad\u7ec3\u8fed\u4ee3",id:"\u8bad\u7ec3\u8fed\u4ee3",level:4},{value:"\u4f2a\u91cf\u5316\u7b97\u5b50",id:"\u4f2a\u91cf\u5316\u7b97\u5b50",level:3},{value:"\u4f2a\u91cf\u5316\u8fc7\u7a0b",id:"\u4f2a\u91cf\u5316\u8fc7\u7a0b",level:4},{value:"\u57fa\u4e8e\u7edf\u8ba1\u7684\u65b9\u6cd5",id:"\u57fa\u4e8e\u7edf\u8ba1\u7684\u65b9\u6cd5",level:4},{value:"\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5",id:"\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5",level:4},{value:"\u5f02\u6784\u6a21\u578b\u6307\u5357",id:"\u5f02\u6784\u6a21\u578b\u6307\u5357",level:2},{value:"\u5f02\u6784\u6a21\u578b\u4ecb\u7ecd",id:"\u5f02\u6784\u6a21\u578b\u4ecb\u7ecd",level:3},{value:"\u4f7f\u7528\u6d41\u7a0b",id:"\u4f7f\u7528\u6d41\u7a0b",level:3},{value:"\u7b97\u5b50\u9650\u5236",id:"\u7b97\u5b50\u9650\u5236",level:3},{value:"\u4e3b\u8981\u63a5\u53e3\u53c2\u6570\u8bf4\u660e",id:"\u4e3b\u8981\u63a5\u53e3\u53c2\u6570\u8bf4\u660e",level:3},{value:"\u6d41\u7a0b\u548c\u793a\u4f8b",id:"\u6d41\u7a0b\u548c\u793a\u4f8b-2",level:3},{value:"\u5206\u6790\u5de5\u5177\u4f7f\u7528\u6307\u5357",id:"\u5206\u6790\u5de5\u5177\u4f7f\u7528\u6307\u5357",level:2},{value:"\u603b\u89c8",id:"\u603b\u89c8",level:3},{value:"\u96c6\u6210\u63a5\u53e3",id:"a-name-integration-a",level:3},{value:"fuse \u68c0\u67e5",id:"fuse-a-name-fuse-check-a",level:3},{value:"\u5171\u4eab op \u68c0\u67e5",id:"op-a-name-shared-op-check-a",level:3},{value:"\u91cf\u5316\u914d\u7f6e\u68c0\u67e5",id:"a-name-qconfig-check-a",level:3},{value:"\u53ef\u89c6\u5316\uff1aONNX \u6a21\u578b\u53ef\u89c6\u5316",id:"onnx-a-name-onnx-a",level:3},{value:"\u76f8\u4f3c\u5ea6\u5bf9\u6bd4",id:"a-name-similarity-a",level:3},{value:"\u7edf\u8ba1\u91cf",id:"a-name-statistic-a",level:3},{value:"\u6a21\u578b weight \u6bd4\u8f83",id:"weight-a-name-weight-comparison-a",level:3},{value:"\u5206\u6b65\u91cf\u5316",id:"a-name-step-quantization-a",level:3},{value:"\u5355\u7b97\u5b50\u8f6c\u6362\u7cbe\u5ea6\u8c03\u8bd5",id:"a-name-single-op-error-a",level:3},{value:"\u5f02\u6784\u6a21\u578b\u90e8\u7f72 device \u68c0\u67e5",id:"device-a-name-hybrid-device-check-a",level:3},{value:"torchscript \u548c hbdk \u7ed3\u679c\u5bf9\u6bd4",id:"torchscript-hbdk",level:3},{value:"\u4e0d\u540c\u7248\u672c torchscript \u6a21\u578b\u7684\u7ed3\u679c\u5bf9\u6bd4",id:"torchscript",level:3},{value:"\u6a21\u578b\u663e\u5b58\u5360\u7528\u5206\u6790\u5de5\u5177",id:"a-name-cuda-memory-a",level:3},{value:"\u91cf\u5316\u8bad\u7ec3\u7cbe\u5ea6\u8c03\u4f18\u5efa\u8bae",id:"debug_precision",level:2},{value:"\u53c2\u8003\u6d41\u7a0b",id:"\u53c2\u8003\u6d41\u7a0b",level:3},{value:"\u524d\u8a00",id:"\u524d\u8a00",level:3},{value:"\u63a8\u8350\u8d85\u53c2\u914d\u7f6e",id:"a-name-recommended-configuration-a",level:3},{value:"\u7cbe\u5ea6\u5f02\u5e38\u73b0\u8c61",id:"\u7cbe\u5ea6\u5f02\u5e38\u73b0\u8c61",level:3},{value:"\u8c03\u53c2\u7b56\u7565",id:"a-name-para-policy-a",level:3},{value:"Debug \u91cf\u5316\u5f02\u5e38\u5c42",id:"debug-a-name-quantization-exception-a",level:3},{value:"\u91cf\u5316\u90e8\u7f72 PT \u6a21\u578b\u7684\u8de8\u8bbe\u5907 Inference \u8bf4\u660e",id:"\u91cf\u5316\u90e8\u7f72-pt-\u6a21\u578b\u7684\u8de8\u8bbe\u5907-inference-\u8bf4\u660e",level:2},{value:"PT \u6a21\u578b\u6267\u884c\u4f7f\u7528\u7684 device \u548c trace \u4e0d\u4e00\u81f4",id:"pt-\u6a21\u578b\u6267\u884c\u4f7f\u7528\u7684-device-\u548c-trace-\u4e0d\u4e00\u81f4",level:3},{value:"\u591a\u5361\u5e76\u884c\u63a8\u7406",id:"\u591a\u5361\u5e76\u884c\u63a8\u7406",level:3},{value:"\u5e38\u89c1\u95ee\u9898",id:"\u5e38\u89c1\u95ee\u9898",level:2},{value:"import \u51fa\u9519",id:"import-\u51fa\u9519",level:3},{value:"\u65e0\u6cd5\u6b63\u5e38 prepare_calibration/qat",id:"\u65e0\u6cd5\u6b63\u5e38-prepare_calibrationqat",level:3},{value:"prepare_qat \u540e forward \u62a5\u9519",id:"prepare_qat-\u540e-forward-\u62a5\u9519",level:3},{value:"\u7f16\u8bd1\u62a5\u9519",id:"\u7f16\u8bd1\u62a5\u9519",level:3},{value:"\u91cf\u5316\u7cbe\u5ea6\u5f02\u5e38",id:"\u91cf\u5316\u7cbe\u5ea6\u5f02\u5e38",level:3},{value:"\u4f7f\u7528 torch.jit.load \u52a0\u8f7d pt \u6587\u4ef6\u62a5\u9519",id:"\u4f7f\u7528-torchjitload-\u52a0\u8f7d-pt-\u6587\u4ef6\u62a5\u9519",level:3},{value:"\u5e38\u89c1\u4f7f\u7528\u8bef\u533a",id:"\u5e38\u89c1\u4f7f\u7528\u8bef\u533a",level:2},{value:"\u8bbe\u7f6e\u7c7b\u9519\u8bef",id:"\u8bbe\u7f6e\u7c7b\u9519\u8bef",level:3},{value:"\u65b9\u6cd5\u7c7b\u9519\u8bef",id:"\u65b9\u6cd5\u7c7b\u9519\u8bef",level:3},{value:"\u7f51\u7edc\u7c7b\u9519\u8bef",id:"\u7f51\u7edc\u7c7b\u9519\u8bef",level:3},{value:"\u7b97\u5b50\u7c7b\u9519\u8bef",id:"\u7b97\u5b50\u7c7b\u9519\u8bef",level:3},{value:"\u6a21\u578b\u7c7b\u9519\u8bef",id:"\u6a21\u578b\u7c7b\u9519\u8bef",level:3}];function d(n){const e={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"\u5f00\u53d1\u6307\u5357",children:"\u5f00\u53d1\u6307\u5357"})}),"\n",(0,o.jsx)(e.h2,{id:"\u6d6e\u70b9\u6a21\u578b\u7684\u8981\u6c42",children:"\u6d6e\u70b9\u6a21\u578b\u7684\u8981\u6c42"}),"\n",(0,o.jsx)(e.h3,{id:"symbolic_trace",children:"symbolic_trace"}),"\n",(0,o.jsx)(e.p,{children:"\u548c PyTorch \u7684\u91cf\u5316\u8bad\u7ec3\u7c7b\u4f3c\uff0chorizon_plugin_pytorch \u57fa\u4e8e fx \u8bbe\u8ba1\u548c\u5f00\u53d1\uff0c\u56e0\u6b64\uff0c\u8981\u6c42\u6d6e\u70b9\u6a21\u578b\u5fc5\u987b\u662f\u53ef\u4ee5\u6b63\u786e\u7684\u5b8c\u6210 symbolic_trace \u7684"}),"\n",(0,o.jsx)(e.h3,{id:"\u4ec5\u652f\u6301\u90e8\u5206\u7b97\u5b50",children:"\u4ec5\u652f\u6301\u90e8\u5206\u7b97\u5b50"}),"\n",(0,o.jsx)(e.p,{children:"\u7531\u4e8e BPU \u53ea\u652f\u6301\u6570\u91cf\u6709\u9650\u7684\u7b97\u5b50\uff0c\u56e0\u6b64\uff0chorizon_plugin_pytorch \u53ea\u652f\u6301\u7b97\u5b50\u5217\u8868\u4e2d\u7684\u7b97\u5b50\u548c\u57fa\u4e8e BPU \u9650\u5236\u800c\u5185\u90e8\u7279\u6b8a\u5b9a\u4e49\u7684\u7279\u6b8a\u7b97\u5b50\u3002"}),"\n",(0,o.jsx)(e.h3,{id:"\u6784\u5efa\u91cf\u5316\u53cb\u597d\u6a21\u578b",children:"\u6784\u5efa\u91cf\u5316\u53cb\u597d\u6a21\u578b"}),"\n",(0,o.jsx)(e.p,{children:"\u6d6e\u70b9\u6a21\u578b\u53d8\u4e3a\u5b9a\u70b9\u6a21\u578b\u7684\u8fc7\u7a0b\u5b58\u5728\u4e00\u5b9a\u7684\u7cbe\u5ea6\u8bef\u5dee\uff0c\u8d8a\u662f\u91cf\u5316\u53cb\u597d\u7684\u6d6e\u70b9\u6a21\u578b\uff0c qat \u7cbe\u5ea6\u63d0\u5347\u8d8a\u5bb9\u6613\uff0c\u91cf\u5316\u540e\u7684\u7cbe\u5ea6\u4e5f\u8d8a\u9ad8\u3002\u4e00\u822c\u800c\u8a00\uff0c\u6709\u4ee5\u4e0b\u51e0\u79cd\u60c5\u51b5\u4f1a\u5bfc\u81f4\u6a21\u578b\u53d8\u5f97\u91cf\u5316\u4e0d\u53cb\u597d\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u6709\u7cbe\u5ea6\u98ce\u9669\u7684\u7b97\u5b50\u3002\u4f8b\u5982\uff1a softmax , layernorm \u7b49\uff08\u8be6\u89c1 op \u6587\u6863\uff09\uff0c\u8fd9\u7c7b\u7b97\u5b50\u4e00\u822c\u5e95\u5c42\u7531\u67e5\u8868\u6216\u591a\u4e2a op \u62fc\u63a5\u5b9e\u73b0\uff0c\u5bb9\u6613\u53d1\u751f\u6389\u70b9\u95ee\u9898\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4e00\u6b21 forward \u4e2d\u591a\u6b21\u8c03\u7528\u540c\u4e00\u7b97\u5b50\u3002\u540c\u4e00\u7b97\u5b50\u591a\u6b21\u8c03\u7528\uff0c\u5bf9\u5e94\u7684\u8f93\u51fa\u5206\u5e03\u5b58\u5728\u5dee\u5f02\uff0c\u4f46\u53ea\u4f1a\u7edf\u8ba1\u4e00\u7ec4\u91cf\u5316\u53c2\u6570\uff0c\u5f53\u591a\u6b21\u8c03\u7528\u7684\u8f93\u51fa\u5206\u5e03\u5dee\u5f02\u8fc7\u5927\u65f6\uff0c\u91cf\u5316\u8bef\u5dee\u4f1a\u53d8\u5927\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"add , cat \u7b49\u591a\u8f93\u5165\u7b97\u5b50\u7684\u4e0d\u540c\u8f93\u5165\u5dee\u5f02\u8fc7\u5927\uff0c\u53ef\u80fd\u9020\u6210\u8f83\u5927\u8bef\u5dee\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6570\u636e\u5206\u5e03\u4e0d\u5408\u7406\u3002plugin \u91c7\u7528\u7684\u662f\u5747\u5300\u5bf9\u79f0\u91cf\u5316\uff0c\u6240\u4ee5 0 \u5747\u503c\u7684\u5747\u5300\u5206\u5e03\u6700\u597d\uff0c\u5e94\u5c3d\u91cf\u907f\u514d\u957f\u5c3e\u548c\u79bb\u7fa4\u70b9\u3002\u540c\u65f6\uff0c\u6570\u503c\u8303\u56f4\u9700\u8981\u4e0e\u91cf\u5316 bit \u76f8\u5339\u914d\uff0c\u5982\u679c\u4f7f\u7528int8\u91cf\u5316\u5206\u5e03\u4e3a [-1000, 1000] \u5747\u5300\u5206\u5e03\u7684\u6570\u636e\uff0c\u90a3\u4e48\u7cbe\u5ea6\u663e\u7136\u4e5f\u662f\u4e0d\u591f\u7684\u3002\u4f8b\u5982\uff0c\u4e0b\u9762\u4e09\u4e2a\u5206\u5e03\u56fe\uff0c\u4ece\u5de6\u5230\u53f3\u5bf9\u91cf\u5316\u7684\u53cb\u597d\u6027\u4f9d\u6b21\u9012\u51cf\uff0c\u6a21\u578b\u4e2d\u5927\u90e8\u5206\u6570\u503c\u7684\u5206\u5e03\u5e94\u5f53\u4e3a\u4e2d\u95f4\u8fd9\u79cd\u5206\u5e03\u3002\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u53ef\u4ee5\u7528 debug \u5de5\u5177\u67e5\u770b\u6a21\u578b weight \u548c feature map \u7684\u5206\u5e03\u662f\u5426\u91cf\u5316\u53cb\u597d\u3002\u56e0\u4e3a\u6a21\u578b\u5197\u4f59\u6027\u7684\u5b58\u5728\uff0c\u6709\u4e9b\u770b\u8d77\u6765\u5206\u5e03\u975e\u5e38\u91cf\u5316\u4e0d\u53cb\u597d\u7684 op \u5e76\u4e0d\u4f1a\u663e\u8457\u964d\u4f4e\u6a21\u578b\u7684\u6700\u7ec8\u7cbe\u5ea6\uff0c\u9700\u8981\u7ed3\u5408\u5b9e\u9645\u7684 qat \u8bad\u7ec3\u96be\u5ea6\u548c\u6700\u540e\u8fbe\u5230\u7684\u91cf\u5316\u7cbe\u5ea6\u7efc\u5408\u8003\u8651\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/data_distribution.png",alt:"data_distribution"})}),"\n",(0,o.jsx)(e.p,{children:"\u90a3\u4e48\u5982\u4f55\u4f7f\u5f97\u6a21\u578b\u66f4\u52a0\u91cf\u5316\u53cb\u597d\u5462\uff1f\u5177\u4f53\u6765\u8bf4\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u5c3d\u91cf\u5c11\u4f7f\u7528\u7cbe\u5ea6\u98ce\u9669\u8fc7\u5927\u7684\u7b97\u5b50\uff0c\u8be6\u89c1 op \u6587\u6863\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4fdd\u8bc1\u591a\u6b21\u8c03\u7528\u7684\u5171\u4eab\u7b97\u5b50\u6bcf\u6b21\u8c03\u7528\u7684\u8f93\u51fa\u5206\u5e03\u5dee\u5f02\u4e0d\u8981\u592a\u5927\uff0c\u6216\u8005\u5c06\u5171\u4eab\u7b97\u5b50\u62c6\u5f00\u5206\u522b\u5355\u72ec\u4f7f\u7528\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u907f\u514d\u591a\u8f93\u5165\u7b97\u5b50\u4e0d\u540c\u8f93\u5165\u7684\u6570\u503c\u8303\u56f4\u5dee\u5f02\u8fc7\u5927\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528 int16 \u91cf\u5316\u6570\u503c\u8303\u56f4\u548c\u8bef\u5dee\u90fd\u975e\u5e38\u5927\u7684 op \u3002\u53ef\u901a\u8fc7 debug \u5de5\u5177\u627e\u5230\u8fd9\u7c7b op \u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u901a\u8fc7\u8c03\u5927 weight decay \uff0c\u589e\u52a0\u6570\u636e\u589e\u5f3a\u7b49\u65b9\u5f0f\u9632\u6b62\u6a21\u578b\u8fc7\u62df\u5408\u3002\u8fc7\u62df\u5408\u6a21\u578b\u5bb9\u6613\u51fa\u73b0\u8f83\u5927\u6570\u503c\uff0c\u4e14\u5bf9\u8f93\u5165\u975e\u5e38\u654f\u611f\uff0c\u8f7b\u5fae\u7684\u8bef\u5dee\u53ef\u80fd\u5bfc\u81f4\u8f93\u51fa\u5b8c\u5168\u9519\u8bef\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528 BN \u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u5bf9\u6a21\u578b\u8f93\u5165\u505a\u5173\u4e8e0\u5bf9\u79f0\u7684\u5f52\u4e00\u5316\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c qat \u81ea\u8eab\u5177\u6709\u4e00\u5b9a\u7684\u8c03\u6574\u80fd\u529b\uff0c\u91cf\u5316\u4e0d\u53cb\u597d\u5e76\u4e0d\u4ee3\u8868\u4e0d\u80fd\u91cf\u5316\uff0c\u5f88\u591a\u60c5\u51b5\u4e0b\uff0c\u5373\u4f7f\u51fa\u73b0\u4e0a\u9762\u7684\u4e0d\u9002\u5408\u91cf\u5316\u7684\u73b0\u8c61\uff0c\u4ecd\u7136\u53ef\u4ee5\u91cf\u5316\u5f97\u5f88\u597d\u3002\u56e0\u4e3a\u4e0a\u8ff0\u5efa\u8bae\u4e5f\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6d6e\u70b9\u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\uff0c\u6240\u4ee5\u5e94\u5f53\u5728 qat \u7cbe\u5ea6\u65e0\u6cd5\u8fbe\u6807\u65f6\u518d\u5c1d\u8bd5\u4e0a\u8ff0\u5efa\u8bae\uff0c\u5c24\u5176\u662f 1 - 5 \u6761\u5efa\u8bae\uff0c\u6700\u540e\u5e94\u5f53\u662f\u5728\u6d6e\u70b9\u6a21\u578b\u7cbe\u5ea6\u548c\u91cf\u5316\u6a21\u578b\u7cbe\u5ea6\u4e2d\u627e\u4e00\u4e2a\u5e73\u8861\u70b9\u3002"}),"\n",(0,o.jsx)(e.h2,{id:"qconfig-\u8be6\u89e3",children:"qconfig \u8be6\u89e3"}),"\n",(0,o.jsx)(e.h3,{id:"\u4ec0\u4e48\u662f-qconfig",children:"\u4ec0\u4e48\u662f qconfig"}),"\n",(0,o.jsx)(e.p,{children:"\u6a21\u578b\u7684\u91cf\u5316\u65b9\u5f0f\u7531 qconfig \u51b3\u5b9a\uff0c\u5728\u51c6\u5907 qat / calibration \u6a21\u578b\u4e4b\u524d\uff0c\u9700\u8981\u5148\u7ed9\u6a21\u578b\u8bbe\u7f6e qconfig\u3002\u6211\u4eec\u4e0d\u63a8\u8350\u60a8\u81ea\u5b9a\u4e49 qconfig\uff0c\u5c3d\u91cf\u53ea\u4f7f\u7528\u9884\u5b9a\u4e49\u597d\u7684qconfig\u53d8\u91cf\uff0c\u56e0\u4e3a\u81ea\u5b9a\u4e49 qconfig \u9700\u8981\u5bf9\u5177\u4f53\u7684\u5904\u7406\u5668\u9650\u5236\u8ba4\u77e5\u6e05\u6670\uff0c\u8be6\u7ec6\u4e86\u89e3\u8bad\u7ec3\u5de5\u5177\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u5b9a\u4e49\u51fa\u9519\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u6b63\u5e38\u6536\u655b\u3001\u6a21\u578b\u65e0\u6cd5\u7f16\u8bd1\u7b49\u95ee\u9898\uff0c\u6d6a\u8d39\u5927\u91cf\u65f6\u95f4\u548c\u4eba\u529b\u3002"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-{attention}",children:"\u76ee\u524d\uff0cPlugin \u4e2d\u7ef4\u62a4\u4e86\u4e24\u4e2a\u7248\u672c\u7684qconfig\uff0c\u65e9\u671f\u7248\u672c\u7684 qconfig \u5c06\u5728\u4e0d\u4e45\u7684\u5c06\u6765\u88ab\u5e9f\u5f03\uff0c\u6211\u4eec\u53ea\u63a8\u8350\u60a8\u4f7f\u7528\u6b64\u6587\u6863\u4e2d\u4ecb\u7ecd\u7684 qconfig \u7528\u6cd5\u3002\n"})}),"\n",(0,o.jsx)(e.h3,{id:"\u5982\u4f55\u83b7\u53d6-qconfig",children:"\u5982\u4f55\u83b7\u53d6 qconfig"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\u4f7f\u7528\u5c01\u88c5\u597d\u7684 qconfig \u53d8\u91cf\u3002\u8fd9\u4e9b qconfig \u5b58\u653e\u5728 ",(0,o.jsx)(e.code,{children:"horizon_plugin_pytorch/quantization/qconfig.py"})," \u4e2d\uff0c\u53ef\u4ee5\u9002\u7528\u4e8e\u7edd\u5927\u591a\u6570\u60c5\u51b5\u3002\u5305\u62ec\uff1a"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"from horizon_plugin_pytorch.quantization.qconfig import (\n    default_calib_8bit_fake_quant_qconfig,\n    default_qat_8bit_fake_quant_qconfig,\n    default_qat_8bit_fixed_act_fake_quant_qconfig,\n    default_calib_8bit_weight_16bit_act_fake_quant_qconfig,\n    default_qat_8bit_weight_16bit_act_fake_quant_qconfig,\n    default_qat_8bit_weight_16bit_fixed_act_fake_quant_qconfig,\n    default_qat_8bit_weight_32bit_out_fake_quant_qconfig, # \u53c2\u8003\u7b97\u5b50\u5217\u8868\uff0c\u652f\u6301\u9ad8\u7cbe\u5ea6\u8f93\u51fa\u7684\u7b97\u5b50\u53ef\u4ee5\u8bbe\u7f6e\u6b64 qconfig \u83b7\u5f97\u66f4\u9ad8\u7684\u7cbe\u5ea6\n    default_calib_8bit_weight_32bit_out_fake_quant_qconfig, # \u53c2\u8003\u7b97\u5b50\u5217\u8868\uff0c\u652f\u6301\u9ad8\u7cbe\u5ea6\u8f93\u51fa\u7684\u7b97\u5b50\u53ef\u4ee5\u8bbe\u7f6e\u6b64 qconfig \u83b7\u5f97\u66f4\u9ad8\u7684\u7cbe\u5ea6\n)\n"})}),"\n",(0,o.jsxs)(e.ol,{start:"2",children:["\n",(0,o.jsxs)(e.li,{children:["\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"get_default_qconfig"})," \u63a5\u53e3\u3002\u6b64\u63a5\u53e3\u8f83\u56fa\u5b9a qconfig \u53d8\u91cf\u66f4\u7075\u6d3b\uff0c\u6211\u4eec\u63a8\u8350\u60a8\u5bf9\u91cf\u5316\u548c\u786c\u4ef6\u9650\u5236\u6709\u6e05\u6670\u8ba4\u77e5\u4e4b\u540e\u518d\u4f7f\u7528\u3002\u5e38\u7528\u53c2\u6570\u548c\u89e3\u91ca\u5982\u4e0b\uff1a"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from horizon_plugin_pytorch.quantization.qconfig import get_default_qconfig\n\nqconfig = get_default_qconfig(\n    activation_fake_quant="fake_quant",  # \u652f\u6301 fake_quant, lsq, pact\uff0c\u5e38\u7528 fake quant\n    weight_fake_quant="fake_quant", # \u652f\u6301 fake_quant, lsq, pact\uff0c\u5e38\u7528 fake quant\n    activation_observer="min_max", # \u652f\u6301 min_max, fixed_scale, clip, percentile, clip_std, mse, kl\n    weight_observer="min_max", # \u652f\u6301 min_max, fixed_scale, clip, percentile, clip_std, mse, kl\n    activation_qkwargs={\n        "dtype": qint16, # \u7531\u5177\u4f53\u7b97\u5b50\u51b3\u5b9a\u662f\u5426\u652f\u6301 int16\n        "is_sync_quantize": False, # \u662f\u5426\u540c\u6b65\u7edf\u8ba1\u6570\u636e\uff0c\u9ed8\u8ba4\u5173\u95ed\u63d0\u5347forward\u901f\u5ea6\n        "averaging_constant": 0.01 # \u6ed1\u52a8\u5e73\u5747\u7cfb\u6570\uff0c\u8bbe\u7f6e\u4e3a0\u65f6\uff0cscale\u4e0d\u66f4\u65b0\n    },\n    weight_qkwargs={ # \u53ea\u652f\u6301 dtype = qint8, qscheme = torch.per_channel_symmetric, ch_axis = 0, \u4e0d\u5efa\u8bae\u505a\u989d\u5916\u914d\u7f6e\n        "dtype": qint8,\n        "qscheme": torch.per_channel_symmetric,\n        "ch_axis": 0,\n    },\n)\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u5982\u4f55\u8bbe\u7f6e-qconfig",children:"\u5982\u4f55\u8bbe\u7f6e qconfig"}),"\n",(0,o.jsx)(e.p,{children:"\u5171\u6709\u4e09\u79cd\u8bbe\u7f6e\u65b9\u6cd5\uff0c\u6211\u4eec\u63a8\u8350\u60a8\u4f7f\u7528\u524d\u4e24\u79cd\uff0c\u6700\u540e\u4e00\u79cd\u8bbe\u7f6e\u65b9\u5f0f\u5c06\u5e9f\u5f03\u3002"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"\u76f4\u63a5\u8bbe\u7f6e qconfig \u5c5e\u6027\u3002\u6b64\u65b9\u6cd5\u4f18\u5148\u7ea7\u6700\u9ad8\uff0c\u5176\u4f59\u65b9\u6cd5\u4e0d\u4f1a\u8986\u76d6\u76f4\u63a5\u8bbe\u7f6e\u7684 qconfig\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"model.qconfig = default_qat_8bit_fake_quant_qconfig\n"})}),"\n",(0,o.jsxs)(e.ol,{start:"2",children:["\n",(0,o.jsx)(e.li,{children:"qconfig \u6a21\u677f\u3002\u5728 prepare \u63a5\u53e3\u4e0a\u6307\u5b9a qconfig setter \u548c example_inputs\uff0c\u81ea\u52a8\u4e3a\u6a21\u578b\u8bbe\u7f6e qconfig\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"model = prepare_qat_fx(\n    model,\n    example_inputs=data,\n    qconfig_setter=default_qat_qconfig_setter,\n)\n"})}),"\n",(0,o.jsxs)(e.ol,{start:"3",children:["\n",(0,o.jsx)(e.li,{children:"qconfig_dict\u3002\u5728 prepare_qat_fx \u63a5\u53e3\u4e0a\u6307\u5b9a qconfig_dict\u3002\u6b64\u7528\u6cd5\u5c06\u9010\u6b65\u5e9f\u5f03\uff0c\u5982\u65e0\u517c\u5bb9\u6027\u9700\u6c42\uff0c\u4e0d\u63a8\u8350\u518d\u4f7f\u7528\uff0c\u8fd9\u91cc\u4e0d\u5c55\u5f00\u4ecb\u7ecd\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-py",children:'model = prepare_qat_fx(\n    model,\n    qconfig_dict={"": default_qat_qconfig_setter},\n)\n'})}),"\n",(0,o.jsx)(e.h3,{id:"qconfig-\u6a21\u677f",children:"qconfig \u6a21\u677f"}),"\n",(0,o.jsx)(e.p,{children:"\u957f\u671f\u4ee5\u6765\uff0c\u914d\u7f6e qconfig \u51fa\u9519\u7684\u95ee\u9898\u7ecf\u5e38\u53d1\u751f\uff0c\u56e0\u6b64\u6211\u4eec\u5f00\u53d1\u4e86 qconfig \u6a21\u677f\u3002qconfig \u6a21\u677f\u57fa\u4e8e subclass trace \u65b9\u6848\u611f\u77e5\u6a21\u578b\u7684\u56fe\u7ed3\u6784\uff0c\u5e76\u6309\u8bbe\u5b9a\u7684\u89c4\u5219\u81ea\u52a8\u8bbe\u7f6e qconfig\uff0c\u662f\u6211\u4eec\u6700\u63a8\u8350\u7684\u8bbe\u7f6e qconfig \u65b9\u6cd5\u3002\u7528\u6cd5\u5982\u4e0b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"qat_model = prepare_qat_fx(\n    model,\n    example_inputs=example_input,  # \u7528\u6765\u611f\u77e5\u56fe\u7ed3\u6784\n    qconfig_setter=( # qconfig \u6a21\u677f\uff0c\u652f\u6301\u4f20\u5165\u591a\u4e2a\u6a21\u677f\uff0c\u4f18\u5148\u7ea7\u4ece\u9ad8\u5230\u4f4e\u3002\n        sensitive_op_qat_8bit_weight_16bit_act_qconfig_setter(table, ratio=0.2),\n        default_calibration_qconfig_setter,\n    )\n)\n"})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-{attention}",children:"\u6a21\u677f\u7684\u4f18\u5148\u7ea7\u4f4e\u4e8e\u76f4\u63a5\u7ed9\u6a21\u578b\u8bbe\u7f6e qconfig \u5c5e\u6027\uff0c\u5982\u679c\u6a21\u578b\u5728 prepare \u4e4b\u524d\u5df2\u7ecf\u4f7f\u7528 model.qconfig = xxx \u8fdb\u884c\u4e86\u914d\u7f6e\uff0c\u90a3\u4e48\u6a21\u677f\u5c06\u4e0d\u4f1a\u751f\u6548\u3002\u5982\u679c\u6ca1\u6709\u7279\u6b8a\u9700\u6c42\uff0c\u6211\u4eec\u4e0d\u63a8\u8350\u5c06\u4e24\u8005\u6df7\u5408\u4f7f\u7528\uff0c\u8fd9\u5f88\u5bb9\u6613\u5f15\u53d1\u4f4e\u7ea7\u9519\u8bef\u3002\u7edd\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u63a8\u8350\u60a8\u4f7f\u7528\u6a21\u677f\u548c model.qconfig = xxx \u4e24\u79cd\u8bbe\u7f6e\u65b9\u5f0f\u4e2d\u7684\u4e00\u79cd\u5373\u53ef\u6ee1\u8db3\u9700\u6c42\u3002\n"})}),"\n",(0,o.jsx)(e.p,{children:"\u6a21\u677f\u53ef\u5206\u4e3a\u4e09\u7c7b\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"\u56fa\u5b9a\u6a21\u677f\u3002\u56fa\u5b9a\u6a21\u677f\u4e2d calibration / qat / qat_fixed_act_scale \u533a\u522b\u5728\u4e8e\u4f7f\u7528\u7684 observer \u7c7b\u578b\u548c scale \u66f4\u65b0\u903b\u8f91\uff0c\u5206\u522b\u7528\u4e8e\u6821\u51c6\uff0cqat \u8bad\u7ec3\uff0c\u56fa\u5b9a activation scale qat \u8bad\u7ec3\u3002default \u6a21\u677f( default_calibration_qconfig_setter / default_qat_qconfig_setter / default_qat_fixed_act_qconfig_setter )\u4f1a\u505a\u4e09\u4ef6\u4e8b\uff1a\u9996\u5148\uff0c\u5c06\u53ef\u4ee5\u8bbe\u7f6e\u7684\u9ad8\u7cbe\u5ea6\u8f93\u51fa\u90fd\u8bbe\u7f6e\u4e0a\uff0c\u5bf9\u4e8e\u4e0d\u652f\u6301\u9ad8\u7cbe\u5ea6\u7684\u8f93\u51fa\u5c06\u7ed9\u51fa\u63d0\u793a\uff1b\u7136\u540e\uff0c\u4ece grid sample \u7b97\u5b50\u7684 grid \u8f93\u5165\u5411\u524d\u641c\u7d22\uff0c\u76f4\u5230\u51fa\u73b0\u7b2c\u4e00\u4e2a gemm \u7c7b\u7b97\u5b50\u6216\u8005QuantStub\uff0c\u5c06\u4e2d\u95f4\u7684\u6240\u6709\u7b97\u5b50\u90fd\u8bbe\u7f6e\u4e3a int16\u3002\u6839\u636e\u7ecf\u9a8c\u8fd9\u91cc\u7684 grid \u4e00\u822c\u8868\u8fbe\u8303\u56f4\u8f83\u5bbd\uff0cint8 \u6709\u8f83\u5927\u53ef\u80fd\u4e0d\u6ee1\u8db3\u7cbe\u5ea6\u9700\u6c42\uff1b\u6700\u540e\uff0c\u5c06\u5176\u4f59\u7b97\u5b50\u8bbe\u7f6e\u4e3a int8\u3002int16 \u6a21\u677f( qat_8bit_weight_16bit_act_qconfig_setter / qat_8bit_weight_16bit_fixed_act_qconfig_setter / calibration_8bit_weight_16bit_act_qconfig_setter )\u4f1a\u505a\u4e24\u4ef6\u4e8b\uff1a\u9996\u5148\uff0c\u5c06\u53ef\u4ee5\u8bbe\u7f6e\u7684\u9ad8\u7cbe\u5ea6\u8f93\u51fa\u90fd\u8bbe\u7f6e\u4e0a\uff0c\u5bf9\u4e8e\u4e0d\u652f\u6301\u9ad8\u7cbe\u5ea6\u7684\u8f93\u51fa\u5c06\u7ed9\u51fa\u63d0\u793a\uff1b\u5176\u6b21\uff0c\u5c06\u5176\u4f59\u7b97\u5b50\u8bbe\u7f6e\u4e3a int16\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"from horizon_plugin_pytorch.quantization.qconfig_template import (\n    default_calibration_qconfig_setter,\n    default_qat_qconfig_setter,\n    default_qat_fixed_act_qconfig_setter,\n    qat_8bit_weight_16bit_act_qconfig_setter,\n    qat_8bit_weight_16bit_fixed_act_qconfig_setter,\n    calibration_8bit_weight_16bit_act_qconfig_setter,\n)\n"})}),"\n",(0,o.jsxs)(e.ol,{start:"2",children:["\n",(0,o.jsx)(e.li,{children:"\u654f\u611f\u5ea6\u6a21\u677f\u3002\u654f\u611f\u5ea6\u6a21\u677f\u6709 sensitive_op_calibration_8bit_weight_16bit_act_qconfig_setter\uff0c sensitive_op_qat_8bit_weight_16bit_act_qconfig_setter\uff0c sensitive_op_qat_8bit_weight_16bit_fixed_act_qconfig_setter\uff0c\u4e09\u8005\u7684\u533a\u522b\u548c\u56fa\u5b9a\u6a21\u677f\u4e2d\u4e09\u8005\u7684\u533a\u522b\u4e00\u81f4\uff0c\u4e5f\u662f\u5206\u522b\u7528\u4e8e\u6821\u51c6\uff0cqat \u8bad\u7ec3\uff0c\u56fa\u5b9a activation scale qat \u8bad\u7ec3\u3002\n\u654f\u611f\u5ea6\u6a21\u677f\u7684\u7b2c\u4e00\u4e2a\u8f93\u5165\u662f\u7cbe\u5ea6 debug \u5de5\u5177\u4ea7\u751f\u7684\u654f\u611f\u5ea6\u7ed3\u679c\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u53ef\u4ee5\u6307\u5b9a ratio \u6216 topk \uff0c\u654f\u611f\u5ea6\u6a21\u677f\u4f1a\u5c06\u91cf\u5316\u654f\u611f\u5ea6\u6700\u9ad8\u7684 topk \u4e2a\u7b97\u5b50\u8bbe\u7f6e\u4e3a int16\u3002\u642d\u914d\u56fa\u5b9a\u6a21\u677f\uff0c\u53ef\u4ee5\u8f7b\u677e\u5b9e\u73b0\u6df7\u5408\u7cbe\u5ea6\u8c03\u4f18\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from horizon_plugin_pytorch.quantization.qconfig_template import (\n    default_calibration_qconfig_setter,\n    default_qat_qconfig_setter,\n    default_qat_fixed_act_qconfig_setter,\n    qat_8bit_weight_16bit_act_qconfig_setter,\n    qat_8bit_weight_16bit_fixed_act_qconfig_setter,\n    calibration_8bit_weight_16bit_act_qconfig_setter,\n    sensitive_op_qat_8bit_weight_16bit_act_qconfig_setter,\n    sensitive_op_qat_8bit_weight_16bit_fixed_act_qconfig_setter,\n    sensitive_op_calibration_8bit_weight_16bit_act_qconfig_setter,\n)\n\ntable = torch.load("output_0-0_dataindex_1_sensitive_ops.pt")\n\nqat_model = prepare_qat_fx(\n    model,\n    example_inputs=example_input,\n    qconfig_setter=( \n        sensitive_op_qat_8bit_weight_16bit_fixed_act_qconfig_setter(table, ratio=0.2),\n        default_calibration_qconfig_setter,\n    )\n)\n'})}),"\n",(0,o.jsxs)(e.ol,{start:"3",children:["\n",(0,o.jsx)(e.li,{children:"\u81ea\u5b9a\u4e49\u6a21\u677f\u3002\u81ea\u5b9a\u4e49\u6a21\u677f\u53ea\u6709 ModuleNameQconfigSetter\uff0c\u9700\u8981\u4f20\u5165\u6a21\u5757\u540d\u548c\u5bf9\u5e94 qconfig \u7684\u5b57\u5178\uff0c\u4e00\u822c\u7528\u4e8e\u8bbe\u7f6e fixed scale \u7b49\u7279\u6b8a\u9700\u6c42\uff0c\u53ef\u4ee5\u548c\u56fa\u5b9a\u6a21\u677f\uff0c\u654f\u611f\u5ea6\u6a21\u677f\u642d\u914d\u4f7f\u7528\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from horizon_plugin_pytorch.quantization.qconfig_template import (\n    default_calibration_qconfig_setter,\n    default_qat_qconfig_setter,\n    default_qat_fixed_act_qconfig_setter,\n    qat_8bit_weight_16bit_act_qconfig_setter,\n    qat_8bit_weight_16bit_fixed_act_qconfig_setter,\n    calibration_8bit_weight_16bit_act_qconfig_setter,\n    sensitive_op_qat_8bit_weight_16bit_act_qconfig_setter,\n    sensitive_op_qat_8bit_weight_16bit_fixed_act_qconfig_setter,\n    sensitive_op_calibration_8bit_weight_16bit_act_qconfig_setter,\n    ModuleNameQconfigSetter,\n)\n\ntable = torch.load("output_0-0_dataindex_1_sensitive_ops.pt")\n\nmodule_name_to_qconfig = {\n    "op_1": default_qat_8bit_fake_quant_qconfig,\n    "op_2": get_default_qconfig(\n        activation_observer="fixed_scale",\n        activation_qkwargs={\n            "dtype": qint16,\n            "scale": OP2_MAX / QINT16_MAX,\n        },\n    )\n}\n\nqat_model = prepare_qat_fx(\n    model,\n    example_inputs=example_input,\n    qconfig_setter=(\n        ModuleNameQconfigSetter(module_name_to_qconfig),\n        sensitive_op_qat_8bit_weight_16bit_fixed_act_qconfig_setter(table, ratio=0.2),\n        default_calibration_qconfig_setter,\n    )\n)\n'})}),"\n",(0,o.jsx)(e.h2,{id:"Calibration",children:"Calibration \u6307\u5357"}),"\n",(0,o.jsx)(e.p,{children:"\u5728\u91cf\u5316\u4e2d\uff0c\u4e00\u4e2a\u91cd\u8981\u7684\u6b65\u9aa4\u662f\u786e\u5b9a\u91cf\u5316\u53c2\u6570\uff0c\u5408\u7406\u7684\u521d\u59cb\u91cf\u5316\u53c2\u6570\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u7cbe\u5ea6\u5e76\u52a0\u5feb\u6a21\u578b\u7684\u6536\u655b\u901f\u5ea6\u3002Calibration \u5c31\u662f\u5728\u6d6e\u70b9\u6a21\u578b\u4e2d\u63d2\u5165 Observer\uff0c\u4f7f\u7528\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u6a21\u578b forward \u8fc7\u7a0b\u4e2d\u7edf\u8ba1\u5404\u5904\u7684\u6570\u636e\u5206\u5e03\uff0c\u4ee5\u786e\u5b9a\u5408\u7406\u7684\u91cf\u5316\u53c2\u6570\u7684\u8fc7\u7a0b\u3002\u867d\u7136\u4e0d\u505a Calibration \u4e5f\u53ef\u4ee5\u8fdb\u884c\u91cf\u5316\u8bad\u7ec3\uff0c\u4f46\u4e00\u822c\u6765\u8bf4\uff0c\u5b83\u5bf9\u91cf\u5316\u8bad\u7ec3\u6709\u76ca\u65e0\u5bb3\uff0c\u6240\u4ee5\u63a8\u8350\u7528\u6237\u5c06\u6b64\u6b65\u9aa4\u4f5c\u4e3a\u5fc5\u9009\u9879\u3002"}),"\n",(0,o.jsx)(e.h3,{id:"\u6d41\u7a0b\u548c\u793a\u4f8b",children:"\u6d41\u7a0b\u548c\u793a\u4f8b"}),"\n",(0,o.jsx)(e.p,{children:"Calibration \u4e0e QAT \u7684\u6574\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/calibration_v2_workflow.svg",alt:"quick_start"})}),"\n",(0,o.jsx)(e.p,{children:"\u4e0b\u9762\u5206\u522b\u4ecb\u7ecd\u5404\u4e2a\u6b65\u9aa4\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u6784\u5efa\u5e76\u8bad\u7ec3\u6d6e\u70b9\u6a21\u578b\u3002\u53c2\u8003 horizon_plugin_pytorch \u5feb\u901f\u5165\u95e8\u7ae0\u8282\u4e2d\u7684 ",(0,o.jsx)(e.a,{href:"./quick_start#Float-Model",children:(0,o.jsx)(e.strong,{children:"\u83b7\u53d6\u6d6e\u70b9\u6a21\u578b"})})," \u5c0f\u8282\u5185\u5bb9\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u5728\u6d6e\u70b9\u6a21\u578b\u4e0a\u63d2\u5165 Observer \u8282\u70b9\u3002\u53c2\u8003 horizon_plugin_pytorch \u5feb\u901f\u5165\u95e8\u7ae0\u8282\u4e2d\u7684 ",(0,o.jsx)(e.a,{href:"./quick_start#Calibration",children:(0,o.jsx)(e.strong,{children:"Calibration"})})," \u5c0f\u8282\u5185\u5bb9\u3002\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"prepare_qat_fx"})," \u65b9\u6cd5\u8f6c\u5316\u6d6e\u70b9\u6a21\u578b\u524d\uff0c\u9700\u8981\u4e3a\u6a21\u578b\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"qconfig"})," \u3002"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    model.qconfig = horizon.quantization.get_default_qconfig()\n"})}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.code,{children:"get_default_qconfig"})," \u53ef\u4ee5\u4e3a ",(0,o.jsx)(e.code,{children:"weight"})," \u548c ",(0,o.jsx)(e.code,{children:"activation"})," \u8bbe\u7f6e\u4e0d\u540c\u7684 ",(0,o.jsx)(e.code,{children:"observer"})," \u3002\u76ee\u524d\uff0ccalibration \u53ef\u9009 ",(0,o.jsx)(e.code,{children:"observer"}),' \u6709 "min_max"\u3001 "percentile"\u3001 "mse"\u3001 "kl" \u548c "mix"\u3002\u5982\u65e0\u7279\u6b8a\u9700\u6c42\uff0c',(0,o.jsx)(e.code,{children:"weight_observer"}),' \u63a8\u8350\u4f7f\u7528\u9ed8\u8ba4\u7684 "min_max"\uff0c',(0,o.jsx)(e.code,{children:"activation_observer"}),' \u63a8\u8350\u4f7f\u7528 "mse"\u3002\u7279\u6b8a\u7528\u6cd5\u548c\u8c03\u8bd5\u6280\u5de7\u89c1\u4e0b\u9762\u7684\u5e38\u89c1\u7b97\u6cd5\u4ecb\u7ecd\u3002']}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsxs)(e.em,{children:[(0,o.jsx)(e.code,{children:"fake_quant"})," \u53c2\u6570\u5bf9 Calibration \u7ed3\u679c\u65e0\u5f71\u54cd\uff0c\u4fdd\u7559\u9ed8\u8ba4\u72b6\u6001\u5373\u53ef\u3002"]})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'    def get_default_qconfig(\n        activation_fake_quant: Optional[str] = "fake_quant",\n        weight_fake_quant: Optional[str] = "fake_quant",\n        activation_observer: Optional[str] = "min_max",\n        weight_observer: Optional[str] = "min_max",\n        activation_qkwargs: Optional[Dict] = None,\n        weight_qkwargs: Optional[Dict] = None,\n    ):\n'})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"fake quantize"})," \u72b6\u6001\u4e3a ",(0,o.jsx)(e.code,{children:"CALIBRATION"})," \u3002"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    horizon.quantization.set_fake_quantize(model, horizon.quantization.FakeQuantState.CALIBRATION)\n"})}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.code,{children:"fake quantize"})," \u4e00\u5171\u6709\u4e09\u79cd\u72b6\u6001\uff0c\u5206\u522b\u9700\u8981\u5728 ",(0,o.jsx)(e.code,{children:"QAT"})," \u3001 ",(0,o.jsx)(e.code,{children:"calibration"})," \u3001 ",(0,o.jsx)(e.code,{children:"validation"})," \u524d\u5c06\u6a21\u578b\u7684 ",(0,o.jsx)(e.code,{children:"fake quantize"})," \u8bbe\u7f6e\u4e3a\u5bf9\u5e94\u7684\u72b6\u6001\u3002\u5728 calibration \u72b6\u6001\u4e0b\uff0c\u4ec5\u89c2\u6d4b\u5404\u7b97\u5b50\u8f93\u5165\u8f93\u51fa\u7684\u7edf\u8ba1\u91cf\u3002\u5728 QAT \u72b6\u6001\u4e0b\uff0c\u9664\u89c2\u6d4b\u7edf\u8ba1\u91cf\u5916\u8fd8\u4f1a\u8fdb\u884c\u4f2a\u91cf\u5316\u64cd\u4f5c\u3002\u800c\u5728 validation \u72b6\u6001\u4e0b\uff0c\u4e0d\u4f1a\u89c2\u6d4b\u7edf\u8ba1\u91cf\uff0c\u4ec5\u8fdb\u884c\u4f2a\u91cf\u5316\u64cd\u4f5c\u3002"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'    class FakeQuantState(Enum):\n        QAT = "qat"\n        CALIBRATION = "calibration"\n        VALIDATION = "validation"\n'})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"calibration\u3002\u628a\u51c6\u5907\u597d\u7684\u6821\u51c6\u6570\u636e\u5582\u7ed9\u6a21\u578b\uff0c\u6a21\u578b\u5728 forward \u8fc7\u7a0b\u4e2d\u7531 observer \u89c2\u6d4b\u76f8\u5173\u7edf\u8ba1\u91cf\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u8bbe\u7f6e\u6a21\u578b\u72b6\u6001\u4e3a eval \u5e76\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"fake quantize"})," \u72b6\u6001\u4e3a ",(0,o.jsx)(e.code,{children:"VALIDATION"})," \u3002"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    model.eval()\n    horizon.quantization.set_fake_quantize(model, horizon.quantization.FakeQuantState.VALIDATION)\n"})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u9a8c\u8bc1 ",(0,o.jsx)(e.code,{children:"calibration"})," \u6548\u679c\u3002\u5982\u679c\u6548\u679c\u6ee1\u610f\uff0c\u5219\u53ef\u4ee5\u76f4\u63a5\u5c06\u6a21\u578b\u8f6c\u4e3a\u5b9a\u70b9\u6216\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u884c\u91cf\u5316\u8bad\u7ec3\uff0c\u4e0d\u6ee1\u610f\u5219\u8c03\u6574 ",(0,o.jsx)(e.code,{children:"calibration qconfig"})," \u4e2d\u7684\u53c2\u6570\u7ee7\u7eed calibration\u3002"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"\u5e38\u7528\u7b97\u6cd5\u4ecb\u7ecd",children:"\u5e38\u7528\u7b97\u6cd5\u4ecb\u7ecd"}),"\n",(0,o.jsx)(e.admonition,{title:"\u5907\u6ce8",type:"info",children:(0,o.jsx)(e.p,{children:"\u6709\u5173\u6bcf\u4e2a\u7b97\u5b50\u7684\u53c2\u6570\u8bf4\u660e\uff0c\u8bf7\u53c2\u8003\u6587\u672b API \u6587\u6863\u3002"})}),"\n",(0,o.jsxs)(e.table,{children:[(0,o.jsx)(e.thead,{children:(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.th,{children:"\u7b97\u6cd5"}),(0,o.jsx)(e.th,{children:"\u901f\u5ea6\u6392\u540d"}),(0,o.jsx)(e.th,{children:"\u7cbe\u5ea6\u6392\u540d"}),(0,o.jsx)(e.th,{children:"\u6613\u7528\u6027\u6392\u540d"})]})}),(0,o.jsxs)(e.tbody,{children:[(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"min_max"}),(0,o.jsx)(e.td,{children:"1"}),(0,o.jsx)(e.td,{children:"5"}),(0,o.jsx)(e.td,{children:"1"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"percentile"}),(0,o.jsx)(e.td,{children:"2"}),(0,o.jsx)(e.td,{children:"4"}),(0,o.jsx)(e.td,{children:"4"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"mse"}),(0,o.jsx)(e.td,{children:"4"}),(0,o.jsx)(e.td,{children:"1"}),(0,o.jsx)(e.td,{children:"2"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"kl"}),(0,o.jsx)(e.td,{children:"5"}),(0,o.jsx)(e.td,{children:"2"}),(0,o.jsx)(e.td,{children:"3"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"mix"}),(0,o.jsx)(e.td,{children:"3"}),(0,o.jsx)(e.td,{children:"2"}),(0,o.jsx)(e.td,{children:"1"})]})]})]}),"\n",(0,o.jsx)(e.p,{children:"\u5e38\u7528\u7684\u51e0\u79cd\u6821\u51c6\u65b9\u6cd5\u6027\u80fd\u5982\u4e0a\u8868\u6240\u793a\uff0c\u6570\u5b57\u8d8a\u5c0f\u8d8a\u597d\uff0c\u901f\u5ea6\u8868\u793a\u76f8\u540c\u6570\u636e\u6821\u51c6\u8017\u65f6\uff0c\u7cbe\u5ea6\u8868\u793a\u8be5\u65b9\u6cd5\u5728\u5927\u591a\u6570\u6a21\u578b\u4e0a\u7684\u6821\u51c6\u6548\u679c\uff0c\u6613\u7528\u6027\u8868\u793a\u8be5\u65b9\u6cd5\u7684\u8c03\u53c2\u590d\u6742\u5ea6\u3002"}),"\n",(0,o.jsx)(e.p,{children:"\u5bf9\u4e8e\u540c\u4e00\u6a21\u578b\u800c\u8a00\uff0c\u4e0d\u540c\u65b9\u6cd5\u4e0d\u540c\u53c2\u6570\u7684\u7cbe\u5ea6/\u901f\u5ea6\u4f1a\u5b58\u5728\u8f83\u5927\u5dee\u522b\uff0c\u6700\u65b0\u7684\u4e00\u4e9b\u7814\u7a76\u5de5\u4f5c\u4e5f\u8868\u660e\uff0c\u6ca1\u6709\u4e00\u79cd\u65b9\u6cd5\u53ef\u4ee5\u5728\u6240\u6709\u6a21\u578b\u4e0a\u90fd\u53d6\u5f97\u6700\u597d\u7684\u7cbe\u5ea6\uff0c\u9700\u8981\u9488\u5bf9\u5730\u8c03\u6574\u5176\u53c2\u6570\u3002\u6240\u4ee5\u63a8\u8350\u7528\u6237\u5bf9\u8fd9\u51e0\u79cd\u6821\u51c6\u65b9\u6cd5\u90fd\u8fdb\u884c\u5c1d\u8bd5\u3002"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"min_max\u3002\u6b64\u65b9\u6cd5\u4ec5\u7edf\u8ba1\u6700\u5927\u503c\u6700\u5c0f\u503c\u7684\u6ed1\u52a8\u5e73\u5747\uff0c\u7528\u4e8e\u5feb\u901f\u786e\u5b9a Batch size\u3001average_constant \u7b49\u901a\u7528\u53c2\u6570\uff0c\u6ca1\u6709\u592a\u591a\u6280\u5de7\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"percentile\u3002\u6b64\u65b9\u6cd5\u662f\u6240\u6709\u65b9\u6cd5\u4e2d\u7cbe\u5ea6\u4e0a\u9650\u6700\u9ad8\u7684\uff0c\u4f46\u4e5f\u662f\u8c03\u6574\u8d77\u6765\u6700\u9ebb\u70e6\u7684\uff0c\u5982\u679c\u901a\u8fc7\u5176\u4ed6\u65b9\u6cd5\u6216\u672c\u65b9\u6cd5\u7684\u9ed8\u8ba4\u53c2\u6570\u5c31\u53ef\u4ee5\u6ee1\u8db3\u7cbe\u5ea6\u8981\u6c42\uff0c\u90a3\u4e48\u4e0d\u5efa\u8bae\u5728\u8c03\u53c2\u4e0a\u82b1\u592a\u591a\u65f6\u95f4\u3002percentile \u53ef\u8c03\u7684\u53c2\u6570\u4e00\u5171\u6709\u4e24\u4e2a bins\u3001percentile\u3002bins \u8d8a\u591a\uff0cmax \u7684\u5019\u9009\u9879\u95f4\u9694\u8d8a\u5c0f\uff0c\u53ef\u4f9b\u8c03\u6574\u7684\u7c92\u5ea6\u8d8a\u7ec6\uff0c\u4f46\u4e5f\u610f\u5473\u7740\u66f4\u9ad8\u7684\u8ba1\u7b97\u8017\u65f6\u3002\u5efa\u8bae\u5148\u786e\u5b9a percentile \u518d\u8c03\u6574 bins\uff0c\u4e24\u8005\u4ea4\u66ff\u8fed\u4ee3\u7f29\u5c0f\u8c03\u53c2\u8303\u56f4\u76f4\u81f3\u8fbe\u5230\u6ee1\u610f\u7684\u6548\u679c\u3002\u7edd\u5927\u90e8\u5206\u60c5\u51b5\u4e0b bins \u53d6 2048 \u63d0\u4f9b\u7684\u8c03\u6574\u7c92\u5ea6\u5b8c\u5168\u8db3\u591f\uff0c\u4e0d\u9700\u8981\u5355\u72ec\u8c03\u6574\u8fd9\u4e2a\u53c2\u6570\u3002\u4ee5\u4e0b\u662f\u4e00\u4e2a\u6a21\u578b\u7684\u8c03\u53c2\u8def\u5f84\uff1a"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.table,{children:[(0,o.jsx)(e.thead,{children:(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.th,{children:"\u987a\u5e8f"}),(0,o.jsx)(e.th,{children:"percentile"}),(0,o.jsx)(e.th,{children:"bins"}),(0,o.jsx)(e.th,{children:"\u7cbe\u5ea6"})]})}),(0,o.jsxs)(e.tbody,{children:[(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"1"}),(0,o.jsx)(e.td,{children:"99.99"}),(0,o.jsx)(e.td,{children:"2048"}),(0,o.jsx)(e.td,{children:"53.75"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"2"}),(0,o.jsx)(e.td,{children:"99.99"}),(0,o.jsx)(e.td,{children:"4096"}),(0,o.jsx)(e.td,{children:"54.38"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"3"}),(0,o.jsx)(e.td,{children:"99.995"}),(0,o.jsx)(e.td,{children:"4096"}),(0,o.jsx)(e.td,{children:"16.25"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"4"}),(0,o.jsx)(e.td,{children:"99.985"}),(0,o.jsx)(e.td,{children:"4096"}),(0,o.jsx)(e.td,{children:"32.67"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"5"}),(0,o.jsx)(e.td,{children:"99.9875"}),(0,o.jsx)(e.td,{children:"4096"}),(0,o.jsx)(e.td,{children:"57.06"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"6"}),(0,o.jsx)(e.td,{children:"99.9875"}),(0,o.jsx)(e.td,{children:"8192"}),(0,o.jsx)(e.td,{children:"62.84"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"7"}),(0,o.jsx)(e.td,{children:"99.98875"}),(0,o.jsx)(e.td,{children:"8192"}),(0,o.jsx)(e.td,{children:"57.62"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"8"}),(0,o.jsx)(e.td,{children:"99.988125"}),(0,o.jsx)(e.td,{children:"8192"}),(0,o.jsx)(e.td,{children:"63.15"})]})]})]}),"\n",(0,o.jsx)(e.p,{children:"\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u53ef\u4ee5\u770b\u5230\u4ed4\u7ec6\u8c03\u6574\u540e\uff0c\u7cbe\u5ea6\u63d0\u5347\u4e86\u5927\u7ea6 10%\u3002\n\u6a21\u578b\u4e2d\u4e0d\u540c op \u7684\u8f93\u5165\u8f93\u51fa\u4e4b\u95f4\u5b58\u5728\u5f88\u5927\u5dee\u5f02\uff0c\u4e00\u7ec4\u5168\u5c40\u7684 percentile \u53c2\u6570\u53ef\u80fd\u5f88\u96be\u6ee1\u8db3\u6240\u6709 op \u7684\u9700\u6c42\uff0c\u5bf9\u7cbe\u5ea6\u8981\u6c42\u8f83\u9ad8\u65f6\uff0c\u53ef\u4ee5\u5148\u901a\u8fc7\u4e0a\u9762\u7684\u65b9\u6cd5\u627e\u5230\u8f83\u597d\u7684\u5168\u5c40\u53c2\u6570\uff0c\u518d\u901a\u8fc7 debug \u5de5\u5177\u627e\u5230\u8bef\u5dee\u8f83\u5927\u7684\u51e0\u4e2a op\uff0c\u5355\u72ec\u4e3a\u8fd9\u51e0\u4e2a op \u8bbe\u7f6e percentile \u53c2\u6570\uff0c\u8bbe\u7f6e\u65b9\u5f0f\u53c2\u7167 qconfig \u8bbe\u7f6e\u3002\u4e0b\u9762\u5217\u4e3e\u51e0\u79cd\u5e38\u89c1\u7684\u5bb9\u6613\u5bfc\u81f4\u8bef\u5dee\u8f83\u5927\u7684\u6570\u636e\u5206\u5e03\uff1a"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/calibration_percentile_longtail.png",alt:"calibration_percentile_longtail"})}),"\n",(0,o.jsx)(e.p,{children:"\u8d85\u957f\u5c3e\u5206\u5e03\uff0cpercentile \u7684\u53d6\u503c\u5e94\u5f53\u5c0f\u4e00\u4e9b\uff0c\u56fe\u4e2d 99.9 \u662f\u8f83\u597d\u7684\u53d6\u503c\u3002"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/calibration_percentile_bimodal.png",alt:"calibration_percentile_bimodal"})}),"\n",(0,o.jsx)(e.p,{children:"\u503c\u57df\u8fc7\u5927\uff0c\u4e14\u5206\u5e03\u5e76\u4e0d\u96c6\u4e2d\u5728\u4e00\u5904\uff0c\u8fd9\u79cd\u60c5\u51b5\u65e0\u8bba\u662f\u4fdd\u7559\u5c3e\u90e8\u8fd8\u662f\u5ffd\u7565\u5c3e\u90e8\u90fd\u4f1a\u5e26\u6765\u8f83\u5927\u7684\u7cbe\u5ea6\u635f\u5931\uff0c\u5e94\u8be5\u5728\u8bad\u7ec3\u6d6e\u70b9\u6a21\u578b\u65f6\u901a\u8fc7\u8c03\u6574 weight decay \u7b49\u53c2\u6570\u907f\u514d\u8fd9\u79cd\u60c5\u51b5\u7684\u51fa\u73b0\u3002"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/calibration_percentile_ln.png",alt:"calibration_percentile_ln"})}),"\n",(0,o.jsx)(e.p,{children:"layernorm \u7684\u8f93\u51fa\u5206\u5e03\u4f1a\u5448\u73b0\u51fa\u82e5\u5e72\u96c6\u4e2d\u5ea6\u975e\u5e38\u9ad8\u7684\u533a\u57df\uff0c\u6b64\u65f6 percentile \u6309\u7167\u6b63\u5e38\u65b9\u6cd5\u8c03\u6574\u5bf9\u4e8e\u91cf\u5316\u7ed3\u679c\u4e0d\u4f1a\u6709\u4efb\u4f55\u5f71\u54cd\uff0c\u9700\u8981\u5c06 percentile \u8c03\u6574\u5e45\u5ea6\u589e\u52a0\u3002"}),"\n",(0,o.jsxs)(e.ol,{start:"3",children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"mse\u3002\u53ef\u8c03\u6574\u7684\u53c2\u6570\u53ea\u6709 stride\uff0c\u9ed8\u8ba4 stride \u4e3a 1\uff0c\u4f1a\u9010\u6b65\u5c1d\u8bd5\u6700\u5927\u503c\u7684 100 \u5206\u4f4d\u5e76\u9009\u51fa\u91cf\u5316\u53cd\u91cf\u5316\u524d\u540e\u8bef\u5dee\u6700\u5c0f\uff08L2 \u8ddd\u79bb\uff09\u7684\u5206\u4f4d\u5bf9\u5e94\u7684\u503c\u3002\u6b64\u65b9\u6cd5\u5bf9\u5927\u6a21\u578b\u8017\u65f6\u8f83\u9ad8\uff0c\u5728\u5408\u7406\u8303\u56f4\u5185\u8c03\u5927 stride \u53ef\u4ee5\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u8017\u65f6\uff0cstride \u8c03\u6574\u8fc7\u5927\u4f1a\u5f71\u54cd\u7cbe\u5ea6\u3002\u6ce8\u610f\uff0c\u8c03\u6574\u6b64\u65b9\u6cd5\u7684\u53c2\u6570\u53ea\u80fd\u4f18\u5316\u8017\u65f6\uff0c\u5e76\u4e0d\u80fd\u663e\u8457\u63d0\u5347\u7cbe\u5ea6\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"kl\u3002\u53ef\u8c03\u7684\u53c2\u6570\u4e00\u5171\u6709\u4e24\u4e2a bin \u548c update_interval\u3002\u7531\u4e8e\u6b64\u65b9\u6cd5\u8017\u65f6\u8fc7\u957f\uff0c\u4e0d\u5efa\u8bae\u8c03\u6574\u9ed8\u8ba4 bin\uff0cupdate_interval \u9ed8\u8ba4\u4e3a 1\uff0c\u8c03\u5927\u53ef\u4ee5\u51cf\u5c11\u8017\u65f6\uff0c\u4f46\u9700\u8981\u4fdd\u8bc1 update_interval \u5c0f\u4e8e\u603b\u7684 calibration step\uff0c\u5426\u5219\u65e0\u6cd5\u5f97\u5230\u6b63\u5e38\u7684\u91cf\u5316\u53c2\u6570\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"mix\u3002\u6b64\u65b9\u6cd5\u4e3a\u6df7\u5408\u6821\u51c6\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u9700\u8981\u7edf\u8ba1\u7684\u5730\u65b9\uff0c\u90fd\u4f1a\u5c1d\u8bd5 percentile \u65b9\u6cd5\u7684\u4e0d\u540c\u53c2\u6570\uff0c\u9009\u51fa\u91cf\u5316\u53cd\u91cf\u5316\u524d\u540e\u8bef\u5dee\u6700\u5c0f\uff08L2 \u8ddd\u79bb\uff09\u7684\u65b9\u6cd5\u3002\u81ea\u52a8\u5316\u7a0b\u5ea6\u8f83\u9ad8\uff0c\u6ca1\u6709\u9700\u8981\u8c03\u6574\u7684\u53c2\u6570\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"\u8c03\u53c2\u6280\u5de7",children:"\u8c03\u53c2\u6280\u5de7"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"calibration \u6570\u636e\u8d8a\u591a\u8d8a\u597d\uff0c\u4f46\u56e0\u4e3a\u8fb9\u9645\u6548\u5e94\u7684\u5b58\u5728\uff0c\u5f53\u6570\u636e\u91cf\u5927\u5230\u4e00\u5b9a\u7a0b\u5ea6\u540e\uff0c\u5bf9\u7cbe\u5ea6\u7684\u63d0\u5347\u5c06\u975e\u5e38\u6709\u9650\u3002\u5982\u679c\u8bad\u7ec3\u96c6\u8f83\u5c0f\uff0c\u53ef\u4ee5\u5168\u90e8\u7528\u6765 calibration\uff0c\u5982\u679c\u8bad\u7ec3\u96c6\u8f83\u5927\uff0c\u53ef\u4ee5\u7ed3\u5408 calibration \u8017\u65f6\u6311\u9009\u5927\u5c0f\u5408\u9002\u7684\u5b50\u96c6\uff0c\u5efa\u8bae\u81f3\u5c11\u8fdb\u884c 10 - 100 \u4e2a step \u7684\u6821\u51c6\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6570\u636e\u53ef\u4ee5\u505a\u6c34\u5e73\u7ffb\u8f6c\u8fd9\u7c7b augmentation\uff0c\u4e0d\u8981\u505a\u9a6c\u8d5b\u514b\u8fd9\u79cd augmentation\u3002\u5c3d\u91cf\u4f7f\u7528 infer \u9636\u6bb5\u7684\u524d\u5904\u7406 + \u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u6821\u51c6\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Batch size \u5c3d\u53ef\u80fd\u5927\uff0c\u5982\u679c\u6570\u636e\u566a\u58f0\u8f83\u5927\u6216\u6a21\u578b\u79bb\u7fa4\u70b9\u8f83\u591a\uff0c\u53ef\u4ee5\u9002\u5f53\u51cf\u5c0f\u3002\u6b64\u53c2\u6570\u5e94\u5f53\u5728\u5c1d\u8bd5 min max \u65b9\u6cd5\u65f6\u786e\u5b9a\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"average_constant \u8868\u793a\u6bcf\u4e2a step \u5bf9\u6700\u5927\u503c\u6700\u5c0f\u503c\u7684\u5f71\u54cd\uff0caverage_constant \u8d8a\u5c0f\uff0c\u5f53\u524d step \u7684\u5f71\u54cd\u8d8a\u5c0f\uff0c\u5386\u53f2\u6ed1\u52a8\u5747\u503c\u7684\u5f71\u54cd\u8d8a\u5927\u3002\u8be5\u53c2\u6570\u9700\u8981\u7ed3\u5408\u6570\u636e\u91cf\u5728 0.01 ~ 0.5 \u4e4b\u95f4\u8c03\u6574\u3002\u5f53\u6570\u636e\u91cf\u5145\u8db3\u65f6\uff08step > 100\uff09\uff0caverage_constant \u53d6 0.01\uff0c\u6570\u636e\u91cf\u4e0d\u8db3\u65f6\uff0caverage_constant \u914c\u60c5\u589e\u52a0\uff0c\u6781\u7aef\u60c5\u51b5\u4e0b\uff0c\u53ea\u6709 2 \u4e2a step \u7684\u6570\u636e\uff0caverage_constant \u53d6 0.5\u3002\u6b64\u53c2\u6570\u5e94\u5f53\u5728\u5c1d\u8bd5 min max \u65b9\u6cd5\u65f6\u786e\u5b9a\uff0c\u4e4b\u540e\u5176\u4ed6\u65b9\u6cd5\u90fd\u6cbf\u7528\u6b64\u53c2\u6570\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"calibration \u6a21\u578b\u7cbe\u5ea6\u8f83\u597d\u65f6\uff0c\u56fa\u5b9a feature map \u7684\u91cf\u5316\u53c2\u6570\u8fdb\u884c QAT \u8bad\u7ec3\u53ef\u4ee5\u53d6\u5f97\u66f4\u597d\u7684\u6548\u679c\uff0c\u7cbe\u5ea6\u8f83\u5dee\u65f6\uff0c\u5219\u4e0d\u80fd\u56fa\u5b9a calibration \u5f97\u5230\u7684\u91cf\u5316\u53c2\u6570\u3002\u5173\u4e8e\u7cbe\u5ea6\u662f\u597d\u8fd8\u662f\u574f\uff0c\u6ca1\u6709\u660e\u786e\u7684\u6807\u51c6\uff0c\u9700\u8981\u53bb\u5c1d\u8bd5\u3002\u6bd4\u5982\uff1a\u67d0\u6a21\u578b\u7cbe\u5ea6\u4e3a 100\uff0c\u5982\u679c calibration  \u7cbe\u5ea6\u4e3a 50\uff0c\u90a3\u4e48\u7cbe\u5ea6\u80af\u5b9a\u79f0\u4e0d\u4e0a\u597d\uff0c\u4f46\u5982\u679c calibration \u7cbe\u5ea6\u4e3a 95\uff0c\u90a3\u4e48\u8fd9\u4e2a\u7cbe\u5ea6\u662f\u5426\u53ef\u4ee5\u8fbe\u5230\u56fa\u5b9a feature map \u91cf\u5316\u53c2\u6570\u7684\u7a0b\u5ea6\u5c31\u9700\u8981\u5c1d\u8bd5\u4e86\uff0c\u901a\u5e38\u505a\u6cd5\u662f\u56fa\u5b9a\u4e0e\u4e0d\u56fa\u5b9a\u90fd\u505a\u5b9e\u9a8c\u8fdb\u884c\u5bf9\u6bd4\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4f18\u5148\u5c1d\u8bd5 min max \u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u662f\u901f\u5ea6\u6700\u5feb\u7684\uff0c\u7528\u6765\u8dd1\u901a calibration \u6d41\u7a0b\uff0c\u8c03\u6574\u5e76\u786e\u5b9a batch size \u548c average_constant \u4e24\u4e2a\u53c2\u6570\uff0c\u63a5\u7740\u5206\u522b\u5c1d\u8bd5 percentile\u3001kl\u3001mse \u548c mix \u56db\u79cd\u65b9\u6cd5\u5e76\u9009\u53d6\u6548\u679c\u6700\u597d\u7684\u65b9\u6cd5\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"observer-\u53c2\u6570\u6587\u6863",children:"Observer \u53c2\u6570\u6587\u6863"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"\n    class horizon_plugin_pytorch.quantization.observer_v2.KLObserver(bins: int = 512, update_interval: int = 1, averaging_constant: float = 0.01, ch_axis: int = - 1, dtype: Union[torch.dtype, horizon_plugin_pytorch.dtype.QuantDType] = 'qint8', qscheme: torch.qscheme = torch.per_tensor_symmetric, quant_min: int = None, quant_max: int = None, is_sync_quantize: bool = False, factory_kwargs: Dict = None)\n\n"})}),"\n",(0,o.jsx)(e.p,{children:"KL observer.\nKL observer based on histogram. Histogram is calculated online and won\u2019t be saved."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"\u53c2\u6570"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"bins"})," \u2013 Number of histograms bins."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"update_interval"})," \u2013 Interval of computing KL entropy and update min/max. KLObserver will constantly collect histograms of activations, but only perform KL calculation when update_interval is satisfied. if it is set to 1, KL entropy will be computed every forward step. Larger interval guarantees less time and does no harm to calibration accuracy. Set it to the total calibration steps can achieve best performance. update_interval must be no greater than total calibration steps, otherwise no min/max will be computed."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"averaging_constant"})," \u2013 Averaging constant for min/max."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"ch_axis"})," \u2013 Channel axis."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"dtype"})," \u2013 Quantized data type."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"qscheme"})," \u2013 Quantization scheme to be used."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_min"})," \u2013 Min quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_max"})," \u2013 Max quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"is_sync_quantize"})," \u2013 If sync statistics when training with multiple devices."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"factory_kwargs"})," \u2013 kwargs which are passed to factory functions for min_val and max_val."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    forward(x_orig)\n"})}),"\n",(0,o.jsx)(e.p,{children:"Defines the computation performed at every call."}),"\n",(0,o.jsx)(e.p,{children:"Should be overridden by all subclasses."}),"\n",(0,o.jsx)(e.admonition,{title:"\u5c0f\u6280\u5de7",type:"info",children:(0,o.jsx)(e.p,{children:"Although the recipe for forward pass needs to be defined within this function, one should call the Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them."})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"\n    class horizon_plugin_pytorch.quantization.observer_v2.MSEObserver(stride: int = 1, averaging_constant: float = 0.01, ch_axis: int = - 1, dtype: Union[torch.dtype, horizon_plugin_pytorch.dtype.QuantDType] = 'qint8', qscheme: torch.qscheme = torch.per_tensor_symmetric, quant_min: int = None, quant_max: int = None, is_sync_quantize: bool = False, factory_kwargs: Dict = None)\n\n"})}),"\n",(0,o.jsx)(e.p,{children:"MSE observer."}),"\n",(0,o.jsx)(e.p,{children:"Observer module for computing the quantization parameters based on the Mean Square Error (MSE) between the original tensor and the quantized one."}),"\n",(0,o.jsx)(e.p,{children:"This observer linear searches the quantization scales that minimize MSE."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"\u53c2\u6570"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"stride"})," \u2013 Searching stride. Larger value gives smaller search space, which means less computing time but possibly poorer accuracy. Default is 1. Suggests no greater than 20."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"averaging_constant"})," \u2013 Averaging constant for min/max."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"ch_axis"})," \u2013 Channel axis."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"dtype"})," \u2013 Quantized data type."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"qscheme"})," \u2013 Quantization scheme to be used."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_min"})," \u2013 Min quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_max"})," \u2013 Max quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"is_sync_quantize"})," \u2013 If sync statistics when training with multiple devices."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"factory_kwargs"})," \u2013 kwargs which are passed to factory functions for min_val and max_val."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    forward(x_orig)\n"})}),"\n",(0,o.jsx)(e.p,{children:"Defines the computation performed at every call."}),"\n",(0,o.jsx)(e.p,{children:"Should be overridden by all subclasses."}),"\n",(0,o.jsx)(e.admonition,{title:"\u5c0f\u6280\u5de7",type:"info",children:(0,o.jsx)(e.p,{children:"Although the recipe for forward pass needs to be defined within this function, one should call the Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them."})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"\n    class horizon_plugin_pytorch.quantization.observer_v2.MinMaxObserver(averaging_constant: float = 0.01, ch_axis: int = - 1, dtype: Union[torch.dtype, horizon_plugin_pytorch.dtype.QuantDType] = 'qint8', qscheme: torch.qscheme = torch.per_tensor_symmetric, quant_min: int = None, quant_max: int = None, is_sync_quantize: bool = False, factory_kwargs: Dict = None)\n"})}),"\n",(0,o.jsx)(e.p,{children:"Min max observer."}),"\n",(0,o.jsx)(e.p,{children:"This observer computes the quantization parameters based on minimums and maximums of the incoming tensors. The module records the moving average minimum and maximum of incoming tensors, and uses this statistic to compute the quantization parameters."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"\u53c2\u6570"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"averaging_constant"})," \u2013 Averaging constant for min/max."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"ch_axis"})," \u2013 Channel axis."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"dtype"})," \u2013 Quantized data type."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"qscheme"})," \u2013 Quantization scheme to be used."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_min"})," \u2013 Min quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_max"})," \u2013 Max quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"is_sync_quantize"})," \u2013 If sync statistics when training with multiple devices."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"factory_kwargs"})," \u2013 kwargs which are passed to factory functions for min_val and max_val."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    forward(x_orig)\n"})}),"\n",(0,o.jsx)(e.p,{children:"Record the running minimum and maximum of x."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"\n    class horizon_plugin_pytorch.quantization.observer_v2.MixObserver(averaging_constant: float = 0.01, ch_axis: int = - 1, dtype: Union[torch.dtype, horizon_plugin_pytorch.dtype.QuantDType] = 'qint8', qscheme: torch.qscheme = torch.per_tensor_symmetric, quant_min: int = None, quant_max: int = None, is_sync_quantize: bool = False, factory_kwargs: Dict = None)\n\n"})}),"\n",(0,o.jsx)(e.p,{children:"Mix observer."}),"\n",(0,o.jsx)(e.p,{children:"This observer computes the quantization parameters based on multiple calibration methods and selects the quantization parameters with the smallest quantization error."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"\u53c2\u6570"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"averaging_constant"})," \u2013 Averaging constant for min/max."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"ch_axis"})," \u2013 Channel axis."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"dtype"})," \u2013 Quantized data type."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"qscheme"})," \u2013 Quantization scheme to be used."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_min"})," \u2013 Min quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_max"})," \u2013 Max quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"is_sync_quantize"})," \u2013 If sync statistics when training with multiple devices."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"factory_kwargs"})," \u2013 kwargs which are passed to factory functions for min_val and max_val."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    forward(x_orig)\n"})}),"\n",(0,o.jsx)(e.p,{children:"Defines the computation performed at every call."}),"\n",(0,o.jsx)(e.p,{children:"Should be overridden by all subclasses."}),"\n",(0,o.jsx)(e.admonition,{title:"\u5c0f\u6280\u5de7",type:"info",children:(0,o.jsx)(e.p,{children:"Although the recipe for forward pass needs to be defined within this function, one should call the Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them."})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"\n    class horizon_plugin_pytorch.quantization.observer_v2.PercentileObserver(percentile: float = 99.99, bins: int = 2048, averaging_constant: float = 0.01, ch_axis: int = - 1, dtype: Union[torch.dtype, horizon_plugin_pytorch.dtype.QuantDType] = 'qint8', qscheme: torch.qscheme = torch.per_tensor_symmetric, quant_min: int = None, quant_max: int = None, is_sync_quantize: bool = False, factory_kwargs: Dict = None)\n"})}),"\n",(0,o.jsx)(e.p,{children:"Percentile observer."}),"\n",(0,o.jsx)(e.p,{children:"Percentile observer based on histogram. Histogram is calculated online and won\u2019t be saved. The minimum and maximum are moving averaged to compute the quantization parameters."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"\u53c2\u6570"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"percentile"})," \u2013 Index percentile of histrogram"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"bins"})," \u2013 Number of histograms bins."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"averaging_constant"})," \u2013 Averaging constant for min/max."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"ch_axis"})," \u2013 Channel axis."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"dtype"})," \u2013 Quantized data type."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"qscheme"})," \u2013 Quantization scheme to be used."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_min"})," \u2013 Min quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_max"})," \u2013 Max quantization value. Will follow dtype if unspecified."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"is_sync_quantize"})," \u2013 If sync statistics when training with multiple devices."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"factory_kwargs"})," \u2013 kwargs which are passed to factory functions for min_val and max_val."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    forward(x_orig)\n"})}),"\n",(0,o.jsx)(e.p,{children:"Defines the computation performed at every call."}),"\n",(0,o.jsx)(e.p,{children:"Should be overridden by all subclasses."}),"\n",(0,o.jsx)(e.admonition,{title:"\u5c0f\u6280\u5de7",type:"info",children:(0,o.jsx)(e.p,{children:"Although the recipe for forward pass needs to be defined within this function, one should call the Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them."})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"\n    class horizon_plugin_pytorch.quantization.MovingAverageMinMaxObserver(averaging_constant=0.01, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, quant_min=None, quant_max=None, is_sync_quantize=False, factory_kwargs=None)\n"})}),"\n",(0,o.jsx)(e.p,{children:"MovingAverageMinMax Observer."}),"\n",(0,o.jsx)(e.p,{children:"Observer module for computing the quantization parameters based on the moving average of the min and max values."}),"\n",(0,o.jsx)(e.p,{children:"This observer computes the quantization parameters based on the moving averages of minimums and maximums of the incoming tensors. The module records the average minimum and maximum of incoming tensors, and uses this statistic to compute the quantization parameters."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"\u53c2\u6570"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"averaging_constant"})," \u2013 Averaging constant for min/max."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"dtype"})," \u2013 Quantized data type"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"qscheme"})," \u2013 Quantization scheme to be used, only support per_tensor_symmetric scheme"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"reduce_range"})," \u2013 Reduces the range of the quantized data type by 1 bit"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_min"})," \u2013 Minimum quantization value."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_max"})," \u2013 Maximum quantization value."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"is_sync_quantize"})," \u2013 Whether use sync quantize"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"factory_kwargs"})," \u2013 Arguments for register data buffer"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    forward(x_orig)\n"})}),"\n",(0,o.jsx)(e.p,{children:"Record the running minimum and maximum of x."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"\n    class horizon_plugin_pytorch.quantization.MovingAveragePerChannelMinMaxObserver(averaging_constant=0.01, ch_axis=0, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, quant_min=None, quant_max=None, is_sync_quantize=False, factory_kwargs=None)\n"})}),"\n",(0,o.jsx)(e.p,{children:"MovingAveragePerChannelMinMax Observer."}),"\n",(0,o.jsx)(e.p,{children:"Observer module for computing the quantization parameters based on the running per channel min and max values."}),"\n",(0,o.jsx)(e.p,{children:"This observer uses the tensor min/max statistics to compute the per channel quantization parameters. The module records the running minimum and maximum of incoming tensors, and uses this statistic to compute the quantization parameters."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"\u53c2\u6570"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"averaging_constant"})," \u2013 Averaging constant for min/max."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"ch_axis"})," \u2013 Channel axis"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"dtype"})," \u2013 Quantized data type"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"qscheme"})," \u2013 Quantization scheme to be used, Only support per_channel_symmetric"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_min"})," \u2013 Minimum quantization value."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"quant_max"})," \u2013 Maximum quantization value."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"is_sync_quantize"})," \u2013 whether use sync quantize"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"factory_kwargs"})," \u2013 Arguments for register data buffer"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"    forward(x_orig)\n"})}),"\n",(0,o.jsx)(e.p,{children:"Defines the computation performed at every call."}),"\n",(0,o.jsx)(e.p,{children:"Should be overridden by all subclasses."}),"\n",(0,o.jsx)(e.admonition,{title:"\u5c0f\u6280\u5de7",type:"info",children:(0,o.jsx)(e.p,{children:"Although the recipe for forward pass needs to be defined within this function, one should call the Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them."})}),"\n",(0,o.jsx)(e.h2,{id:"quantization",children:"\u91cf\u5316\u8bad\u7ec3\u6307\u5357"}),"\n",(0,o.jsx)(e.p,{children:"\u91cf\u5316\u8bad\u7ec3\u901a\u8fc7\u5728\u6a21\u578b\u4e2d\u63d2\u5165\u4e00\u4e9b\u4f2a\u91cf\u5316\u8282\u70b9\uff0c\u4ece\u800c\u4f7f\u5f97\u901a\u8fc7\u91cf\u5316\u8bad\u7ec3\u5f97\u5230\u7684\u6a21\u578b\u8f6c\u6362\u6210\u5b9a\u70b9\u6a21\u578b\u65f6\u5c3d\u53ef\u80fd\u51cf\u5c11\u7cbe\u5ea6\u635f\u5931\u3002\n\u91cf\u5316\u8bad\u7ec3\u548c\u4f20\u7edf\u7684\u6a21\u578b\u8bad\u7ec3\u65e0\u5f02\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u4ece\u96f6\u5f00\u59cb\uff0c\u642d\u5efa\u4e00\u4e2a\u4f2a\u91cf\u5316\u6a21\u578b\uff0c\u7136\u540e\u5bf9\u8be5\u4f2a\u91cf\u5316\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u3002\n\u7531\u4e8e\u90e8\u7f72\u7684\u786c\u4ef6\u5e73\u53f0\u6709\u8bf8\u591a\u9650\u5236\uff0c\u5bf9\u4e8e\u5f00\u53d1\u8005\u6765\u8bf4\uff0c\u641e\u6e05\u8fd9\u4e9b\u9650\u5236\uff0c\u5e76\u4e14\u6839\u636e\u8fd9\u4e9b\u9650\u5236\u642d\u5efa\u4f2a\u91cf\u5316\u6a21\u578b\u95e8\u69db\u8f83\u9ad8\u3002\u91cf\u5316\u8bad\u7ec3\u5de5\u5177\u901a\u8fc7\u5728\u5f00\u53d1\u8005\u63d0\u4f9b\u7684\u6d6e\u70b9\u6a21\u578b\u4e0a\u6839\u636e\u90e8\u7f72\u5e73\u53f0\u7684\u9650\u5236\u81ea\u52a8\u63d2\u5165\u4f2a\u91cf\u5316\u91cf\u5316\u7b97\u5b50\u7684\u65b9\u6cd5\uff0c\u964d\u4f4e\u5f00\u53d1\u8005\u5f00\u53d1\u91cf\u5316\u6a21\u578b\u7684\u95e8\u69db\u3002"}),"\n",(0,o.jsx)(e.p,{children:"\u91cf\u5316\u8bad\u7ec3\u7531\u4e8e\u65bd\u52a0\u4e86\u5404\u79cd\u9650\u5236\uff0c\u56e0\u6b64\uff0c\u4e00\u822c\u6765\u8bf4\uff0c\u91cf\u5316\u8bad\u7ec3\u6bd4\u7eaf\u6d6e\u70b9\u6a21\u578b\u7684\u8bad\u7ec3\u66f4\u52a0\u56f0\u96be\u3002\u91cf\u5316\u8bad\u7ec3\u5de5\u5177\u7684\u76ee\u6807\u662f\u964d\u4f4e\u91cf\u5316\u8bad\u7ec3\u7684\u96be\u5ea6\uff0c\u964d\u4f4e\u91cf\u5316\u6a21\u578b\u90e8\u7f72\u7684\u5de5\u7a0b\u96be\u5ea6\u3002"}),"\n",(0,o.jsx)(e.h3,{id:"\u6d41\u7a0b\u548c\u793a\u4f8b-1",children:"\u6d41\u7a0b\u548c\u793a\u4f8b"}),"\n",(0,o.jsx)(e.p,{children:"\u867d\u7136\u91cf\u5316\u8bad\u7ec3\u5de5\u5177\u4e0d\u5f3a\u5236\u8981\u6c42\u7528\u6237\u4ece\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684\u6d6e\u70b9\u6a21\u578b\u5f00\u59cb\uff0c\u4f46\u662f\uff0c\u7ecf\u9a8c\u8868\u660e\uff0c\u901a\u5e38\u4ece\u9884\u8bad\u7ec3\u7684\u9ad8\u7cbe\u5ea6\u6d6e\u70b9\u6a21\u578b\u5f00\u59cb\u91cf\u5316\u8bad\u7ec3\u80fd\u5927\u5927\u964d\u4f4e\u91cf\u5316\u8bad\u7ec3\u7684\u96be\u5ea6\u3002"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from horizon_plugin_pytorch.quantization import get_default_qconfig\n# \u5c06\u6a21\u578b\u8f6c\u4e3a QAT \u72b6\u6001\ndefault_qat_8bit_fake_quant_qconfig = get_default_qconfig(\n    activation_fake_quant="fake_quant",\n    weight_fake_quant="fake_quant",\n    activation_observer="min_max",\n    weight_observer="min_max",\n    activation_qkwargs=None,\n    weight_qkwargs={\n        "qscheme": torch.per_channel_symmetric,\n        "ch_axis": 0,\n    },\n)\ndefault_qat_out_8bit_fake_quant_qconfig = get_default_qconfig(\n    activation_fake_quant=None,\n    weight_fake_quant="fake_quant",\n    activation_observer=None,\n    weight_observer="min_max",\n    activation_qkwargs=None,\n    weight_qkwargs={\n        "qscheme": torch.per_channel_symmetric,\n        "ch_axis": 0,\n    },\n)\nqat_model = prepare_qat_fx(\n    float_model,\n    {\n        "": default_qat_8bit_fake_quant_qconfig,\n        "module_name": {\n            "classifier": default_qat_out_8bit_fake_quant_qconfig,\n        },\n    },\n).to(device)\n# \u52a0\u8f7d Calibration \u6a21\u578b\u4e2d\u7684\u91cf\u5316\u53c2\u6570\nqat_model.load_state_dict(calib_model.state_dict())\n# \u8fdb\u884c\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\n# \u4f5c\u4e3a\u4e00\u4e2a filetune \u8fc7\u7a0b\uff0c\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u4e00\u822c\u9700\u8981\u8bbe\u5b9a\u8f83\u5c0f\u7684\u5b66\u4e60\u7387\noptimizer = torch.optim.SGD(\n    qat_model.parameters(), lr=0.0001, weight_decay=2e-4\n)\n\nfor nepoch in range(epoch_num):\n    # \u6ce8\u610f\u6b64\u5904\u5bf9 QAT \u6a21\u578b training \u72b6\u6001\u7684\u63a7\u5236\u65b9\u6cd5\n    qat_model.train()\n    set_fake_quantize(qat_model, FakeQuantState.QAT)\n\n    train_one_epoch(\n        qat_model,\n        nn.CrossEntropyLoss(),\n        optimizer,\n        None,\n        train_data_loader,\n        device,\n    )\n\n    # \u6ce8\u610f\u6b64\u5904\u5bf9 QAT \u6a21\u578b eval \u72b6\u6001\u7684\u63a7\u5236\u65b9\u6cd5\n    qat_model.eval()\n    set_fake_quantize(qat_model, FakeQuantState.VALIDATION)\n\n    # \u6d4b\u8bd5 qat \u6a21\u578b\u7cbe\u5ea6\n    top1, top5 = evaluate(\n        qat_model,\n        eval_data_loader,\n        device,\n    )\n    print(\n        "QAT model: evaluation Acc@1 {:.3f} Acc@5 {:.3f}".format(\n            top1.avg, top5.avg\n        )\n    )\n\n# \u6d4b\u8bd5 quantized \u6a21\u578b\u7cbe\u5ea6\nquantized_model = convert_fx(qat_model.eval()).to(device)\n\ntop1, top5 = evaluate(\n    quantized_model,\n    eval_data_loader,\n    device,\n)\nprint(\n    "Quantized model: evaluation Acc@1 {:.3f} Acc@5 {:.3f}".format(\n        top1.avg, top5.avg\n    )\n)\n'})}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsx)(e.p,{children:"\u7531\u4e8e\u90e8\u7f72\u5e73\u53f0\u7684\u5e95\u5c42\u9650\u5236\uff0cQAT \u6a21\u578b\u65e0\u6cd5\u5b8c\u5168\u4ee3\u8868\u6700\u7ec8\u4e0a\u677f\u7cbe\u5ea6\uff0c\u8bf7\u52a1\u5fc5\u76d1\u63a7 quantized \u6a21\u578b\u7cbe\u5ea6\uff0c\u786e\u4fdd quantized \u6a21\u578b\u7cbe\u5ea6\u6b63\u5e38\uff0c\u5426\u5219\u53ef\u80fd\u51fa\u73b0\u6a21\u578b\u4e0a\u677f\u6389\u70b9\u95ee\u9898\u3002"})}),"\n",(0,o.jsx)(e.p,{children:"\u7531\u4e0a\u8ff0\u793a\u4f8b\u4ee3\u7801\u53ef\u4ee5\u770b\u5230\uff0c\u4e0e\u4f20\u7edf\u7684\u7eaf\u6d6e\u70b9\u6a21\u578b\u8bad\u7ec3\u76f8\u6bd4\uff0c\u91cf\u5316\u8bad\u7ec3\u591a\u4e86\u4e24\u4e2a\u6b65\u9aa4\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"prepare_qat_fx"}),"\n",(0,o.jsx)(e.li,{children:"\u52a0\u8f7d Calibration \u6a21\u578b\u53c2\u6570"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"prepare_qat_fx",children:"prepare_qat_fx"}),"\n",(0,o.jsx)(e.p,{children:"\u8fd9\u4e00\u6b65\u9aa4\u7684\u76ee\u6807\u662f\u5bf9\u6d6e\u70b9\u7f51\u7edc\u8fdb\u884c\u53d8\u6362\uff0c\u63d2\u5165\u4f2a\u91cf\u5316\u8282\u70b9\u3002"}),"\n",(0,o.jsx)(e.h4,{id:"\u52a0\u8f7d-calibration-\u6a21\u578b\u53c2\u6570",children:"\u52a0\u8f7d Calibration \u6a21\u578b\u53c2\u6570"}),"\n",(0,o.jsx)(e.p,{children:"\u901a\u8fc7\u52a0\u8f7d Calibration \u5f97\u5230\u7684\u4f2a\u91cf\u5316\u53c2\u6570\uff0c\u6765\u83b7\u5f97\u4e00\u4e2a\u8f83\u597d\u7684\u521d\u59cb\u5316\u3002"}),"\n",(0,o.jsx)(e.h4,{id:"\u8bad\u7ec3\u8fed\u4ee3",children:"\u8bad\u7ec3\u8fed\u4ee3"}),"\n",(0,o.jsx)(e.p,{children:"\u81f3\u6b64\uff0c\u5b8c\u6210\u4e86\u4f2a\u91cf\u5316\u6a21\u578b\u7684\u642d\u5efa\u548c\u53c2\u6570\u7684\u521d\u59cb\u5316\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u8fdb\u884c\u5e38\u89c4\u7684\u8bad\u7ec3\u8fed\u4ee3\u548c\u6a21\u578b\u53c2\u6570\u66f4\u65b0\uff0c\u5e76\u4e14\u76d1\u63a7 quantized \u6a21\u578b\u7cbe\u5ea6\u3002"}),"\n",(0,o.jsx)(e.h3,{id:"\u4f2a\u91cf\u5316\u7b97\u5b50",children:"\u4f2a\u91cf\u5316\u7b97\u5b50"}),"\n",(0,o.jsx)(e.p,{children:"\u91cf\u5316\u8bad\u7ec3\u548c\u4f20\u7edf\u7684\u6d6e\u70b9\u6a21\u578b\u7684\u8bad\u7ec3\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u63d2\u5165\u4e86\u4f2a\u91cf\u5316\u7b97\u5b50\uff0c\u5e76\u4e14\uff0c\u4e0d\u540c\u91cf\u5316\u8bad\u7ec3\u7b97\u6cd5\u4e5f\u662f\u901a\u8fc7\u4f2a\u91cf\u5316\u7b97\u5b50\u6765\u4f53\u73b0\u7684\uff0c\u56e0\u6b64\uff0c\u8fd9\u91cc\u4ecb\u7ecd\u4e00\u4e0b\u4f2a\u91cf\u5316\u7b97\u5b50\u3002"}),"\n",(0,o.jsx)(e.admonition,{title:"\u5907\u6ce8",type:"info",children:(0,o.jsx)(e.p,{children:"\u7531\u4e8e BPU \u53ea\u652f\u6301\u5bf9\u79f0\u91cf\u5316\uff0c\u56e0\u6b64\uff0c\u8fd9\u91cc\u4ee5\u5bf9\u79f0\u91cf\u5316\u4e3a\u4f8b\u4ecb\u7ecd\u3002"})}),"\n",(0,o.jsx)(e.h4,{id:"\u4f2a\u91cf\u5316\u8fc7\u7a0b",children:"\u4f2a\u91cf\u5316\u8fc7\u7a0b"}),"\n",(0,o.jsx)(e.p,{children:"\u4ee5 int8 \u91cf\u5316\u8bad\u7ec3\u4e3a\u4f8b\uff0c\u4e00\u822c\u6765\u8bf4\uff0c\u4f2a\u91cf\u5316\u7b97\u5b50\u7684\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\uff1a"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.code,{children:"fake_quant_x = clip(round(x / scale)\uff0c-128, 127) * scale"})}),"\n",(0,o.jsx)(e.p,{children:"\u548c Conv2d \u901a\u8fc7\u8bad\u7ec3\u6765\u4f18\u5316 weight, bias \u53c2\u6570\u7c7b\u4f3c\uff0c\u4f2a\u91cf\u5316\u7b97\u5b50\u8981\u901a\u8fc7\u8bad\u7ec3\u6765\u4f18\u5316 scale \u53c2\u6570\u3002\n\u7136\u800c\uff0c\u7531\u4e8e round \u4f5c\u4e3a\u9636\u68af\u51fd\u6570\uff0c\u5176\u68af\u5ea6\u4e3a 0\uff0c\u4ece\u800c\u5bfc\u81f4\u4e86\u4f2a\u91cf\u5316\u7b97\u5b50\u65e0\u6cd5\u76f4\u63a5\u901a\u8fc7\u68af\u5ea6\u53cd\u5411\u4f20\u64ad\u7684\u65b9\u5f0f\u8fdb\u884c\u8bad\u7ec3\u3002\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u901a\u5e38\u6709\u4e24\u79cd\u65b9\u6848\uff1a\u57fa\u4e8e\u7edf\u8ba1\u7684\u65b9\u6cd5\u548c\u57fa\u4e8e\u201c\u5b66\u4e60\u201d\u7684\u65b9\u6cd5\u3002"}),"\n",(0,o.jsx)(e.h4,{id:"\u57fa\u4e8e\u7edf\u8ba1\u7684\u65b9\u6cd5",children:"\u57fa\u4e8e\u7edf\u8ba1\u7684\u65b9\u6cd5"}),"\n",(0,o.jsx)(e.p,{children:"\u91cf\u5316\u5730\u76ee\u6807\u662f\u628a Tensor \u4e2d\u7684\u6d6e\u70b9\u6570\u901a\u8fc7 scale \u53c2\u6570\u5747\u5300\u5730\u6620\u5c04\u5230 int8 \u8868\u793a\u7684 [-128, 127] \u7684\u8303\u56f4\u4e0a\u3002\u65e2\u7136\u662f\u5747\u5300\u6620\u5c04\uff0c\u90a3\u4e48\u5f88\u5bb9\u6613\u5f97\u5230 scale \u7684\u8ba1\u7b97\u65b9\u6cd5\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"def compute_scale(x: Tensor):\n    xmin, xmax = x.max(), maxv = x.min()\n    return max(xmin.abs(), xmax.abs()) / 256.0\n"})}),"\n",(0,o.jsxs)(e.p,{children:["\u7531\u4e8e Tensor \u4e2d\u6570\u636e\u5206\u5e03\u4e0d\u5747\u5300\u4ee5\u53ca\u5916\u70b9\u95ee\u9898\uff0c\u53c8\u884d\u751f\u4e86\u4e0d\u540c\u7684\u8ba1\u7b97 xmin \u548c xmax \u7684\u65b9\u6cd5\u3002\u53ef\u4ee5\u53c2\u8003 ",(0,o.jsx)(e.code,{children:"MovingAverageMinMaxObserver"})," \u7b49\u3002"]}),"\n",(0,o.jsxs)(e.p,{children:["\u5728\u5de5\u5177\u4e2d\u7684\u4f7f\u7528\u65b9\u6cd5\u8bf7\u53c2\u8003 ",(0,o.jsx)(e.code,{children:"default_qat_8bit_fake_quant_qconfig"})," \u53ca\u5176\u76f8\u5173\u63a5\u53e3\u3002"]}),"\n",(0,o.jsx)(e.h4,{id:"\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5",children:"\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5"}),"\n",(0,o.jsx)(e.p,{children:"\u867d\u7136 round \u7684\u68af\u5ea6\u4e3a 0\uff0c\u7814\u7a76\u8005\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5728\u8be5\u573a\u666f\u4e0b\uff0c\u5982\u679c\u76f4\u63a5\u8bbe\u7f6e\u5176\u68af\u5ea6\u4e3a 1 \u4e5f\u53ef\u4ee5\u4f7f\u5f97\u6a21\u578b\u6536\u655b\u5230\u9884\u671f\u7684\u7cbe\u5ea6\u3002"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"def round_ste(x: Tensor):\n    return (x.round() - x).detach() + x\n"})}),"\n",(0,o.jsxs)(e.p,{children:["\u5728\u5de5\u5177\u4e2d\u7684\u4f7f\u7528\u65b9\u6cd5\u8bf7\u53c2\u8003 ",(0,o.jsx)(e.code,{children:"default_qat_8bit_lsq_quant_qconfig"})," \u53ca\u5176\u76f8\u5173\u63a5\u53e3\u3002"]}),"\n",(0,o.jsxs)(e.p,{children:["\u6709\u5174\u8da3\u8fdb\u4e00\u6b65\u4e86\u89e3\u7684\u7528\u6237\u53ef\u4ee5\u53c2\u8003\u5982\u4e0b\u8bba\u6587\uff1a",(0,o.jsx)(e.a,{href:"https://arxiv.org/abs/1902.08153",children:(0,o.jsx)(e.strong,{children:"Learned Step Size Quantization"})})]}),"\n",(0,o.jsx)(e.h2,{id:"\u5f02\u6784\u6a21\u578b\u6307\u5357",children:"\u5f02\u6784\u6a21\u578b\u6307\u5357"}),"\n",(0,o.jsx)(e.h3,{id:"\u5f02\u6784\u6a21\u578b\u4ecb\u7ecd",children:"\u5f02\u6784\u6a21\u578b\u4ecb\u7ecd"}),"\n",(0,o.jsx)(e.p,{children:"\u5f02\u6784\u6a21\u578b\u662f\u90e8\u7f72\u65f6\u4e00\u90e8\u5206\u8fd0\u884c\u5728 BPU \u4e0a\uff0c\u4e00\u90e8\u5206\u8fd0\u884c\u5728 CPU \u4e0a\u7684\u6a21\u578b\uff0c\u800c\u975e\u5f02\u6784\u6a21\u578b\u90e8\u7f72\u65f6\u5219\u5b8c\u5168\u8fd0\u884c\u5728 BPU \u4e0a\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4ee5\u4e0b\u4e24\u7c7b\u6a21\u578b\u5728\u90e8\u7f72\u65f6\u4f1a\u6210\u4e3a\u5f02\u6784\u6a21\u578b\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u5305\u542b BPU \u4e0d\u652f\u6301\u7b97\u5b50\u7684\u6a21\u578b\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u7531\u4e8e\u91cf\u5316\u7cbe\u5ea6\u8bef\u5dee\u8fc7\u5927\uff0c\u7528\u6237\u6307\u5b9a\u67d0\u4e9b\u7b97\u5b50\u8fd0\u884c\u5728 CPU \u4e0a\u7684\u6a21\u578b\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"\u4f7f\u7528\u6d41\u7a0b",children:"\u4f7f\u7528\u6d41\u7a0b"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/hybrid_qat_workflow.svg",alt:"hybrid_qat_workflow"})}),"\n",(0,o.jsx)(e.p,{children:"\u901a\u8fc7 prepare \u5c06\u6d6e\u70b9\u6a21\u578b\u8f6c\u4e3a QAT \u6a21\u578b\uff0c\u8bad\u7ec3\u4e4b\u540e\u5bfc\u51fa\u4e3a onnx \u683c\u5f0f\u6a21\u578b\uff0c\u7531 hb_mapper \u5de5\u5177\u8f6c\u4e3a bin \u6a21\u578b\u3002"}),"\n",(0,o.jsx)(e.admonition,{title:"\u5907\u6ce8",type:"info",children:(0,o.jsx)(e.p,{children:"\u7528\u6237\u53ef\u4ee5\u901a\u8fc7 convert \u8fc7\u7a0b\u5f97\u5230\u5f02\u6784\u5b9a\u70b9\u6a21\u578b\uff0c\u7528\u4e8e\u6a21\u578b\u7cbe\u5ea6\u8bc4\u6d4b\u3002"})}),"\n",(0,o.jsx)(e.h3,{id:"\u7b97\u5b50\u9650\u5236",children:"\u7b97\u5b50\u9650\u5236"}),"\n",(0,o.jsx)(e.p,{children:"\u7531\u4e8e\u5f02\u6784\u6a21\u578b\u5bf9\u63a5\u7684\u662f horizon_nn\uff0c\u56e0\u6b64\uff0c\u5176\u7b97\u5b50\u7684\u652f\u6301\u60c5\u51b5\u548c horizon_nn \u76f8\u540c\u3002"}),"\n",(0,o.jsx)(e.h3,{id:"\u4e3b\u8981\u63a5\u53e3\u53c2\u6570\u8bf4\u660e",children:"\u4e3b\u8981\u63a5\u53e3\u53c2\u6570\u8bf4\u660e"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.code,{children:"horizon_plugin_pytorch.quantization.prepare_qat_fx"})}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"hybrid=True"})," \u6765\u5f00\u542f\u5f02\u6784\u6a21\u578b\u529f\u80fd\u3002"]}),"\n",(0,o.jsxs)(e.li,{children:["\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"hybrid_dict"})," \u53c2\u6570\u6765\u5f3a\u5236\u6307\u5b9a\u67d0\u4e9b BPU \u652f\u6301\u7684\u7b97\u5b50\u8dd1\u5728 CPU \u4e0a\u3002"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def prepare_qat_fx(\n    model: Union[torch.nn.Module, GraphModule],\n    qconfig_dict: Dict[str, Any] = None,\n    prepare_custom_config_dict: Dict[str, Any] = None,\n    optimize_graph: bool = False,\n    hybrid: bool = False,\n    hybrid_dict: Dict[str, List] = None,\n) -> ObservedGraphModule:\n    """Prepare QAT \u6a21\u578b\n        `model`: torch.nn.Module \u6216 GraphModule(\u4f7f\u7528 fuse_fx \u540e\u7684\u6a21\u578b)\n        `qconfig_dict`: \u5b9a\u4e49 Qconfig\u3002\u5982\u679c\u9664\u4e86 qconfig_dict \u4ee5\u5916\uff0c\u8fd8\u4f7f\u7528\u4e86 eager mode \u5728 module \u5185\u5b9a\u4e49 qconfig \u7684\u65b9\u5f0f\uff0c\u5219 module \u5185\u5b9a\u4e49\u7684 qconfig \u4f18\u5148\u751f\u6548\u3002qconfig_dict \u7684\u914d\u7f6e\u683c\u5f0f\u5982\u4e0b\uff1a\n            qconfig_dict = {\n                # \u53ef\u9009\uff0c\u5168\u5c40\u914d\u7f6e\n                "": qconfig,\n                # \u53ef\u9009\uff0c\u6309 module \u7c7b\u578b\u914d\u7f6e\n                "module_type": [(torch.nn.Conv2d, qconfig), ...],\n                # \u53ef\u9009\uff0c\u6309 module \u540d\u914d\u7f6e\n                "module_name": [("foo.bar", qconfig),...],\n                # \u4f18\u5148\u7ea7\uff1aglobal < module_type < module_name < module.qconfig\n                # \u975e module \u7c7b\u578b\u7684\u7b97\u5b50\u7684 qconfig \u9ed8\u8ba4\u4e0e\u5176\u7236 module \u7684 qconfig \u4fdd\u6301\u4e00\u81f4\uff0c\u5982\u679c\u9700\u8981\u5355\u72ec\u8bbe\u7f6e\uff0c\u8bf7\u5c06\u8fd9\u90e8\u5206\u5355\u72ec\u5c01\u88c5\u6210 module\u3002\n            }\n        `prepare_custom_config_dict`: \u81ea\u5b9a\u4e49\u914d\u7f6e\u5b57\u5178\n            prepare_custom_config_dict = {\n                # \u6682\u65f6\u53ea\u652f\u6301 preserved_attributes\u3002\u4e00\u822c\u800c\u8a00\u4f1a\u81ea\u52a8\u4fdd\u7559\u6240\u6709\u5c5e\u6027\uff0c\u8fd9\u4e2a\u9009\u9879\u53ea\u662f\u4ee5\u9632\u4e07\u4e00\uff0c\u51e0\u4e4e\u4e0d\u4f1a\u7528\u5230\u3002\n                "preserved_attributes": ["preserved_attr"],\n            }\n        `optimize_graph`: \u4fdd\u6301 cat \u8f93\u5165\u8f93\u51fa scale \u4e00\u81f4\uff0c\u76ee\u524d\u53ea\u6709\u5728 Bernoulli \u67b6\u6784\u4e0b\u6709\u6548\u3002\n        `hybrid`: \u662f\u5426\u4f7f\u7528\u5f02\u6784\u6a21\u5f0f\u3002\u5728\u4ee5\u4e0b\u60c5\u51b5\u4e0b\u5fc5\u987b\u6253\u5f00\u5f02\u6784\u6a21\u5f0f\uff1a\n            1. \u6a21\u578b\u5305\u542b BPU \u4e0d\u652f\u6301\u7684\u7b97\u5b50\u6216\u7528\u6237\u5e0c\u671b\u6307\u5b9a\u90e8\u5206 BPU \u7b97\u5b50\u9000\u56de CPU\u3002\n            2. \u7528\u6237\u5e0c\u671b QAT \u6a21\u578b\u4e0e horizon_nn \u5bf9\u63a5\u8fdb\u884c\u5b9a\u70b9\u5316\u3002\n        `hybrid_dict`: \u5b9a\u4e49\u7528\u6237\u4e3b\u52a8\u6307\u5b9a\u7684 CPU \u7b97\u5b50\u3002\n            hybrid_dict = {\n                # \u53ef\u9009\uff0c\u6309 module \u7c7b\u578b\u914d\u7f6e\n                "module_type": [torch.nn.Conv2d, ...],\n                # \u53ef\u9009\uff0c\u6309 module \u540d\u914d\u7f6e\n                "module_name": ["foo.bar", ...],\n                # \u4f18\u5148\u7ea7\uff1amodule_type < module_name\n                # \u4e0e qconfig_dict \u7c7b\u4f3c\uff0c\u5982\u679c\u60f3\u8981\u975e module \u7c7b\u578b\u7684\u7b97\u5b50\u8fd0\u884c\u5728 CPU \u4e0a\uff0c\u9700\u8981\u5c06\u8fd9\u90e8\u5206\u5355\u72ec\u5c01\u88c5\u6210 module\u3002\n            }\n    """\n'})}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.code,{children:"horizon_plugin_pytorch.utils.onnx_helper.export_to_onnx"})}),"\n",(0,o.jsxs)(e.p,{children:["\u5bfc\u51fa ",(0,o.jsx)(e.code,{children:"onnx"})," \u6a21\u578b\uff0c\u4ece\u800c\u5bf9\u63a5 ",(0,o.jsx)(e.code,{children:"hb_mapper"})," \u3002"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u5907\u6ce8",type:"info",children:(0,o.jsx)(e.p,{children:"\u8be5\u63a5\u53e3\u4e5f\u652f\u6301\u975e\u5f02\u6784\u6a21\u578b\uff0c\u5176\u5bfc\u51fa\u7684 ONNX \u683c\u5f0f\u6a21\u578b\u4ec5\u7528\u4e8e\u53ef\u89c6\u5316\u3002"})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def export_to_onnx(\n    model,\n    args,\n    f,\n    export_params=True,\n    verbose=False,\n    training=TrainingMode.EVAL,\n    input_names=None,\n    output_names=None,\n    operator_export_type=OperatorExportTypes.ONNX_FALLTHROUGH,\n    opset_version=11,\n    do_constant_folding=True,\n    example_outputs=None,\n    strip_doc_string=True,\n    dynamic_axes=None,\n    keep_initializers_as_inputs=None,\n    custom_opsets=None,\n    enable_onnx_checker=False,\n):\n    """\u6b64\u63a5\u53e3\u4e0e torch.onnx.export \u57fa\u672c\u4e00\u81f4\uff0c\u9690\u85cf\u4e86\u65e0\u9700\u4fee\u6539\u7684\u53c2\u6570\uff0c\u9700\u8981\u7684\u6ce8\u610f\u53c2\u6570\u6709\uff1a\n        `model`: \u9700\u8981 export \u7684\u6a21\u578b\n        `args`: \u6a21\u578b\u8f93\u5165\uff0c\u7528\u4e8e trace \u6a21\u578b\n        `f`: \u4fdd\u5b58\u7684 onnx \u6587\u4ef6\u540d\u6216\u6587\u4ef6\u63cf\u8ff0\u7b26\n        `operator_export_type`: \u7b97\u5b50\u5bfc\u51fa\u7c7b\u578b\n            1. \u5bf9\u4e8e\u975e\u5f02\u6784\u6a21\u578b\uff0connx \u4ec5\u7528\u4e8e\u53ef\u89c6\u5316\uff0c\u4e0d\u9700\u8981\u4fdd\u8bc1\u5b9e\u9645\u53ef\u7528\uff0c\u4f7f\u7528\u9ed8\u8ba4\u503c OperatorExportTypes.ONNX_FALLTHROUGH\n            2. \u5bf9\u4e8e\u5f02\u6784\u6a21\u578b\uff0connx \u9700\u8981\u4fdd\u8bc1\u5b9e\u9645\u53ef\u7528\uff0c\u4f7f\u7528 None \u786e\u4fdd\u5bfc\u51fa\u7684\u4e3a\u6807\u51c6 onnx \u7b97\u5b50\u3002\n        `opset_version`: \u53ea\u80fd\u4e3a 11\uff0chorizon_plugin_pytorch \u5728 opset 11 \u4e2d\u6ce8\u518c\u4e86\u7279\u5b9a\u7684\u6620\u5c04\u89c4\u5219\u3002\n        \u6ce8\u610f\uff1a\u5982\u679c\u4f7f\u7528\u516c\u7248 torch.onnx.export\uff0c\u9700\u8981\u786e\u4fdd\u4e0a\u8ff0\u53c2\u6570\u8bbe\u7f6e\u6b63\u786e\uff0c\n        \u5e76\u4e14 import horizon_plugin_pytorch.utils._register_onnx_ops\n        \u4ee5\u5411 opset 11 \u4e2d\u6ce8\u518c\u7279\u5b9a\u7684\u6620\u5c04\u89c4\u5219\u3002\n    """\n'})}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.code,{children:"horizon_plugin_pytorch.quantization.convert_fx"})}),"\n",(0,o.jsxs)(e.p,{children:["\u5f02\u6784\u6a21\u5f0f\u53ef\u4ee5\u590d\u7528 ",(0,o.jsx)(e.code,{children:"convert_fx"})," \u628a\u4f2a\u91cf\u5316\u6a21\u578b\u8f6c\u6362\u6210\u5f02\u6784\u91cf\u5316\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u6d4b\u6a21\u578b\u7cbe\u5ea6\u3002"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsx)(e.p,{children:"\u901a\u8fc7 convert_fx \u5f97\u5230\u7684\u5f02\u6784\u91cf\u5316\u6a21\u578b\u65e0\u6cd5\u8fdb\u884c\u90e8\u7f72\u3002\u76ee\u524d\u4ec5\u7528\u4e8e\u8bc4\u6d4b\u6a21\u578b\u7cbe\u5ea6\u3002"})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def convert_fx(\n    graph_module: GraphModule,\n    convert_custom_config_dict: Dict[str, Any] = None,\n    _remove_qconfig: bool = True,\n) -> QuantizedGraphModule:\n    """\u8f6c\u6362 QAT \u6a21\u578b\uff0c\u4ec5\u7528\u4e8e\u8bc4\u6d4b\u5b9a\u70b9\u6a21\u578b\u3002\n        `graph_module`: \u7ecf\u8fc7 prepare->(calibration)->train \u4e4b\u540e\u7684\u6a21\u578b\n        `convert_custom_config_dict`: \u81ea\u5b9a\u4e49\u914d\u7f6e\u5b57\u5178\n            convert_custom_config_dict = {\n                # \u6682\u65f6\u53ea\u652f\u6301 preserved_attributes\u3002\u4e00\u822c\u800c\u8a00\u4f1a\u81ea\u52a8\u4fdd\u7559\u6240\u6709\u5c5e\u6027\uff0c\u8fd9\u4e2a\u9009\u9879\u53ea\u662f\u4ee5\u9632\u4e07\u4e00\uff0c\u51e0\u4e4e\u4e0d\u4f1a\u7528\u5230\u3002\n                "preserved_attributes": ["preserved_attr"],\n            }\n        `_remove_qconfig`: convert \u4e4b\u540e\u662f\u5426\u5220\u9664 qconfig\uff0c\u4e00\u822c\u4e0d\u4f1a\u7528\u5230\n    """\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u6d41\u7a0b\u548c\u793a\u4f8b-2",children:"\u6d41\u7a0b\u548c\u793a\u4f8b"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6539\u9020\u6d6e\u70b9\u6a21\u578b\u3002"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u63d2\u5165 ",(0,o.jsx)(e.code,{children:"QuantStub"})," \u4e0e ",(0,o.jsx)(e.code,{children:"DeQuantStub"})," \uff0c\u4fdd\u6301\u4e0e\u975e\u5f02\u6784\u7684\u7528\u6cd5\u4e00\u81f4\u3002"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u5982\u679c\u7b2c\u4e00\u4e2a op \u662f ",(0,o.jsx)(e.code,{children:"cpu op"})," \uff0c\u90a3\u4e48\u4e0d\u9700\u8981\u63d2\u5165 ",(0,o.jsx)(e.code,{children:"QuantStub"})," \u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u5982\u679c\u6700\u540e\u4e00\u4e2a op \u662f ",(0,o.jsx)(e.code,{children:"cpu op"})," \uff0c\u90a3\u4e48\u53ef\u4ee5\u4e0d\u7528\u63d2\u5165 ",(0,o.jsx)(e.code,{children:"DeQuantStub"})," \u3002"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u5bf9\u4e8e\u975e ",(0,o.jsx)(e.code,{children:"module"})," \u7684\u8fd0\u7b97\uff0c\u5982\u679c\u9700\u8981\u5355\u72ec\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"qconfig"})," \u6216\u6307\u5b9a\u5176\u8fd0\u884c\u5728 CPU \u4e0a\uff0c\u9700\u8981\u5c06\u5176\u5c01\u88c5\u6210 ",(0,o.jsx)(e.code,{children:"module"})," \uff0c\u53c2\u8003\u793a\u4f8b\u4e2d\u7684 ",(0,o.jsx)(e.code,{children:"_SeluModule"})," \u3002"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"march"})," \u3002 ",(0,o.jsx)(e.strong,{children:"RDK X3"})," \u8bbe\u7f6ebernoulli2\uff0c ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u8bbe\u7f6e\u4e3abayes\uff0c ",(0,o.jsx)(e.strong,{children:"RDK X5"})," \u8bbe\u7f6e\u4e3abayes-e\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"qconfig"})," \u3002\u4fdd\u7559\u975e\u5f02\u6784\u6a21\u5f0f\u4e0b\u5728 ",(0,o.jsx)(e.code,{children:"module"})," \u5185\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"qconfig"})," \u7684\u914d\u7f6e\u65b9\u5f0f\uff0c\u9664\u6b64\u4ee5\u5916\uff0c\u8fd8\u53ef\u4ee5\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"prepare_qat_fx"})," \u63a5\u53e3\u7684 ",(0,o.jsx)(e.code,{children:"qconfig_dict"})," \u53c2\u6570\u4f20\u5165 ",(0,o.jsx)(e.code,{children:"qconfig"}),"\uff0c\u5177\u4f53\u7528\u6cd5\u89c1\u63a5\u53e3\u53c2\u6570\u8bf4\u660e\u3002"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u5bf9\u4e8e ",(0,o.jsx)(e.code,{children:"BPU op"})," \uff0c\u5fc5\u987b\u4fdd\u8bc1\u6709 ",(0,o.jsx)(e.code,{children:"qconfig"})," \uff0c\u5982\u679c\u5176\u8f93\u5165 op \u4e0d\u4e3a ",(0,o.jsx)(e.code,{children:"QuantStub"})," \uff0c\u90a3\u4e48\u8fd8\u9700\u8981\u4fdd\u8bc1\u8be5\u8f93\u5165 op \u6709 ",(0,o.jsx)(e.code,{children:"activation qconfig"})," \u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u5bf9\u4e8e ",(0,o.jsx)(e.code,{children:"CPU op"})," \uff0c",(0,o.jsx)(e.code,{children:"qconfig"})," \u4e0d\u4f1a\u5bf9\u5176\u4ea7\u751f\u4efb\u4f55\u5f71\u54cd\uff0c\u4f46\u5982\u679c\u540e\u9762\u63a5 ",(0,o.jsx)(e.code,{children:"BPU op"})," \uff0c\u5219\u5fc5\u987b\u6709 ",(0,o.jsx)(e.code,{children:"qconfig"})," \u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u63a8\u8350\u8bbe\u7f6e\u65b9\u5f0f\uff1a\u5148\u8bbe\u7f6e\u5168\u5c40 ",(0,o.jsx)(e.code,{children:"qconfig"})," \u4e3a ",(0,o.jsx)(e.code,{children:"horizon.quantization.default_qat_8bit_fake_quant_qconfig"})," (\u6216\u8005 ",(0,o.jsx)(e.code,{children:"horizon.quantization.default_calib_8bit_fake_quant_qconfig"})," \uff0c\u6839\u636e calibration \u6216 qat \u9636\u6bb5\u9009\u62e9) \uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u6839\u636e\u9700\u6c42\u4fee\u6539\uff0c\u4e00\u822c\u800c\u8a00\uff0c\u53ea\u9700\u8981\u5bf9 int16 \u548c\u9ad8\u7cbe\u5ea6\u8f93\u51fa\u7684 op \u5355\u72ec\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"qconfig"})," \u3002"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u548c  ",(0,o.jsx)(e.code,{children:"BAYES_E"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK X5"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]})}),"\n",(0,o.jsxs)(e.ol,{start:"4",children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"hybrid_dict"})," \u3002\u53ef\u9009\uff0c\u5177\u4f53\u7528\u6cd5\u89c1\u63a5\u53e3\u53c2\u6570\u8bf4\u660e\uff0c\u5982\u679c\u6ca1\u6709\u4e3b\u52a8\u6307\u5b9a\u7684 CPU \u7b97\u5b50\uff0c\u53ef\u4ee5\u4e0d\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"hybrid_dict"})," \u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u8c03\u7528 ",(0,o.jsx)(e.code,{children:"prepare_qat_fx"})," \u5e76\u8fdb\u884c ",(0,o.jsx)(e.code,{children:"calibration"})," \u3002\u53c2\u8003 horizon_plugin_pytorch \u5f00\u53d1\u6307\u5357\u7ae0\u8282\u4e2d\u7684 ",(0,o.jsx)(e.a,{href:"#Calibration",children:(0,o.jsx)(e.strong,{children:"Calibration"})})," \u5c0f\u8282\u5185\u5bb9\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u8c03\u7528 ",(0,o.jsx)(e.code,{children:"prepare_qat_fx"})," \uff0c\u52a0\u8f7d ",(0,o.jsx)(e.code,{children:"calibration"})," \u6a21\u578b\u5e76\u8fdb\u884c QAT \u8bad\u7ec3\u3002\u53c2\u8003 horizon_plugin_pytorch \u5f00\u53d1\u6307\u5357\u7ae0\u8282\u4e2d\u7684 ",(0,o.jsx)(e.a,{href:"#quantization",children:(0,o.jsx)(e.strong,{children:"\u91cf\u5316\u8bad\u7ec3"})})," \u5c0f\u8282\u5185\u5bb9\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u8c03\u7528 ",(0,o.jsx)(e.code,{children:"convert_fx"})," \u3002\u53ef\u9009\uff0c\u6ca1\u6709\u8bc4\u6d4b\u5b9a\u70b9\u6a21\u578b\u7cbe\u5ea6\u7684\u9700\u6c42\u65f6\u53ef\u4ee5\u8df3\u8fc7\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u8c03\u7528 ",(0,o.jsx)(e.code,{children:"export_to_onnx"})," \u3002\u4e5f\u53ef\u4ee5\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"torch.onnx.export"})," \u4f46\u9700\u8981\u9075\u5b88 ",(0,o.jsx)(e.code,{children:"export_to_onnx"})," \u63a5\u53e3\u8bf4\u660e\u4e2d\u7684\u6ce8\u610f\u4e8b\u9879\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"hb_mapper"})," \u8f6c\u6362 onnx \u6a21\u578b\u3002\u8f6c\u6362\u540e\u9700\u68c0\u67e5\u7b97\u5b50\u662f\u5426\u8fd0\u884c\u5728\u9884\u671f\u7684\u8bbe\u5907\u4e0a\uff0c\u5728\u90e8\u5206\u60c5\u51b5\u4e0b\uff0c ",(0,o.jsx)(e.code,{children:"hb_mapper"})," \u4ecd\u7136\u9700\u8981\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"run_on_cpu"})," \u53c2\u6570\u3002\u6bd4\u5982\uff1a\u867d\u7136 ",(0,o.jsx)(e.code,{children:"conv"})," \u5728 QAT \u9636\u6bb5\u6ca1\u6709\u91cf\u5316\uff0c\u4f46\u7531\u4e8e\u5176\u8f93\u5165\uff08\u4e0a\u4e00\u4e2a\u7b97\u5b50\u8f93\u51fa\uff09\u7ecf\u8fc7\u4e86\u4f2a\u91cf\u5316\uff0c ",(0,o.jsx)(e.code,{children:"hb_mapper"})," \u4ecd\u7136\u4f1a\u9ed8\u8ba4\u5c06\u5176\u91cf\u5316\u3002"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/hybrid_qat_run_on_cpu.jpg",alt:"hybrid_qat_run_on_cpu"})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import copy\nimport numpy as np\nimport torch\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn import qat\nfrom horizon_plugin_pytorch.quantization import (\n    prepare_qat_fx,\n    convert_fx,\n    set_fake_quantize,\n    FakeQuantState,\n    load_observer_params,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_calib_8bit_fake_quant_qconfig,\n    default_calib_out_8bit_fake_quant_qconfig,\n    default_qat_8bit_fake_quant_qconfig,\n    default_qat_out_8bit_fake_quant_qconfig,\n)\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\nfrom horizon_plugin_pytorch.utils.onnx_helper import export_to_onnx\n\nclass _ConvBlock(nn.Module):\n    def __init__(self, channels=3):\n        super().__init__()\n        self.conv = nn.Conv2d(channels, channels, 1)\n        self.prelu = torch.nn.PReLU()\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = self.prelu(x)\n        return torch.nn.functional.selu(x)\n\n# \u5c01\u88c5 functional selu \u4e3a module\uff0c\u4fbf\u4e8e\u5355\u72ec\u8bbe\u7f6e\nclass _SeluModule(nn.Module):\n    def forward(self, input):\n        return torch.nn.functional.selu(input)\n\nclass HybridModel(nn.Module):\n    def __init__(self, channels=3):\n        super().__init__()\n        # \u63d2\u5165 QuantStub\n        self.quant = QuantStub()\n        self.conv0 = nn.Conv2d(channels, channels, 1)\n        self.prelu = torch.nn.PReLU()\n        self.conv1 = _ConvBlock(channels)\n        self.conv2 = nn.Conv2d(channels, channels, 1)\n        self.conv3 = nn.Conv2d(channels, channels, 1)\n        self.conv4 = nn.Conv2d(channels, channels, 1)\n        self.selu = _SeluModule()\n        # \u63d2\u5165 DequantStub\n        self.dequant = DeQuantStub()\n        self.identity = torch.nn.Identity()\n\n    def forward(self, input):\n        x = self.quant(input)\n        x = self.conv0(x)\n        x = self.identity(x)\n        x = self.prelu(x)\n        x = torch.nn.functional.selu(x)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.identity(x)\n        x = self.conv4(x)\n        x = self.selu(x)\n        return self.dequant(x)\n\n# \u8bbe\u7f6e march **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\ndata_shape = [1, 3, 224, 224]\ndata = torch.rand(size=data_shape)\nmodel = HybridModel()\nqat_model = copy.deepcopy(model)\n# float \u6a21\u578b\u7684\u63a8\u7406\u4e0d\u8981\u653e\u5728 prepare_qat_fx \u4e4b\u540e\uff0cprepare_qat_fx \u4f1a\u5bf9 float \u6a21\u578b\u505a inplace \u4fee\u6539\nfloat_res = model(data)\n\ncalibration_model = prepare_qat_fx(\n    model,\n    {\n        "": default_calib_8bit_fake_quant_qconfig,\n        # selu \u4e3a cpu \u7b97\u5b50\uff0cconv4 \u5b9e\u9645\u4e0a\u662f bpu \u6a21\u578b\u7684\u8f93\u51fa\uff0c\u8bbe\u7f6e\u4e3a\u9ad8\u7cbe\u5ea6\u8f93\u51fa\n        "module_name": [("conv4", default_calib_out_8bit_fake_quant_qconfig)]\n    },\n    hybrid=True,\n    hybrid_dict={\n        "module_name": ["conv1.conv", "conv3"],\n        "module_type": [_SeluModule],\n    },\n)\n# calibration \u9636\u6bb5\u9700\u786e\u4fdd\u539f\u6709\u6a21\u578b\u4e0d\u4f1a\u53d1\u751f\u53d8\u5316\ncalibration_model.eval()\nset_fake_quantize(calibration_model, FakeQuantState.CALIBRATION)\n\nfor i in range(5):\n    calibration_model(torch.rand(size=data_shape))\n\nqat_model = prepare_qat_fx(\n    qat_model,\n    {\n        "": default_qat_8bit_fake_quant_qconfig,\n        # selu \u4e3a cpu \u7b97\u5b50\uff0cconv4 \u5b9e\u9645\u4e0a\u662f bpu \u6a21\u578b\u7684\u8f93\u51fa\uff0c\u8bbe\u7f6e\u4e3a\u9ad8\u7cbe\u5ea6\u8f93\u51fa\n        "module_name": [("conv4", default_qat_out_8bit_fake_quant_qconfig)]\n    },\n    hybrid=True,\n    hybrid_dict={\n        "module_name": ["conv1.conv", "conv3"],\n        "module_type": [_SeluModule],\n    },\n)\n\nload_observer_params(calibration_model, qat_model)\nset_fake_quantize(calibration_model, FakeQuantState.QAT)\n\n# qat training start\n# ......\n# qat training end\n\n# \u5bfc\u51fa qat.onnx\nexport_to_onnx(\n    qat_model,\n    data,\n    "qat.onnx",\n    operator_export_type=None,\n)\n\n# \u8bc4\u6d4b\u5b9a\u70b9\u6a21\u578b\nquantize_model = convert_fx(qat_model)\nquantize_res = quantize_model(data)\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u6253\u5370 QAT \u6a21\u578b\u7684\u7ed3\u679c\u3002"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"HybridModel(\n  (quant): QuantStub(\n    (activation_post_process): FakeQuantize(\n      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1,         scale=tensor([0.0078]), zero_point=tensor([0])\n      (activation_post_process): MovingAverageMinMaxObserver(min_val=tensor([-0.9995]), max_val=tensor([0.9995]))\n    )\n  )\n  (conv0): Conv2d(\n    3, 3, kernel_size=(1, 1), stride=(1, 1)\n    (weight_fake_quant): FakeQuantize(\n      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_channel_symmetric, ch_axis=0,         scale=tensor([0.0038, 0.0041, 0.0016]), zero_point=tensor([0, 0, 0])\n      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.4881, -0.4944,  0.0787]), max_val=tensor([-0.1213,  0.5284,  0.1981]))\n    )\n    (activation_post_process): FakeQuantize(\n      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1,         scale=tensor([0.0064]), zero_point=tensor([0])\n      (activation_post_process): MovingAverageMinMaxObserver(min_val=tensor([-0.8159]), max_val=tensor([0.8159]))\n    )\n  )\n  (prelu): PReLU(num_parameters=1)\n  (conv1): _ConvBlock(\n    (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n    (prelu): PReLU(num_parameters=1)\n  )\n  (conv2): Conv2d(\n    3, 3, kernel_size=(1, 1), stride=(1, 1)\n    (weight_fake_quant): FakeQuantize(\n      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_channel_symmetric, ch_axis=0,         scale=tensor([0.0040, 0.0044, 0.0040]), zero_point=tensor([0, 0, 0])\n      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.5044, -0.4553, -0.5157]), max_val=tensor([0.1172, 0.5595, 0.4104]))\n    )\n    (activation_post_process): FakeQuantize(\n      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1,         scale=tensor([0.0059]), zero_point=tensor([0])\n      (activation_post_process): MovingAverageMinMaxObserver(min_val=tensor([-0.7511]), max_val=tensor([0.7511]))\n    )\n  )\n  (conv3): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n  (conv4): Conv2d(\n    3, 3, kernel_size=(1, 1), stride=(1, 1)\n    (weight_fake_quant): FakeQuantize(\n      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_channel_symmetric, ch_axis=0,         scale=tensor([0.0025, 0.0037, 0.0029]), zero_point=tensor([0, 0, 0])\n      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2484, -0.4718, -0.3689]), max_val=tensor([ 0.3239, -0.0056,  0.3312]))\n    )\n    (activation_post_process): None\n  )\n  (selu): _SeluModule()\n  (dequant): DeQuantStub()\n  (identity): Identity()\n  (prelu_input_dequant): DeQuantStub()\n  (selu_1_activation_post_process): _WrappedCalibFakeQuantize(\n    (activation_post_process): FakeQuantize(\n      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1,         scale=tensor([0.0042]), zero_point=tensor([0])\n      (activation_post_process): MovingAverageMinMaxObserver(min_val=tensor([-0.5301]), max_val=tensor([0.5301]))\n    )\n  )\n  (conv3_activation_post_process): _WrappedCalibFakeQuantize(\n    (activation_post_process): FakeQuantize(\n      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1,         scale=tensor([0.0072]), zero_point=tensor([0])\n      (activation_post_process): MovingAverageMinMaxObserver(min_val=tensor([-0.9156]), max_val=tensor([0.9156]))\n    )\n  )\n  (conv3_input_dequant): DeQuantStub()\n  (selu_2_input_dequant): DeQuantStub()\n)\n\ndef forward(self, input):\n    input_1 = input\n    quant = self.quant(input_1);  input_1 = None\n    conv0 = self.conv0(quant);  quant = None\n    identity = self.identity(conv0);  conv0 = None\n    prelu_input_dequant_0 = self.prelu_input_dequant(identity);  identity = None\n    prelu = self.prelu(prelu_input_dequant_0);  prelu_input_dequant_0 = None\n    selu = torch.nn.functional.selu(prelu, inplace = False);  prelu = None\n    conv1_conv = self.conv1.conv(selu);  selu = None\n    conv1_prelu = self.conv1.prelu(conv1_conv);  conv1_conv = None\n    selu_1 = torch.nn.functional.selu(conv1_prelu, inplace = False);  conv1_prelu = None\n    selu_1_activation_post_process = self.selu_1_activation_post_process(selu_1);  selu_1 = None\n    conv2 = self.conv2(selu_1_activation_post_process);  selu_1_activation_post_process = None\n    conv3_input_dequant_0 = self.conv3_input_dequant(conv2);  conv2 = None\n    conv3 = self.conv3(conv3_input_dequant_0);  conv3_input_dequant_0 = None\n    conv3_activation_post_process = self.conv3_activation_post_process(conv3);  conv3 = None\n    identity_1 = self.identity(conv3_activation_post_process);  conv3_activation_post_process = None\n    conv4 = self.conv4(identity_1);  identity_1 = None\n    selu_2_input_dequant_0 = self.selu_2_input_dequant(conv4);  conv4 = None\n    selu_2 = torch.nn.functional.selu(selu_2_input_dequant_0, inplace = False);  selu_2_input_dequant_0 = None\n    dequant = self.dequant(selu_2);  selu_2 = None\n    return dequant\n"})}),"\n",(0,o.jsx)(e.p,{children:"\u5bfc\u51fa\u7684 onnx \u5982\u56fe\u6240\u793a\uff0c\u7ea2\u8272\u5708\u51fa\u90e8\u5206\u4e3a CPU \u7b97\u5b50\u3002"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/hybrid_qat_onnx.jpg",alt:"hybrid_qat_onnx"})}),"\n",(0,o.jsx)(e.h2,{id:"\u5206\u6790\u5de5\u5177\u4f7f\u7528\u6307\u5357",children:"\u5206\u6790\u5de5\u5177\u4f7f\u7528\u6307\u5357"}),"\n",(0,o.jsx)(e.p,{children:"\u5f53 QAT \u6216\u8005\u5b9a\u70b9\u6a21\u578b\u51fa\u73b0\u7cbe\u5ea6\u95ee\u9898\u65f6\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u6211\u4eec\u63d0\u4f9b\u7684\u5404\u79cd\u5de5\u5177\u6765\u5206\u6790\u6a21\u578b\uff0c\u5b9a\u4f4d\u7cbe\u5ea6\u6389\u70b9\u95ee\u9898\u3002"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/debug_tools.svg",alt:"debug_tools"})}),"\n",(0,o.jsx)(e.h3,{id:"\u603b\u89c8",children:"\u603b\u89c8"}),"\n",(0,o.jsxs)(e.p,{children:["\u5404\u79cd\u5de5\u5177\u7684\u4f7f\u7528\u63a5\u53e3\u548c\u4f7f\u7528\u573a\u666f\u603b\u7ed3\u5982\u4e0b\u8868\u3002\u9664\u4e86\u6a21\u578b\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5176\u5b83\u5de5\u5177\u5747\u5728 ",(0,o.jsx)(e.code,{children:"horizon_plugin_pytorch.utils.quant_profiler"})," \u5305\u4e2d\u3002"]}),"\n",(0,o.jsxs)(e.table,{children:[(0,o.jsx)(e.thead,{children:(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.th,{children:(0,o.jsx)(e.strong,{children:"\u5de5\u5177"})}),(0,o.jsx)(e.th,{children:(0,o.jsx)(e.strong,{children:"\u4f7f\u7528\u63a5\u53e3/\u65b9\u5f0f"})}),(0,o.jsx)(e.th,{children:(0,o.jsx)(e.strong,{children:"\u4f7f\u7528\u573a\u666f"})})]})}),(0,o.jsxs)(e.tbody,{children:[(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#a-name-integration-a",children:(0,o.jsx)(e.strong,{children:"\u96c6\u6210\u63a5\u53e3"})})}),(0,o.jsx)(e.td,{children:"model_profiler"}),(0,o.jsxs)(e.td,{children:["\u8c03\u7528\u5176\u5b83 debug \u5de5\u5177\u5e76\u5c06\u7ed3\u679c\u96c6\u4e2d\u663e\u793a\u5230\u4e00\u4e2a html \u9875\u9762;",(0,o.jsx)("br",{}),"\u76ee\u524d\u4f1a\u8c03\u7528\u76f8\u4f3c\u5ea6\u3001\u7edf\u8ba1\u91cf\u3001\u5171\u4eab op \u68c0\u67e5\u3001fuse \u68c0\u67e5\u3001weight \u6bd4\u8f83\u548c\u91cf\u5316\u914d\u7f6e\u68c0\u67e5\u8fd9\u51e0\u4e2a\u5de5\u5177"]})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#fuse-a-name-fuse-check-a",children:(0,o.jsx)(e.strong,{children:"fuse \u68c0\u67e5"})})}),(0,o.jsx)(e.td,{children:"check_unfused_operations"}),(0,o.jsxs)(e.td,{children:["\u68c0\u67e5",(0,o.jsx)(e.strong,{children:"\u6d6e\u70b9\u6a21\u578b"}),"\u4e2d\u662f\u5426\u6709\u53ef\u4ee5 fuse \u4f46\u662f\u6ca1\u6709 fuse \u7684 op pattern"]})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#op-a-name-shared-op-check-a",children:(0,o.jsx)(e.strong,{children:"\u5171\u4eab op \u68c0\u67e5"})})}),(0,o.jsx)(e.td,{children:"get_module_called_count"}),(0,o.jsx)(e.td,{children:"\u68c0\u67e5\u6a21\u578b\u4e2d\u662f\u5426\u6709\u5171\u4eab\u4f7f\u7528\u7684 op"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#a-name-qconfig-check-a",children:(0,o.jsx)(e.strong,{children:"\u91cf\u5316\u914d\u7f6e\u68c0\u67e5"})})}),(0,o.jsx)(e.td,{children:"check_qconfig"}),(0,o.jsx)(e.td,{children:"\u68c0\u67e5 QAT \u6a21\u578b\u4e2d\u91cf\u5316\u914d\u7f6e\u662f\u5426\u7b26\u5408\u9884\u671f"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#onnx-a-name-onnx-a",children:(0,o.jsx)(e.strong,{children:"\u6a21\u578b\u53ef\u89c6\u5316"})})}),(0,o.jsxs)(e.td,{children:["export_to_onnx ",(0,o.jsx)("br",{}),"export_quantized_onnx"]}),(0,o.jsxs)(e.td,{children:["\u5bfc\u51fa onnx \u6a21\u578b\u4ee5\u67e5\u770b\u6a21\u578b\u7ed3\u6784\uff0c",(0,o.jsx)(e.strong,{children:"\u4e0d\u652f\u6301 onnx run"})]})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#a-name-similarity-a",children:(0,o.jsx)(e.strong,{children:"\u76f8\u4f3c\u5ea6\u5bf9\u6bd4"})})}),(0,o.jsx)(e.td,{children:"featuremap_similarity"}),(0,o.jsx)(e.td,{children:"\u5f53\u91cf\u5316\u6a21\u578b\u7cbe\u5ea6\u964d\u4f4e\u65f6\uff0c\u5b9a\u4f4d\u51fa\u73b0\u95ee\u9898\u7684 op"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#a-name-statistic-a",children:(0,o.jsx)(e.strong,{children:"\u7edf\u8ba1\u91cf"})})}),(0,o.jsxs)(e.td,{children:["get_raw_features /",(0,o.jsx)("br",{}),"profile_featuremap"]}),(0,o.jsx)(e.td,{children:"\u8f93\u51fa\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u8f93\u51fa\u7684\u6570\u503c\u7279\u5f81\uff0c\u7528\u4e8e\u8bc4\u4f30\u5f53\u524d\u7684\u6570\u636e\u5206\u5e03\u548c\u91cf\u5316\u7cbe\u5ea6\u662f\u5426\u9002\u5408\u91cf\u5316"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#weight-a-name-weight-comparison-a",children:(0,o.jsx)(e.strong,{children:"\u6a21\u578b weight \u6bd4\u8f83"})})}),(0,o.jsx)(e.td,{children:"compare_weights"}),(0,o.jsx)(e.td,{children:"\u6bd4\u8f83\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42 weight \u7684\u76f8\u4f3c\u5ea6"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#a-name-step-quantization-a",children:(0,o.jsx)(e.strong,{children:"\u5206\u6b65\u91cf\u5316"})})}),(0,o.jsx)(e.td,{children:"qconfig=None"}),(0,o.jsx)(e.td,{children:"\u5f53 QAT \u6a21\u578b\u8bad\u7ec3\u56f0\u96be\u65f6\uff0c\u901a\u8fc7\u5c06\u6a21\u578b\u4e2d\u7684\u67d0\u4e00\u90e8\u5206\u8bbe\u7f6e\u4e3a\u6d6e\u70b9\u6765\u5bfb\u627e\u7cbe\u5ea6\u635f\u5931\u7684\u74f6\u9888"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#a-name-single-op-error-a",children:(0,o.jsx)(e.strong,{children:"\u5355\u7b97\u5b50\u8f6c\u6362\u7cbe\u5ea6\u8c03\u8bd5"})})}),(0,o.jsx)(e.td,{children:"set_preserve_qat_mode"}),(0,o.jsx)(e.td,{children:"\u5f53\u51fa\u73b0 QAT \u6a21\u578b\u8f6c\u5b9a\u70b9\u7cbe\u5ea6\u964d\u4f4e\u65f6\uff0c\u901a\u8fc7\u6b64\u63a5\u53e3\u5c06\u5b9a\u70b9\u6a21\u578b\u4e2d\u7684\u90e8\u5206 op \u66ff\u6362\u4e3a QAT \u7684\u5f62\u5f0f\u6765\u5bfb\u627e\u7cbe\u5ea6\u635f\u5931\u7684\u74f6\u9888"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#device-a-name-hybrid-device-check-a",children:(0,o.jsx)(e.strong,{children:"\u5f02\u6784\u6a21\u578b\u90e8\u7f72 device \u68c0\u67e5"})})}),(0,o.jsx)(e.td,{children:"check_deploy_device"}),(0,o.jsx)(e.td,{children:"\u68c0\u67e5\u5f02\u6784\u6a21\u578b\u90e8\u7f72\u65f6\u6bcf\u4e2a op \u662f\u5426\u6309\u7167\u9884\u671f\u8fd0\u884c\u5728 BPU \u6216\u8005 CPU \u4e0a"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#torchscript-hbdk",children:(0,o.jsx)(e.strong,{children:"torchscript \u548c hbdk \u7ed3\u679c\u5bf9\u6bd4"})})}),(0,o.jsx)(e.td,{children:"script_profile"}),(0,o.jsx)(e.td,{children:"\u6bd4\u8f83 horizon_plugin_pytorch \u751f\u6210\u7684\u5b9a\u70b9 pt \u4e2d\u6bcf\u4e00\u4e2a op \u548c hbdk \u7684\u89e3\u6790\u7ed3\u679c\u662f\u5426\u4e00\u81f4"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#torchscript",children:(0,o.jsx)(e.strong,{children:"\u4e0d\u540c\u7248\u672c torchscript \u7684\u7ed3\u679c\u5bf9\u6bd4"})})}),(0,o.jsx)(e.td,{children:"compare_script_models"}),(0,o.jsx)(e.td,{children:"\u6bd4\u8f83\u76f8\u540c\u6a21\u578b\uff0c\u4f7f\u7528\u4e0d\u540c\u7248\u672c\u7684 horizon_plugin_pytorch \u751f\u6210\u7684\u5b9a\u70b9 pt \u4e2d\u6bcf\u4e00\u4e2a op \u7684\u7ed3\u679c"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.a,{href:"#a-name-cuda-memory-a",children:(0,o.jsx)(e.strong,{children:"\u6a21\u578b\u663e\u5b58\u5360\u7528\u5206\u6790\u5de5\u5177"})})}),(0,o.jsx)(e.td,{children:"show_cuda_memory_consumption"}),(0,o.jsx)(e.td,{children:"\u5206\u6790\u6a21\u578b\u663e\u5b58\u5360\u7528\u60c5\u51b5\uff0c\u5b9a\u4f4d\u663e\u5b58\u74f6\u9888"})]})]})]}),"\n",(0,o.jsx)(e.h3,{id:"a-name-integration-a",children:"\u96c6\u6210\u63a5\u53e3"}),"\n",(0,o.jsxs)(e.p,{children:["\u4e3a\u65b9\u4fbf\u4f7f\u7528\u548c\u67e5\u770b\uff0chorizon_plugin_pytorch \u63d0\u4f9b\u4e86\u4e00\u4e2a\u96c6\u6210\u63a5\u53e3 ",(0,o.jsx)(e.code,{children:"model_profiler"}),"\uff0c\u8be5\u63a5\u53e3\u4f1a\u8c03\u7528\u5176\u5b83 debug \u5de5\u5177\u5e76\u5c06\u7ed3\u679c\u96c6\u4e2d\u663e\u793a\u5230\u4e00\u4e2a html \u9875\u9762\u4e2d\uff0c\u6240\u6709\u5176\u5b83 debug \u5de5\u5177\u7684\u7ed3\u679c\u4e5f\u4f1a\u540c\u65f6\u4fdd\u5b58\u3002\u76ee\u524d\u4f1a\u8c03\u7528\u76f8\u4f3c\u5ea6\u3001\u7edf\u8ba1\u91cf\u3001\u5171\u4eab op \u68c0\u67e5\u3001fuse \u68c0\u67e5\u3001weight \u6bd4\u8f83\u548c\u91cf\u5316\u914d\u7f6e\u68c0\u67e5\u8fd9\u51e0\u4e2a\u5de5\u5177\u3002"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsx)(e.p,{children:"\u8be5\u63a5\u53e3\u6d89\u53ca\u4e24\u4e2a\u6a21\u578b\u4e4b\u95f4\u7684\u6bd4\u8f83\uff0cfx \u6a21\u5f0f\u4e0b\uff0c\u6a21\u578b\u8f6c\u6362\u7684\u8fc7\u7a0b\u9ed8\u8ba4\u90fd\u662f inplace \u7684\uff0c\u5982\u679c\u9700\u8981\u4f7f\u7528\u8be5\u5de5\u5177\uff0c\u8bf7\u60a8\u624b\u52a8\u5728\u8fdb\u884c\u8f6c\u6362\u524d deepcopy \u4e00\u4efd\u539f\u59cb\u6a21\u578b\u3002\u5426\u5219\u8f6c\u6362\u540e\uff0c\u4f1a\u9519\u8bef\u5730\u6bd4\u8f83\u4e24\u4e2a\u76f8\u540c\u6a21\u578b\u3002"})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import model_profiler\n\ndef model_profiler(\n    model1: torch.nn.Module,\n    model2: torch.nn.Module,\n    example_inputs: Any,\n    mode: str,\n    out_dir: Optional[str] = None,\n    kwargs_dict: Optional[dict] = None,\n):\n    """\u8fd0\u884c\u5404\u79cd\u68c0\u67e5\u5206\u6790\u5de5\u5177\u5e76\u5c06\u7ed3\u679c\u7edf\u4e00\u5c55\u793a\u5230\u4e00\u4e2a html \u9875\u9762\n\n    \u8be5\u51fd\u6570\u4f1a\u6bd4\u8f83\uff1a\n    1\uff09\u4e24\u4e2a\u6a21\u578b\u4e2d\u5404\u4e2a op \u7684\u76f8\u4f3c\u5ea6\uff0c\u7edf\u8ba1\u91cf\uff0cweight \u7684\u76f8\u4f3c\u5ea6\uff0c\u540c\u65f6\u68c0\u67e5\u6a21\u578b\u4e2d\u7684\u5171\u4eab op\n    2\uff09\u68c0\u67e5\u6d6e\u70b9\u6a21\u578b\u4e2d\u662f\u5426\u6709\u672a fuse \u7684 pattern\uff0c\u68c0\u67e5 QAT \u6a21\u578b\u7684\u91cf\u5316\u914d\u7f6e\n    \u7ed3\u679c\u4f1a\u7edf\u4e00\u5c55\u793a\u5728`profiler.html`\u4e2d\u3002\n\n    \u6ce8\u610f\uff1a\n        1\uff09\u8be5\u63a5\u53e3\u4ec5\u652f\u6301\u540c\u4e00\u4e2a\u6a21\u578b\u7684\u76f8\u90bb\u4e24\u4e2a\u9636\u6bb5\uff0c\u5e76\u6309\u8f6c\u6362\u987a\u5e8f\u8f93\u5165\u7684\u6bd4\u8f83\u3002\u5982`\u6d6e\u70b9 vs QAT`\n        \u6216\u8005`QAT vs \u5b9a\u70b9`\u3002\u4e0d\u652f\u6301\u6d6e\u70b9\u6a21\u578b\u76f4\u63a5\u548c\u5b9a\u70b9\u6a21\u578b\u6bd4\u8f83\uff0c`QAT \u6a21\u578b vs \u6d6e\u70b9\u6a21\u578b`\u8fd9\u6837\n        \u7684\u8f93\u5165\u987a\u5e8f\u4e5f\u662f\u4e0d\u652f\u6301\u7684\u3002\n        2\uff09\u6a21\u578b\u7ed3\u6784\u7684 onnx \u53ef\u89c6\u5316\u7ed3\u679c\uff0c\u4ee5\u53ca\u5404\u5c42 featuremap \u7684\u7edf\u8ba1\u76f4\u65b9\u56fe\u5e76\u6ca1\u6709\u5728 html \u9875\u9762\u4e2d\n        \u663e\u793a\u3002\u60a8\u53ef\u4ee5\u624b\u52a8\u8c03\u7528`export_to_onnx/export_quantized_onnx`\u548c\n        `profile_featuremap(with_tensorboard=True)`\u3002\u6b64\u5916\uff0c\u8be5\u63a5\u53e3\u4e5f\u652f\u6301\u901a\u8fc7\n        `kwargs_dict`\u53c2\u6570\u6765\u4f20\u9012\u8c03\u7528\u5404\u4e2a debug \u5de5\u5177\u65f6\u7684\u81ea\u5b9a\u4e49\u53c2\u6570\u3002\n\n    \u53c2\u6570\uff1a\n        model1: \u6d6e\u70b9/\u6821\u51c6/QAT\u6a21\u578b\n        model2: \u6821\u51c6/QAT/\u5b9a\u70b9\u6a21\u578b\n        example_inputs: \u6a21\u578b\u8f93\u5165\n        mode\uff1a\u8868\u793a\u8fdb\u884c\u6bd4\u8f83\u7684\u662f\u54ea\u4e24\u4e2a\u6a21\u578b\uff0c\u4ec5\u652f\u6301\u4ee5\u4e0b\u4e09\u79cd\u6a21\u5f0f\n            - `FvsQ`\uff1afloat \u6a21\u578b\u548c qat/calibration \u6a21\u578b\u5bf9\u6bd4\n            - `QvsQ`\uff1aqat \u6a21\u578b\u548c quantized \u6a21\u578b\u5bf9\u6bd4\n            - `CvsQ`\uff1acalibration \u6a21\u578b\u548c qat \u6a21\u578b\u5bf9\u6bd4\n        out_dir\uff1a\u6307\u5b9a\u8f93\u51fa\u7684\u7ed3\u679c\u6587\u4ef6`profiler.html`\u548c\u6240\u6709 debug \u5de5\u5177\u8c03\u7528\u7ed3\u679c\u7684\u8def\u5f84\u3002\u9ed8\u8ba4\n        \u4e3a`None`\uff0c\u4f1a\u5728`ckpt_dir`\u6307\u5b9a\u7684\u76ee\u5f55\u4e0b\u6216\u5f53\u524d\u76ee\u5f55\u4e0b\u751f\u6210`profiler`\u76ee\u5f55\uff0c\u5e76\u5c06\u6240\u6709\n        \u7ed3\u679c\u5b58\u50a8\u5728\u8be5\u76ee\u5f55\u4e0b\u3002\n        kwargs_dict\uff1a\u8c03\u7528\u5176\u4ed6 debug \u5de5\u5177\u65f6\u7684\u53c2\u6570\uff0c\u4ee5`dict`\u7684\u5f62\u5f0f\u7ed9\u51fa\u3002**\u5177\u4f53\u7684\u53c2\u6570\u53ef\u4ee5\n        \u53c2\u8003\u4e0a\u9762\u6bcf\u4e2a\u5de5\u5177\u7684\u5177\u4f53\u4ecb\u7ecd**\u3002\u652f\u6301 7 \u4e2a key \u503c\n            1\uff09`featuremap_similarity`\uff1a\u76f8\u4f3c\u5ea6\n            2\uff09`get_raw_features`\uff1a\u8ba1\u7b97\u6bcf\u4e00\u5c42 op \u8f93\u5165\u8f93\u51fa feature \u7684\u76f8\u5173\u7279\u5f81\n            3\uff09`profile_featuremap`\uff1a\u7edf\u8ba1\u91cf\u51fd\u6570\uff0c\u8f93\u51fa\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u7ed3\u679c\u7684\u6700\u5927\u6700\u5c0f\u503c\uff0c\u5747\n            \u503c\u548c\u65b9\u5dee\u7b49\n            4\uff09`get_module_called_count`\uff1a\u68c0\u67e5\u6a21\u578b\u662f\u5426\u6709\u5171\u4eab op\n            5\uff09`check_unfused_operations`\uff1a\u68c0\u67e5\u6a21\u578b\u662f\u5426\u6709\u672a fuse \u7684 pattern\n            6\uff09`compare_weights`\uff1a\u6bd4\u8f83\u4e24\u4e2a\u6a21\u578b\u4e2d weight \u7684\u76f8\u4f3c\u5ea6\n            7\uff09`check_qconfig`\uff1a\u68c0\u67e5 QAT \u6a21\u578b\u4e2d\u7684 Qconfig \u914d\u7f6e\n            \u6ce8\u610f\uff1a\n                1) `model`\u548c`example_inputs`\u4e24\u4e2a\u53c2\u6570\u5df2\u5728`model_profiler`\u63a5\u53e3\u4e2d\u5b9a\n                \u4e49\uff0ckwargs_dict \u4e2d\u5fc5\u987b\u6ca1\u6709\u8fd9\u4e24\u4e2a\u53c2\u6570\u7684\u5b9a\u4e49\n                2) kwargs_dict \u4e2d\u7684`out_dir`\u53c2\u6570\u4f1a\u88ab`model_profiler`\u63a5\u53e3\u4e2d\u7684\n                `out_dir`\u53c2\u6570\u66ff\u6362\n    """\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from copy import deepcopy\n\nimport numpy as np\nimport pytest\nimport torch\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\n\nimport horizon_plugin_pytorch as horizon\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.qat_mode import QATMode, set_qat_mode\nfrom horizon_plugin_pytorch.quantization import (\n    convert_fx,\n    prepare_qat_fx,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.utils.quant_profiler import model_profiler\n\n\nclass Conv2dModule(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel_size=1,\n        stride=1,\n        padding=0,\n        dilation=1,\n        groups=1,\n        bias=True,\n        padding_mode="zeros",\n    ):\n        super().__init__()\n        self.conv2d = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            groups,\n            bias,\n            padding_mode,\n        )\n\n        self.add = FloatFunctional()\n        self.bn_mod = nn.BatchNorm2d(out_channels)\n        self.relu_mod = nn.ReLU()\n\n    def forward(self, x, y):\n        x = self.conv2d(x)\n        x = self.bn_mod(x)\n        x = self.add.add(x, y)\n        x = self.relu_mod(x)\n\n        return x\n\n\nclass TestFuseNet(nn.Module):\n    def __init__(self, channels) -> None:\n        super().__init__()\n        self.quantx = QuantStub()\n        self.quanty = QuantStub()\n        self.convmod1 = Conv2dModule(channels, channels)\n        self.convmod2 = Conv2dModule(channels, channels)\n        self.convmod3 = Conv2dModule(channels, channels)\n        self.shared_conv = nn.Conv2d(channels, channels, 1)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.bn2 = nn.BatchNorm2d(channels)\n        self.sub = FloatFunctional()\n        self.relu = nn.ReLU()\n        self.dequant = DeQuantStub()\n\n    def forward(self, x, y):\n        x = self.quantx(x)\n        y = self.quanty(y)\n        x = self.convmod1(x, y)\n        x = self.convmod2(y, x)\n        x = self.convmod3(x, y)\n        x = self.shared_conv(x)\n        x = self.bn1(x)\n        y = self.shared_conv(y)\n        y = self.bn2(y)\n        x = self.sub.sub(x, y)\n        x = self.relu(x)\n        return self.dequant(x)\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\ndevice = torch.device("cpu")\ndata = torch.arange(1 * 3 * 4 * 4) / 100 + 1\ndata = data.reshape((1, 3, 4, 4))\ndata = data.to(torch.float32).to(device)\n\nfloat_net = TestFuseNet(3).to(device)\nfloat_net(data, data)\n\nqat_net = prepare_qat_fx(float_net, {"": default_qat_8bit_fake_quant_qconfig})\nqat_net = qat_net.to(device)\nqat_net(data, data)\n\n# fx \u6a21\u5f0f\u4e0b\uff0c\u9700\u8981 deepcopy \u8f6c\u6362\u524d\u7684\u6a21\u578b\nqat_net2 = deepcopy(qat_net)\nquantized_net = convert_fx(qat_net2)\n\nmodel_profiler(qat_net, quantized_net, (data, data), mode="QvsQ")\n'})}),"\n",(0,o.jsxs)(e.p,{children:["\u82e5\u6ca1\u6709\u6307\u5b9a",(0,o.jsx)(e.code,{children:"out_dir"}),"\u53c2\u6570\uff0c\u5219\u4f1a\u5728\u5f53\u524d\u76ee\u5f55\u4e0b\u751f\u6210",(0,o.jsx)(e.code,{children:"horizon_quant_debug"}),"\u6587\u4ef6\u5939\uff0c",(0,o.jsx)(e.code,{children:"profiler.html"}),"\u548c\u5404\u4e2a debug \u5de5\u5177\u7684\u8fd0\u884c\u7ed3\u679c\u5747\u4f1a\u4fdd\u5b58\u5230\u8be5\u6587\u4ef6\u5939\u4e0b\u3002\u6bcf\u4e2a debug \u5de5\u5177\u7684\u8f93\u51fa\u8be6\u89e3\u8bf7\u53c2\u8003\u4e0b\u5217\u5404\u4e2a\u5de5\u5177\u7684\u5177\u4f53\u4ecb\u7ecd\u3002"]}),"\n",(0,o.jsx)(e.h3,{id:"fuse-a-name-fuse-check-a",children:"fuse \u68c0\u67e5"}),"\n",(0,o.jsxs)(e.p,{children:["\u6a21\u578b ",(0,o.jsx)(e.code,{children:"fuse"})," \u7684\u6b63\u786e\u6027\u5305\u542b\u4e24\u65b9\u9762\uff1a"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"\u53ef\u4ee5 fuse \u7684\u7b97\u5b50\u662f\u5426\u90fd fuse \u4e86\u3002"}),"\n",(0,o.jsx)(e.li,{children:"\u5df2\u7ecf fuse \u7684\u7b97\u5b50\u662f\u5426\u6b63\u786e\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"\u8be5\u63a5\u53e3\u53ea\u80fd\u5bf9\u7b2c\u4e00\u79cd\u60c5\u51b5\u8fdb\u884c\u68c0\u67e5\uff0c\u5bf9\u4e8e\u7b2c\u4e8c\u79cd\u60c5\u51b5\uff0c\u8bf7\u4f7f\u7528\u76f8\u4f3c\u5ea6\u5bf9\u6bd4\u5de5\u5177\u5bf9 fuse \u524d\u540e\u6a21\u578b\u7684 feature \u76f8\u4f3c\u5ea6\u8fdb\u884c\u5bf9\u6bd4\uff0c\u82e5\u53d1\u73b0\u4ece\u67d0\u4e00\u4e2a\u7b97\u5b50\u4e4b\u540e\u6240\u6709 feature \u7684\u76f8\u4f3c\u5ea6\u90fd\u6709\u95ee\u9898\uff0c\u5219\u8fd9\u4e2a\u7b97\u5b50\u7684 fuse \u53ef\u80fd\u662f\u9519\u8bef\u7684\uff08fuse \u8fc7\u7a0b\u4f1a\u5c06\u51e0\u4e2a op \u5408\u5e76\u4e3a\u4e00\u4e2a\uff0c\u5176\u4ed6\u4f4d\u7f6e\u7528 Identity \u4ee3\u66ff\uff0c\u56e0\u6b64\u5728\u8fd9\u4e9b Identity \u7684\u4f4d\u7f6e\u51fa\u73b0 feature \u76f8\u4f3c\u5ea6\u4f4e\u7684\u60c5\u51b5\u53ef\u80fd\u662f\u6b63\u5e38\u7684\uff09\u3002"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"\u8be5\u63a5\u53e3\u4ec5\u63a5\u53d7\u6d6e\u70b9\u6a21\u578b\u8f93\u5165\u3002"})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import check_unfused_operations\n\ndef check_unfused_operations(\n    model: torch.nn.Module,\n    example_inputs,\n    print_tabulate=True,\n):\n"""\u68c0\u67e5\u6a21\u578b\u4e2d\u662f\u5426\u6709\u53ef\u878d\u5408\u4f46\u662f\u672a\u878d\u5408\u7684 op\u3002\n    \u8be5\u63a5\u53e3\u53ea\u80fd\u68c0\u67e5\u662f\u5426\u6709\u672a\u878d\u5408\u7684 op\u3002\u4e0d\u80fd\u68c0\u67e5\u878d\u5408\u7684\u6b63\u786e\u6027\uff0c\u82e5\u8981\u68c0\u67e5 op \u878d\u5408\u662f\u5426\u6b63\u786e\uff0c\n    \u8bf7\u4f7f\u7528`featuremap_similarity`\u63a5\u53e3\u6bd4\u8f83 fuse \u524d\u540e\u4e24\u4e2a\u6a21\u578b\u7684\u76f8\u4f3c\u5ea6\u3002\n\n    \u53c2\u6570\uff1a\n        model\uff1a\u8f93\u5165\u6a21\u578b\n        example_inputs\uff1a\u6a21\u578b\u8f93\u5165\u53c2\u6570\n        print_tabulate\uff1a\u662f\u5426\u6253\u5370\u7ed3\u679c\u3002\u9ed8\u8ba4\u4e3a True\u3002\n\n    \u8f93\u51fa\uff1a\n        List[List[str]]\uff1a\u53ef\u878d\u5408\u7684 op pattern \u5217\u8868\n"""\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.admonition,{title:"\u5907\u6ce8",type:"info",children:(0,o.jsx)(e.p,{children:"\u8be5\u793a\u4f8b\u4e3a eager \u6a21\u5f0f\u4e0b\u7684\u793a\u4f8b\uff08\u624b\u52a8\u5b9a\u4e49 fuse pattern \u5e76\u8c03\u7528 fuse \u51fd\u6570\uff09\u3002\u82e5\u4f7f\u7528 fx \u8fdb\u884c\u91cf\u5316\uff0c\u4f1a\u81ea\u52a8\u5bf9\u6a21\u578b\u4e2d\u6240\u6709\u53ef\u4ee5 fuse \u7684 pattern \u505a fuse \u64cd\u4f5c\u3002"})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import horizon_plugin_pytorch as horizon\nimport numpy as np\nimport torch\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.utils.quant_profiler import check_unfused_operations\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\n\nclass Conv2dModule(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel_size=1,\n        stride=1,\n        padding=0,\n        dilation=1,\n        groups=1,\n        bias=True,\n        padding_mode="zeros",\n    ):\n        super().__init__()\n        self.conv2d = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            groups,\n            bias,\n            padding_mode,\n        )\n\n        self.add = FloatFunctional()\n        self.bn_mod = nn.BatchNorm2d(out_channels)\n        self.relu_mod = nn.ReLU()\n\n    def forward(self, x, y):\n        x = self.conv2d(x)\n        x = self.bn_mod(x)\n        x = self.add.add(x, y)\n        x = self.relu_mod(x)\n\n        return x\n\n    def fuse_model(self):\n        from horizon_plugin_pytorch.quantization import fuse_modules\n\n        fuse_list = ["conv2d", "bn_mod", "add", "relu_mod"]\n\n        fuse_modules(\n            self,\n            fuse_list,\n            inplace=True,\n        )\n\n\nclass TestFuseNet(nn.Module):\n    def __init__(self, channels) -> None:\n        super().__init__()\n        self.convmod1 = Conv2dModule(channels, channels)\n        self.convmod2 = Conv2dModule(channels, channels)\n        self.convmod3 = Conv2dModule(channels, channels)\n        self.shared_conv = nn.Conv2d(channels, channels, 1)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.bn2 = nn.BatchNorm2d(channels)\n        self.sub = FloatFunctional()\n        self.relu = nn.ReLU()\n\n    def forward(self, x, y):\n        x = self.convmod1(x, y)\n        x = self.convmod2(y, x)\n        x = self.convmod3(x, y)\n        x = self.shared_conv(x)\n        x = self.bn1(x)\n        y = self.shared_conv(y)\n        y = self.bn2(y)\n        x = self.sub.sub(x, y)\n        x = self.relu(x)\n\n        return x\n\n    def fuse_model(self):\n        self.convmod1.fuse_model()\n        self.convmod3.fuse_model()\n\nshape = np.random.randint(10, 20, size=4).tolist()\ndata0 = torch.rand(size=shape)\ndata1 = torch.rand(size=shape)\nfloat_net = TestFuseNet(shape[1])\nfloat_net.fuse_model()\ncheck_unfused_operations(float_net, (data0, data1))\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u8f93\u51fa\u7ed3\u679c\u5982\u4e0b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"name                 type\n-------------------  ------------------------------------------------\nshared_conv(shared)  <class 'torch.nn.modules.conv.Conv2d'>\nbn1                  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n\nname                 type\n-------------------  ------------------------------------------------\nshared_conv(shared)  <class 'torch.nn.modules.conv.Conv2d'>\nbn2                  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n\nname               type\n-----------------  --------------------------------------------------------------------------------\nconvmod2.conv2d    <class 'torch.nn.modules.conv.Conv2d'>\nconvmod2.bn_mod    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\nconvmod2.add       <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.FloatFunctional'>\nconvmod2.relu_mod  <class 'torch.nn.modules.activation.ReLU'>\n"})}),"\n",(0,o.jsx)(e.p,{children:"\u6bcf\u4e00\u7ec4\u53ef\u4ee5 fuse \u4f46\u662f\u672a fuse \u7684 pattern \u90fd\u4f1a\u4ee5\u8868\u683c\u7684\u5f62\u5f0f\u8f93\u51fa\uff0c\u7b2c\u4e00\u5217\u4e3a module \u5728\u6a21\u578b\u4e2d\u5b9a\u4e49\u7684 name\uff0c\u7b2c\u4e8c\u5217\u4e3a module \u7684\u7c7b\u578b\u3002"}),"\n",(0,o.jsx)(e.h3,{id:"op-a-name-shared-op-check-a",children:"\u5171\u4eab op \u68c0\u67e5"}),"\n",(0,o.jsx)(e.p,{children:"\u6b64\u63a5\u53e3\u7edf\u8ba1\u5e76\u6253\u5370\u6a21\u578b\u5728\u4e00\u6b21 forward \u8fc7\u7a0b\u4e2d\u6bcf\u4e2a op \u88ab\u8c03\u7528\u7684\u6b21\u6570\uff0c\u4ee5\u6b64\u68c0\u67e5\u6a21\u578b\u4e2d\u662f\u5426\u5b58\u5728\u5171\u4eab op\u3002\u82e5\u4e00\u4e2a module \u5b9e\u4f8b\u5728\u6a21\u578b\u4e2d\u4ee5\u4e0d\u540c\u7684\u540d\u5b57\u51fa\u73b0\u4e86\u591a\u6b21\uff0c\u51fd\u6570\u4f1a\u4f7f\u7528\u7b2c\u4e00\u4e2a\u540d\u5b57\uff0c\u4e14\u5c06\u6240\u6709\u7684\u8c03\u7528\u8bb0\u5728\u8fd9\u4e2a\u540d\u5b57\u4e0a\uff08\u60a8\u53ef\u4ee5\u770b\u5230\u76f8\u5173\u8b66\u544a\uff09\u3002"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import get_module_called_count\n\ndef get_module_called_count(\n    model: torch.nn.Module,\n    example_inputs,\n    check_leaf_module: callable = None,\n    print_tabulate: bool = True,\n) -> Dict[str, int]:\n"""\u8ba1\u7b97\u6a21\u578b\u4e2d\u53f6\u5b50\u8282\u70b9\u7684\u8c03\u7528\u6b21\u6570\n\n    \u53c2\u6570\uff1a\n        model\uff1a\u6a21\u578b\n        example_inputs\uff1a\u6a21\u578b\u8f93\u5165\n        check_leaf_module\uff1a\u68c0\u67e5 module \u662f\u5426\u662f\u4e00\u4e2a\u53f6\u5b50\u8282\u70b9\u3002\u9ed8\u8ba4\u4e3a None\uff0c\u4f7f\u7528\u9884\u5b9a\u4e49\u7684\n        is_leaf_module\uff0c\u5c06\u6240\u6709 horizon_plugin_pytorch \u4e2d\u5b9a\u4e49\u7684 op \u4ee5\u53ca\u672a\u652f\u6301\u7684\u6d6e\u70b9 op \u5f53\u4f5c\u4e3a\u53f6\u5b50\u8282\u70b9\u3002\n        print_tabulate\uff1a\u662f\u5426\u6253\u5370\u7ed3\u679c\u3002\u9ed8\u8ba4\u4e3a True\u3002\n\n    \u8f93\u51fa\uff1a\n        Dict[str, int]\uff1a\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u7684 name \u4ee5\u53ca\u5bf9\u5e94\u7684\u8c03\u7528\u6b21\u6570\u3002\n"""\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\nimport horizon_plugin_pytorch as horizon\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.utils.quant_profiler import get_module_called_count\n\nclass Net(nn.Module):\n    def __init__(self, quant=False, share_op=True):\n        super(Net, self).__init__()\n\n        self.quant_stubx = QuantStub()\n        self.quant_stuby = QuantStub()\n        self.mul_op = FloatFunctional()\n        self.cat_op = FloatFunctional()\n        self.quantized_ops = nn.Sequential(\n            nn.ReLU(),\n            nn.Sigmoid(),\n            nn.Softmax(),\n            nn.SiLU(),\n            horizon_nn.Interpolate(\n                scale_factor=2, recompute_scale_factor=True\n            ),\n            horizon_nn.Interpolate(\n                scale_factor=2.3, recompute_scale_factor=True\n            ),\n            nn.AvgPool2d(kernel_size=4),\n            nn.Upsample(scale_factor=1.3, mode="bilinear"),\n            nn.UpsamplingBilinear2d(scale_factor=0.7),\n        )\n        self.dequant_stub = DeQuantStub()\n        self.float_ops = nn.Sequential(\n            nn.Tanh(),\n            nn.LeakyReLU(),\n            nn.PReLU(),\n            nn.UpsamplingNearest2d(scale_factor=0.7),\n        )\n        self.quant = quant\n        self.share_op = share_op\n\n    def forward(self, x, y):\n        x = self.quant_stubx(x)\n        y = self.quant_stuby(y)\n        z = self.mul_op.mul(x, y)\n        x = self.cat_op.cat((x, y), dim=1)\n        if self.share_op:\n            x = self.cat_op.cat((x, y), dim=1)\n        x = self.quantized_ops(x)\n        x = self.dequant_stub(x)\n        if not self.quant:\n            x = self.float_ops(x)\n        return x\n\nshape = np.random.randint(10, 20, size=4).tolist()\ndata0 = torch.rand(size=shape)\ndata1 = torch.rand(size=shape)\nfloat_net = Net()\nget_module_called_count(float_net, (data0, data1))\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u8f93\u51fa\u4e3a\u4e00\u4e2a\u8868\u683c\uff0c\u8bb0\u5f55\u4e86\u6a21\u578b\u4e2d\u6bcf\u4e2a module \u7684\u8c03\u7528\u6b21\u6570\u3002\u6b63\u5e38\u60c5\u51b5\u4e0b\uff0c\u6bcf\u4e2a module \u5747\u8c03\u7528 1 \u6b21\uff1b\u82e5\u4e3a 0 \u6b21\uff0c\u5219\u8bf4\u660e\u8be5 module \u5b9a\u4e49\u4e86\u4f46\u672a\u88ab\u4f7f\u7528\uff1b\u82e5\u5927\u4e8e 1 \u6b21\uff0c\u5219\u8bf4\u660e\u8be5 module \u88ab\u5171\u4eab\u4f7f\u7528\u4e86\u591a\u6b21\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"name               called times\n---------------  --------------\nquant_stubx                   1\nquant_stuby                   1\nunused                        0\nmul_op                        1\ncat_op                        2\nquantized_ops.0               1\nquantized_ops.1               1\nquantized_ops.2               1\nquantized_ops.3               1\nquantized_ops.4               1\nquantized_ops.5               1\nquantized_ops.6               1\nquantized_ops.7               1\nquantized_ops.8               1\ndequant_stub                  1\nfloat_ops.0                   1\nfloat_ops.1                   1\nfloat_ops.2                   1\nfloat_ops.3                   1\n"})}),"\n",(0,o.jsx)(e.h3,{id:"a-name-qconfig-check-a",children:"\u91cf\u5316\u914d\u7f6e\u68c0\u67e5"}),"\n",(0,o.jsxs)(e.p,{children:["\u68c0\u67e5 calibration/QAT \u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42 op \u7684\u91cf\u5316\u914d\u7f6e\u3002 ",(0,o.jsx)(e.strong,{children:"\u8f93\u5165\u5fc5\u987b\u4e3a QAT \u6216 calibration \u6a21\u578b"})," \u3002\u8f93\u51fa\u7ed3\u679c\u4f1a\u4fdd\u5b58\u5230 ",(0,o.jsx)(e.code,{children:"qconfig_info.txt"})," \u6587\u4ef6\u3002"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import check_qconfig\n\ndef check_qconfig(\n    model: torch.nn.Module,\n    example_inputs: Any,\n    prefixes: Tuple = (),\n    types: Tuple = (),\n    custom_check_func: Optional[Callable] = None,\n    out_dir: Optional[str] = None,\n):\n    """\u68c0\u67e5 calibration/QAT \u6a21\u578b\u91cf\u5316\u914d\u7f6e\u3002\n\n    \u8be5\u51fd\u6570\u4f1a\n    1\uff09\u68c0\u67e5\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u7684\u8f93\u51fa activation \u548c weight \u7684\u91cf\u5316\u914d\u7f6e\u3002\u914d\u7f6e\u4fe1\u606f\u4f1a\u4fdd\u5b58\u5728\n    `qconfig_info.txt`\u4e2d\u3002\n    2\uff09\u68c0\u67e5\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u7684\u8f93\u5165\u8f93\u51fa\u7c7b\u578b\n\n    \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u51fd\u6570\u5728\u68c0\u67e5\u5230\u4e0b\u5217\u60c5\u51b5\u65f6\u4f1a\u6253\u5370\u63d0\u793a\u4fe1\u606f\u3002\n    1\uff09\u8f93\u51fa\u5c42 activation \u6ca1\u6709\u91cf\u5316\n    2\uff09\u56fa\u5b9a scale\n    3\uff09\u975e int8 \u91cf\u5316\u7684 weight\uff08\u76ee\u524d\u4ec5\u652f\u6301 int8 \u91cf\u5316\u7684 weight\uff09\n    4\uff09\u6a21\u578b\u8f93\u5165\u8f93\u51fa\u7c7b\u578b\u4e0d\u4e00\u6837\n    \u5982\u679c\u8981\u68c0\u67e5\u66f4\u591a\u7684\u4fe1\u606f\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7`custom_check_func`\u4f20\u5165\u81ea\u5b9a\u4e49\u7684\u68c0\u67e5\u51fd\u6570\n\n    \u53c2\u6570\uff1a\n        model\uff1a\u8f93\u5165\u6a21\u578b\uff0c\u5fc5\u987b\u4e3a qat \u6a21\u578b\n        example_inputs\uff1a\u6a21\u578b\u8f93\u5165\n        prefixes\uff1a\u6307\u5b9a\u8981\u68c0\u67e5\u91cf\u5316\u914d\u7f6e\u7684 op \u5728\u6a21\u578b\u4e2d\u5bf9\u5e94\u7684 layer name\uff08\u4ee5 prefixes \u5f00\n        \u5934\u7684 layer\uff09\n        types\uff1a\u6307\u5b9a\u8981\u68c0\u67e5\u91cf\u5316\u914d\u7f6e\u7684 op \u7684\u7c7b\u578b\n        custom_check_func\uff1a\u81ea\u5b9a\u4e49\u51fd\u6570\uff0c\u7528\u4e8e\u68c0\u67e5\u5176\u4ed6\u4fe1\u606f\u3002\u8fd9\u4e2a\u51fd\u6570\u5728 module \u7684 hook\n        \u4e2d\u8c03\u7528\uff0c\u56e0\u6b64\u9700\u8981\u5b9a\u4e49\u4e3a\u5982\u4e0b\u683c\u5f0f\uff1a\n            func(module, input, output) -> None\n        out_dir\uff1a\u4fdd\u5b58\u7ed3\u679c\u6587\u4ef6`qconfig_info.txt`\u7684\u8def\u5f84\u3002\u82e5\u4e3a None\uff0c\u5219\u9ed8\u8ba4\u4fdd\u5b58\u5728\u5f53\u524d\n        \u8def\u5f84\u3002\n    """\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport torch\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.dtype import qint16\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.quantization import get_default_qconfig\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.quantization.quantize_fx import (\n    convert_fx,\n    prepare_qat_fx,\n)\nfrom horizon_plugin_pytorch.quantization.observer import FixedScaleObserver\nfrom horizon_plugin_pytorch.utils.quant_profiler import check_qconfig\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\n\n\nclass Conv2dModule(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel_size=1,\n        stride=1,\n        padding=0,\n        dilation=1,\n        groups=1,\n        bias=True,\n        padding_mode="zeros",\n    ):\n        super().__init__()\n        self.conv2d = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            groups,\n            bias,\n            padding_mode,\n        )\n\n        self.add = FloatFunctional()\n        self.bn_mod = nn.BatchNorm2d(out_channels)\n        self.relu_mod = nn.ReLU()\n\n    def forward(self, x, y):\n        x = self.conv2d(x)\n        x = self.bn_mod(x)\n        x = self.add.add(x, y)\n        x = self.relu_mod(x)\n\n        return x\n\n\nclass TestFuseNet(nn.Module):\n    def __init__(self, channels) -> None:\n        super().__init__()\n        self.convmod1 = Conv2dModule(channels, channels)\n        self.convmod2 = Conv2dModule(channels, channels)\n        self.convmod3 = Conv2dModule(channels, channels)\n        self.shared_conv = nn.Conv2d(channels, channels, 1)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.bn2 = nn.BatchNorm2d(channels)\n        self.sub = FloatFunctional()\n        self.relu = nn.ReLU()\n\n    def forward(self, x, y):\n        x = self.convmod1(x, y)\n        x = self.convmod2(y, x)\n        x = self.convmod3(x, y)\n        x = self.shared_conv(x)\n        x = self.bn1(x)\n        y = self.shared_conv(y)\n        y = self.bn2(y)\n        x = self.sub.sub(x, y)\n        x = self.relu(x)\n\n        return x\n\n\nfloat_net = TestFuseNet(3)\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\n\n# \u624b\u52a8\u6784\u9020\u4e0d\u652f\u6301\u7684\u6216\u7279\u6b8a\u7684 cases\nsub_qconfig = get_default_qconfig(\n    # \u56fa\u5b9a sub \u7684\u8f93\u51fa scale\n    activation_qkwargs={\n        "observer": FixedScaleObserver,\n        "scale": 1 / 2 ** 15,\n        "dtype": qint16,\n    }\n)\nqat_net = prepare_qat_fx(\n    float_net,\n    {\n        "": get_default_qconfig(\n            weight_qkwargs={\n                "qscheme": torch.per_channel_symmetric,\n                "ch_axis": 0,\n                # \u4e0d\u652f\u6301 weight \u7684 int16 \u91cf\u5316\n                "dtype": qint16,\n            }\n        ),\n        "module_name": [("sub", sub_qconfig)]\n    }\n)\n\nshape = np.random.randint(10, 20, size=4).tolist()\nshape[1] = 3\ndata0 = torch.rand(size=shape)\ndata1 = torch.rand(size=shape)\ncheck_qconfig(qat_net, (data0, data1))\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u8f93\u51fa\u7ed3\u679c\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"qconfig_info.txt"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"Each layer out qconfig:\n+-------------------+----------------------------------------------------------------------------+--------------------+-------------+----------------+\n| Module Name       | Module Type                                                                | Input dtype        | out dtype   | ch_axis        |\n|-------------------+----------------------------------------------------------------------------+--------------------+-------------+----------------|\n| quantx            | <class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'>                    | torch.float32      | qint8       | -1             |\n| quanty            | <class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'>                    | torch.float32      | qint8       | -1             |\n| convmod1.add      | <class 'horizon_plugin_pytorch.nn.qat.conv2d.ConvAddReLU2d'>               | ['qint8', 'qint8'] | qint8       | -1             |\n| convmod2.conv2d   | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>                      | qint8              | qint8       | -1             |\n| convmod2.bn_mod   | <class 'horizon_plugin_pytorch.nn.qat.batchnorm.BatchNorm2d'>              | qint8              | qint8       | -1             |\n| convmod2.add[add] | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | ['qint8', 'qint8'] | qint8       | -1             |\n| convmod2.relu_mod | <class 'horizon_plugin_pytorch.nn.qat.relu.ReLU'>                          | qint8              | qint8       | qconfig = None |\n| convmod3.add      | <class 'horizon_plugin_pytorch.nn.qat.conv2d.ConvAddReLU2d'>               | ['qint8', 'qint8'] | qint8       | -1             |\n| shared_conv       | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>                      | qint8              | qint8       | -1             |\n| bn1               | <class 'horizon_plugin_pytorch.nn.qat.batchnorm.BatchNorm2d'>              | qint8              | qint8       | -1             |\n| shared_conv(1)    | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>                      | qint8              | qint8       | -1             |\n| bn2               | <class 'horizon_plugin_pytorch.nn.qat.batchnorm.BatchNorm2d'>              | qint8              | qint8       | -1             |\n| sub[sub]          | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | ['qint8', 'qint8'] | qint16      | -1             |\n| relu              | <class 'horizon_plugin_pytorch.nn.qat.relu.ReLU'>                          | qint16             | qint16      | qconfig = None |\n+-------------------+----------------------------------------------------------------------------+--------------------+-------------+----------------+\n\nWeight qconfig:\n+-----------------+--------------------------------------------------------------+----------------+-----------+\n| Module Name     | Module Type                                                  | weight dtype   |   ch_axis |\n|-----------------+--------------------------------------------------------------+----------------+-----------|\n| convmod1.add    | <class 'horizon_plugin_pytorch.nn.qat.conv2d.ConvAddReLU2d'> | qint16         |         0 |\n| convmod2.conv2d | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>        | qint16         |         0 |\n| convmod3.add    | <class 'horizon_plugin_pytorch.nn.qat.conv2d.ConvAddReLU2d'> | qint16         |         0 |\n| shared_conv     | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>        | qint16         |         0 |\n| shared_conv(1)  | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>        | qint16         |         0 |\n+-----------------+--------------------------------------------------------------+----------------+-----------+\n\nPlease check if these OPs qconfigs are expected..\n+-----------------+----------------------------------------------------------------------------+------------------------------------------------------------------+\n| Module Name     | Module Type                                                                | Msg                                                              |\n|-----------------+----------------------------------------------------------------------------+------------------------------------------------------------------|\n| convmod1.add    | <class 'horizon_plugin_pytorch.nn.qat.conv2d.ConvAddReLU2d'>               | qint16 weight!!!                                                 |\n| convmod2.conv2d | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>                      | qint16 weight!!!                                                 |\n| convmod3.add    | <class 'horizon_plugin_pytorch.nn.qat.conv2d.ConvAddReLU2d'>               | qint16 weight!!!                                                 |\n| shared_conv     | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>                      | qint16 weight!!!                                                 |\n| shared_conv(1)  | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>                      | qint16 weight!!!                                                 |\n| sub[sub]        | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | input dtype ['qint8', 'qint8'] is not same with out dtype qint16 |\n| sub[sub]        | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | Fixed scale 3.0517578125e-05                                     |\n+-----------------+----------------------------------------------------------------------------+------------------------------------------------------------------+\n"})}),"\n",(0,o.jsx)(e.p,{children:"\u8f93\u51fa\u7684 txt \u6587\u4ef6\u4e2d\u4fdd\u5b58\u4e86\u4e09\u4e2a\u8868\u683c\uff0c\u6309\u7167\u4ece\u4e0a\u5230\u4e0b\u7684\u987a\u5e8f\uff0c\u6bcf\u4e2a\u8868\u683c\u7684\u542b\u4e49\u5982\u4e0b\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6bcf\u4e00\u5c42\u8f93\u51fa\u7684\u91cf\u5316\u4fe1\u606f\uff0c\u4ece\u5de6\u5230\u53f3\u6bcf\u4e00\u5217\u5206\u522b\u8868\u793a\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Module Name\uff1a\u6bcf\u4e2a module \u5728\u6a21\u578b\u4e2d\u5b9a\u4e49\u7684 name"}),"\n",(0,o.jsx)(e.li,{children:"Module Type\uff1a\u6bcf\u4e2a module \u7684\u5b9e\u9645\u7c7b\u578b"}),"\n",(0,o.jsx)(e.li,{children:"Input dtype\uff1a\u6bcf\u4e2a module \u7684\u8f93\u5165\u7c7b\u578b"}),"\n",(0,o.jsx)(e.li,{children:"out dtype\uff1a\u6bcf\u4e2a module \u7684\u8f93\u51fa\u7c7b\u578b"}),"\n",(0,o.jsx)(e.li,{children:"ch_axis\uff1a\u5728\u54ea\u4e00\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u91cf\u5316\u3002-1 \u8868\u793a per-tensor \u91cf\u5316\uff1b\u82e5\u663e\u793a qconfig=None\uff0c\u5219\u8bf4\u660e\u8be5 module \u6ca1\u6709\u914d\u7f6e qconfig\uff0c\u4e0d\u4f1a\u8fdb\u884c\u91cf\u5316\u64cd\u4f5c"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6bcf\u4e00\u5c42\u4e2d weight \u7684\u91cf\u5316\u4fe1\u606f\uff0c\u4ece\u5de6\u5230\u53f3\u6bcf\u4e00\u5217\u5206\u522b\u8868\u793a\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Module Name\uff1a\u6bcf\u4e2a module \u5728\u6a21\u578b\u4e2d\u5b9a\u4e49\u7684 name"}),"\n",(0,o.jsx)(e.li,{children:"Module Type\uff1a\u6bcf\u4e2a module \u7684\u5b9e\u9645\u7c7b\u578b"}),"\n",(0,o.jsx)(e.li,{children:"weight dtype\uff1a\u5bf9 weight \u91c7\u7528\u7684\u4f55\u79cd\u91cf\u5316\u7cbe\u5ea6\uff0c\u76ee\u524d\u4ec5\u652f\u6301 qint8 \u91cf\u5316"}),"\n",(0,o.jsx)(e.li,{children:"ch_axis\uff1a\u5728\u54ea\u4e00\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u91cf\u5316\u3002-1 \u8868\u793a per-tensor \u91cf\u5316\uff1b\u9ed8\u8ba4 weight \u5747\u5728\u7b2c 0 \u7ef4\u4e0a\u91cf\u5316\uff0c\u82e5\u663e\u793a qconfig=None\uff0c\u5219\u8bf4\u660e\u8be5 module \u7684 weight \u6ca1\u6709\u914d\u7f6e qconfig\uff0c\u4e0d\u4f1a\u8fdb\u884c\u91cf\u5316\u64cd\u4f5c"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6a21\u578b\u4e2d\u7279\u6b8a\u91cf\u5316\u914d\u7f6e\u7684 module\uff08\u5e76\u4e0d\u8868\u793a\u914d\u7f6e\u9519\u8bef\uff0c\u9700\u8981\u9010\u4e2a\u68c0\u67e5\uff09\u3002\u8be5\u8868\u683c\u4e5f\u4f1a\u5728\u5c4f\u5e55\u4e0a\u8f93\u51fa\u3002"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Module Name\uff1a\u6bcf\u4e2a module \u5728\u6a21\u578b\u4e2d\u5b9a\u4e49\u7684 name"}),"\n",(0,o.jsx)(e.li,{children:"Module Type\uff1a\u6bcf\u4e2a module \u7684\u5b9e\u9645\u7c7b\u578b"}),"\n",(0,o.jsx)(e.li,{children:"Msg\uff1a\u7279\u6b8a\u7684\u91cf\u5316\u914d\u7f6e"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u5c4f\u5e55\u8f93\u51fa"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"Please check if these OPs qconfigs are expected..\n+---------------+----------------------------------------------------------------------------+------------------------------------------------------------------+\n| Module Name   | Module Type                                                                | Msg                                                              |\n|---------------+----------------------------------------------------------------------------+------------------------------------------------------------------|\n| convmod1.add  | <class 'horizon_plugin_pytorch.nn.qat.conv2d.ConvAddReLU2d'>               | qint16 weight!!!                                                 |\n| convmod2.add  | <class 'horizon_plugin_pytorch.nn.qat.conv2d.ConvAddReLU2d'>               | qint16 weight!!!                                                 |\n| convmod3.add  | <class 'horizon_plugin_pytorch.nn.qat.conv2d.ConvAddReLU2d'>               | qint16 weight!!!                                                 |\n| bn1           | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>                      | qint16 weight!!!                                                 |\n| shared_conv   | <class 'horizon_plugin_pytorch.nn.qat.conv2d.Conv2d'>                      | qint16 weight!!!                                                 |\n| sub           | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | input dtype ['qint8', 'qint8'] is not same with out dtype qint16 |\n| sub           | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | Fixed scale 3.0517578125e-05                                     |\n+---------------+----------------------------------------------------------------------------+------------------------------------------------------------------+\n"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"onnx-a-name-onnx-a",children:"\u53ef\u89c6\u5316\uff1aONNX \u6a21\u578b\u53ef\u89c6\u5316"}),"\n",(0,o.jsxs)(e.p,{children:["\u76ee\u524d horizon_plugin_pytorch \u652f\u6301\u4efb\u610f\u9636\u6bb5\u7684\u6a21\u578b\u53ef\u89c6\u5316\u3002\u8fd9\u91cc\u7684\u53ef\u89c6\u5316\u6307\u7684\u662f\u53ef\u89c6\u5316\u6a21\u578b\u7ed3\u6784\uff0c\u9ed8\u8ba4\u5bfc\u51fa onnx\uff0c\u53ef\u4ee5\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"netron"})," \u67e5\u770b\u3002",(0,o.jsx)(e.strong,{children:"\u76ee\u524d\u5bfc\u51fa\u7684 onnx \u4e0d\u652f\u6301\u63a8\u7406\uff0c\u4ec5\u652f\u6301\u53ef\u89c6\u5316\u67e5\u770b\u6a21\u578b\u7ed3\u6784\u3002"})]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# from horizon_plugin_pytorch.utils.onnx_helper import (\n#     export_to_onnx,\n#     export_quantized_onnx,\n# )\n\nexport_to_onnx(\n    model,\n    args,\n    f,\n    export_params=True,\n    verbose=False,\n    training=TrainingMode.EVAL,\n    input_names=None,\n    output_names=None,\n    operator_export_type=OperatorExportTypes.ONNX_FALLTHROUGH,\n    do_constant_folding=True,\n    example_outputs=None,\n    dynamic_axes=None,\n    enable_onnx_checker=False,\n)\n\nexport_quantized_onnx(\n    model,\n    args,\n    f,\n    export_params=True,\n    verbose=False,\n    training=TrainingMode.EVAL,\n    input_names=None,\n    output_names=None,\n    operator_export_type=OperatorExportTypes.ONNX_FALLTHROUGH,\n    opset_version=None,\n    do_constant_folding=True,\n    example_outputs=None,\n    dynamic_axes=None,\n    keep_initializers_as_inputs=None,\n    custom_opsets=None,\n)\n"})}),"\n",(0,o.jsxs)(e.p,{children:["\u53c2\u6570\u7684\u542b\u4e49\u548c ",(0,o.jsx)(e.code,{children:"torch.onnx.export"})," \u4fdd\u6301\u4e00\u81f4\uff0c\u552f\u4e00\u7684\u533a\u522b\u662f\u53c2\u6570",(0,o.jsx)(e.code,{children:"operator_export_type=OperatorExportTypes.ONNX_FALLTHROUGH"})," \u3002"]}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u65f6\u9700\u6ce8\u610f\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u6d6e\u70b9\u6a21\u578b\u548c QAT \u6a21\u578b\u5bfc\u51fa onnx \u8bf7\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"export_to_onnx"})," \u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u5b9a\u70b9\u6a21\u578b\u5bfc\u51fa onnx \u8bf7\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"export_quantized_onnx"})," \u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u53ef\u89c6\u5316\u7684\u7c92\u5ea6\u4e3a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"horizon_plugin_pytorch \u4e2d\u81ea\u5b9a\u4e49\u7684 op\uff0c\u5305\u62ec\u6d6e\u70b9 op \u548c\u5b9a\u70b9 op\uff0cop \u5185\u90e8\u7684\u5b9e\u73b0\u4e0d\u4f1a\u88ab\u53ef\u89c6\u5316\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6d6e\u70b9\u6a21\u578b\u4e2d\u4f7f\u7528\u7684\u793e\u533a op \u7684\u53ef\u89c6\u5316\u7c92\u5ea6\u7531\u793e\u533a\u51b3\u5b9a\u3002"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from copy import deepcopy\n\nimport torch\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\nimport horizon_plugin_pytorch as horizon\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.quantization.quantize_fx import (\n    convert_fx,\n    prepare_qat_fx,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.utils.onnx_helper import (\n    export_to_onnx,\n    export_quantized_onnx,\n)\n\nclass Net(nn.Module):\n    def __init__(self, quant=False, share_op=True):\n        super(Net, self).__init__()\n\n        self.quant_stubx = QuantStub()\n        self.quant_stuby = QuantStub()\n        self.mul_op = FloatFunctional()\n        self.cat_op = FloatFunctional()\n        self.quantized_ops = nn.Sequential(\n            nn.ReLU(),\n            nn.Sigmoid(),\n            nn.Softmax(),\n            nn.SiLU(),\n            horizon_nn.Interpolate(\n                scale_factor=2, recompute_scale_factor=True\n            ),\n            horizon_nn.Interpolate(\n                scale_factor=2.3, recompute_scale_factor=True\n            ),\n            nn.AvgPool2d(kernel_size=4),\n            nn.Upsample(scale_factor=1.3, mode="bilinear"),\n            nn.UpsamplingBilinear2d(scale_factor=0.7),\n        )\n        self.dequant_stub = DeQuantStub()\n        self.float_ops = nn.Sequential(\n            nn.Tanh(),\n            nn.LeakyReLU(),\n            nn.PReLU(),\n            nn.UpsamplingNearest2d(scale_factor=0.7),\n        )\n        self.quant = quant\n        self.share_op = share_op\n\n    def forward(self, x, y):\n        x = self.quant_stubx(x)\n        y = self.quant_stuby(y)\n        z = self.mul_op.mul(x, y)\n        x = self.cat_op.cat((x, y), dim=1)\n        if self.share_op:\n            x = self.cat_op.cat((x, y), dim=1)\n        x = self.quantized_ops(x)\n        x = self.dequant_stub(x)\n        if not self.quant:\n            x = self.float_ops(x)\n        return x\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\ndevice = torch.device("cuda")\nfloat_net = Net(quant=True, share_op=True).to(device)\nfloat_net2 = deepcopy(float_net)\nqat_net = prepare_qat_fx(\n    float_net2, {"": default_qat_8bit_fake_quant_qconfig}\n)\nqat_net(data, data)\nqat_net2 = deepcopy(qat_net)\nquantized_net = convert_fx(qat_net2)\ndata = torch.arange(1 * 3 * 4 * 4) / 100 + 1\ndata = data.reshape((1, 3, 4, 4))\ndata = data.to(torch.float32).to(device)\n\nexport_to_onnx(float_net, (data, data), "float_test.onnx")\nexport_to_onnx(qat_net, (data, data), "qat_test.onnx")\nexport_quantized_onnx(quantized_net, (data, data), "quantized_test.onnx")\n'})}),"\n",(0,o.jsx)(e.h3,{id:"a-name-similarity-a",children:"\u76f8\u4f3c\u5ea6\u5bf9\u6bd4"}),"\n",(0,o.jsx)(e.p,{children:"\u5f53\u51fa\u73b0\u5b9a\u70b9\u6a21\u578b\u76f8\u6bd4 QAT \u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\u8f83\u591a\u7684\u60c5\u51b5\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u76f8\u4f3c\u5ea6\u5bf9\u6bd4\u5de5\u5177\u6bd4\u8f83\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u8f93\u51fa\u7684\u76f8\u4f3c\u5ea6\uff0c\u5feb\u901f\u5b9a\u4f4d\u5230\u662f\u54ea\u4e00\u4e2a op \u5bfc\u81f4\u7684\u7cbe\u5ea6\u4e0b\u964d\u3002"}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u82e5",(0,o.jsx)(e.strong,{children:"\u67d0\u4e00\u5c42\u7684\u8f93\u51fa\u5168\u4e3a0\uff0c\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65f6\u76f8\u4f3c\u5ea6\u7ed3\u679c\u4e5f\u662f0"}),"\u3002\u6b64\u65f6\u53ef\u4ee5\u68c0\u67e5\u4e00\u4e0b\u8be5\u5c42\u8f93\u51fa\u662f\u5426\u4e3a\u51680\uff0c\u6216\u8005\u6839\u636e\u6253\u5370\u7684 ",(0,o.jsx)(e.code,{children:"atol"})," \u7b49\u6307\u6807\u786e\u8ba4\u4e00\u4e0b\u8f93\u51fa\u662f\u5426\u76f8\u540c\u3002\u82e5",(0,o.jsx)(e.strong,{children:"\u67d0\u4e00\u5c42\u7684\u8f93\u51fa\u5b8c\u5168\u76f8\u540c\uff0c\u4f7f\u7528\u4fe1\u566a\u6bd4\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u65f6\u7ed3\u679c\u4e3ainf"}),"\uff1b"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u82e5",(0,o.jsx)(e.code,{children:"device=None"}),"\uff0c\u5de5\u5177\u4e0d\u4f1a\u505a\u6a21\u578b\u548c\u8f93\u5165\u6570\u636e\u7684\u642c\u8fd0\uff0c",(0,o.jsx)(e.strong,{children:"\u9700\u8981\u60a8\u624b\u52a8\u4fdd\u8bc1\u6a21\u578b\u548c\u6a21\u578b\u8f93\u5165\u5747\u5728\u540c\u4e00\u4e2adevice\u4e0a"}),"\uff1b"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u652f\u6301\u4efb\u610f\u4e24\u9636\u6bb5\u7684\u6a21\u578b\u4ee5\u4efb\u610f\u8f93\u5165\u987a\u5e8f\uff0c\u5728\u4efb\u610f\u4e24\u4e2a ",(0,o.jsx)(e.code,{children:"device"})," \u4e0a\u6bd4\u8f83\u76f8\u4f3c\u5ea6\u3002\u63a8\u8350\u6309\u7167 ",(0,o.jsx)(e.code,{children:"float/qat/quantized"})," \u7684\u987a\u5e8f\u8f93\u5165\uff0c\u6bd4\u5982\uff08float\uff0cqat\uff09\uff08qat\uff0cquantized\uff09\u8fd9\u6837\u3002\u5982\u679c\u662f\uff08qat\uff0cfloat\uff09\u7684\u987a\u5e8f\uff0c\u5bf9\u76f8\u4f3c\u5ea6\u548c\u5355\u7b97\u5b50\u8bef\u5dee\u6ca1\u6709\u5f71\u54cd\uff0c\u4f46\u662f\u7ed3\u679c\u4e2d",(0,o.jsx)(e.code,{children:"\u76f8\u540c\u8f93\u5165\u4e0b\u7684\u5355\u7b97\u5b50\u8bef\u5dee"}),"\u9879\u53ef\u80fd\u4f1a\u6709\u504f\u5dee\uff0c\u56e0\u4e3a\u65e0\u6cd5\u751f\u6210\u548c float \u6a21\u578b\u5b8c\u5168\u5bf9\u5e94\u7684\u8f93\u5165\u7ed9 QAT \u6a21\u578b\u3002\u6b64\u5916\uff0c\u56e0\u4e3a QAT \u8bad\u7ec3\u4e4b\u540e\uff0c\u6a21\u578b\u53c2\u6570\u4f1a\u6539\u53d8\uff0c\u6240\u4ee5\u76f4\u63a5\u6bd4\u8f83 float \u548c\u8bad\u7ec3\u4e4b\u540e\u7684 QAT \u6a21\u578b\u7684\u76f8\u4f3c\u5ea6\u53c2\u8003\u610f\u4e49\u4e0d\u5927\uff0c\u5efa\u8bae\u6bd4\u8f83 float \u548c\u7ecf\u8fc7 calibration \u4e4b\u540e\u4e14\u672a\u8bad\u7ec3\u7684 QAT \u6a21\u578b\u7684\u76f8\u4f3c\u5ea6\uff1b"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"fx \u6a21\u5f0f\u4e0b\uff0c\u6a21\u578b\u8f6c\u6362\u7684\u8fc7\u7a0b\u9ed8\u8ba4\u90fd\u662f inplace \u7684\uff0c\u5982\u679c\u9700\u8981\u4f7f\u7528\u76f8\u4f3c\u5ea6\u5de5\u5177\uff0c\u8bf7\u60a8\u624b\u52a8\u5728\u8fdb\u884c\u8f6c\u6362\u524d deepcopy \u4e00\u4efd\u539f\u59cb\u6a21\u578b\u3002\u5426\u5219\u8f6c\u6362\u540e\uff0c\u4f1a\u9519\u8bef\u5730\u6bd4\u8f83\u4e24\u4e2a\u76f8\u540c\u6a21\u578b\u7684\u76f8\u4f3c\u5ea6\u3002"}),"\n"]}),"\n"]})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import featuremap_similarity\n\ndef featuremap_similarity(\n    model1: torch.nn.Module,\n    model2: torch.nn.Module,\n    inputs: Any,\n    similarity_func: Union[str, Callable] = "Cosine",\n    threshold: Optional[Real] = None,\n    devices: Union[torch.device, tuple, None] = None,\n    out_dir: Optional[str] = None,\n)\n"""\n    \u76f8\u4f3c\u5ea6\u5bf9\u6bd4\u51fd\u6570\uff0c\u8ba1\u7b97\u5e76\u5bf9\u6bd4\u4e24\u4e2a\u8f93\u5165\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u8f93\u51fa\u7279\u5f81\u7684\u76f8\u4f3c\u5ea6\u3002\u8f93\u5165\u6a21\u578b\u53ef\u4ee5\u662f\n    \u6d6e\u70b9\u6a21\u578b\u3001\u7b97\u5b50\u878d\u5408\u540e\u7684\u6a21\u578b\u3001\u6821\u51c6\u6a21\u578b\u3001QAT \u6a21\u578b\u6216\u8005\u5b9a\u70b9\u6a21\u578b\u3002\n\n    \u53c2\u6570\uff1a\n        model1\uff1a\u53ef\u4ee5\u662f\u6d6e\u70b9\u6a21\u578b\u3001\u7b97\u5b50\u878d\u5408\u540e\u7684\u6a21\u578b\u3001\u6821\u51c6\u6a21\u578b\u3001QAT \u6a21\u578b\u6216\u8005\u5b9a\u70b9\u6a21\u578b\n        model2\uff1a\u53ef\u4ee5\u662f\u6d6e\u70b9\u6a21\u578b\u3001\u7b97\u5b50\u878d\u5408\u540e\u7684\u6a21\u578b\u3001\u6821\u51c6\u6a21\u578b\u3001QAT \u6a21\u578b\u6216\u8005\u5b9a\u70b9\u6a21\u578b\n        inputs\uff1a\u6a21\u578b\u8f93\u5165\n        similarity_func\uff1a\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u7684\u65b9\u6cd5\u3002\u9ed8\u8ba4\u4e3a\u4f59\u5f26\u76f8\u4f3c\u5ea6 Cosine\u3002\u652f\u6301 Cosine/\n            MSE/L1/KL/SQNR/\u81ea\u5b9a\u4e49\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u51fd\u6570\u3002\u5982\u679c\u662f\u81ea\u5b9a\u4e49\u76f8\u4f3c\u5ea6\u51fd\u6570\uff0c\u6700\u597d\u8fd4\u56de\u4e00\u4e2a\n            \u5e38\u91cf\u6216\u8005\u4ec5\u6709\u4e00\u4e2a\u6570\u503c\u7684 tensor\uff0c\u5426\u5219\u663e\u793a\u7684\u7ed3\u679c\u53ef\u80fd\u4e0d\u7b26\u5408\u9884\u671f\u3002\n        threshold\uff1a\u9608\u503c\u3002\u9ed8\u8ba4\u4e3a None\uff0c\u4f1a\u6839\u636e\u4e0d\u540c\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u51fd\u6570\u8bbe\u7f6e\u6210\u4e0d\u540c\u7684\u9ed8\u8ba4\u9608\u503c\u3002\n            \u5982\u679c\u60a8\u4f20\u8fdb\u4e00\u4e2a\u6570\u503c\uff0c\u6309\u7167\u76f8\u4f3c\u5ea6\u6bd4\u8f83\u65b9\u6cd5\u7684\u4e0d\u540c\uff0c\u8d85\u8fc7\u6216\u8005\u5c0f\u4e8e\u8be5\u9608\u503c\u7684\u503c\u548c\u5bf9\u5e94\n            op \u7684\u76f8\u4f3c\u5ea6\u4fe1\u606f\u4f1a\u5728\u5c4f\u5e55\u6253\u5370\u3002\n        devices\uff1a\u6307\u5b9a\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u65f6\u6a21\u578b\u5728\u54ea\u4e2a device \u4e0a\u8fdb\u884c forward\u3002\u82e5\u4e3a None\uff0c\u5219\u9ed8\u8ba4\u5728\u6a21\n            \u578b\u8f93\u5165\u65f6\u7684 device \u4e0a\u8fdb\u884c forward\uff1b\u82e5\u4ec5\u6709\u4e00\u4e2a\u53c2\u6570\u5982 torch.device("cpu")\uff0c\u5219\n            \u4f1a\u628a\u4e24\u4e2a\u6a21\u578b\u5747\u79fb\u52a8\u5230\u6307\u5b9a\u7684 device \u4e0a forward\uff1b\u82e5\u6307\u5b9a\u4e86\u4e24\u4e2a\u503c\u5982\n            (torch.device("cpu"), torch.device("cuda"))\uff0c\u5219\u4f1a\u628a\u4e24\u4e2a\u6a21\u578b\u5206\u522b\u79fb\u52a8\u5230\n            \u5bf9\u5e94\u7684 device \u4e0a forward\u3002\u4e00\u822c\u7528\u4e8e\u6bd4\u8f83\u540c\u4e00\u4e2a\u6a21\u578b\u540c\u4e00\u4e2a\u9636\u6bb5\u7684 CPU/GPU \u7684\u4e2d\u95f4\u7ed3\u679c\u3002\n        out_dir: \u6307\u5b9a\u8f93\u51fa\u7684\u7ed3\u679c\u6587\u4ef6\u548c\u56fe\u7247\u7684\u8def\u5f84\u3002\u9ed8\u8ba4\u4e3a None\uff0c\u4fdd\u5b58\u5230\u5f53\u524d\u8def\u5f84\u3002\n\n    \u8f93\u51fa\uff1a\n        \u8f93\u51fa\u4e3a\u4e00\u4e2a\u5217\u8868\uff0c\u5217\u8868\u4e2d\u6bcf\u4e00\u9879\u90fd\u662f\u4e00\u4e2a\u5b50\u5217\u8868\uff0c\u6bcf\u4e2a\u5b50\u5217\u8868\u4ee3\u8868\u6bcf\u4e00\u5c42\u7684\u76f8\u4f3c\u5ea6\u4fe1\u606f\uff0c\n        \u683c\u5f0f\u4e3a [\u7d22\u5f15\uff0c\u6a21\u5757\u540d\uff0c\u6a21\u5757\u7c7b\u578b\uff0c\u76f8\u4f3c\u5ea6\uff0c\u8f93\u51fa\u503c\u7684 scale\uff0c\u6700\u5927\u8bef\u5dee\uff0c\n        \u5355\u7b97\u5b50\u8bef\u5dee\uff08N scale\uff09\uff0c\u76f8\u540c\u8f93\u5165\u65f6\u8f93\u51fa\u7684\u5355\u7b97\u5b50\u8bef\u5dee\uff08N scale\uff09]\n"""\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from copy import deepcopy\n\nimport torch\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\nimport horizon_plugin_pytorch as horizon\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.quantization.quantize_fx import (\n    convert_fx,\n    prepare_qat_fx,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.utils.quant_profiler import featuremap_similarity\n\nclass Net(nn.Module):\n    def __init__(self, quant=False, share_op=True):\n        super(Net, self).__init__()\n\n        self.quant_stubx = QuantStub()\n        self.quant_stuby = QuantStub()\n        self.mul_op = FloatFunctional()\n        self.cat_op = FloatFunctional()\n        self.quantized_ops = nn.Sequential(\n            nn.ReLU(),\n            nn.Sigmoid(),\n            nn.Softmax(),\n            nn.SiLU(),\n            horizon_nn.Interpolate(\n                scale_factor=2, recompute_scale_factor=True\n            ),\n            horizon_nn.Interpolate(\n                scale_factor=2.3, recompute_scale_factor=True\n            ),\n            nn.AvgPool2d(kernel_size=4),\n            nn.Upsample(scale_factor=1.3, mode="bilinear"),\n            nn.UpsamplingBilinear2d(scale_factor=0.7),\n        )\n        self.dequant_stub = DeQuantStub()\n        self.float_ops = nn.Sequential(\n            nn.Tanh(),\n            nn.LeakyReLU(),\n            nn.PReLU(),\n            nn.UpsamplingNearest2d(scale_factor=0.7),\n        )\n        self.quant = quant\n        self.share_op = share_op\n\n    def forward(self, x, y):\n        x = self.quant_stubx(x)\n        y = self.quant_stuby(y)\n        z = self.mul_op.mul(x, y)\n        x = self.cat_op.cat((x, y), dim=1)\n        if self.share_op:\n            x = self.cat_op.cat((x, y), dim=1)\n        x = self.quantized_ops(x)\n        x = self.dequant_stub(x)\n        if not self.quant:\n            x = self.float_ops(x)\n        return x\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\ndevice = torch.device("cuda")\nfloat_net = Net(quant=True, share_op=True).to(device)\n# fx \u5747\u4e3a inplace \u7684\u4fee\u6539\uff0c\u5982\u679c\u9700\u8981\u6bd4\u8f83\u76f8\u4f3c\u5ea6\uff0c\u9700\u8981\u624b\u52a8\u5c06\u6a21\u578b deepcopy \u4e00\u4efd\u518d\u8fdb\u884c\u8f6c\u6362\nfloat_net2 = deepcopy(float_net)\nqat_net = prepare_qat_fx(\n    float_net2, {"": default_qat_8bit_fake_quant_qconfig}\n)\nqat_net(data, data)\nqat_net2 = deepcopy(qat_net)\nbpu_net = convert_fx(qat_net2)\ndata = torch.arange(1 * 3 * 4 * 4) / 100 + 1\ndata = data.reshape((1, 3, 4, 4))\ndata = data.to(torch.float32).to(device)\nfeaturemap_similarity(qat_net, bpu_net, (data, data))\n'})}),"\n",(0,o.jsxs)(e.p,{children:["\u8fd0\u884c\u540e\u4f1a\u5728\u5f53\u524d\u76ee\u5f55\u6216\u8005 ",(0,o.jsx)(e.code,{children:"out_dir"})," \u53c2\u6570\u6307\u5b9a\u7684\u76ee\u5f55\u4e0b\u751f\u6210\u5982\u4e0b\u6587\u4ef6\uff1a"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["similarity.txt\uff1a\u4ee5\u8868\u683c\u7684\u5f62\u5f0f\uff0c\u6309\u7167\u6a21\u578b ",(0,o.jsx)(e.code,{children:"forward"})," \u7684\u987a\u5e8f\u6253\u5370\u6bcf\u4e00\u5c42\u7684\u76f8\u4f3c\u5ea6\u548c\u5355\u7b97\u5b50\u8bef\u5dee\u7b49\u7ed3\u679c\uff0c\u8868\u683c\u4e2d\u4ece\u5de6\u5230\u53f3\u6bcf\u4e00\u5217\u5206\u522b\u4e3a\uff1a"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Index\uff1a\u7d22\u5f15\uff0c\u6309\u7167\u6a21\u578b forward \u987a\u5e8f\uff0c\u4ece 0 \u5f00\u59cb\u4e3a\u6a21\u578b\u4e2d\u6bcf\u4e00\u4e2a op \u7f16\u53f7\u3002\u65e0\u5b9e\u9645\u610f\u4e49\uff0c\u7528\u4e8e\u76f8\u4f3c\u5ea6\u56fe\u50cf\u4e2d\u7684\u6a2a\u8f74\u7f16\u53f7\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Module Name\uff1a\u8be5 op \u5728\u6a21\u578b\u4e2d\u5b9a\u4e49\u4f7f\u7528\u7684\u540d\u5b57\uff0c\u5982 backbone.mod1.conv\uff1b\u4e0d\u540c\u683c\u5f0f\u7684\u540e\u7f00\u4ee3\u7406\u4e86\u4e0d\u540c\u7684\u542b\u4e49\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u82e5\u6a21\u5757\u540d\u6709\u540e\u7f00'(I)'\uff0c\u8868\u793a\u8be5 op \u5728\u67d0\u4e00\u4e2a\u6a21\u578b\u4e2d\u4e3a ",(0,o.jsx)(e.code,{children:"Identity"}),"\uff1b"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u82e5\u6a21\u5757\u540d\u6709\u540e\u7f00'(I vs I)'\uff0c\u8868\u793a\u8be5 op \u5728\u6bd4\u8f83\u7684\u4e24\u4e2a\u6a21\u578b\u4e2d\u5747\u4e3a ",(0,o.jsx)(e.code,{children:"Identity"}),"\uff1b"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u82e5\u6a21\u5757\u540d\u6709\u540e\u7f00'(i)' \uff08i >= 1\uff09\uff0c\u8868\u793a\u8be5\u5c42\u4e3a\u5171\u4eab op\uff0c\u4e14\u88ab\u5171\u4eab\u4e86 i \u6b21\uff0c\u76ee\u524d\u662f\u7b2c i+1 \u6b21\u8c03\u7528\u3002\u5171\u4eab op \u7b2c 1 \u6b21\u88ab\u8c03\u7528\u65f6\u548c\u5176\u4ed6 op \u4e00\u6837\uff0c\u4e0d\u5e26\u540e\u7f00\u3002"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Module Type\uff1a\u8be5 op \u7684\u7c7b\u578b\uff0c\u5982 torch.nn.Conv2d\uff0chorizon_plugin_pytorch.nn.qat.stubs.QuantStub \u7b49\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Similarity\uff1a\u4e24\u4e2a\u6a21\u578b\u4e2d\u5bf9\u5e94 op \u8f93\u51fa\u7684\u76f8\u4f3c\u5ea6\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u5982\u679c\u67d0\u4e00\u5c42\u76f8\u4f3c\u5ea6\u7a81\u7136\u5927\u5e45\u964d\u4f4e\u4e14\u540e\u7eed\u6ca1\u6709\u4e0a\u5347\uff0c\u5219\u5927\u6982\u7387\u5c31\u662f\u8be5\u5c42\u5bfc\u81f4\u7684\u6a21\u578b\u7cbe\u5ea6\u964d\u4f4e\uff0c\u53ef\u4ee5\u7ed3\u5408\u7edf\u8ba1\u91cf\u7b49\u5de5\u5177\u5bf9\u8be5\u5c42\u8fdb\u4e00\u6b65\u5206\u6790\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"qscale\uff1a\u91cf\u5316\u6a21\u578b\u4e2d\u8be5 op \u7684 scale \u503c\uff1b\u5982\u679c\u662f per-channel \u91cf\u5316\uff0c\u5219\u4e0d\u4f1a\u8f93\u51fa\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["Acc Error(float atol)\uff1a\u4e24\u4e2a\u6a21\u578b\u4e2d\u5bf9\u5e94 op \u8f93\u51fa\u7684\u6700\u5927\u5dee\u503c\uff0c",(0,o.jsx)(e.code,{children:"Acc Error = N * qscale"}),"\uff1b"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Acc Error(N out_qscale)\uff1a\u4e24\u4e2a\u6a21\u578b\u4e2d\u5bf9\u5e94 op \u8f93\u51fa\u7684\u6700\u5927\u5dee\u503c\u4e3a\u51e0\u4e2a scale\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Op Error with Same Input (N out_qscale)\uff1a\u4e24\u4e2a\u6a21\u578b\u4e2d\u5bf9\u5e94 op \u7684\u8f93\u5165\u82e5\u5b8c\u5168\u76f8\u540c\uff08\u6392\u9664\u7d2f\u79ef\u8bef\u5dee\u7684\u5f71\u54cd\uff09\uff0c\u8f93\u51fa\u7684\u6700\u5927\u5dee\u503c\u4e3a\u51e0\u4e2a scale\u3002\u7406\u8bba\u4e0a\u76f8\u540c\u8f93\u5165\u4e0b\u7684\u5355\u7b97\u5b50\u8bef\u5dee\u5e94\u8be5\u90fd\u5728\u51e0\u4e2a scale \u4e4b\u5185\uff0c\u5982\u679c\u76f8\u5dee\u5f88\u5927\uff0c\u5219\u8bf4\u660e\u8be5 op \u8f6c\u6362\u53ef\u80fd\u5b58\u5728\u95ee\u9898\u5bfc\u81f4\u7ed3\u679c\u76f8\u5dee\u5f88\u591a\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"    ---------------------------------------------------------------\n    Note:\n    * Suffix '(I)' means this layer is Identity in one model\n    * Suffix '(I vs I)' means this layer is Identity in both models\n    * Suffix '(i)'(i >= 1) means this op is shared i times\n    ---------------------------------------------------------------\n    +---------+----------------------------+----------------------------------------------------------------------------+--------------+-----------+----------------+------------------+------------------------+\n    | Index   | Module Name                | Module Type                                                                | Similarity   | qscale    | Acc Error      | Acc Error        | Op Error with Same     |\n    |         |                            |                                                                            |              |           | (float atol)   | (N out_qscale)   | Input (N out_qscale)   |\n    |---------+----------------------------+----------------------------------------------------------------------------+--------------+-----------+----------------+------------------+------------------------|\n    | 0       | quant_stubx                | <class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'>                    | 1.0000000    | 0.0115294 | 0.0000000      | 0                | 0                      |\n    | 1       | quant_stuby                | <class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'>                    | 1.0000000    | 0.0115294 | 0.0000000      | 0                | 0                      |\n    | 2       | mul_op                     | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 0.9999989    | 0.0168156 | 0.0168156      | 1                | 1                      |\n    | 3       | cat_op                     | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 0.9999971    | 0.0167490 | 0.0334979      | 2                | 0                      |\n    | 4       | cat_op(1)                  | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 0.9999980    | 0.0167490 | 0.0334979      | 2                | 0                      |\n    | 5       | quantized_ops.0            | <class 'horizon_plugin_pytorch.nn.qat.relu.ReLU'>                          | 0.9999980    | 0.0167490 | 0.0334979      | 2                | 0                      |\n    | 6       | quantized_ops.1            | <class 'horizon_plugin_pytorch.nn.qat.segment_lut.SegmentLUT'>             | 1.0000000    | 0.0070079 | 0.0000000      | 0                | 0                      |\n    | 7       | quantized_ops.2.sub        | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 0.9999999    | 0.0000041 | 0.0000041      | 1                | 1                      |\n    | 8       | quantized_ops.2.exp        | <class 'horizon_plugin_pytorch.nn.qat.segment_lut.SegmentLUT'>             | 1.0000000    | 0.0000305 | 0.0000305      | 1                | 1                      |\n    | 9       | quantized_ops.2.sum        | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 1.0000000    | 0.0002541 | 0.0005081      | 2                | 2                      |\n    | 10      | quantized_ops.2.reciprocal | <class 'horizon_plugin_pytorch.nn.qat.segment_lut.SegmentLUT'>             | 1.0000001    | 0.0000037 | 0.0000186      | 5                | 5                      |\n    | 11      | quantized_ops.2.mul        | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 1.0000000    | 0.0009545 | 0.0000000      | 0                | 0                      |\n    | 12      | quantized_ops.3            | <class 'horizon_plugin_pytorch.nn.qat.segment_lut.SegmentLUT'>             | 1.0000000    | 0.0005042 | 0.0000000      | 0                | 0                      |\n    | 13      | quantized_ops.4            | <class 'horizon_plugin_pytorch.nn.qat.interpolate.Interpolate'>            | 1.0000000    | 0.0005042 | 0.0005042      | 1                | 1                      |\n    | 14      | quantized_ops.5            | <class 'horizon_plugin_pytorch.nn.qat.interpolate.Interpolate'>            | 0.9999999    | 0.0005042 | 0.0005042      | 1                | 0                      |\n    | 15      | quantized_ops.6            | <class 'horizon_plugin_pytorch.nn.qat.avg_pool2d.AvgPool2d'>               | 0.9999995    | 0.0005022 | 0.0005022      | 1                | 1                      |\n    | 16      | quantized_ops.7            | <class 'horizon_plugin_pytorch.nn.qat.upsampling.Upsample'>                | 0.9999998    | 0.0005022 | 0.0005022      | 1                | 0                      |\n    | 17      | quantized_ops.8            | <class 'horizon_plugin_pytorch.nn.qat.upsampling.UpsamplingBilinear2d'>    | 1.0000000    | 0.0005022 | 0.0000000      | 0                | 0                      |\n    | 18      | dequant_stub               | <class 'horizon_plugin_pytorch.nn.qat.stubs.DeQuantStub'>                  | 1.0000000    |           | 0.0000000      | 0                | 0                      |\n    +---------+----------------------------+----------------------------------------------------------------------------+--------------+-----------+----------------+------------------+------------------------+\n"})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["ordered_op_error_similarity.txt\uff1a\u540c\u6837\u4ee5\u8868\u683c\u7684\u5f62\u5f0f\uff0c\u6309\u7167",(0,o.jsx)(e.strong,{children:"\u76f8\u540c\u8f93\u5165\u4e0b\u5355\u7b97\u5b50\u8bef\u5dee"}),"\u4ece\u9ad8\u5230\u4f4e\u8fdb\u884c\u6392\u5e8f\u7684\u7ed3\u679c\uff0c\u65b9\u4fbf\u60a8\u5feb\u901f\u5b9a\u4f4d\u662f\u54ea\u4e2a op \u7684 convert \u8bef\u5dee\u8f83\u5927\uff0c\u8868\u683c\u4e2d\u6bcf\u4e00\u5217\u7684\u542b\u4e49\u548c similarity.txt \u76f8\u540c\u3002"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"    ---------------------------------------------------------------\n    Note:\n    * Suffix '(I)' means this layer is Identity in one model\n    * Suffix '(I vs I)' means this layer is Identity in both models\n    * Suffix '(i)'(i >= 1) means this op is shared i times\n    ---------------------------------------------------------------\n    +---------+----------------------------+----------------------------------------------------------------------------+--------------+-----------+----------------+------------------+------------------------+\n    | Index   | Module Name                | Module Type                                                                | Similarity   | qscale    | Acc Error      | Acc Error        | Op Error with Same     |\n    |         |                            |                                                                            |              |           | (float atol)   | (N out_qscale)   | Input (N out_qscale)   |\n    |---------+----------------------------+----------------------------------------------------------------------------+--------------+-----------+----------------+------------------+------------------------|\n    | 10      | quantized_ops.2.reciprocal | <class 'horizon_plugin_pytorch.nn.qat.segment_lut.SegmentLUT'>             | 1.0000001    | 0.0000037 | 0.0000186      | 5                | 5                      |\n    | 9       | quantized_ops.2.sum        | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 1.0000000    | 0.0002541 | 0.0005081      | 2                | 2                      |\n    | 2       | mul_op                     | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 0.9999989    | 0.0168156 | 0.0168156      | 1                | 1                      |\n    | 7       | quantized_ops.2.sub        | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 0.9999999    | 0.0000041 | 0.0000041      | 1                | 1                      |\n    | 8       | quantized_ops.2.exp        | <class 'horizon_plugin_pytorch.nn.qat.segment_lut.SegmentLUT'>             | 1.0000000    | 0.0000305 | 0.0000305      | 1                | 1                      |\n    | 13      | quantized_ops.4            | <class 'horizon_plugin_pytorch.nn.qat.interpolate.Interpolate'>            | 1.0000000    | 0.0005042 | 0.0005042      | 1                | 1                      |\n    | 15      | quantized_ops.6            | <class 'horizon_plugin_pytorch.nn.qat.avg_pool2d.AvgPool2d'>               | 0.9999995    | 0.0005022 | 0.0005022      | 1                | 1                      |\n    | 0       | quant_stubx                | <class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'>                    | 1.0000000    | 0.0115294 | 0.0000000      | 0                | 0                      |\n    | 1       | quant_stuby                | <class 'horizon_plugin_pytorch.nn.qat.stubs.QuantStub'>                    | 1.0000000    | 0.0115294 | 0.0000000      | 0                | 0                      |\n    | 3       | cat_op                     | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 0.9999971    | 0.0167490 | 0.0334979      | 2                | 0                      |\n    | 4       | cat_op(1)                  | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 0.9999980    | 0.0167490 | 0.0334979      | 2                | 0                      |\n    | 5       | quantized_ops.0            | <class 'horizon_plugin_pytorch.nn.qat.relu.ReLU'>                          | 0.9999980    | 0.0167490 | 0.0334979      | 2                | 0                      |\n    | 6       | quantized_ops.1            | <class 'horizon_plugin_pytorch.nn.qat.segment_lut.SegmentLUT'>             | 1.0000000    | 0.0070079 | 0.0000000      | 0                | 0                      |\n    | 11      | quantized_ops.2.mul        | <class 'horizon_plugin_pytorch.nn.qat.functional_modules.FloatFunctional'> | 1.0000000    | 0.0009545 | 0.0000000      | 0                | 0                      |\n    | 12      | quantized_ops.3            | <class 'horizon_plugin_pytorch.nn.qat.segment_lut.SegmentLUT'>             | 1.0000000    | 0.0005042 | 0.0000000      | 0                | 0                      |\n    | 14      | quantized_ops.5            | <class 'horizon_plugin_pytorch.nn.qat.interpolate.Interpolate'>            | 0.9999999    | 0.0005042 | 0.0005042      | 1                | 0                      |\n    | 16      | quantized_ops.7            | <class 'horizon_plugin_pytorch.nn.qat.upsampling.Upsample'>                | 0.9999998    | 0.0005022 | 0.0005022      | 1                | 0                      |\n    | 17      | quantized_ops.8            | <class 'horizon_plugin_pytorch.nn.qat.upsampling.UpsamplingBilinear2d'>    | 1.0000000    | 0.0005022 | 0.0000000      | 0                | 0                      |\n    | 18      | dequant_stub               | <class 'horizon_plugin_pytorch.nn.qat.stubs.DeQuantStub'>                  | 1.0000000    |           | 0.0000000      | 0                | 0                      |\n    +---------+----------------------------+----------------------------------------------------------------------------+--------------+-----------+----------------+------------------+------------------------+\n"})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"similarity.html\uff1a\u4e00\u4e2a\u53ef\u4ea4\u4e92\u7684\u56fe\u7247\uff0c\u663e\u793a\u968f\u7740\u6a21\u578b forward\uff0c\u6bcf\u4e00\u5c42\u76f8\u4f3c\u5ea6\u7684\u53d8\u5316\u66f2\u7ebf\u3002\u53ef\u4ee5\u653e\u5927\u7f29\u5c0f\uff0c\u5149\u6807\u79fb\u52a8\u5230\u5bf9\u5e94\u7684\u70b9\u53ef\u4ee5\u663e\u793a\u5177\u4f53\u7684\u76f8\u4f3c\u5ea6\u6570\u503c\uff08\u8fd9\u91cc\u5c55\u793a\u7684\u662f html \u7f51\u9875\u622a\u56fe\uff0c\u6ca1\u6709\u4ea4\u4e92\u529f\u80fd\uff09\u3002"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/similarity.svg",alt:""})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"a-name-statistic-a",children:"\u7edf\u8ba1\u91cf"}),"\n",(0,o.jsxs)(e.p,{children:["\u8ba1\u7b97\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u8f93\u5165\u8f93\u51fa\u7684\u6570\u503c\u7279\u5f81 ",(0,o.jsx)(e.code,{children:"min/max/mean/var/scale"})," \u3002\u7edf\u8ba1\u91cf\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89c2\u5bdf\u5f53\u524d\u6a21\u578b\u4e2d\u7684\u6570\u636e\u5206\u5e03\u60c5\u51b5\uff0c\u5e76\u8bc4\u4f30\u9700\u8981\u9009\u7528\u4f55\u79cd\u91cf\u5316\u7cbe\u5ea6\uff08int8/int16 \u91cf\u5316\uff09\u3002\u8be5\u5de5\u5177\u4e5f\u4f1a\u540c\u65f6\u68c0\u67e5\u6a21\u578b\u4e2d\u662f\u5426\u6709 NaN \u6216\u8005 inf \u8fd9\u6837\u7684\u6570\u503c\u5f02\u5e38\u5c42\u3002"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u548c ",(0,o.jsx)(e.code,{children:"BAYES_E"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK X5"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import get_raw_features, profile_featuremap\n\nget_raw_features(\n    model: torch.nn.Module,\n    example_inputs: Any,\n    prefixes: Tuple = (),\n    types: Tuple = (),\n    device: torch.device = None,\n    preserve_int: bool = False,\n    use_class_name: bool = False,\n    skip_identity: bool = False,\n)\n"""\n    \u53c2\u6570\uff1a\n        model\uff1a\u9700\u8981\u8f93\u51fa\u7edf\u8ba1\u91cf\u7684\u6a21\u578b\n        example_inputs\uff1amodel \u7684\u8f93\u5165\n        prefixes\uff1a\u6307\u5b9a\u8981\u8f93\u51fa\u7edf\u8ba1\u91cf\u7684 op \u5728\u6a21\u578b\u4e2d\u5bf9\u5e94\u7684 layer name\uff08\u4ee5 prefixes \u5f00\u5934\n        \u7684 layer\uff09\n        types\uff1a\u6307\u5b9a\u8981\u8f93\u51fa\u7edf\u8ba1\u91cf\u7684 op \u7684\u7c7b\u578b\n        device\uff1a\u6307\u5b9a\u6a21\u578b\u5728 CPU/GPU \u4e0a forward\n        preserve_int\uff1a\u662f\u5426\u4ee5\u5b9a\u70b9\u6570\u503c\u7684\u5f62\u5f0f\u8f93\u51fa\u3002\u9ed8\u8ba4\u8f93\u51fa\u4e3a\u6d6e\u70b9\u503c\u3002\u8be5\u53c2\u6570\u4ec5\u5bf9 qat \u548c\u5b9a\n            \u70b9\u6a21\u578b\u751f\u6548\uff0c\u4e14\u53ea\u4f1a\u5728\u8be5\u5c42\u8f93\u51fa\u6709 scale \u7684\u60c5\u51b5\u4e0b\u751f\u6548\uff08\u6bd4\u5982\uff0cdequant \u5c42\u8f93\u51fa\u7684\u7ed3\n            \u679c\u662f\u6d6e\u70b9\uff0c\u8be5\u53c2\u6570\u5c31\u4e0d\u8d77\u6548\u679c\uff09\n        use_class_name\uff1a\u662f\u5426\u6253\u5370\u6bcf\u4e00\u5c42 op \u7684 name\uff0c\u9ed8\u8ba4\u6253\u5370\u7684\u662f op \u7684\u7c7b\u578b\n        skip_identity\uff1a\u662f\u5426\u8df3\u8fc7 Identity op \u7684\u7edf\u8ba1\u3002\u9ed8\u8ba4\u6240\u6709\u7c7b\u578b\u7684 op \u90fd\u4f1a\u8f93\u51fa\u7edf\u8ba1\u91cf\n\n    \u8f93\u51fa\uff1a\n        list(dict)\uff1a\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u5217\u8868\u91cc\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u662f dict\uff0c\u8868\u793a\u6bcf\u4e00\u5c42\u7684\u8f93\u5165\u8f93\u51fa\n        \u503c\u548c\u4e00\u4e9b\u53c2\u6570\u503c\uff0c\u683c\u5f0f\u5982\u4e0b\n        - "module_name": (str) \u8be5 module \u5728\u539f\u6a21\u578b\u4e2d\u7684\u540d\u5b57\n        - "attr": (str) module \u7684\u5c5e\u6027\u3002\u53ef\u4ee5\u662f input/output/weight/bias \u7b49\u7b49\u3002\n          input/output \u8868\u793a\u8fd9\u4e00\u5c42\u7684\u8f93\u5165/\u8f93\u51fa\uff0c\u5176\u4ed6\u7684\u5219\u8868\u793a module \u4e2d\u7684\u53c2\u6570\n        - "data": (Tensor) \u8be5\u5c42\u5bf9\u5e94\u5c5e\u6027\u7684\u6570\u503c\u3002\u82e5\u6570\u636e\u4e3a QTensor\uff0c\u8fd9\u91cc\u8bb0\u5f55\u7684\u662f\u53cd\u91cf\u5316\n          \u4e4b\u540e\u7684\u6570\u503c\n        - "scale": (Tensor | None) \u82e5 data \u4e3a QTensor\uff0c\u8868\u793a\u5bf9\u5e94\u7684 scale\uff0c\u53ef\u80fd\u662f\n          per-tensor \u91cf\u5316\u7684 scale\uff0c\u4e5f\u53ef\u80fd\u662f per-channel \u91cf\u5316\u7684 scale\uff1b\u5426\u5219\u4e3a None\n        - "ch_axis": (int) \u82e5 data \u4e3a per-channel \u91cf\u5316\u7684\u6570\u636e\uff0c\u8868\u793a\u91cf\u5316\u7684\u7ef4\u5ea6\u3002\u5426\u5219\u4e3a -1\n        - \u201cff_method\u201d: (str) \u82e5\u5f53\u524dmodule\u4e3aFloatFunctional/QFunctional\uff0c\u8bb0\u5f55\u5b9e\u9645\n          \u8c03\u7528\u7684 method\uff08add/sub/mul/...\uff09\u3002\u5426\u5219\u4e3a None\n"""\n\nprofile_featuremap(\n    featuremap: List[Dict],\n    with_tensorboard: bool = False,\n    tensorboard_dir: Optional[str] = None,\n    print_per_channel_scale: bool = False,\n    show_per_channel: bool = False,\n    out_dir: Optional[str] = None,\n    file_name: Optional[str] = None,\n)\n"""\n    \u8f93\u5165\uff1a\n        featuremap\uff1aget_raw_features \u7684\u8f93\u51fa\n        with_tensorboard\uff1a\u662f\u5426\u4f7f\u7528 tensorboard \u663e\u793a\u6570\u636e\u5206\u5e03\u3002\u9ed8\u8ba4 False\n        tensorboard_dir\uff1atensorboard log \u6587\u4ef6\u8def\u5f84\u3002\u9ed8\u8ba4 None\u3002\u4ec5\u5728\n        with_tensorboard=True \u65f6\u6709\u6548\n        print_per_channel_scale\uff1a\u662f\u5426\u6253\u5370 per channel \u91cf\u5316\u7684 scale\u3002\u9ed8\u8ba4 False\u3002\n        show_per_channel\uff1a\u5728 tensorboard \u4e2d\u662f\u5426\u4ee5 per channel \u7684\u65b9\u5f0f\u663e\u793a feature\n            \u4e2d\u6bcf\u4e2a channel \u7684\u6570\u636e\u76f4\u65b9\u56fe\u3002\u9ed8\u8ba4\u4e3a False\u3002\n        out_dir\uff1a\u6307\u5b9a\u8f93\u51fa\u7684\u7ed3\u679c\u6587\u4ef6\u548c\u56fe\u7247\u7684\u8def\u5f84\u3002\u82e5\u672a\u6307\u5b9a\uff0c\u5219\u9ed8\u8ba4\u4fdd\u5b58\u5230\u5f53\u524d\u8def\u5f84\u3002\n        file_name\uff1a\u4fdd\u5b58\u7684\u6587\u4ef6\u548c\u56fe\u7247\u7684\u540d\u5b57\u3002\u82e5\u672a\u6307\u5b9a\uff0c\u9ed8\u8ba4\u4e3a\u201cstatistic.txt\u201d\u548c\u4e00\u4e2a\n            \u53ef\u4ea4\u4e92\u7684\u201cstatistic.html\u201d\u3002\n"""\n'})}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u9ed8\u8ba4\u4e24\u4e2a\u63a5\u53e3\u914d\u5408\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"profile_featuremap(get_raw_features(model, example_inputs), with_tensorboard=True)"}),"\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u9ed8\u8ba4\u4f1a\u5c06\u7edf\u8ba1\u91cf\u7ed3\u679c\u4fdd\u5b58\u5230 ",(0,o.jsx)(e.code,{children:"statistic.txt"}),"\uff0c\u5e76\u5c06\u7ed3\u679c\u7ed8\u56fe\uff0c\u4fdd\u5b58\u5230",(0,o.jsx)(e.code,{children:"statistic.html"}),"\u6587\u4ef6\uff0c\u53ef\u7528\u6d4f\u89c8\u5668\u6253\u5f00\u67e5\u770b\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u82e5\u60a8\u9700\u8981\u7edf\u8ba1\u5176\u4ed6\u4fe1\u606f\uff0c\u53ef\u4ee5\u81ea\u5b9a\u4e49 featuremap \u7edf\u8ba1\u5904\u7406\u51fd\u6570\uff0c\u5904\u7406 ",(0,o.jsx)(e.code,{children:"get_raw_features"})," \u51fd\u6570\u7684\u8fd4\u56de\u6570\u636e\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u51fd\u6570 ",(0,o.jsx)(e.code,{children:"get_raw_features"})," \u4f7f\u7528\u63d2\u5165 ",(0,o.jsx)(e.code,{children:"hooks"})," \u7684\u65b9\u6cd5\u8bb0\u5f55\u6a21\u578b\u6bcf\u4e00\u5c42\u7684\u8f93\u5165\u8f93\u51fa\u3002\u4f46\u662f\u793e\u533a\u7684 ",(0,o.jsx)(e.code,{children:"hooks"})," \u6682\u65f6\u4e0d\u652f\u6301 ",(0,o.jsx)(e.code,{children:"kwargs"})," \uff08\u53c2\u8003",(0,o.jsx)(e.a,{href:"https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py#L1193",children:"\u8fd9\u91cc"}),"\uff09\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4e24\u4e2a\u95ee\u9898\u3002"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.code,{children:"cat((x,y), 1)"}),"\uff1a\u8fd9\u79cd\u5199\u6cd5\uff0c\u53c2\u6570",(0,o.jsx)(e.code,{children:"dim=1"}),"\u4f1a\u88ab\u8fc7\u6ee4\u6389\uff0c\u53ea\u8bb0\u5f55 x \u548c y \u4e24\u4e2a tensor\uff0c\u8fd9\u4e5f\u7b26\u5408\u9884\u671f\uff1b"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.code,{children:"cat(x=(x,y), dim=1)"}),"\uff1a\u8fd9\u79cd\u5199\u6cd5\u4e0b\uff0c\u4e24\u4e2a\u5173\u952e\u5b57\u53c2\u6570\u5728 hook \u8fd0\u884c\u65f6\u4e0d\u4f1a\u8d77\u4f5c\u7528\u3002\u76ee\u524d\u6ca1\u6709\u65b9\u6cd5\u5904\u7406\u8fd9\u6837\u7684\u60c5\u51b5\uff0c\u9700\u8981\u60a8\u4fdd\u8bc1\u6a21\u578b forward \u65f6 ",(0,o.jsx)(e.strong,{children:"tensor \u7c7b\u578b\u7684\u6570\u636e\u4e0d\u662f\u4ee5\u5173\u952e\u5b57\u53c2\u6570\u7684\u5f62\u5f0f\u4f20\u9012\u7684"})," \u3002"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import torch\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\nimport horizon_plugin_pytorch as horizon\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.quantization.quantize_fx import (\n    convert_fx,\n    prepare_qat_fx,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.utils.quant_profiler import (\n    get_raw_features,\n    profile_featuremap,\n)\n\nclass Net(nn.Module):\n    def __init__(self, quant=False, share_op=True):\n        super(Net, self).__init__()\n\n        self.quant_stubx = QuantStub()\n        self.quant_stuby = QuantStub()\n        self.mul_op = FloatFunctional()\n        self.cat_op = FloatFunctional()\n        self.quantized_ops = nn.Sequential(\n            nn.ReLU(),\n            nn.Sigmoid(),\n            nn.Softmax(),\n            nn.SiLU(),\n            horizon_nn.Interpolate(\n                scale_factor=2, recompute_scale_factor=True\n            ),\n            horizon_nn.Interpolate(\n                scale_factor=2.3, recompute_scale_factor=True\n            ),\n            nn.AvgPool2d(kernel_size=4),\n            nn.Upsample(scale_factor=1.3, mode="bilinear"),\n            nn.UpsamplingBilinear2d(scale_factor=0.7),\n        )\n        self.dequant_stub = DeQuantStub()\n        self.float_ops = nn.Sequential(\n            nn.Tanh(),\n            nn.LeakyReLU(),\n            nn.PReLU(),\n            nn.UpsamplingNearest2d(scale_factor=0.7),\n        )\n        self.quant = quant\n        self.share_op = share_op\n\n    def forward(self, x, y):\n        x = self.quant_stubx(x)\n        y = self.quant_stuby(y)\n        z = self.mul_op.mul(x, y)\n        x = self.cat_op.cat((x, y), dim=1)\n        if self.share_op:\n            x = self.cat_op.cat((x, y), dim=1)\n        x = self.quantized_ops(x)\n        x = self.dequant_stub(x)\n        if not self.quant:\n            x = self.float_ops(x)\n        return x\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\ndevice = torch.device("cuda")\nfloat_net = Net(quant=True, share_op=True).to(device)\nqat_net = prepare_qat_fx(\n    float_net, {"": default_qat_8bit_fake_quant_qconfig}\n)\nqat_net = qat_net.to(device)\ndata = torch.arange(1 * 3 * 4 * 4) / 100 + 1\ndata = data.reshape((1, 3, 4, 4))\ndata = data.to(torch.float32).to(device)\nprofile_featuremap(get_raw_features(qat_net, (data, data)), True)\n'})}),"\n",(0,o.jsxs)(e.p,{children:["\u8fd0\u884c\u540e\u4f1a\u5728\u5f53\u524d\u76ee\u5f55\u6216\u8005",(0,o.jsx)(e.code,{children:"out_dir"}),"\u53c2\u6570\u6307\u5b9a\u7684\u76ee\u5f55\u4e0b\u751f\u6210\u5982\u4e0b\u6587\u4ef6\uff1a"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"statistic.txt\uff1a\u4ee5\u8868\u683c\u7684\u5f62\u5f0f\uff0c\u8f93\u51fa\u6bcf\u4e00\u5c42\u8f93\u5165\u8f93\u51fa\u7684\u7edf\u8ba1\u4fe1\u606f\u3002\u8868\u683c\u4e2d\u4ece\u5de6\u5230\u53f3\u6bcf\u4e00\u5217\u5206\u522b\u8868\u793a\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Module Index\uff1a\u7d22\u5f15\uff0c\u6309\u7167\u6a21\u578b forward \u987a\u5e8f\uff0c\u4ece 0 \u5f00\u59cb\u4e3a\u6a21\u578b\u4e2d\u6bcf\u4e00\u4e2a op \u7f16\u53f7\u3002\u65e0\u5b9e\u9645\u610f\u4e49\uff0c\u7528\u4e8e\u76f8\u4f3c\u5ea6\u56fe\u50cf\u4e2d\u7684\u6a2a\u8f74\u7f16\u53f7\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Module Name\uff1a\u8be5 op \u5728\u6a21\u578b\u4e2d\u5b9a\u4e49\u4f7f\u7528\u7684\u540d\u5b57\uff0c\u5982 backbone.mod1.conv\uff1b\u4e0d\u540c\u683c\u5f0f\u7684\u540e\u7f00\u4ee3\u7406\u4e86\u4e0d\u540c\u7684\u542b\u4e49\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"\u82e5\u6a21\u5757\u540d\u6709\u540e\u7f00'(i)' \uff08i >= 1\uff09\uff0c\u8868\u793a\u8be5\u5c42\u4e3a\u5171\u4eab op\uff0c\u4e14\u88ab\u5171\u4eab\u4e86 i \u6b21\uff0c\u76ee\u524d\u662f\u7b2c i+1 \u6b21\u8c03\u7528\u3002\u5171\u4eab op \u7b2c 1 \u6b21\u88ab\u8c03\u7528\u65f6\u548c\u5176\u4ed6 op \u4e00\u6837\uff0c\u4e0d\u5e26\u540e\u7f00\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Module Type\uff1a\u8be5 op \u7684\u7c7b\u578b\uff0c\u5982 torch.nn.Conv2d\uff0chorizon_plugin_pytorch.nn.qat.stubs.QuantStub \u7b49\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u5c5e\u6027\uff1a\u5f53\u524d\u884c\u6253\u5370\u7684\u662f module \u54ea\u4e00\u4e2a\u5c5e\u6027\uff0c\u53ef\u4ee5\u662f\u8f93\u5165\u3001\u8f93\u51fa\u3001weight\u3001bias \u7b49\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Min\uff1a\u6570\u636e\u7684\u6700\u5c0f\u503c\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Max\uff1a\u6570\u636e\u7684\u6700\u5927\u503c\u3002\u901a\u8fc7 min \u548c max \u53ef\u4ee5\u5f97\u5230\u5f53\u524d\u7684\u6570\u636e\u8303\u56f4\uff0c\u7ed3\u5408 scale \u6570\u503c\u53ef\u4ee5\u5224\u65ad\u5f53\u524d\u91cf\u5316\u7cbe\u5ea6\uff08int8/int16\uff09\u662f\u5426\u6ee1\u8db3\u7cbe\u5ea6\u8981\u6c42\uff1b"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"}),"  \u548c ",(0,o.jsx)(e.code,{children:"BAYES_E"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK X5"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Mean\uff1a\u6570\u636e\u7684\u5747\u503c\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Var\uff1a\u6570\u636e\u7684\u65b9\u5dee\u3002\u82e5\u65b9\u5dee\u4e3a NaN\uff0c\u4e14 min=max=mean\uff0c\u8bf4\u660e\u4ec5\u6709\u4e00\u4e2a\u6570\u503c\uff1b\u82e5\u65b9\u5dee\u5f88\u5927\uff0c\u8bf4\u660e\u8be5\u7ec4\u6570\u7ec4\u5206\u5e03\u4e0d\u5747\u5300\uff0c\u53ef\u80fd\u4e0d\u9002\u5408\u91cf\u5316\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Scale\uff1a\u6570\u636e\u7684\u91cf\u5316 scale\uff0c\u82e5\u4e3a\u7a7a\uff0c\u8bf4\u660e\u8be5\u7ec4\u6570\u636e\u662f per-channel \u91cf\u5316\u6216\u8005\u6ca1\u6709\u91cf\u5316\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Dtype\uff1a\u5f53\u524d\u5c42\u7684\u91cf\u5316 dtype\uff0c\u5982 qint8/qint16\u3002\u82e5\u5f53\u524d\u5c42\u6ca1\u6709\u91cf\u5316\uff0c\u5219\u76f4\u63a5\u6253\u5370\u6d6e\u70b9\u6570\u636e\u7c7b\u578b\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"}),"  \u548c ",(0,o.jsx)(e.code,{children:"BAYES_E"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK X5"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]})}),"\n",(0,o.jsx)(e.p,{children:"\u6b63\u5e38\u60c5\u51b5\u4e0b\uff0cstatistic.txt \u4e2d\u4f1a\u5305\u542b\u4e24\u4e2a\u4e0a\u8ff0\u683c\u5f0f\u7684\u8868\u683c\uff0c\u4e00\u4e2a\u662f\u6309\u7167\u6a21\u578b forward \u987a\u5e8f\u6253\u5370\u7684\u6bcf\u4e00\u5c42\u7684\u7edf\u8ba1\u91cf\uff1b\u53e6\u4e00\u4e2a\u662f\u6309\u7167\u91cf\u5316\u6570\u636e\u7684\u8303\u56f4\u4ece\u5927\u5230\u5c0f\u6253\u5370\u7684\u6bcf\u4e00\u5c42\u7684\u7edf\u8ba1\u91cf\u4fe1\u606f\uff0c\u65b9\u4fbf\u60a8\u5feb\u901f\u5b9a\u4f4d\u5230\u67d0\u4e9b\u6570\u503c\u8303\u56f4\u5f88\u5927\u7684\u5c42\u3002\u82e5\u6a21\u578b\u4e2d\u67d0\u4e9b\u5c42\u5b58\u5728 NaN \u6216\u8005 inf\uff0c\u90a3 statistic.txt \u4e2d\u4e5f\u4f1a\u989d\u5916\u5305\u542b\u4e00\u4e2a\u54ea\u4e9b\u5c42 NaN \u6216\u8005 inf \u7684\u8868\u683c\uff0c\u8be5\u8868\u683c\u4e5f\u4f1a\u5728\u5c4f\u5e55\u6253\u5370\uff0c\u63d0\u793a\u60a8\u68c0\u67e5\u8fd9\u4e9b\u5f02\u5e38\u5c42\u3002"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"+----------------+----------------------------+-------------------------------------------------------------------------------+---------------------+------------+-----------+------------+-----------+-----------+---------------+\n| Module Index   | Module Name                | Module Type                                                                   | Input/Output/Attr   | Min        | Max       | Mean       | Var       | Scale     | Dtype         |\n|----------------+----------------------------+-------------------------------------------------------------------------------+---------------------+------------+-----------+------------+-----------+-----------+---------------|\n| 0              | quant_stubx                | <class 'horizon_plugin_pytorch.nn.quantized.quantize.Quantize'>               | input               | -2.9943717 | 2.9613159 | -0.0791836 | 2.7670853 |           | torch.float32 |\n| 0              | quant_stubx                | <class 'horizon_plugin_pytorch.nn.quantized.quantize.Quantize'>               | output              | -2.9826291 | 2.9591436 | -0.0786467 | 2.7688842 | 0.0234853 | qint8         |\n| 1              | quant_stuby                | <class 'horizon_plugin_pytorch.nn.quantized.quantize.Quantize'>               | input               | 0.5011058  | 0.9995295 | 0.7525039  | 0.0210502 |           | torch.float32 |\n| 1              | quant_stuby                | <class 'horizon_plugin_pytorch.nn.quantized.quantize.Quantize'>               | output              | 0.5017246  | 0.9956098 | 0.7525385  | 0.0210164 | 0.0078394 | qint8         |\n| 2              | mul_op[mul]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0             | -2.9826291 | 2.9591436 | -0.0786467 | 2.7688842 | 0.0234853 | qint8         |\n| 2              | mul_op[mul]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-1             | 0.5017246  | 0.9956098 | 0.7525385  | 0.0210164 | 0.0078394 | qint8         |\n| 2              | mul_op[mul]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | -2.9577060 | 2.5648856 | -0.0374420 | 1.5830494 | 0.0231071 | qint8         |\n| 3              | cat_op[cat]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0-0           | -2.9826291 | 2.9591436 | -0.0786467 | 2.7688842 | 0.0234853 | qint8         |\n| 3              | cat_op[cat]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0-1           | -2.9577060 | 2.5648856 | -0.0374420 | 1.5830494 | 0.0231071 | qint8         |\n| 3              | cat_op[cat]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | -2.9942081 | 2.9474237 | -0.0580113 | 2.1627743 | 0.0233923 | qint8         |\n| 4              | cat_op[cat](1)             | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0             | -2.9942081 | 2.9474237 | -0.0580113 | 2.1627743 | 0.0233923 | qint8         |\n| 4              | cat_op[cat](1)             | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-1             | 0.5017246  | 0.9956098 | 0.7525385  | 0.0210164 | 0.0078394 | qint8         |\n| 4              | cat_op[cat](1)             | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | -2.9942081 | 2.9474237 | 0.2123352  | 1.5946714 | 0.0233923 | qint8         |\n| 5              | quantized_ops.0            | <class 'horizon_plugin_pytorch.nn.quantized.relu.ReLU'>                       | input               | -2.9942081 | 2.9474237 | 0.2123352  | 1.5946714 | 0.0233923 | qint8         |\n| 5              | quantized_ops.0            | <class 'horizon_plugin_pytorch.nn.quantized.relu.ReLU'>                       | output              | 0.0000000  | 2.9474237 | 0.6510122  | 0.4357365 | 0.0233923 | qint8         |\n| 6              | quantized_ops.1            | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | input               | 0.0000000  | 2.9474237 | 0.6510122  | 0.4357365 | 0.0233923 | qint8         |\n| 6              | quantized_ops.1            | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | output              | 0.4992901  | 0.9464155 | 0.6408262  | 0.0163976 | 0.0074521 | qint8         |\n| 7              | quantized_ops.2.sub[sub]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0             | 0.4992901  | 0.9464155 | 0.6408262  | 0.0163976 | 0.0074521 | qint8         |\n| 7              | quantized_ops.2.sub[sub]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-1             | 0.6334277  | 0.9464155 | 0.7888176  | 0.0090090 | 0.0074521 | qint8         |\n| 7              | quantized_ops.2.sub[sub]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | -0.4471186 | 0.0000000 | -0.1479909 | 0.0140247 | 0.0000136 | qint16        |\n| 8              | quantized_ops.2.exp        | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | input               | -0.4471186 | 0.0000000 | -0.1479909 | 0.0140247 | 0.0000136 | qint16        |\n| 8              | quantized_ops.2.exp        | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | output              | 0.6394446  | 0.9999847 | 0.8683713  | 0.0100195 | 0.0000305 | qint16        |\n| 9              | quantized_ops.2.sum[sum]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input               | 0.6394446  | 0.9999847 | 0.8683713  | 0.0100195 | 0.0000305 | qint16        |\n| 9              | quantized_ops.2.sum[sum]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | 4.6700654  | 5.9043884 | 5.2101822  | 0.0529649 | 0.0001802 | qint16        |\n| 10             | quantized_ops.2.reciprocal | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | input               | 4.6700654  | 5.9043884 | 5.2101822  | 0.0529649 | 0.0001802 | qint16        |\n| 10             | quantized_ops.2.reciprocal | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | output              | 0.1693695  | 0.2141069 | 0.1923085  | 0.0000730 | 0.0000065 | qint16        |\n| 11             | quantized_ops.2.mul[mul]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0             | 0.6394446  | 0.9999847 | 0.8683713  | 0.0100195 | 0.0000305 | qint16        |\n| 11             | quantized_ops.2.mul[mul]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-1             | 0.1693695  | 0.2141069 | 0.1923085  | 0.0000730 | 0.0000065 | qint16        |\n| 11             | quantized_ops.2.mul[mul]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | 0.1326724  | 0.2132835 | 0.1666716  | 0.0003308 | 0.0016794 | qint8         |\n| 12             | quantized_ops.3            | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | input               | 0.1326724  | 0.2132835 | 0.1666716  | 0.0003308 | 0.0016794 | qint8         |\n| 12             | quantized_ops.3            | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | output              | 0.0703202  | 0.1175087 | 0.0903590  | 0.0001112 | 0.0009253 | qint8         |\n| 13             | quantized_ops.4            | <class 'horizon_plugin_pytorch.nn.quantized.interpolate.Interpolate'>         | input               | 0.0703202  | 0.1175087 | 0.0903590  | 0.0001112 | 0.0009253 | qint8         |\n| 13             | quantized_ops.4            | <class 'horizon_plugin_pytorch.nn.quantized.interpolate.Interpolate'>         | output              | 0.0712454  | 0.1147329 | 0.0903947  | 0.0000526 | 0.0009253 | qint8         |\n| 14             | quantized_ops.5            | <class 'horizon_plugin_pytorch.nn.quantized.interpolate.Interpolate'>         | input               | 0.0712454  | 0.1147329 | 0.0903947  | 0.0000526 | 0.0009253 | qint8         |\n| 14             | quantized_ops.5            | <class 'horizon_plugin_pytorch.nn.quantized.interpolate.Interpolate'>         | output              | 0.0712454  | 0.1147329 | 0.0903947  | 0.0000461 | 0.0009253 | qint8         |\n| 15             | quantized_ops.6            | <class 'horizon_plugin_pytorch.nn.quantized.avg_pool2d.AvgPool2d'>            | input               | 0.0712454  | 0.1147329 | 0.0903947  | 0.0000461 | 0.0009253 | qint8         |\n| 15             | quantized_ops.6            | <class 'horizon_plugin_pytorch.nn.quantized.avg_pool2d.AvgPool2d'>            | output              | 0.0747764  | 0.1091563 | 0.0903856  | 0.0000372 | 0.0008595 | qint8         |\n| 16             | quantized_ops.7            | <class 'horizon_plugin_pytorch.nn.quantized.upsampling.Upsample'>             | input               | 0.0747764  | 0.1091563 | 0.0903856  | 0.0000372 | 0.0008595 | qint8         |\n| 16             | quantized_ops.7            | <class 'horizon_plugin_pytorch.nn.quantized.upsampling.Upsample'>             | output              | 0.0756359  | 0.1074373 | 0.0903877  | 0.0000286 | 0.0008595 | qint8         |\n| 17             | quantized_ops.8            | <class 'horizon_plugin_pytorch.nn.quantized.upsampling.UpsamplingBilinear2d'> | input               | 0.0756359  | 0.1074373 | 0.0903877  | 0.0000286 | 0.0008595 | qint8         |\n| 17             | quantized_ops.8            | <class 'horizon_plugin_pytorch.nn.quantized.upsampling.UpsamplingBilinear2d'> | output              | 0.0773549  | 0.1048589 | 0.0903853  | 0.0000251 | 0.0008595 | qint8         |\n| 18             | dequant_stub               | <class 'horizon_plugin_pytorch.nn.quantized.quantize.DeQuantize'>             | input               | 0.0773549  | 0.1048589 | 0.0903853  | 0.0000251 | 0.0008595 | qint8         |\n| 18             | dequant_stub               | <class 'horizon_plugin_pytorch.nn.quantized.quantize.DeQuantize'>             | output              | 0.0773549  | 0.1048589 | 0.0903853  | 0.0000251 |           | torch.float32 |\n+----------------+----------------------------+-------------------------------------------------------------------------------+---------------------+------------+-----------+------------+-----------+-----------+---------------+\n\nStatistics with quant range in descending order...\n+----------------+----------------------------+-------------------------------------------------------------------------------+---------------------+------------+-----------+------------+-----------+-----------+---------------+\n| Module Index   | Module Name                | Module Type                                                                   | Input/Output/Attr   | Min        | Max       | Mean       | Var       | Scale     | Dtype         |\n|----------------+----------------------------+-------------------------------------------------------------------------------+---------------------+------------+-----------+------------+-----------+-----------+---------------|\n| 9              | quantized_ops.2.sum[sum]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | 4.6700654  | 5.9043884 | 5.2101822  | 0.0529649 | 0.0001802 | qint16        |\n| 10             | quantized_ops.2.reciprocal | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | input               | 4.6700654  | 5.9043884 | 5.2101822  | 0.0529649 | 0.0001802 | qint16        |\n| 0              | quant_stubx                | <class 'horizon_plugin_pytorch.nn.quantized.quantize.Quantize'>               | input               | -2.9943717 | 2.9613159 | -0.0791836 | 2.7670853 |           | torch.float32 |\n| 3              | cat_op[cat]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | -2.9942081 | 2.9474237 | -0.0580113 | 2.1627743 | 0.0233923 | qint8         |\n| 4              | cat_op[cat](1)             | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0             | -2.9942081 | 2.9474237 | -0.0580113 | 2.1627743 | 0.0233923 | qint8         |\n| 4              | cat_op[cat](1)             | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | -2.9942081 | 2.9474237 | 0.2123352  | 1.5946714 | 0.0233923 | qint8         |\n| 5              | quantized_ops.0            | <class 'horizon_plugin_pytorch.nn.quantized.relu.ReLU'>                       | input               | -2.9942081 | 2.9474237 | 0.2123352  | 1.5946714 | 0.0233923 | qint8         |\n| 0              | quant_stubx                | <class 'horizon_plugin_pytorch.nn.quantized.quantize.Quantize'>               | output              | -2.9826291 | 2.9591436 | -0.0786467 | 2.7688842 | 0.0234853 | qint8         |\n| 2              | mul_op[mul]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0             | -2.9826291 | 2.9591436 | -0.0786467 | 2.7688842 | 0.0234853 | qint8         |\n| 3              | cat_op[cat]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0-0           | -2.9826291 | 2.9591436 | -0.0786467 | 2.7688842 | 0.0234853 | qint8         |\n| 2              | mul_op[mul]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | -2.9577060 | 2.5648856 | -0.0374420 | 1.5830494 | 0.0231071 | qint8         |\n| 3              | cat_op[cat]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0-1           | -2.9577060 | 2.5648856 | -0.0374420 | 1.5830494 | 0.0231071 | qint8         |\n| 5              | quantized_ops.0            | <class 'horizon_plugin_pytorch.nn.quantized.relu.ReLU'>                       | output              | 0.0000000  | 2.9474237 | 0.6510122  | 0.4357365 | 0.0233923 | qint8         |\n| 6              | quantized_ops.1            | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | input               | 0.0000000  | 2.9474237 | 0.6510122  | 0.4357365 | 0.0233923 | qint8         |\n| 8              | quantized_ops.2.exp        | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | output              | 0.6394446  | 0.9999847 | 0.8683713  | 0.0100195 | 0.0000305 | qint16        |\n| 9              | quantized_ops.2.sum[sum]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input               | 0.6394446  | 0.9999847 | 0.8683713  | 0.0100195 | 0.0000305 | qint16        |\n| 11             | quantized_ops.2.mul[mul]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0             | 0.6394446  | 0.9999847 | 0.8683713  | 0.0100195 | 0.0000305 | qint16        |\n| 1              | quant_stuby                | <class 'horizon_plugin_pytorch.nn.quantized.quantize.Quantize'>               | input               | 0.5011058  | 0.9995295 | 0.7525039  | 0.0210502 |           | torch.float32 |\n| 1              | quant_stuby                | <class 'horizon_plugin_pytorch.nn.quantized.quantize.Quantize'>               | output              | 0.5017246  | 0.9956098 | 0.7525385  | 0.0210164 | 0.0078394 | qint8         |\n| 2              | mul_op[mul]                | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-1             | 0.5017246  | 0.9956098 | 0.7525385  | 0.0210164 | 0.0078394 | qint8         |\n| 4              | cat_op[cat](1)             | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-1             | 0.5017246  | 0.9956098 | 0.7525385  | 0.0210164 | 0.0078394 | qint8         |\n| 6              | quantized_ops.1            | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | output              | 0.4992901  | 0.9464155 | 0.6408262  | 0.0163976 | 0.0074521 | qint8         |\n| 7              | quantized_ops.2.sub[sub]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-0             | 0.4992901  | 0.9464155 | 0.6408262  | 0.0163976 | 0.0074521 | qint8         |\n| 7              | quantized_ops.2.sub[sub]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-1             | 0.6334277  | 0.9464155 | 0.7888176  | 0.0090090 | 0.0074521 | qint8         |\n| 7              | quantized_ops.2.sub[sub]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | -0.4471186 | 0.0000000 | -0.1479909 | 0.0140247 | 0.0000136 | qint16        |\n| 8              | quantized_ops.2.exp        | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | input               | -0.4471186 | 0.0000000 | -0.1479909 | 0.0140247 | 0.0000136 | qint16        |\n| 10             | quantized_ops.2.reciprocal | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | output              | 0.1693695  | 0.2141069 | 0.1923085  | 0.0000730 | 0.0000065 | qint16        |\n| 11             | quantized_ops.2.mul[mul]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | input-1             | 0.1693695  | 0.2141069 | 0.1923085  | 0.0000730 | 0.0000065 | qint16        |\n| 11             | quantized_ops.2.mul[mul]   | <class 'horizon_plugin_pytorch.nn.quantized.functional_modules.QFunctional'>  | output              | 0.1326724  | 0.2132835 | 0.1666716  | 0.0003308 | 0.0016794 | qint8         |\n| 12             | quantized_ops.3            | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | input               | 0.1326724  | 0.2132835 | 0.1666716  | 0.0003308 | 0.0016794 | qint8         |\n| 12             | quantized_ops.3            | <class 'horizon_plugin_pytorch.nn.quantized.segment_lut.SegmentLUT'>          | output              | 0.0703202  | 0.1175087 | 0.0903590  | 0.0001112 | 0.0009253 | qint8         |\n| 13             | quantized_ops.4            | <class 'horizon_plugin_pytorch.nn.quantized.interpolate.Interpolate'>         | input               | 0.0703202  | 0.1175087 | 0.0903590  | 0.0001112 | 0.0009253 | qint8         |\n| 13             | quantized_ops.4            | <class 'horizon_plugin_pytorch.nn.quantized.interpolate.Interpolate'>         | output              | 0.0712454  | 0.1147329 | 0.0903947  | 0.0000526 | 0.0009253 | qint8         |\n| 14             | quantized_ops.5            | <class 'horizon_plugin_pytorch.nn.quantized.interpolate.Interpolate'>         | input               | 0.0712454  | 0.1147329 | 0.0903947  | 0.0000526 | 0.0009253 | qint8         |\n| 14             | quantized_ops.5            | <class 'horizon_plugin_pytorch.nn.quantized.interpolate.Interpolate'>         | output              | 0.0712454  | 0.1147329 | 0.0903947  | 0.0000461 | 0.0009253 | qint8         |\n| 15             | quantized_ops.6            | <class 'horizon_plugin_pytorch.nn.quantized.avg_pool2d.AvgPool2d'>            | input               | 0.0712454  | 0.1147329 | 0.0903947  | 0.0000461 | 0.0009253 | qint8         |\n| 15             | quantized_ops.6            | <class 'horizon_plugin_pytorch.nn.quantized.avg_pool2d.AvgPool2d'>            | output              | 0.0747764  | 0.1091563 | 0.0903856  | 0.0000372 | 0.0008595 | qint8         |\n| 16             | quantized_ops.7            | <class 'horizon_plugin_pytorch.nn.quantized.upsampling.Upsample'>             | input               | 0.0747764  | 0.1091563 | 0.0903856  | 0.0000372 | 0.0008595 | qint8         |\n| 16             | quantized_ops.7            | <class 'horizon_plugin_pytorch.nn.quantized.upsampling.Upsample'>             | output              | 0.0756359  | 0.1074373 | 0.0903877  | 0.0000286 | 0.0008595 | qint8         |\n| 17             | quantized_ops.8            | <class 'horizon_plugin_pytorch.nn.quantized.upsampling.UpsamplingBilinear2d'> | input               | 0.0756359  | 0.1074373 | 0.0903877  | 0.0000286 | 0.0008595 | qint8         |\n| 17             | quantized_ops.8            | <class 'horizon_plugin_pytorch.nn.quantized.upsampling.UpsamplingBilinear2d'> | output              | 0.0773549  | 0.1048589 | 0.0903853  | 0.0000251 | 0.0008595 | qint8         |\n| 18             | dequant_stub               | <class 'horizon_plugin_pytorch.nn.quantized.quantize.DeQuantize'>             | input               | 0.0773549  | 0.1048589 | 0.0903853  | 0.0000251 | 0.0008595 | qint8         |\n| 18             | dequant_stub               | <class 'horizon_plugin_pytorch.nn.quantized.quantize.DeQuantize'>             | output              | 0.0773549  | 0.1048589 | 0.0903853  | 0.0000251 |           | torch.float32 |\n+----------------+----------------------------+-------------------------------------------------------------------------------+---------------------+------------+-----------+------------+-----------+-----------+---------------+\n"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"statistic.html"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/statistic.svg",alt:""})}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:["\u82e5\u8bbe\u7f6e",(0,o.jsx)(e.code,{children:"with_tensorboard=True"}),"\uff0c\u5219\u4f1a\u5728\u6307\u5b9a\u76ee\u5f55\u4e0b\u751f\u6210 ",(0,o.jsx)(e.code,{children:"tensorboard"})," \u7684 log \u6587\u4ef6\uff0c\u53ef\u4ee5\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"tensorboard"})," \u6253\u5f00\u67e5\u770b\u6bcf\u7ec4\u6570\u636e\u7684\u5206\u5e03\u76f4\u65b9\u56fe\u3002"]}),"\n",(0,o.jsx)(e.h3,{id:"weight-a-name-weight-comparison-a",children:"\u6a21\u578b weight \u6bd4\u8f83"}),"\n",(0,o.jsxs)(e.p,{children:["\u8be5\u5de5\u5177\u9ed8\u8ba4\u4f1a\u8ba1\u7b97\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42 ",(0,o.jsx)(e.code,{children:"weight"})," \u7684\u76f8\u4f3c\u5ea6\uff08\u5982\u679c\u6709\u7684\u8bdd\uff09\uff0c\u9ed8\u8ba4\u4f1a\u8f93\u51fa\u5230\u5c4f\u5e55\u540c\u65f6\u4fdd\u5b58\u5230\u6587\u4ef6\u3002\u60a8\u4e5f\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e",(0,o.jsx)(e.code,{children:"with_tensorboard=True"}),"\uff0c\u7ed8\u5236 ",(0,o.jsx)(e.code,{children:"weight"})," \u7684\u76f4\u65b9\u56fe\uff0c\u65b9\u4fbf\u66f4\u76f4\u89c2\u5730\u89c2\u770b\u6bd4\u8f83\u3002"]}),"\n",(0,o.jsxs)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:[(0,o.jsx)(e.p,{children:"\u82e5\u4f7f\u7528 fx \u6a21\u5f0f\u8fdb\u884c\u91cf\u5316\uff0c\u4f7f\u7528\u65f6\u9700\u6ce8\u610f\uff1a"}),(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"\u6a21\u578b\u8f6c\u6362\u7684\u8fc7\u7a0b\u9ed8\u8ba4\u90fd\u662f inplace \u7684\uff0c\u8bf7\u60a8\u624b\u52a8\u5728\u8fdb\u884c\u8f6c\u6362\u524d deepcopy \u4e00\u4efd\u539f\u59cb\u6a21\u578b\u3002\u5426\u5219\u8f6c\u6362\u540e\uff0c\u4f1a\u9519\u8bef\u5730\u6bd4\u8f83\u4e24\u4e2a\u76f8\u540c\u6a21\u578b\u7684 weight\uff1b"}),"\n",(0,o.jsx)(e.li,{children:"\u82e5\u6d89\u53ca float \u6a21\u578b\u7684 weight \u6bd4\u8f83\uff0c\u8bf7\u60a8\u624b\u52a8\u8c03\u7528 fuse_fx \u5c06\u539f\u59cb float \u6a21\u578b\u8fdb\u884c fuse\u3002\u5426\u5219\u4f1a\u9519\u8bef\u5730\u6bd4\u8f83\u672a fuse \u7684 float \u6a21\u578b\u548c fuse \u4e4b\u540e\u7684 qat \u6216\u5b9a\u70b9\u6a21\u578b\u7684 weight\u3002"}),"\n"]})]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import compare_weights\n\ndef compare_weights(\n    float_model: torch.nn.Module,\n    qat_quantized_model: torch.nn.Module,\n    similarity_func="Cosine",\n    with_tensorboard: bool = False,\n    tensorboard_dir: Optional[str] = None,\n    out_dir: Optional[str] = None,\n) -> Dict[str, Dict[str, torch.Tensor]]:\n    """\u6bd4\u8f83 float/qat/quantized \u6a21\u578b\u7684 weights\u3002\n\n    \u8be5\u51fd\u6570\u4f7f\u7528 torch.quantization._numeric_suite.compare_weights \u6bd4\u8f83\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u7684\n    weight\u3002weight \u76f8\u4f3c\u5ea6\u548c atol \u5c06\u4f1a\u6253\u5370\u5230\u5c4f\u5e55\u540c\u65f6\u4fdd\u5b58\u5230\u201cweight_comparison.txt\u201d\u3002\n    \u60a8\u8fd8\u53ef\u4ee5\u8bbe\u7f6e with_tensorboard=True\uff0c\u5c06 weight \u76f4\u65b9\u56fe\u901a\u8fc7 tensorboard \u6253\u5370\u3002\n\n    \u53c2\u6570\uff1a\n        float_model: \u6d6e\u70b9\u6a21\u578b\n        qat_quantized_model: qat/\u5b9a\u70b9\u6a21\u578b\n        similarity_func: \u76f8\u4f3c\u5ea6\u8ba1\u7b97\u51fd\u6570\u3002\u652f\u6301 Cosine/MSE/L1/KL/SQNR \u548c\u4efb\u610f\u60a8\u81ea\u5b9a\n            \u4e49\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u51fd\u6570\u3002\u5982\u679c\u662f\u81ea\u5b9a\u4e49\u7684\u51fd\u6570\uff0c\u987b\u8fd4\u56de\u6807\u91cf\u6216\u8005\u4ec5\u542b\u4e00\u4e2a\u6570\u7684 tensor\uff0c\n            \u5426\u5219\u7ed3\u679c\u663e\u793a\u53ef\u80fd\u4e0d\u7b26\u5408\u9884\u671f\u3002\u9ed8\u8ba4\u4e3a Cosine\u3002\n        with_tensorboard: \u662f\u5426\u4f7f\u7528 tensorboard\uff0c\u9ed8\u8ba4\u4e3a False\u3002\n        tensorboard_dir: tensorboard \u65e5\u5fd7\u6587\u4ef6\u8def\u5f84\u3002\u9ed8\u8ba4\u4e3a None\u3002\n        out_dir: \u4fdd\u5b58 txt \u7ed3\u679c\u7684\u8def\u5f84\u3002\u9ed8\u8ba4\u4e3a None, \u4fdd\u5b58\u5230\u5f53\u524d\u8def\u5f84\u3002\n\n    \u8f93\u51fa\uff1a\n        \u4e00\u4e2a\u8bb0\u5f55\u4e24\u4e2a\u6a21\u578b weight \u7684 dict\uff0c\u683c\u5f0f\u5982\u4e0b\uff1a\n            * KEY (str): module \u540d (\u5982 layer1.0.conv.weight)\n            * VALUE (dict): \u4e24\u4e2a\u6a21\u578b\u4e2d\u5bf9\u5e94\u5c42\u7684 weight:\n                "float": \u6d6e\u70b9\u6a21\u578b\u4e2d\u7684 weight\n                "quantized": qat/\u5b9a\u70b9\u6a21\u578b\u4e2d\u7684weight\n    """\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from copy import deepcopy\n\nimport horizon_plugin_pytorch as horizon\nimport numpy as np\nimport torch\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.quantization import (\n    convert,\n    get_default_qat_qconfig,\n    prepare_qat,\n    fuse_modules,\n)\nfrom horizon_plugin_pytorch.quantization.quantize_fx import (\n    convert_fx,\n    fuse_fx,\n    prepare_qat_fx,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.utils.quant_profiler import compare_weights\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\n\n\n# \u8fd9\u91cc\u7565\u53bb Resnet18 \u7684\u5b9a\u4e49\nfloat_net = Resnet18().to(device)\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\nfloat_net.qconfig = get_default_qat_qconfig()\nfloat_net2 = deepcopy(float_net)\nqat_net = prepare_qat_fx(float_net2, {"": default_qat_8bit_fake_quant_qconfig})\nqat_net(data)\n\n# \u5fc5\u987b\uff01\uff01\u5426\u5219\u4e3a\u6bd4\u8f83\u672a fuse \u7684 float \u6a21\u578b\u548c fuse \u4e4b\u540e\u7684 qat \u6a21\u578b\uff0c\u6a21\u578b\u4e2d\u7684 weight\n# \u6709\u53ef\u80fd\u65e0\u6cd5\u5bf9\u5e94\nfloat_net = fuse_fx(float_net)\n\ncompare_weights(float_net, qat_net)\n'})}),"\n",(0,o.jsxs)(e.p,{children:["\u4f1a\u4ee5\u8868\u683c\u7684\u5f62\u5f0f\uff0c\u540c\u65f6\u5728\u5c4f\u5e55\u8f93\u51fa\u5e76\u5728 ",(0,o.jsx)(e.code,{children:"weight_comparsion.txt"})," \u4e2d\u4fdd\u5b58\u7ed3\u679c\u3002\u8868\u683c\u4e2d\u4ece\u5de6\u5230\u53f3\u6bcf\u4e00\u5217\u5206\u522b\u8868\u793a\uff1a"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Weight Name\uff1a\u662f\u6a21\u578b\u4e2d\u54ea\u4e00\u5c42\u7684 weight"}),"\n",(0,o.jsx)(e.li,{children:"Similarity\uff1a\u4e24\u4e2a\u6a21\u578b\u4e2d\u5bf9\u5e94\u5c42\u7684 weight \u7684\u76f8\u4f3c\u5ea6"}),"\n",(0,o.jsx)(e.li,{children:"Atol: \u4e24\u4e2a\u6a21\u578b\u4e2d\u5bf9\u5e94\u5c42\u7684 weight \u76f8\u5dee\u4e86\u51e0\u4e2a scale"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"+-------------------------------------+--------------+-----------+\n| Weight Name                         | Similarity   | Atol      |\n|-------------------------------------+--------------+-----------|\n| conv1.conv.weight                   | 1.0000000    | 0.0000000 |\n| layer1.0.conv_cell1.conv.weight     | 1.0000000    | 0.0000000 |\n| layer1.0.shortcut.conv.weight       | 1.0000000    | 0.0000000 |\n| layer1.0.conv_cell2.skip_add.weight | 1.0000000    | 0.0000000 |\n| layer1.1.conv_cell1.conv.weight     | 1.0000000    | 0.0000000 |\n| layer1.1.conv_cell2.conv.weight     | 1.0000000    | 0.0000000 |\n| layer2.0.conv_cell1.conv.weight     | 1.0000000    | 0.0000000 |\n| layer2.0.shortcut.conv.weight       | 1.0000000    | 0.0000000 |\n| layer2.0.conv_cell2.skip_add.weight | 1.0000000    | 0.0000000 |\n| layer2.1.conv_cell1.conv.weight     | 1.0000000    | 0.0000001 |\n| layer2.1.conv_cell2.conv.weight     | 1.0000000    | 0.0000001 |\n| layer3.0.conv_cell1.conv.weight     | 1.0000000    | 0.0000001 |\n| layer3.0.shortcut.conv.weight       | 1.0000000    | 0.0000001 |\n| layer3.0.conv_cell2.skip_add.weight | 1.0000000    | 0.0000002 |\n| layer3.1.conv_cell1.conv.weight     | 1.0000000    | 0.0000005 |\n| layer3.1.conv_cell2.conv.weight     | 1.0000001    | 0.0000008 |\n| conv2.conv.weight                   | 1.0000001    | 0.0000010 |\n| pool.conv.weight                    | 0.9999999    | 0.0000024 |\n| fc.weight                           | 1.0000000    | 0.0000172 |\n+-------------------------------------+--------------+-----------+\n"})}),"\n",(0,o.jsx)(e.h3,{id:"a-name-step-quantization-a",children:"\u5206\u6b65\u91cf\u5316"}),"\n",(0,o.jsxs)(e.p,{children:["\u5f53\u9047\u5230 QAT \u6a21\u578b\u8bad\u7ec3\u56f0\u96be\u5bfc\u81f4\u6307\u6807\u4e0a\u4e0d\u53bb\u7684\u60c5\u51b5\u65f6\uff0c\u60a8\u53ef\u80fd\u9700\u8981\u4f7f\u7528\u5206\u6b65\u91cf\u5316\u5bfb\u627e\u7cbe\u5ea6\u7684\u74f6\u9888\uff0c\u6b64\u65f6\u9700\u8981\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"qconfig=None"})," \u7684\u65b9\u5f0f\u5c06\u6a21\u578b\u7684\u67d0\u4e00\u90e8\u5206\u8bbe\u7f6e\u4e3a\u6d6e\u70b9\u3002"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u5907\u6ce8",type:"info",children:(0,o.jsxs)(e.p,{children:["\u82e5\u60a8\u4f7f\u7528 fx \u8fdb\u884c\u91cf\u5316\uff0c\u53ef\u4ee5\u76f4\u63a5\u53c2\u8003 API \u6587\u6863\u4e2d\u7684 ",(0,o.jsx)(e.a,{href:"/rdk_doc/Advanced_development/toolchain_development/expert/api_reference",children:(0,o.jsx)(e.strong,{children:"prepare_qat_fx"})}),"\uff0c\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"hybrid"})," \u548c ",(0,o.jsx)(e.code,{children:"hybrid_dict"})," \u53c2\u6570\u8fdb\u884c\u5f00\u542f\u5206\u6b65\u91cf\u5316\u3002"]})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.quantization import prepare_qat\n\ndef prepare_qat(\n    model: torch.nn.Module,\n    mapping: Optional[Dict[torch.nn.Module, torch.nn.Module]] = None,\n    inplace: bool = False,\n    optimize_graph: bool = False,\n    hybrid: bool = False,\n):\n"""\u5728 prepare_qat \u63a5\u53e3\u4e2d\u901a\u8fc7 hybrid \u53c2\u6570\u6765\u5f00\u542f\u5206\u6b65\u91cf\u5316\n    \u53c2\u6570\uff1a\n        hybrid: \u751f\u6210\u4e00\u4e2a\u4e2d\u95f4 op \u662f\u6d6e\u70b9\u8ba1\u7b97\u7684\u6df7\u5408\u6a21\u578b\u3002\u5176\u4e2d\u6709\u4e00\u4e9b\u9650\u5236\u662f\uff1a\n        1. \u6df7\u5408\u6a21\u578b\u4e0d\u80fd\u901a\u8fc7 check_model \u4e5f\u4e0d\u80fd\u7f16\u8bd1\n        2. \u67d0\u4e9b\u91cf\u5316 op \u4e0d\u80fd\u76f4\u63a5\u63a5\u53d7\u6d6e\u70b9\u8f93\u5165\uff0c\u60a8\u9700\u8981\u624b\u52a8\u63d2\u5165 QuantStub\n"""\n'})}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u91cf\u5316\u7b97\u5b50\u2192\u6d6e\u70b9\u7b97\u5b50\uff1a\u91cf\u5316\u7b97\u5b50\u8f93\u51fa\u7c7b\u578b\u4e3a ",(0,o.jsx)(e.code,{children:"QTensor"})," \uff0c ",(0,o.jsx)(e.code,{children:"QTensor"})," \u9ed8\u8ba4\u4e0d\u5141\u8bb8\u76f4\u63a5\u4f5c\u4e3a\u6d6e\u70b9\u7b97\u5b50\u7684\u8f93\u5165\uff0c\u56e0\u6b64\u4f1a\u5bfc\u81f4 forward \u65f6\u51fa\u73b0 ",(0,o.jsx)(e.code,{children:"NotImplementedError"})," \u62a5\u9519\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u4e0a\u8ff0\u63a5\u53e3\u653e\u5f00\u8fd9\u4e2a\u9650\u5236\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u6d6e\u70b9\u7b97\u5b50\u2192\u91cf\u5316\u7b97\u5b50\uff1aQAT \u65f6\u7684\u91cf\u5316\u7b97\u5b50\u5b9e\u73b0\u4e00\u822c\u4e3a ",(0,o.jsx)(e.strong,{children:"\u6d6e\u70b9\u7b97\u5b50+FakeQuant"})," \u7684\u5f62\u5f0f\uff0c\u56e0\u6b64\u5927\u90e8\u5206\u60c5\u51b5\u4e0b\u91cf\u5316\u7b97\u5b50\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"Tensor"})," \u4f5c\u4e3a\u8f93\u5165\u3002\u7531\u4e8e\u548c\u5b9a\u70b9\u5bf9\u9f50\u7684\u9700\u6c42\uff0c\u5c11\u6570\u7b97\u5b50\u5728 QAT \u65f6\u9700\u8981 input \u7684 scale \u4fe1\u606f\uff0c\u56e0\u6b64\u5fc5\u987b\u8f93\u5165 ",(0,o.jsx)(e.code,{children:"QTensor"})," \uff0c\u5bf9\u4e8e\u8fd9\u79cd\u60c5\u51b5\u6211\u4eec\u6dfb\u52a0\u4e86\u68c0\u67e5\uff0c\u82e5\u60a8\u9047\u5230\u76f8\u5173\u62a5\u9519\uff0c\u9700\u8981\u624b\u52a8\u5728\u6d6e\u70b9\u7b97\u5b50\u548c\u91cf\u5316\u7b97\u5b50\u4e4b\u95f4\u63d2\u5165",(0,o.jsx)(e.code,{children:"QuantStub"})," \u3002"]}),"\n"]}),"\n"]})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport pytest\nimport torch\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn import qat\nfrom horizon_plugin_pytorch.quantization import (\n    get_default_qat_qconfig,\n    prepare_qat,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.quantization.quantize_fx import prepare_qat_fx\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\n\n\nclass HyperQuantModel(nn.Module):\n    def __init__(self, channels=3) -> None:\n        super().__init__()\n\n        self.quant = QuantStub()\n        self.conv0 = nn.Conv2d(channels, channels, 1)\n        self.conv1 = nn.Conv2d(channels, channels, 1)\n        self.conv2 = nn.Conv2d(channels, channels, 1)\n        self.dequant = DeQuantStub()\n\n    def forward(self, input):\n        x = self.quant(input)\n        x = self.conv0(x)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return self.dequant(x)\n\n    def set_qconfig(self):\n        self.qconfig = default_qat_8bit_fake_quant_qconfig\n        self.conv1.qconfig = None\n\n\nshape = np.random.randint(10, 20, size=4).tolist()\ndata = torch.rand(size=shape)\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\nmodel = HyperQuantModel(shape[1])\n\n# \u82e5\u4f7f\u7528 eager \u6a21\u5f0f\uff0c\u8bbe\u7f6e qconfig \u4e4b\u540e\uff0c\u8c03\u7528 prepare_qat(hybrid=True)\n# model.set_qconfig()\n# qat_model = prepare_qat(model, hybrid=True)\n\n# fx \u6a21\u5f0f\uff0c\u76f4\u63a5\u901a\u8fc7 prepare_qat_fx \u63a5\u53e3\u8bbe\u7f6e\nqat_model = prepare_qat_fx(\n    model,\n    qconfig_dict={"": default_qat_8bit_fake_quant_qconfig},\n    hybrid=True,\n    hybrid_dict={"module_name": ["conv1",]}\n)\n\nassert isinstance(qat_model.conv0, qat.Conv2d)\n# qat \u6a21\u578b\u4e2d conv1 \u4ecd\u7136\u662f\u6d6e\u70b9 conv\nassert isinstance(qat_model.conv1, nn.Conv2d)\nassert isinstance(qat_model.conv2, qat.Conv2d)\n\nqat_model(data)\n'})}),"\n",(0,o.jsx)(e.h3,{id:"a-name-single-op-error-a",children:"\u5355\u7b97\u5b50\u8f6c\u6362\u7cbe\u5ea6\u8c03\u8bd5"}),"\n",(0,o.jsx)(e.p,{children:"\u5f53\u51fa\u73b0 QAT \u8f6c\u5b9a\u70b9\u7cbe\u5ea6\u964d\u4f4e\u7684\u60c5\u51b5\u65f6\uff0c\u60a8\u53ef\u80fd\u9700\u8981\u901a\u8fc7\u5c06\u5b9a\u70b9\u6a21\u578b\u4e2d\u7684\u90e8\u5206\u91cd\u70b9 op \u66ff\u6362\u4e3a QAT \u7684\u65b9\u5f0f\u6765\u9a8c\u8bc1\u5177\u4f53\u662f\u54ea\u4e2a\u7b97\u5b50\u9020\u6210\u4e86\u8f6c\u6362\u6389\u70b9\u3002"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import set_preserve_qat_mode\n\ndef set_preserve_qat_mode(model: nn.Module, prefixes=(), types=(), value=True):\n"""\n\u901a\u8fc7\u8bbe\u7f6e mod.preserve_qat_mode=True\uff0c\u4f7f\u5f97\u8f6c\u6362\u540e\u7684\u5b9a\u70b9\u6a21\u578b\u4e2d mod \u4ecd\u7136\u4e3a qat \u72b6\u6001\u3002\n\u652f\u6301\u5728 float \u6a21\u578b\u6216\u8005 qat \u6a21\u578b\u65f6\u8c03\u7528\u6b64\u51fd\u6570\u3002\n\n\u9700\u8981\u6ce8\u610f\u4ee5\u4e0b\u4e24\u70b9\uff1a\n1\uff09\u5bf9\u4e8e fuse \u7684\u6a21\u5757\uff0c\u4ec5\u5728 conv \u8bbe\u7f6e\u4e86 preserve_qat_mode = True \u65f6\uff0cfuse \u540e\u7684\u6a21\u5757\u624d\n\u4f1a\u6709 preserve_qat_mode = True\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e conv.preserve_qat_mode = True \u7684\n\u65b9\u5f0f\u6765\u8bbe\u7f6e fused.preserve_qat_mode = True\u3002\u793a\u4f8b\u5982\u4e0b\uff1a\n    class Model(torch.nn.Module):\n        def __init__(self):\n            super(Model, self).__init__()\n            self.conv = torch.nn.Conv2d()\n            self.bn = torch.nn.BatchNorm2d()\n            self.add = FloatFunctional()\n            self.relu = torch.nn.Relu()\n\n    float_model = Model()\n\n    # \u8bbe\u7f6e\u6d6e\u70b9 conv\uff0c\u6b63\u786e\n    set_preserve_qat_mode(float_model, types=(torch.nn.Conv2d,))\n\n    # \u8bbe\u7f6e\u6d6e\u70b9 bn\uff0c\u9519\u8bef\n    set_preserve_qat_mode(float_model, types=(torch.nn.BatchNorm2d,))\n\n    float_model.fuse_modules()\n    float_model.qconfig = get_default_qat_qconfig()\n    qat_model = prepare_qat(float_model)\n\n    # \u5728 fuse \u5e76\u8f6c\u4e3a qat \u6a21\u578b\u4e4b\u540e\uff0c\u8bbe\u7f6e\u6d6e\u70b9 conv\uff0c\u6b63\u786e\u3002\u8fd9\u79cd\u65b9\u5f0f\u4e0b\uff0c\u6a21\u578b\u4e2d\u6240\u6709\u7684 conv\n    # \u548c fuse \u540e\u7684\u6a21\u5757\uff08convbn, convbnadd, ...\uff09\u90fd\u4f1a\u8bbe\u7f6e preserve_qat_mode = True\n    set_preserve_qat_mode(qat_model, types=(torch.nn.Conv2d,))\n\n    # \u4f7f\u7528 prefixes \u53c2\u6570\u6765\u6307\u5b9a\u67d0\u4e2a fuse \u7684\u6a21\u5757\u3002convbnaddrelu \u4f1a\u88ab fuse \u5230 add \u7684\u4f4d\u7f6e\n    set_preserve_qat_mode(qat_model, prefixes=("add",))\n\n2\uff09\u5982\u679c\u6d6e\u70b9\u6a21\u578b\u4f7f\u7528\u4e86 torch \u51fd\u6570\uff08\u5982 torch.add, torch.pow\uff09\uff0c\u5e76\u4f7f\u7528 fx \u8fdb\u884c\u8f6c\u6362\uff0c\u8fd9\u4e9b\n\u51fd\u6570\u4f1a\u88ab\u81ea\u52a8\u66ff\u6362\u6210 horizon \u7684\u7b97\u5b50\u3002\u82e5\u8981\u4e3a\u8fd9\u4e9b\u51fd\u6570\u8bbe\u7f6e preserve_qat_mode = True\uff0c\u9700\u8981\n\u5bf9 qat \u6a21\u578b\u4e2d\u5bf9\u5e94\u7684 horizon \u7b97\u5b50\u8bbe\u7f6e preserve_qat_mode = True\u3002\u793a\u4f8b\u5982\u4e0b\uff1a\n    class Model(torch.nn.Module):\n        def __init__(self):\n            super(Model, self).__init__()\n            self.add = torch.add\n\n    float_model = Model()\n    # \u901a\u8fc7 fx \u8f6c\u4e3a qat \u6a21\u578b\n    qat_model = prepare_qat_fx(float_model)\n\n    # \u901a\u8fc7 types \u8bbe\u7f6e\uff0c\u6b63\u786e\u3002qat \u6a21\u578b\u4e2d\u6240\u6709\u7684 FloatFunctional \u5747\u4f1a\u88ab\u8bbe\u7f6e\n    # preserve_qat_mode = True\n    set_preserve_qat_mode(qat_model, types=(FloatFunctional,))\n\n    # \u4f7f\u7528 prefixes \u53c2\u6570\u6765\u6307\u5b9a\u67d0\u4e2a\u51fd\u6570\uff08\u5982 add\uff09\u3002"add_generated_add_0" \u4e3a\u81ea\u52a8\u751f\u6210\n    \u7684 add \u6a21\u5757\u7684\u540d\u5b57\n    set_preserve_qat_mode(qat_model, prefixes=("add_generated_add_0",))\n\n\u53c2\u6570\uff1a\n    model\uff1a\u9700\u8981\u8f93\u51fa\u7edf\u8ba1\u91cf\u7684\u6a21\u578b\n    prefixes\uff1a\u6307\u5b9a\u8981\u8f93\u51fa\u7edf\u8ba1\u91cf\u7684 op \u5728\u6a21\u578b\u4e2d\u5bf9\u5e94\u7684 layer name\uff08\u4ee5 prefixes \u5f00\u5934\u7684 layer\uff09\n    types\uff1a\u6307\u5b9a\u8981\u8f93\u51fa\u7edf\u8ba1\u91cf\u7684 op \u7684\u7c7b\u578b\u3002\u5982\u679c\u8f93\u5165\u4e3a\u6d6e\u70b9\u6a21\u578b\uff0ctypes \u5fc5\u987b\u4e3a\u6d6e\u70b9 op \u7c7b\u578b\uff1b\n        \u82e5\u8f93\u5165\u4e3a QAT \u6a21\u578b\uff0ctypes \u53ef\u4ee5\u662f\u6d6e\u70b9\u6216\u8005 qat op \u7c7b\u578b\n    value\uff1a\u8bbe\u7f6e preserve_qat_mode=value\u3002\u9ed8\u8ba4\u4e3a True\n"""\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import horizon_plugin_pytorch as horizon\nimport numpy as np\nimport torch\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.quantization.quantize_fx import (\n    convert_fx,\n    prepare_qat_fx,\n)\nfrom horizon_plugin_pytorch.utils.quant_profiler import set_preserve_qat_mode\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\n\nclass Conv2dModule(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel_size=1,\n        stride=1,\n        padding=0,\n        dilation=1,\n        groups=1,\n        bias=True,\n        padding_mode="zeros",\n    ):\n        super().__init__()\n        self.conv2d = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            groups,\n            bias,\n            padding_mode,\n        )\n\n        self.add = FloatFunctional()\n        self.bn_mod = nn.BatchNorm2d(out_channels)\n        self.relu_mod = nn.ReLU()\n\n    def forward(self, x, y):\n        x = self.conv2d(x)\n        x = self.bn_mod(x)\n        x = self.add.add(x, y)\n        x = self.relu_mod(x)\n\n        return x\n\n\nclass TestFuseNet(nn.Module):\n    def __init__(self, channels) -> None:\n        super().__init__()\n        self.convmod1 = Conv2dModule(channels, channels)\n        self.convmod2 = Conv2dModule(channels, channels)\n        self.convmod3 = Conv2dModule(channels, channels)\n        self.shared_conv = nn.Conv2d(channels, channels, 1)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.bn2 = nn.BatchNorm2d(channels)\n        self.sub = FloatFunctional()\n        self.relu = nn.ReLU()\n\n    def forward(self, x, y):\n        x = self.convmod1(x, y)\n        x = self.convmod2(y, x)\n        x = self.convmod3(x, y)\n        x = self.shared_conv(x)\n        x = self.bn1(x)\n        y = self.shared_conv(y)\n        y = self.bn2(y)\n        x = self.sub.sub(x, y)\n        x = self.relu(x)\n\n        return x\n\nmodel = TestFuseNet(3)\n\n# \u53ef\u4ee5\u8c03\u7528\u63a5\u53e3\u8bbe\u7f6e\uff0c\u4e5f\u53ef\u4ee5\u624b\u52a8\u6307\u5b9a preserve_qat_mode=True\nset_preserve_qat_mode(float_net, ("convmod1"), ())\nmodel.convmod1.preserve_qat_mode = True\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\nqat_net = prepare_qat_fx(model, {"": default_qat_8bit_fake_quant_qconfig})\nquant_model = horizon.quantization.convert_fx(qat_net)\n# \u5b9a\u70b9\u6a21\u578b\u4e2d convmod1.add \u4ecd\u7136\u4e3a qat.ConvAddReLU2d\nassert isinstance(quant_model.convmod1.add, horizon_nn.qat.ConvAddReLU2d)\n'})}),"\n",(0,o.jsx)(e.h3,{id:"device-a-name-hybrid-device-check-a",children:"\u5f02\u6784\u6a21\u578b\u90e8\u7f72 device \u68c0\u67e5"}),"\n",(0,o.jsxs)(e.p,{children:["horizon_plugin_pytorch \u652f\u6301\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"fx"})," \u7684\u65b9\u5f0f\u6765\u6784\u5efa\u90e8\u7f72\u5f02\u6784\u6a21\u578b\u3002\u5f02\u6784\u6a21\u578b device \u68c0\u67e5\u5de5\u5177\u4f1a\u68c0\u67e5\u6700\u540e\u90e8\u7f72\u65f6\uff0c\u6a21\u578b\u4e2d\u7684\u6bcf\u4e2a\u7b97\u5b50\u8fd0\u884c\u5728 BPU \u8fd8\u662f CPU \u4e0a\u3002"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import check_deploy_device\n\ndef check_deploy_device(\n    model: torch.fx.GraphModule,\n    print_tabulate: bool = True,\n    out_dir: Optional[str] = None,\n) -> Dict[str, Tuple[str, str]]:\n    """\u68c0\u67e5\u5f02\u6784\u6a21\u578b\u90e8\u7f72\u65f6\u6bcf\u4e2a\u7b97\u5b50\u662f\u8fd0\u884c\u5728 CPU \u8fd8\u662f BPU \u4e0a\u3002\n\n    \u53c2\u6570\uff1a\n        model: QAT \u6a21\u578b\u6216\u5b9a\u70b9\u6a21\u578b\u3002\u5fc5\u987b\u662f\u901a\u8fc7`prepare_qat_fx`\u63a5\u53e3\u8f6c\u6362\u5f97\u5230\u3002\n        print_tabulate\uff1a\u662f\u5426\u6253\u5370\u7ed3\u679c\u3002\u9ed8\u8ba4\u4e3a True\u3002\n        out_dir: \u4fdd\u5b58 deploy_device.txt \u7684\u8def\u5f84\u3002\u9ed8\u8ba4\u4e3a None, \u4fdd\u5b58\u5230\u5f53\u524d\u8def\u5f84\u3002\n\n    \u8f93\u51fa\uff1a\n        \u4e00\u4e2a\u8bb0\u5f55\u6bcf\u4e2a op \u8fd0\u884c device \u7684 dict\uff0c\u683c\u5f0f\u5982\u4e0b\uff1a\n            * KEY (str): module \u540d (\u5982 layer1.0.conv.weight)\n            * VALUE (Tuple): (\u90e8\u7f72 device(BPU/CPU), module \u7c7b\u578b)\n    """\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport torch\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn import qat\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.quantization import (\n    prepare_qat_fx,\n    convert_fx,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n    default_qat_out_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.utils.quant_profiler import check_deploy_device\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\n\n\nclass _ConvBlock(nn.Module):\n    def __init__(self, channels=3):\n        super().__init__()\n        self.conv = nn.Conv2d(channels, channels, 1)\n        self.prelu = torch.nn.PReLU()\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = self.prelu(x)\n        return torch.nn.functional.selu(x)\n\n\nclass _SeluModule(nn.Module):\n    def forward(self, input):\n        return torch.nn.functional.selu(input)\n\n\nclass HybridModel(nn.Module):\n    def __init__(self, channels=3):\n        super().__init__()\n\n        self.quant = QuantStub()\n        self.conv0 = nn.Conv2d(channels, channels, 1)\n        self.prelu = torch.nn.PReLU()\n        self.conv1 = _ConvBlock(channels)\n        self.conv2 = nn.Conv2d(channels, channels, 1)\n        self.conv3 = nn.Conv2d(channels, channels, 1)\n        self.conv4 = nn.Conv2d(channels, channels, 1)\n        self.selu = _SeluModule()\n        self.dequant = DeQuantStub()\n        self.identity = torch.nn.Identity()\n        self.add = FloatFunctional()\n\n    def forward(self, input):\n        x = self.quant(input)\n        x = self.conv0(x)\n        x = self.identity(x)\n        x = self.prelu(x)\n        x = torch.nn.functional.selu(x)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.identity(x)\n        y = self.conv4(x)\n        x = self.add.add(x, y)\n        x = self.selu(x)\n        return self.dequant(x)\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\nshape = np.random.randint(10, 20, size=4).tolist()\ninfer_shape = [1] + shape[1:]\ninfer_data = torch.rand(size=infer_shape)\n\nmodel = HybridModel(shape[1])\nmodel(infer_data)\n\n# \u4f7f\u7528 fx \u63a5\u53e3\u8fdb\u884c\u5f02\u6784\nqat_model = prepare_qat_fx(\n    model,\n    {\n        "": default_qat_8bit_fake_quant_qconfig,\n        "module_name": [("conv4", default_qat_out_8bit_fake_quant_qconfig)],\n    },\n    hybrid=True,\n    hybrid_dict={\n        "module_name": ["conv1.conv", "conv3"],\n        "module_type": [_SeluModule],\n    },\n)\nqat_model(infer_data)\ncheck_deploy_device(qat_model)\n\nquantize_model = convert_fx(qat_model)\ncheck_deploy_device(quantize_model)\n'})}),"\n",(0,o.jsxs)(e.p,{children:["\u4f1a\u4ee5\u8868\u683c\u7684\u5f62\u5f0f\uff0c\u540c\u65f6\u5728\u5c4f\u5e55\u8f93\u5165\u5e76\u5728",(0,o.jsx)(e.code,{children:"deploy_device.txt"}),"\u4e2d\u4fdd\u5b58\u5982\u4e0b\u7ed3\u679c\u3002\u8868\u683c\u4e2d\u4ece\u5de6\u5230\u53f3\u6bcf\u4e00\u5217\u5206\u522b\u8868\u793a\uff1a"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"name\uff1a\u8be5 op \u5728\u6a21\u578b\u4e2d\u5b9a\u4e49\u7684 name"}),"\n",(0,o.jsx)(e.li,{children:"deploy device\uff1a\u90e8\u7f72\u65f6\u5b9e\u9645\u8fd0\u884c\u7684 device\uff0c\u662f CPU \u6216\u8005 BPU"}),"\n",(0,o.jsx)(e.li,{children:"type\uff1a\u8be5 op \u5728\u6a21\u578b\u4e2d\u7684\u8c03\u7528\u5f62\u5f0f\uff0cmodule \u6216 function"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"name                            deploy device    type\n------------------------------  ---------------  --------\nquant                           CPU              module\nconv0                           BPU              module\nprelu_input_dequant             CPU              module\nprelu                           CPU              module\nselu                            CPU              function\nconv1.conv                      CPU              module\nconv1.prelu                     CPU              module\nselu_1                          CPU              function\nselu_1_activation_post_process  CPU              module\nconv2                           BPU              module\nconv3_input_dequant             CPU              module\nconv3                           CPU              module\nconv3_activation_post_process   CPU              module\nadd_1                           BPU              method\nselu_2_input_dequant            CPU              module\nselu_2                          CPU              function\ndequant                         CPU              module\n"})}),"\n",(0,o.jsx)(e.h3,{id:"torchscript-hbdk",children:"torchscript \u548c hbdk \u7ed3\u679c\u5bf9\u6bd4"}),"\n",(0,o.jsx)(e.p,{children:"\u5f53\u9047\u5230 horizon_plugin_pytorch \u751f\u6210\u7684\u5b9a\u70b9 pt \u7684\u63a8\u7406\u7ed3\u679c\uff0c\u548c\u7f16\u8bd1\u540e\u7684 hbm \u63a8\u7406\u7ed3\u679c\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u65f6\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u6b64\u5de5\u5177\u68c0\u67e5 pt \u7684\u63a8\u7406\u7ed3\u679c\u548c hbdk \u89e3\u6790 pt \u7684\u7ed3\u679c\u662f\u5426\u4e00\u81f4\u3002\u6b64\u5de5\u5177\u4f1a\u8f93\u51fa pt \u4e2d\u6bcf\u4e2a op \u548c hbdk \u89e3\u6790\u540e\u5bf9\u5e94 op \u7684\u7ed3\u679c\u5bf9\u6bd4\u3002"}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsx)(e.p,{children:"\u5f53\u9047\u5230\u5b9a\u70b9 pt \u63a8\u7406\u7ed3\u679c\u548c hbm \u7ed3\u679c\u6216\u4e0a\u677f\u7ed3\u679c\u4e0d\u4e00\u81f4\u65f6\uff0c\u8bf7\u5148\u786e\u4fdd\u524d\u540e\u5904\u7406\u7684\u8fc7\u7a0b\u90fd\u662f\u4e00\u81f4\u7684\u3002\u6b64\u5916\uff0chbdk \u5bf9 pt \u7684\u89e3\u6790\u4ec5\u662f\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u7684\u4e00\u6b65\uff0chbm \u63a8\u7406\u7ed3\u679c\u548c\u6700\u7ec8\u4e0a\u677f\u63a8\u7406\u7684\u7ed3\u679c\u7531 hbdk \u548c runtime \u7b49\u51b3\u5b9a\u3002\u5373\u4f7f\u4f7f\u7528\u6b64\u5de5\u5177\u68c0\u67e5\u786e\u8ba4\u5b9a\u70b9 pt \u7684\u63a8\u7406\u7ed3\u679c\u548c hbdk \u5bf9 pt \u7684\u89e3\u6790\u7ed3\u679c\u4e00\u81f4\uff0c\u4ecd\u65e0\u6cd5\u4fdd\u8bc1\u548c\u6700\u7ec8\u7684\u4e0a\u677f\u7ed3\u679c\u4e00\u81f4\u3002\u540e\u7eed\u8fc7\u7a0b\u7684\u9a8c\u8bc1\u8bf7\u8054\u7cfb hbdk \u6216\u8005 runtime \u5f00\u53d1\u56e2\u961f\u3002"})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import script_profile\n\ndef script_profile(\n    model: Union[torch.nn.Module, torch.jit.ScriptModule],\n    example_inputs: Any,\n    out_dir: Optional[str] = None,\n    march: Optional[str] = None,\n    mark_node_func: Optional[Callable] = None,\n    compare_with_hbdk_parser: bool = True,\n):\n    """\u83b7\u53d6 ScriptModel \u4e2d\u6bcf\u4e2a op \u7684\u7ed3\u679c\uff0c\u5e76\u548c hbdk \u89e3\u6790\u7684\u7ed3\u679c\u5bf9\u6bd4\u3002\n\n    \u8be5\u51fd\u6570\u5c06\u83b7\u53d6 ScriptModel \u4e2d\u6bcf\u4e2a op \u7684\u7ed3\u679c\uff0c\u5e76\u4f7f\u7528 torch.save \u5c06\u7ed3\u679c\u5b58\u50a8\u5728\n    \u201chorizon_script_result.pt\u201d\u6587\u4ef6\u4e2d\uff0c\u540c\u65f6\u4e5f\u4f1a\u4ee5 dict \u7684\u5f62\u5f0f\u8fd4\u56de\u6539\u7ed3\u679c\u3002\n\n    \u53c2\u6570\uff1a\n        model: \u9700\u8981\u68c0\u67e5\u7684\u6a21\u578b\u3002\u5fc5\u987b\u662f\u5b9a\u70b9\u6a21\u578b\u6216\u8005 trace \u4e4b\u540e\u7684 ScriptModule\n        example_inputs: \u6a21\u578b\u8f93\u5165\n        out_dir: \u4fdd\u5b58\u7ed3\u679c\u7684\u8def\u5f84\u3002\u82e5\u4e3a None\uff0c\u5219\u4fdd\u5b58\u5728\u5f53\u524d\u8def\u5f84\u4e0b\u3002\u9ed8\u8ba4\u4e3a None\n        march: \u4f7f\u7528\u7684 BPU \u67b6\u6784\u3002\u82e5\u4e3a None\uff0c\u4f1a\u81ea\u52a8\u4f7f\u7528 get_march() \u83b7\u53d6\u5f53\u524d\u6307\u5b9a\u7684\u67b6\u6784\u3002\n            \u9ed8\u8ba4\u4e3a None\u3002 **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\n        mark_node_func: \u6807\u8bb0 ScriptModule \u4e2d\u54ea\u4e9b\u8282\u70b9\u7684\u7ed3\u679c\u9700\u8981\u4fdd\u5b58\u7684\u6807\u8bb0\u51fd\u6570\u3002\n            \u82e5\u4e3a None\uff0c\u4f7f\u7528\u9ed8\u8ba4\u7684\u6807\u8bb0\u51fd\u6570\u3002\u9ed8\u8ba4\u4e3a None\u3002\n        compare_with_hbdk_parser: \u662f\u5426\u5c06 ScriptModule \u4e2d\u6bcf\u4e2a op \u7684\u7ed3\u679c\u548c hbdk \u89e3\u6790\n            \u7684\u7ed3\u679c\u4f5c\u5bf9\u6bd4\u3002\u9ed8\u8ba4\u4e3a True\uff0c\u4f1a\u548c hbdk \u7684\u89e3\u6790\u7ed3\u679c\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u5728\u5c4f\u5e55\u8f93\u51fa\n            \u5bf9\u6bd4\u7ed3\u679c\u3002\n\n    \u8fd4\u56de\u503c\uff1a\n        output(dict<str, tensor>): \u4e00\u4e2a\u8bb0\u5f55 pt \u4e2d\u6bcf\u4e2a op \u7ed3\u679c\u7684 dict\uff0c\u683c\u5f0f\u5982\u4e0b\uff1a\n            * KEY (str): op \u540d\u79f0\uff0c\u548c hbdk \u89e3\u6790\u540e\u7684\u6bcf\u4e2a op \u540d\u79f0\u4e00\u81f4\n            * VALUE (tensor): op \u7ed3\u679c\n    """\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import torch\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\n\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.quantization.quantize_fx import (\n    convert_fx,\n    prepare_qat_fx,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.utils.quant_profiler import script_profile\n\n\nclass Net(nn.Module):\n    def __init__(self, share_op=True):\n        super(Net, self).__init__()\n\n        self.quant_stubx = QuantStub()\n        self.quant_stuby = QuantStub()\n        self.unused = nn.ReLU()\n        self.mul_op = FloatFunctional()\n        self.cat_op = FloatFunctional()\n        self.add_op = FloatFunctional()\n        self.quantized_ops = nn.Sequential(\n            nn.ReLU(),\n            nn.Sigmoid(),\n            nn.Softmax(),\n            nn.SiLU(),\n            horizon_nn.Interpolate(\n                scale_factor=2, recompute_scale_factor=True\n            ),\n            horizon_nn.Interpolate(\n                scale_factor=2.3, recompute_scale_factor=True\n            ),\n            nn.AvgPool2d(kernel_size=4),\n            nn.Upsample(scale_factor=1.3, mode="bilinear"),\n            nn.UpsamplingBilinear2d(scale_factor=0.7),\n        )\n        self.dequant_stub = DeQuantStub()\n        self.share_op = share_op\n\n    def forward(self, x, y):\n        x = self.quant_stubx(x)\n        y = self.quant_stuby(y)\n        y = self.add_op.add(x, y)\n        x = self.cat_op.cat((x, y), 1)\n        if self.share_op:\n            x = self.cat_op.cat((x, y), dim=1)\n        a, b = x.split(15, dim=1)\n        x = self.mul_op.mul(a, b)\n        x = self.quantized_ops(x)\n        x = self.dequant_stub(x)\n        return x\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\ndevice = torch.device("cpu")\ndata = torch.rand((1, 10, 5, 5), device=device)\ndata = (data, data)\nfloat_net = Net().to(device)\nfloat_net(*data)\nqat_net = prepare_qat_fx(float_net, {"": default_qat_8bit_fake_quant_qconfig})\nqat_net = qat_net.to(device)\nqat_net(*data)\nbpu_net = convert_fx(qat_net)\nscript_module = torch.jit.trace(bpu_net.eval(), data)\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nscript_profile(bpu_net, data, march=March.BAYES)\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f1a\u5728\u5c4f\u5e55\u8f93\u51fa\u5982\u4e0b\u5bf9\u6bd4\u7ed3\u679c\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"name                                        if equal\n------------------------------------------  ----------\narg0                                        True\narg1                                        True\n_hz_cat                                     True\n_hz_cat_1                                   True\n_aten_split.0                               True\n_aten_split.1                               True\n_hz_mul                                     True\n_quantized_ops_0_aten_relu                  True\n_quantized_ops_1_hz_lut                     True\n_quantized_ops_2_aten_max_val               True\n_quantized_ops_2_aten_max_arg               True\n_quantized_ops_2_hz_sub                     True\n_quantized_ops_2_exp_hz_segment_lut         True\n_quantized_ops_2_hz_sum                     True\n_quantized_ops_2_reciprocal_hz_segment_lut  True\n_quantized_ops_2_hz_mul                     True\n_quantized_ops_3_hz_lut                     True\n_quantized_ops_4_hz_interpolate             True\n_quantized_ops_5_hz_interpolate             True\n_quantized_ops_6_hz_avg_pool2d              True\n_quantized_ops_7_hz_interpolate             True\n_quantized_ops_8_hz_interpolate             True\nTorch run pt output is same with hbdk parser.\n"})}),"\n",(0,o.jsx)(e.h3,{id:"torchscript",children:"\u4e0d\u540c\u7248\u672c torchscript \u6a21\u578b\u7684\u7ed3\u679c\u5bf9\u6bd4"}),"\n",(0,o.jsxs)(e.p,{children:["\u5f53\u9047\u5230 horizon_plugin_pytorch \u7248\u672c\u53d8\u66f4\u4e4b\u540e\uff0c\u540c\u4e00\u4e2a\u6a21\u578b\u7684\u5b9a\u70b9 pt \u63a8\u7406\u7ed3\u679c\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u65f6\uff0c",(0,o.jsx)(e.strong,{children:"\u5728\u786e\u4fdd\u4e0d\u540c\u7248\u672c\u7684\u524d\u540e\u5904\u7406\u8fc7\u7a0b\u4e00\u81f4\u540e"}),"\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u6b64\u5de5\u5177\u5bf9\u6bd4\u4e0d\u540c\u7248\u672c\u7684 pt \u4e2d\u6bcf\u4e2a op \u7684\u7ed3\u679c\u3002"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import compare_script_models\n\ndef compare_script_models(\n    model1: torch.jit.ScriptModule,\n    model2: torch.jit.ScriptModule,\n    example_inputs: Any,\n    march: Optional[str] = None,\n):\n    """\u6bd4\u8f83\u4e24\u4e2a ScriptModule \u7684\u7ed3\u679c\u3002\n\n    \u8be5\u51fd\u6570\u6bd4\u8f83\u540c\u4e00\u4e2a\u6a21\u578b\u5728\u4e0d\u540c horizon_plugin_pytorch \u4e0b\u751f\u6210\u7684 ScriptModule \u4e2d\u6bcf\u4e2a op \u7ed3\u679c\u662f\u5426\u4e00\u81f4\u3002\n\n    \u53c2\u6570\uff1a\n        model1: \u4f7f\u7528\u67d0\u7248\u672c horizon_plugin_pytorch \u751f\u6210\u7684 ScriptModule\n        model2: \u4f7f\u7528\u53e6\u4e00\u4e2a\u7248\u672c horizon_plugin_pytorch \u751f\u6210\u7684 ScriptModule\n        example_inputs: \u6a21\u578b\u8f93\u5165\n        march: \u4f7f\u7528\u7684 BPU \u67b6\u6784\u3002\u82e5\u4e3a None\uff0c\u4f1a\u81ea\u52a8\u4f7f\u7528 get_march() \u83b7\u53d6\u5f53\u524d\u6307\u5b9a\u7684\u67b6\u6784\u3002\n            \u9ed8\u8ba4\u4e3a None\u3002 **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\n    """\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import torch\nfrom torch import nn\nfrom torch.quantization import DeQuantStub, QuantStub\n\nfrom horizon_plugin_pytorch import nn as horizon_nn\nfrom horizon_plugin_pytorch.march import March, set_march\nfrom horizon_plugin_pytorch.nn.quantized import FloatFunctional\nfrom horizon_plugin_pytorch.quantization.quantize_fx import (\n    convert_fx,\n    prepare_qat_fx,\n)\nfrom horizon_plugin_pytorch.quantization.qconfig import (\n    default_qat_8bit_fake_quant_qconfig,\n)\nfrom horizon_plugin_pytorch.utils.quant_profiler import compare_script_models\n\n\nclass Net(nn.Module):\n    def __init__(self, share_op=True):\n        super(Net, self).__init__()\n\n        self.quant_stubx = QuantStub()\n        self.quant_stuby = QuantStub()\n        self.unused = nn.ReLU()\n        self.mul_op = FloatFunctional()\n        self.cat_op = FloatFunctional()\n        self.add_op = FloatFunctional()\n        self.quantized_ops = nn.Sequential(\n            nn.ReLU(),\n            nn.Sigmoid(),\n            nn.Softmax(),\n            nn.SiLU(),\n            horizon_nn.Interpolate(\n                scale_factor=2, recompute_scale_factor=True\n            ),\n            horizon_nn.Interpolate(\n                scale_factor=2.3, recompute_scale_factor=True\n            ),\n            nn.AvgPool2d(kernel_size=4),\n            nn.Upsample(scale_factor=1.3, mode="bilinear"),\n            nn.UpsamplingBilinear2d(scale_factor=0.7),\n        )\n        self.dequant_stub = DeQuantStub()\n        self.share_op = share_op\n\n    def forward(self, x, y):\n        x = self.quant_stubx(x)\n        y = self.quant_stuby(y)\n        y = self.add_op.add(x, y)\n        x = self.cat_op.cat((x, y), 1)\n        if self.share_op:\n            x = self.cat_op.cat((x, y), dim=1)\n        a, b = x.split(15, dim=1)\n        x = self.mul_op.mul(a, b)\n        x = self.quantized_ops(x)\n        x = self.dequant_stub(x)\n        return x\n\n# **RDK X3** \u8bbe\u7f6eBERNOULLI2\uff0c **RDK Ultra** \u8bbe\u7f6e\u4e3aBAYES\uff0c **RDK X5** \u8bbe\u7f6e\u4e3aBAYES_E\u3002\nset_march(March.BAYES)\ndevice = torch.device("cpu")\ndata = torch.rand((1, 10, 5, 5), device=device)\ndata = (data, data)\nfloat_net = Net().to(device)\nfloat_net(*data)\nqat_net = prepare_qat_fx(float_net, {"": default_qat_8bit_fake_quant_qconfig})\nqat_net = qat_net.to(device)\nqat_net(*data)\nbpu_net = convert_fx(qat_net)\nscript_module = torch.jit.trace(bpu_net.eval(), data)\n\n# \u5b9e\u9645\u4f7f\u7528\u65f6\u5e94\u8f93\u5165\u4e24\u4e2a\u4e0d\u540c\u7248\u672c\u7684 ScriptModule\ncompare_script_models(script_module, script_module, data)\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f1a\u5728\u5c4f\u5e55\u8f93\u51fa\u5982\u4e0b\u7ed3\u679c\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"name                                        if equal\n------------------------------------------  ----------\narg0                                        True\narg1                                        True\n_hz_add                                     True\n_hz_cat                                     True\n_hz_cat_1                                   True\n_aten_split.0                               True\n_aten_split.1                               True\n_hz_mul                                     True\n_quantized_ops_0_aten_relu                  True\n_quantized_ops_1_hz_lut                     True\n_quantized_ops_2_aten_max_arg               True\n_quantized_ops_2_aten_max_val               True\n_quantized_ops_2_hz_sub                     True\n_quantized_ops_2_exp_hz_segment_lut         True\n_quantized_ops_2_hz_sum                     True\n_quantized_ops_2_reciprocal_hz_segment_lut  True\n_quantized_ops_2_hz_mul                     True\n_quantized_ops_3_hz_lut                     True\n_quantized_ops_4_hz_interpolate             True\n_quantized_ops_5_hz_interpolate             True\n_quantized_ops_6_hz_avg_pool2d              True\n_quantized_ops_7_hz_interpolate             True\n_quantized_ops_8_hz_interpolate             True\nAll ops in two ScriptModules are same.\n"})}),"\n",(0,o.jsx)(e.h3,{id:"a-name-cuda-memory-a",children:"\u6a21\u578b\u663e\u5b58\u5360\u7528\u5206\u6790\u5de5\u5177"}),"\n",(0,o.jsx)(e.p,{children:"Plugin \u63d0\u4f9b\u4e86\u6a21\u578b\u663e\u5b58\u5360\u7528\u7684\u5206\u6790\u5de5\u5177\uff0c\u4fbf\u4e8e\u60a8\u5b9a\u4f4d\u663e\u5b58\u74f6\u9888\uff0c\u5408\u7406\u4f7f\u7528 checkpoint \u548c saved tensor \u7b49\u6280\u672f\u8282\u7701\u663e\u5b58\u3002"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# from horizon_plugin_pytorch.utils.quant_profiler import show_cuda_memory_consumption\n\ndef show_cuda_memory_consumption(\n    model: torch.nn.Module,\n    example_inputs: Any,\n    device: torch.device,\n    check_leaf_module=None,\n    out_dir: Optional[str] = None,\n    file_name: Optional[str] = None,\n    custom_backward=None,\n):\n    """\n    \u8bc4\u4f30\u6a21\u578b\u5728 forward \u548c backward \u8fc7\u7a0b\u4e2d\u7684\u663e\u5b58\u5360\u7528\u60c5\u51b5\n\n    \u7ed3\u679c\u5c06\u4fdd\u5b58\u4e3a html \u6587\u4ef6\n\n    \u5df2\u77e5\u95ee\u9898\uff1a\u6a21\u578b\u4e2d\u4f7f\u7528\u4e86 checkpoint \u65f6\uff0c\u90e8\u5206 backward \u6761\u76ee\u7684\u540d\u79f0\u5c06\u663e\u793a\u4e3a forward\uff0c\n    \u56e0\u4e3a checkpoint \u4f7f\u5f97 forward hook \u5728 backward \u8fc7\u7a0b\u4e2d\u88ab\u8c03\u7528\n\n    \u53c2\u6570\uff1a\n        model: \u9700\u8981\u8bc4\u4f30\u7684\u6a21\u578b\n        example_inputs (Any[Tensor]): \u6a21\u578b\u8f93\u5165\n        device: \u8bc4\u4f30\u65f6\u4f7f\u7528\u7684 device\n        check_leaf_module: \u68c0\u67e5 module \u662f\u5426\u662f\u4e00\u4e2a\u53f6\u5b50\u8282\u70b9\u3002\u9ed8\u8ba4\u4e3a None\uff0c\u4f7f\u7528\n            \u9884\u5b9a\u4e49\u7684 is_leaf_module\uff0c\u5c06\u6240\u6709 horizon_plugin_pytorch \u4e2d\u5b9a\u4e49\u7684 op \u4ee5\u53ca\u672a\u652f\u6301\u7684\n            \u6d6e\u70b9 op \u5f53\u4f5c\u4e3a\u53f6\u5b50\u8282\u70b9\n        out_dir: \u4fdd\u5b58 html \u7ed3\u679c\u7684\u8def\u5f84\u3002\u9ed8\u8ba4\u4e3a None, \u4fdd\u5b58\u5230\u5f53\u524d\u8def\u5f84\n        file_name: \u4fdd\u5b58\u7684 html \u6587\u4ef6\u540d\u3002\u82e5\u672a\u6307\u5b9a\uff0c\u9ed8\u8ba4\u4e3a mem_info\n        custom_backward: \u4f7f\u7528\u6a21\u578b\u8f93\u51fa\u6267\u884c backward \u64cd\u4f5c\uff0c\u5fc5\u987b\u8bbe\u7f6e retain_graph=False\u3002\n            \u9ed8\u8ba4\u4e3a None\uff0c\u6b64\u65f6\u6a21\u578b\u8f93\u51fa\u5fc5\u987b\u662f\u5355\u4e2a Tensor\n    """\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528\u793a\u4f8b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# \u8fd9\u91cc\u7565\u53bb MobilenetV1 \u7684\u5b9a\u4e49\nfloat_net = MobilenetV1()\nshow_cuda_memory_consumption(float_net, data, torch.device("cuda"))\n'})}),"\n",(0,o.jsxs)(e.p,{children:["\u5c06\u4f1a\u5728\u5f53\u524d\u76ee\u524d\u6216\u8005",(0,o.jsx)(e.code,{children:"out_dir"}),"\u53c2\u6570\u6307\u5b9a\u7684\u76ee\u5f55\u4e0b\u751f\u6210\u5982\u4e0b\u7ed3\u679c\u3002"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"mem_info.html"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/mobilenetv1_mem_info.svg",alt:"mobilenetv1_mem_info"})}),"\n",(0,o.jsx)(e.h2,{id:"debug_precision",children:"\u91cf\u5316\u8bad\u7ec3\u7cbe\u5ea6\u8c03\u4f18\u5efa\u8bae"}),"\n",(0,o.jsx)(e.h3,{id:"\u53c2\u8003\u6d41\u7a0b",children:"\u53c2\u8003\u6d41\u7a0b"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/debug_precision_flow.png",alt:"debug_precision_flow"})}),"\n",(0,o.jsx)(e.h3,{id:"\u524d\u8a00",children:"\u524d\u8a00"}),"\n",(0,o.jsxs)(e.p,{children:["\u91cf\u5316\u8bad\u7ec3\u5de5\u5177\u662f\u901a\u8fc7\u5728\u8bad\u7ec3\u4e2d\u6a21\u62df\u91cf\u5316\u7684\u65b9\u5f0f\u4f7f\u5f97\u90e8\u7f72\u91cf\u5316\u7cbe\u5ea6",(0,o.jsx)(e.strong,{children:"\u5c3d\u91cf\u63a5\u8fd1"}),"\u6d6e\u70b9\u7cbe\u5ea6\uff1b\u800c\u91cf\u5316\u7cbe\u5ea6\u76f8\u5bf9\u4e8e\u6d6e\u70b9\u7cbe\u5ea6\u635f\u5931\u591a\u5c11\uff0c\u662f\u6709\u5f88\u591a\u56e0\u7d20\u51b3\u5b9a\u3002\u672c\u7ae0\u603b\u7ed3\u4e86\u4e00\u4e9b\u4f7f\u7528\u7ecf\u9a8c\u4f9b\u7528\u6237\u9009\u7528\uff0c\u671f\u5f85\u80fd\u7ed9\u60a8\u7684\u91cf\u5316\u8bad\u7ec3\u7cbe\u5ea6\u8c03\u4f18\u5e26\u6765\u5e2e\u52a9\u3002"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u56e0\u4e3a\u91cf\u5316\u8bad\u7ec3\u662f\u57fa\u4e8e\u6d6e\u70b9\u6a21\u578b\u7684 finetune\uff0c\u6240\u4ee5\u672c\u7ae0\u6240\u8ff0\u7684\u8c03\u4f18\u6307\u5357\u751f\u6548\u7684\u57fa\u7840\u662f",(0,o.jsx)(e.strong,{children:"\u7b26\u5408\u9884\u671f\u7cbe\u5ea6\u7684\u6d6e\u70b9\u6a21\u578b"}),"\u3002"]})}),"\n",(0,o.jsx)(e.admonition,{title:"\u5907\u6ce8",type:"info",children:(0,o.jsx)(e.p,{children:"\u91cf\u5316\u8bad\u7ec3\u672c\u8d28\u4e0a\u4ecd\u7136\u662f\u6a21\u578b\u8bad\u7ec3\uff0c\u4f46\u662f\u7531\u4e8e\u90e8\u7f72\u5e73\u53f0\u7684\u9650\u5236\uff0c\u5bfc\u81f4\u6a21\u578b\u8bad\u7ec3\u96be\u5ea6\u589e\u52a0\u3002\u672c\u6587\u5217\u4e3e\u4e86 horizon_plugin_pytorch \u603b\u7ed3\u7684\u4e00\u4e9b\u7ecf\u9a8c\uff0c\u5e0c\u671b\u80fd\u5bf9\u7528\u6237\u8c03\u53c2\u6709\u4e00\u5b9a\u7684\u5e2e\u52a9\u3002"})}),"\n",(0,o.jsx)(e.h3,{id:"a-name-recommended-configuration-a",children:"\u63a8\u8350\u8d85\u53c2\u914d\u7f6e"}),"\n",(0,o.jsx)(e.p,{children:"\u9664\u4e0b\u8ff0\u8868\u683c\u8d85\u53c2\u5916\uff0c\u5176\u4ed6\u5728 QAT \u9636\u6bb5\u4e0e\u6d6e\u70b9\u9636\u6bb5\u4fdd\u6301\u4e00\u81f4\u3002"}),"\n",(0,o.jsxs)(e.table,{children:[(0,o.jsx)(e.thead,{children:(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.th,{children:"\u8d85\u53c2"}),(0,o.jsx)(e.th,{children:"\u8c03\u6574\u7b56\u7565"})]})}),(0,o.jsxs)(e.tbody,{children:[(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"LR"}),(0,o.jsxs)(e.td,{children:["lr=0.001\uff0c\u914d\u7f6e 2 \u6b21 scale=0.1 \u7684 lr decay ",(0,o.jsx)("br",{})," lr=0.0001\uff0c\u914d\u7f6e 1 \u6b21 scale=0.1 \u7684 lr decay"]})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Epoch"}),(0,o.jsx)(e.td,{children:"\u6d6e\u70b9 epoch \u7684 10%-20%"})]})]})]}),"\n",(0,o.jsx)(e.h3,{id:"\u7cbe\u5ea6\u5f02\u5e38\u73b0\u8c61",children:"\u7cbe\u5ea6\u5f02\u5e38\u73b0\u8c61"}),"\n",(0,o.jsx)(e.p,{children:"QAT \u8bad\u7ec3\u6216 quantized \u6a21\u578b\u90e8\u7f72\u65f6\uff0c\u5e38\u89c1\u7684\u51e0\u79cd\u5f02\u5e38\u73b0\u8c61\u5982\u4e0b\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"QAT \u7cbe\u5ea6\u672a\u8fbe\u9884\u671f\uff0c\u4f46\u76f8\u5bf9 float \u635f\u5931\u4e0d\u5927\uff1b"}),"\n",(0,o.jsxs)(e.p,{children:["\u8fd9\u79cd\u60c5\u51b5\u5efa\u8bae\u60a8\u6839\u636e",(0,o.jsx)(e.a,{href:"#a-name-para-policy-a",children:(0,o.jsx)(e.strong,{children:"\u8c03\u53c2\u7b56\u7565"})}),"\u6765\u63d0\u5347\u7cbe\u5ea6\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u51fa\u73b0 NAN"}),"\n",(0,o.jsx)(e.p,{children:"\u4e00\u822c\u662f\u68af\u5ea6\u7206\u70b8\u5bfc\u81f4\u6570\u503c\u6ea2\u51fa\uff0c\u8fdb\u800c\u51fa\u73b0 NAN\u3002\u5efa\u8bae\u60a8\u9010\u4e00\u5c1d\u8bd5\u4ee5\u4e0b\u6b65\u9aa4\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u68c0\u67e5\u6d6e\u70b9\u6a21\u578b\u7cbe\u5ea6\u662f\u5426\u6b63\u5e38\u3002\u6d6e\u70b9\u9636\u6bb5\u7684\u6a21\u578b\u5982\u679c\u6709\u95ee\u9898\u6216\u8005\u7cbe\u5ea6\u5f88\u4f4e\uff0c\u53ef\u80fd\u9020\u6210\u8fd9\u4e2a\u95ee\u9898\uff0c\u5efa\u8bae\u5c06\u6d6e\u70b9\u6a21\u578b\u5b8c\u5168\u8bad\u7ec3\u6536\u655b\u518d\u4f7f\u7528 QAT\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u68c0\u67e5\u6570\u636e\u548c label \u4e2d\u6709\u65e0 nan\uff0cinf\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u8c03\u4f4e\u5b66\u4e60\u7387\uff0c\u6216\u8005\u4f7f\u7528 warmup \u7b56\u7565\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528 torch.nn.utils.clip_grad_norm_ \u8fdb\u884c\u68af\u5ea6\u622a\u65ad\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:["\u4ee5\u4e0a\u5747\u4e0d\u884c\u7684\u8bdd\uff0c\u5efa\u8bae ",(0,o.jsx)(e.a,{href:"#debug-a-name-quantization-exception-a",children:(0,o.jsx)(e.strong,{children:"Debug \u91cf\u5316\u5f02\u5e38\u5c42"})}),"\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"QAT \u521d\u59cb loss \u76f8\u5bf9 float \u660e\u663e\u5f02\u5e38"}),"\n",(0,o.jsxs)(e.p,{children:["\u5982\u679c\u51fa\u73b0 QAT \u521d\u59cb\u7684 loss \u76f8\u6bd4 float \u7684\u660e\u663e\u5f02\u5e38\uff0c\u5e76\u4e14\u6ca1\u6709\u5f88\u5feb\u964d\u4f4e\u7684\u73b0\u8c61\uff0c\u5efa\u8bae ",(0,o.jsx)(e.a,{href:"#debug-a-name-quantization-exception-a",children:(0,o.jsx)(e.strong,{children:"Debug \u91cf\u5316\u5f02\u5e38\u5c42"})}),"\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Quantized \u76f8\u5bf9 QAT \u7cbe\u5ea6\u635f\u5931\u504f\u5927"}),"\n",(0,o.jsx)(e.p,{children:"\u4e00\u822c\u60c5\u51b5\uff0cQuantized \u76f8\u6bd4 QAT \u7cbe\u5ea6\u635f\u5931\u975e\u5e38\u5c0f\uff0c\u5982\u679c\u51fa\u73b0\u504f\u5927\u6216\u8005\u4e0d\u7b26\u5408\u9884\u671f\u7684\u73b0\u8c61\uff0c\u5efa\u8bae"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u9996\u5148\u660e\u786e\u662f\u6a21\u578b\u5bfc\u81f4\u7684\u7cbe\u5ea6\u635f\u5931\uff0c\u800c\u4e0d\u662f\u524d\u540e\u5904\u7406\u7684\u4e0d\u4e00\u81f4\u5bfc\u81f4\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:["\u786e\u8ba4\u662f\u6a21\u578b\u5c42\u9762\u7684\u7cbe\u5ea6\u635f\u5931\uff0c\u5efa\u8bae ",(0,o.jsx)(e.a,{href:"#debug-a-name-quantization-exception-a",children:(0,o.jsx)(e.strong,{children:"Debug \u91cf\u5316\u5f02\u5e38\u5c42"})}),"\u3002"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Calibration \u7cbe\u5ea6\u504f\u4f4e"}),"\n",(0,o.jsxs)(e.p,{children:["\u8fd9\u79cd\u60c5\u51b5\u5efa\u8bae ",(0,o.jsx)(e.a,{href:"#debug-a-name-quantization-exception-a",children:(0,o.jsx)(e.strong,{children:"Debug \u91cf\u5316\u5f02\u5e38\u5c42"})}),"\u3002"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"a-name-para-policy-a",children:"\u8c03\u53c2\u7b56\u7565"}),"\n",(0,o.jsxs)(e.p,{children:["\u9664",(0,o.jsx)(e.a,{href:"#a-name-recommended-configuration-a",children:(0,o.jsx)(e.strong,{children:"\u63a8\u8350\u8d85\u53c2\u914d\u7f6e"})}),"\u4e2d learning rate \u8c03\u6574\u5916\uff0c\u5efa\u8bae\u8003\u8651\u4ece\u4ee5\u4e0b\u51e0\u4e2a\u65b9\u9762\u6765\u63d0\u5347\u91cf\u5316\u8bad\u7ec3\u7cbe\u5ea6\uff1a"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u91cf\u5316\u53c2\u6570\u521d\u59cb\u5316"}),"\n",(0,o.jsxs)(e.p,{children:["\u91c7\u7528\u66f4\u7b26\u5408\u6570\u636e\u7edf\u8ba1\u7279\u5f81\u7684\u91cf\u5316\u53c2\u6570\u505a\u53c2\u6570\u521d\u59cb\u5316\uff0c\u53ef\u4ee5\u8ba9 QAT \u83b7\u53d6\u66f4\u597d\u7684\u7cbe\u5ea6\uff1b\u6211\u4eec\u63a8\u8350\u5728 QAT \u4e4b\u524d\u4f7f\u7528 ",(0,o.jsx)(e.a,{href:"#Calibration",children:(0,o.jsx)(e.strong,{children:"Calibration"})}),"\u3002"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u5907\u6ce8",type:"info",children:(0,o.jsxs)(e.p,{children:["\u5982\u679c Calibration \u7684\u7cbe\u5ea6\u8ddf\u6d6e\u70b9\u76f8\u5dee\u4e0d\u5927\u65f6\uff0c\u6700\u597d\u4e0d\u518d\u8c03\u6574 activation scale\uff0c\u5373\u8bbe\u7f6e activation  averaging_constant=0.0\uff1b\u5177\u4f53\u8bbe\u7f6e\u65b9\u6cd5\u89c1 ",(0,o.jsx)(e.a,{href:"/rdk_doc/Advanced_development/toolchain_development/expert/advanced_content",children:(0,o.jsx)(e.strong,{children:"\u81ea\u5b9a\u4e49 qconfig"})}),"\u3002"]})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Transform\uff08\u6570\u636e\u589e\u5f3a\uff09"}),"\n",(0,o.jsx)(e.p,{children:"\u5efa\u8bae\u9ed8\u8ba4 QAT \u65f6\u4fdd\u6301\u8ddf\u6d6e\u70b9\u4e00\u81f4\uff0c\u4e5f\u53ef\u4ee5\u9002\u5f53\u51cf\u5f31\uff0c\u6bd4\u5982\u5206\u7c7b\u7684\u989c\u8272\u8f6c\u6362\u53ef\u4ee5\u53bb\u6389\uff0cRandomResizeCrop \u7684\u6bd4\u4f8b\u8303\u56f4\u53ef\u4ee5\u9002\u5f53\u7f29\u5c0f\u7b49\u3002"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Optimizer"}),"\n",(0,o.jsx)(e.p,{children:"\u9ed8\u8ba4\u60c5\u51b5 QAT \u65f6\u4fdd\u6301\u8ddf\u6d6e\u70b9\u4e00\u81f4\uff0c\u4e5f\u53ef\u4ee5\u5c1d\u8bd5 SGD\uff0c\u5982\u679c\u6d6e\u70b9\u8bad\u7ec3\u91c7\u7528\u7684\u662f OneCycle \u7b49\u4f1a\u5f71\u54cd LR \u8bbe\u7f6e\u7684\u4f18\u5316\u5668\uff0c\u5efa\u8bae\u4e0d\u8981\u4e0e\u6d6e\u70b9\u4fdd\u6301\u4e00\u81f4\uff0c\u4f7f\u7528 SGD \u66ff\u6362\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:["\u5982\u679c\u4ee5\u4e0a\u7b56\u7565\u8fd8\u662f\u4e0d\u80fd\u6709\u6548\u63d0\u5347\u91cf\u5316\u7cbe\u5ea6\uff0c\u8bf7\u5c1d\u8bd5 ",(0,o.jsx)(e.a,{href:"#debug-a-name-quantization-exception-a",children:(0,o.jsx)(e.strong,{children:"Debug \u91cf\u5316\u5f02\u5e38\u5c42"})}),"\u3002"]}),"\n",(0,o.jsx)(e.h3,{id:"debug-a-name-quantization-exception-a",children:"Debug \u91cf\u5316\u5f02\u5e38\u5c42"}),"\n",(0,o.jsx)(e.p,{children:"\u4ece\u6839\u672c\u4e0a\u6765\u8bb2\uff0c\u6a21\u578b\u91cf\u5316\u7cbe\u5ea6\u5f02\u5e38\u90fd\u662f\u67d0\u4e9b\u5c42\u91cf\u5316\u540e\u7684\u6570\u503c\u5206\u8fa8\u7387\u4e0d\u8db3\u5bfc\u81f4\u7684\uff1b\u76ee\u524d QAT \u5de5\u5177\u4e2d\u7b97\u5b50\u7684\u8f93\u5165\u8f93\u51fa\uff08featuremap\uff09\u5bf9\u5e94\u4e00\u4e2a\u91cf\u5316\u53c2\u6570\uff08per-tensor\uff09\uff0c\u800c weight \u5bf9\u5e94\u4e00\u7ec4\u91cf\u5316\u53c2\u6570\uff08per-channel\uff09\u3002\u56e0\u6b64\u9488\u5bf9\u67d0\u7ec4\u88ab\u91cf\u5316\u6570\u636e\uff0c\u91cf\u5316\u540e\u6570\u503c\u5206\u8fa8\u7387\u8d8a\u9ad8\uff0c\u5bf9\u91cf\u5316\u7cbe\u5ea6\u5f71\u54cd\u8d8a\u5c0f\u3002\n\u6211\u4eec\u5efa\u8bae\u6309\u7167\u5982\u4e0b\u6b65\u9aa4\uff0c\u9010\u4e00\u6392\u67e5\uff0c\u627e\u51fa\u53ef\u80fd\u5bfc\u81f4\u91cf\u5316\u5206\u8fa8\u7387\u4e0d\u8db3\u7684\u5c42\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u786e\u8ba4\u91cf\u5316\u914d\u7f6e\u662f\u5426\u7b26\u5408\u9884\u671f"}),"\n",(0,o.jsx)(e.p,{children:"\u91cf\u5316\u914d\u7f6e\u51b3\u5b9a\u4e86\u67d0\u5c42\u7684\u91cf\u5316\u7b56\u7565\uff0c\u975e\u5e38\u5173\u952e\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u5efa\u8bae\u4f7f\u7528\u9ed8\u8ba4 int8 \u91cf\u5316\u914d\u7f6e\uff0c\u67d0\u4e9b\u7279\u6b8a\u60c5\u51b5\u624d\u9700\u8981\u4f7f\u7528\u7279\u6b8a\u7684\u91cf\u5316\u914d\u7f6e\uff0c\u6bd4\u5982\u7f51\u7edc\u8f93\u51fa\u4e0d\u91cf\u5316\u3002"}),"\n",(0,o.jsxs)(e.p,{children:["\u5efa\u8bae\u4f7f\u7528 ",(0,o.jsx)(e.a,{href:"#a-name-qconfig-check-a",children:(0,o.jsx)(e.strong,{children:"\u91cf\u5316\u914d\u7f6e\u68c0\u67e5"})})," \u68c0\u67e5\u91cf\u5316\u914d\u7f6e\u662f\u5426\u7b26\u5408\u9884\u671f\uff08\u76ee\u524d\u8fd8\u4e0d\u652f\u6301 calibration \u6a21\u578b\u7684\u68c0\u67e5\uff09\u3002"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u901a\u8fc7 Debug \u5de5\u5177\u627e\u5230\u91cf\u5316\u5f02\u5e38\u5c42"}),"\n",(0,o.jsxs)(e.p,{children:["\u5178\u578b\u7684\u91cf\u5316\u5f02\u5e38\u5c42\u6709\u4ee5\u4e0b\u51e0\u4e2a\u73b0\u8c61\uff0c\u53ef\u4ee5\u901a\u8fc7",(0,o.jsx)(e.a,{href:"#a-name-statistic-a",children:(0,o.jsx)(e.strong,{children:"\u7edf\u8ba1\u91cf\u5de5\u5177"})}),"\u548c",(0,o.jsx)(e.a,{href:"#a-name-similarity-a",children:(0,o.jsx)(e.strong,{children:"\u76f8\u4f3c\u5ea6\u5bf9\u6bd4\u5de5\u5177"})}),"\u53d1\u73b0\uff1a"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6a21\u578b\u4e2d\u67d0\u4e9b\u5c42\u7684\u7edf\u8ba1\u91cf\u5f02\u5e38\uff0c\u5177\u4f53\u4e3a\u6570\u503c\u8303\u56f4\u8f83\u5927\uff0c\u6216\u8005\u76f4\u65b9\u56fe\u5206\u5e03\u4e0d\u5747\u5300\uff08\u6709\u79bb\u7fa4\u70b9\uff09\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u67d0\u5c42\u76f8\u4f3c\u5ea6\u8f83\u4f4e\uff08float vs calibraion \u6216 qat vs quantized\uff09\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u67d0\u5c42\u7684\u5355\u7b97\u5b50\u8bef\u5dee\u8f83\u9ad8\uff08float vs calibraion \u6216 qat vs quantized\uff09\uff1b"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76f8\u4f3c\u5ea6\u5bf9\u6bd4\u5de5\u5177\u9002\u7528\u4e8e\u6bd4\u8f83 ",(0,o.jsx)(e.code,{children:"float \u548c calibration"}),"\u3001",(0,o.jsx)(e.code,{children:"qat \u548c quantized"})," \u6a21\u578b\u76f8\u4f3c\u5ea6\u3002QAT \u7cbe\u5ea6\u5f02\u5e38\u65f6\uff0c\u8003\u8651\u5230 QAT \u4f1a\u8ba9\u6a21\u578b\u8f93\u51fa\u6216 weight \u7684\u5206\u5e03\u53d1\u751f\u53d8\u5316\uff0c\u8bf7\u4e0d\u8981\u4f7f\u7528\u76f8\u4f3c\u5ea6\u5bf9\u6bd4\u5de5\u5177\u3002"]})}),"\n",(0,o.jsx)(e.p,{children:"\u8fd9\u4e09\u4e2a\u73b0\u8c61\u53ef\u80fd\u4f1a\u540c\u65f6\u51fa\u73b0\uff0c\u6bd4\u5982\u76f8\u4f3c\u5ea6\u4f4e\u7684\u65f6\u5019\u5355\u7b97\u5b50\u8bef\u5dee\u4e5f\u5f88\u9ad8\uff0c\u540c\u65f6\u7edf\u8ba1\u91cf\u5f02\u5e38\uff1b\u4e5f\u6709\u53ef\u80fd\u53ea\u51fa\u73b0\u5176\u4e2d\u4e00\u79cd\u73b0\u8c61\uff0c\u6bd4\u5982\u53ea\u662f\u7edf\u8ba1\u91cf\u5927\uff0c\u4f46\u5176\u4ed6\u5e76\u65e0\u5f02\u5e38\u3002\u5bfc\u81f4\u8fd9\u4e9b\u73b0\u8c61\u7684\u53ef\u80fd\u6027\u6709\u5f88\u591a\uff0c\u6211\u4eec\u5efa\u8bae\u4ece\u6a21\u578b\u81ea\u8eab\u51fa\u53d1\u6765\u9010\u6b65\u6392\u67e5\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6a21\u578b\u8f93\u5165"}),"\n",(0,o.jsx)(e.p,{children:"\u6a21\u578b\u8f93\u5165\u4e00\u822c\u6709\u4e24\u79cd\uff1a\u539f\u59cb\u6570\u636e\uff08\u56fe\u50cf\uff0c\u96f7\u8fbe\u7b49\uff09\u548c\u6a21\u578b\u7684\u8f85\u52a9\u8f93\u5165\uff08\u5982 transformer \u7684\u4f4d\u7f6e\u7f16\u7801\uff09\uff1b\u8fd9\u4e9b\u6570\u636e\u90fd\u9700\u8981\u91cf\u5316\u4e4b\u540e\u624d\u80fd\u4f5c\u4e3a\u91cf\u5316\u7f51\u7edc\u7684\u8f93\u5165\u3002"}),"\n",(0,o.jsx)(e.p,{children:"\u7531\u4e8e QAT \u5de5\u5177\u91c7\u7528\u5bf9\u79f0\u5747\u5300\u91cf\u5316\u7684\u65b9\u5f0f\uff0c\u5982\u679c\u6a21\u578b\u8f93\u5165\u6570\u636e\u672c\u8eab\u9700\u8981**\u9ad8\u6570\u503c\u5206\u8fa8\u7387\u6216\u5177\u6709\u975e\u5bf9\u79f0 (\u76f8\u5bf9 0)**\u7684\u7279\u70b9\uff0c\u5efa\u8bae\u901a\u8fc7\u4ee5\u4e0b\u624b\u6bb5\u6765\u6539\u8fdb\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6570\u636e\u9884\u5904\u7406\u65f6\u9488\u5bf9\u8f93\u5165\u6570\u636e\u505a\u5173\u4e8e 0 \u5bf9\u79f0\u7684\u5f52\u4e00\u5316\uff0c\u4e4b\u540e\u518d\u8f93\u5165\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u8c03\u6574\u8f93\u5165\u6570\u636e\u7684\u7269\u7406\u542b\u4e49\uff0c\u4f7f\u7528\u5bf9\u79f0\u3001\u6570\u503c\u8303\u56f4\u5c0f\u4e14\u5206\u8fa8\u7387\u4f4e\u7684\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u67e5\u770b\u91cf\u5316\u914d\u7f6e\u662f\u5426\u5408\u7406\uff0c\u6bd4\u5982\u56fe\u50cf\u8f93\u5165\u5efa\u8bae\u91c7\u7528\u56fa\u5b9a\u91cf\u5316 scale=1/128.0\uff1b\u4f46\u56fa\u5b9a scale \u4e0d\u4e00\u5b9a\u9002\u5408\u6240\u6709\u6570\u636e\uff0c\u9700\u8981\u5177\u4f53\u5206\u6790\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u5982\u679c\u6570\u636e\u5206\u8fa8\u7387\u8981\u6c42\u6bd4\u8f83\u9ad8\u4e14\u65e0\u6cd5\u8c03\u6574\uff0c\u5efa\u8bae\u4f7f\u7528 int16 \u7684\u91cf\u5316"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]})}),"\n",(0,o.jsx)(e.p,{children:"\u4ee5\u56fe\u50cf\u8f93\u5165\u4e3a\u4f8b\uff0c\u7531\u4e8e\u539f\u59cb\u56fe\u50cf\uff08\u4e0d\u7ba1\u662f RGB \u8fd8\u662f YUV\uff09\u8f93\u5165\u8303\u56f4\u662f [0, 255]\uff0c\u4e0d\u9002\u5408\u5bf9\u79f0\u91cf\u5316\uff0c\u800c\u505a\u5173\u4e8e 0 \u5bf9\u79f0\u7684\u5f52\u4e00\u5316\u4e4b\u540e\uff0c\u8f93\u5165\u8303\u56f4\u53d8\u4e3a [-1, 1]\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u56fa\u5b9a scale=1/128.0 \u8fdb\u884c\u91cf\u5316\u3002"}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsx)(e.p,{children:"Debug \u6210\u672c\uff1a\u4e0a\u8ff0\u5efa\u8bae\u4e2d\uff0c\u524d 2 \u70b9\u5747\u9700\u8981\u91cd\u8bad\u6d6e\u70b9\uff0c\u540e 2 \u70b9\u5219\u9700\u8981\u91cd\u8bad QAT\u3002"})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6a21\u578b\u8f93\u51fa"}),"\n",(0,o.jsx)(e.p,{children:"\u6a21\u578b\u8f93\u51fa\u5f88\u591a\u65f6\u5019\u6709\u7269\u7406\u542b\u4e49\uff0c\u53ef\u80fd\u8981\u6c42\u6bd4\u8f83\u9ad8\u7684\u5206\u8fa8\u7387\uff0c\u4e0d\u9002\u5408 int8 \u91cf\u5316\uff0c\u5efa\u8bae\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u8f93\u51fa\u4e0d\u91cf\u5316\u3002\u76ee\u524d conv2d \u4f5c\u4e3a\u7f51\u7edc\u8f93\u51fa\u65f6\uff0c\u652f\u6301\u8f93\u51fa\u4e0d\u91cf\u5316\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u5982\u679c BPU \u6027\u80fd\u7b49\u539f\u56e0\u9700\u8981\u91cf\u5316\u8f93\u51fa\uff0c\u5efa\u8bae\u4f7f\u7528 int16 \u91cf\u5316\uff0c\u6216\u8005\u901a\u8fc7\u8c03\u6574\u8f93\u51fa\u7269\u7406\u542b\u4e49\u7684\u65b9\u5f0f\u964d\u4f4e\u8f93\u51fa\u6570\u636e\u5206\u8fa8\u7387\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]})}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsx)(e.p,{children:"Debug \u6210\u672c\uff1a\u4e0a\u8ff0\u5efa\u8bae\u4e2d\uff0c\u5982\u679c\u6309\u7167\u7b2c 2 \u70b9\u8c03\u6574\u8f93\u51fa\u7269\u7406\u542b\u4e49\uff0c\u9700\u8981\u91cd\u8bad\u6d6e\u70b9\uff1b\u5176\u4ed6\u5219\u9700\u8981\u91cd\u8bad QAT\u3002"})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u6a21\u578b\u4e2d\u95f4\u5c42"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u8f93\u51fa\uff08featuremap\uff09"}),"\n",(0,o.jsx)(e.p,{children:"\u4ece\u5b9e\u73b0\u89d2\u5ea6\u770b\u7b97\u5b50\u6709\u4e24\u79cd\uff1a1. \u5355\u7c92\u5ea6\u7b97\u5b50\uff0c\u5982 conv2d\uff1b2. \u901a\u8fc7\u591a\u4e2a\u5c0f\u7b97\u5b50\u5b9e\u73b0\u7684\u590d\u6742\u7b97\u5b50\uff0c\u5982 layernorm\uff1b\u8fd9\u91cc\u4e3b\u8981\u5173\u6ce8\u7b97\u5b50\u6574\u4f53\u7684\u8f93\u51fa\uff0c\u5ffd\u7565\u590d\u6742\u7b97\u5b50\u5185\u90e8\u7684\u5c0f\u7b97\u5b50\u8f93\u51fa\u3002"}),"\n",(0,o.jsx)(e.p,{children:"\u5982\u679c\u7b97\u5b50\u8f93\u51fa\u7684\u6570\u503c\u8303\u56f4\u8f83\u5927\uff0c\u5efa\u8bae\u5982\u4e0b\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u901a\u8fc7\u4fee\u6539\u6a21\u578b\u7ed3\u6784\u5c06\u6570\u503c\u9650\u5236\u5728\u67d0\u4e2a\u8303\u56f4\uff0c\u53ef\u4ee5\u6839\u636e\u4e0d\u540c\u7b97\u5b50\u91c7\u7528\u4e0d\u540c\u7684\u65b9\u6848\uff0c\u6bd4\u5982 conv2d \u540e\u9762\u52a0 BN\u3001\u66ff\u6362 relu \u4e3a relu6 \u7b49\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528 int16 \u91cf\u5316\uff1b"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]})}),"\n",(0,o.jsxs)(e.ol,{start:"3",children:["\n",(0,o.jsx)(e.li,{children:"\u5982\u679c\u9047\u5230 conv-[bn]-[add]-relu \u8fd9\u6837\u7684 pattern\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u5728 QAT \u9636\u6bb5\u6307\u5b9a\u4f7f\u7528 relu6\uff08\u4e0d\u4e00\u5b9a\u6709\u6548\uff09\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsx)(e.p,{children:"Debug \u6210\u672c\uff1a\u4e0a\u8ff0\u5efa\u8bae\u4e2d\uff0c\u6309\u7167\u7b2c 1 \u70b9\u8c03\u6574\u540e\u9700\u8981\u91cd\u8bad\u6d6e\u70b9\uff1b\u5176\u4ed6\u5219\u9700\u8981\u91cd\u8bad QAT\u3002"})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"weight"}),"\n",(0,o.jsx)(e.p,{children:"\u5982\u679c\u5b58\u5728\u67d0\u5c42\u7684 weight \u7684\u6570\u503c\u8303\u56f4\u8f83\u5927\uff0c\u53ef\u4ee5\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"\u5c1d\u8bd5\u8c03\u6574 weight-decay\uff1b\u5efa\u8bae\u5728 4e-5 \u9644\u8fd1\u505a\u9002\u5f53\u8c03\u6574\uff0c\u4e0d\u8981\u8fc7\u5927\u6216\u8fc7\u5c0f\u3002weight decay \u8fc7\u5c0f\u5bfc\u81f4 weight \u65b9\u5dee\u8fc7\u5927\uff1b\u8fc7\u5927\u5219\u53ef\u80fd\u5bfc\u81f4\u8fde\u9501\u53cd\u5e94\uff0c\u6bd4\u5982\u7f51\u7edc\u5c42\u8f93\u51fa\u7684 weight \u65b9\u5dee\u8fc7\u5927\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsx)(e.p,{children:"Debug \u6210\u672c\uff1a\u8c03\u6574\u540e\u9700\u8981\u91cd\u8bad\u6d6e\u70b9\u3002"})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u7b97\u5b50"}),"\n",(0,o.jsx)(e.p,{children:"\u5982\u679c\u67d0\u5c42\u91cf\u5316\u4e4b\u540e\u76f8\u6bd4\u4e0d\u91cf\u5316\u7684\u8bef\u5dee\u660e\u663e\u8f83\u5927\uff0c\u5219\u8bf4\u660e\u6b64\u7b97\u5b50\u7684\u91cf\u5316\u5b9e\u73b0\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027\u3002\u4e00\u822c\u91cf\u5316\u8bef\u5dee\u8f83\u5927\u7684\u7b97\u5b50\u6709\u4ee5\u4e0b\u51e0\u79cd\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u591a\u8f93\u5165\u7b97\u5b50\uff0c\u5982 cat\uff0c\u5982\u679c\u5b58\u5728\u4e0d\u540c\u7684\u8f93\u5165\u6570\u503c\u8303\u56f4\u5dee\u5f02\u8fc7\u5927\u65f6\uff0c\u53ef\u80fd\u51fa\u73b0\u5927\u6570\u5403\u5c0f\u6570\u7684\u73b0\u8c61\uff0c\u6700\u7ec8\u5bfc\u81f4\u7cbe\u5ea6\u5f02\u5e38\u3002\u5c1d\u8bd5\u4ee5\u4e0b\u65b9\u5f0f\u6539\u8fdb\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u9700\u8981\u901a\u8fc7\u5404\u79cd\u624b\u6bb5\u9650\u5236\u8f93\u5165\u8303\u56f4\uff0c\u8ba9\u591a\u8f93\u5165\u7684\u6570\u503c\u8303\u56f4\u76f8\u8fd1\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528 int16 \u91cf\u5316\uff1b"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]})}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u975e\u7ebf\u6027\u6fc0\u6d3b\u7b97\u5b50\uff0c\u5982\u679c\u7b97\u5b50\u672c\u8eab\u5728\u67d0\u4e9b\u533a\u95f4\u503c\u57df\u6ce2\u52a8\u8f83\u5927\uff0c\u6bd4\u5982 reciprocal\uff1b\u8fd9\u7c7b\u7b97\u5b50\u4e00\u822c\u5185\u90e8\u91c7\u7528\u67e5\u8868\u5b9e\u73b0\uff0c\u7531\u4e8e\u67e5\u8868\u9879\u6709\u9650\uff0c\u5f53\u8f93\u51fa\u5904\u4e8e\u9661\u5ced\u7684\u533a\u95f4\u65f6\uff0c\u53ef\u80fd\u5bfc\u81f4\u5206\u8fa8\u7387\u4e0d\u8db3\u3002\u5c1d\u8bd5\u4ee5\u4e0b\u65b9\u5f0f\u6539\u8fdb\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u8bc4\u4f30\u4e0b\u662f\u5426\u53ef\u4ee5\u4e0d\u4f7f\u7528\u6b64\u7b97\u5b50\u6216\u66ff\u6362\u6210\u5176\u4ed6\u7b97\u5b50\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u9650\u5236\u8f93\u5165\u8303\u56f4\u5728\u8f83\u4e3a\u5e73\u7f13\u7684\u533a\u95f4\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u4f7f\u7528 int16 \u91cf\u5316\uff1b"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]})}),"\n",(0,o.jsxs)(e.ol,{start:"4",children:["\n",(0,o.jsx)(e.li,{children:"\u5982\u679c QAT \u7cbe\u5ea6\u6b63\u5e38\u4f46 quantized \u7cbe\u5ea6\u4e0d\u8db3\uff0c\u53ef\u5c1d\u8bd5\u624b\u52a8\u8c03\u6574\u67e5\u8868\u53c2\u6570\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u590d\u6742\u7b97\u5b50\uff0c\u6bd4\u5982 layernorm \u548c softmax\uff0c\u4e00\u822c\u662f\u7531\u591a\u4e2a\u5c0f\u7b97\u5b50\u62fc\u63a5\u800c\u6210\uff0c\u5176\u4e2d\u53ef\u80fd\u5b58\u5728\u4e0a\u9762\u63d0\u5230\u7684\u975e\u7ebf\u6027\u6fc0\u6d3b\u7b97\u5b50\uff0c\u4e5f\u4f1a\u5bfc\u81f4\u7cbe\u5ea6\u95ee\u9898\u3002\u5c1d\u8bd5\u4ee5\u4e0b\u65b9\u5f0f\u6539\u8fdb\uff1a"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u8bc4\u4f30\u4e0b\u662f\u5426\u53ef\u4ee5\u4e0d\u4f7f\u7528\u6b64\u7b97\u5b50\u6216\u66ff\u6362\u6210\u5176\u4ed6\u7b97\u5b50\uff1b"}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u5982\u679c QAT \u7cbe\u5ea6\u6b63\u5e38\u4f46 quantized \u7cbe\u5ea6\u4e0d\u8db3\uff0c\u53ef\u5c1d\u8bd5\u624b\u52a8\u8c03\u6574\u67e5\u8868\u53c2\u6570\uff0c\u5982 layernorm \u548c softmax \u5747\u652f\u6301\u624b\u8c03\u7684\u53c2\u6570\uff1b"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:[(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]}),(0,o.jsx)(e.p,{children:"Debug \u6210\u672c\uff1a\u8fd9\u4e09\u79cd\u60c5\u51b5\u4e2d\u5982\u679c\u9700\u8981\u8c03\u6574\u8f93\u5165\u8303\u56f4\u6216\u7b97\u5b50\uff0c\u5219\u9700\u8981\u91cd\u8bad\u6d6e\u70b9\uff1b\u5982\u679c\u9700\u8981\u91c7\u7528 int16 \u91cf\u5316\uff0c\u9700\u8981\u91cd\u8bad QAT\uff1b\u5982\u679c\u53ea\u662f\u624b\u52a8\u8c03\u6574\u67e5\u8868\u53c2\u6570\uff0c\u4ec5\u9700\u8981\u91cd\u65b0\u8f6c\u6362 QAT \u6a21\u578b\u5230 quantized \u6a21\u578b\u3002"})]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u7f51\u7edc\u7ed3\u6784"}),"\n",(0,o.jsx)(e.p,{children:"\u7f51\u7edc\u7ed3\u6784\u5b9e\u73b0\u65f6\u5982\u679c\u5b58\u5728\u591a\u5206\u652f\u4e2d\u7b97\u5b50\u5171\u4eab\uff0c\u4f1a\u5bfc\u81f4\u4e00\u4e2a\u91cf\u5316\u53c2\u6570\u540c\u65f6\u91cf\u5316\u591a\u4e2a\u5206\u652f\u8f93\u51fa\uff0c\u8fdb\u800c\u53ef\u80fd\u4f7f\u8f93\u51fa\u91cf\u5316\u7684\u5206\u8fa8\u7387\u4e0d\u8db3\u3002\u5efa\u8bae\u5c06\u5171\u4eab\u7b97\u5b50\u62c6\u5206\u6210\u591a\u4e2a\u7b97\u5b50\u3002"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:(0,o.jsx)(e.p,{children:"Debug \u6210\u672c\uff1a\u9700\u8981\u91cd\u8bad QAT\u3002"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"\u901a\u8fc7\u5206\u6a21\u5757\u91cf\u5316\u65b9\u5f0f\u627e\u5230\u91cf\u5316\u5f02\u5e38\u5c42"}),"\n",(0,o.jsxs)(e.p,{children:["\u5982\u679c\u901a\u8fc7 Debug \u5de5\u5177\u65e0\u6cd5\u5b9a\u4f4d\u5230\u91cf\u5316\u5f02\u5e38\u5c42\uff0c\u9700\u8981\u4f7f\u7528\u5206\u6a21\u5757\u91cf\u5316\u7684\u65b9\u5f0f\u6765\u5206\u6790\u5177\u4f53\u54ea\u4e00\u6a21\u5757\u91cf\u5316\u5bfc\u81f4\u7684\u91cf\u5316\u7cbe\u5ea6\u8bef\u5dee\u3002\u5b9a\u4f4d\u5230\u76f8\u5173\u7684\u6a21\u5757\u6216\u7b97\u5b50\u4e4b\u540e\uff0c\u8bf4\u660e\u6b64\u6a21\u5757\u91cf\u5316\u4e4b\u540e\u7684\u6570\u503c\u5206\u8fa8\u7387\u4e0d\u8db3\uff0c\u5efa\u8bae\u5c1d\u8bd5\u4f7f\u7528 int16 \u91cf\u5316\u3002\u5177\u4f53\u5982\u4f55\u505a\u5206\u6a21\u5757\u91cf\u5316\u8bf7\u53c2\u8003",(0,o.jsx)(e.a,{href:"#a-name-step-quantization-a",children:(0,o.jsx)(e.strong,{children:"\u5206\u6b65\u91cf\u5316\u5de5\u5177"})}),"\uff08Calibration \u6216 QAT \u6a21\u578b\u7cbe\u5ea6\u5f02\u5e38\u65f6\u4f7f\u7528\uff09\u548c",(0,o.jsx)(e.a,{href:"#a-name-single-op-error-a",children:(0,o.jsx)(e.strong,{children:"\u5355\u7b97\u5b50\u7cbe\u5ea6\u8c03\u8bd5\u5de5\u5177"})}),"\uff08\u5b9a\u70b9\u6a21\u578b\u7cbe\u5ea6\u5f02\u5e38\u65f6\u4f7f\u7528\uff09\u3002"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.admonition,{title:"\u6ce8\u610f",type:"caution",children:[(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]}),(0,o.jsx)(e.p,{children:"Debug \u6210\u672c\uff1a\u4f7f\u7528 int16 \u91cf\u5316\u540e\u9700\u8981\u91cd\u8bad QAT\u3002"})]}),"\n",(0,o.jsxs)(e.admonition,{title:"\u5907\u6ce8",type:"info",children:[(0,o.jsxs)(e.p,{children:["\u76ee\u524d\u53ea\u6709BPU\u67b6\u6784\u4e3a ",(0,o.jsx)(e.code,{children:"BAYES"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK Ultra"}),"   \u548c ",(0,o.jsx)(e.code,{children:"BAYES_E"})," \u7684 ",(0,o.jsx)(e.strong,{children:"RDK X5"})," \u652f\u6301\u8bbe\u7f6e ",(0,o.jsx)(e.code,{children:"int16"})," \u91cf\u5316\u3002"]}),(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"\u91c7\u7528 int16 \u4f1a\u5e26\u6765\u90e8\u7f72\u6027\u80fd\u7684\u964d\u4f4e\uff0c\u8bf7\u6839\u636e\u5177\u4f53\u60c5\u51b5\u9009\u62e9\u4f7f\u7528\uff1b"}),"\n",(0,o.jsx)(e.li,{children:"\u90e8\u5206\u7b97\u5b50\u4e0d\u652f\u6301 int16 \u91cf\u5316\uff0c\u8be6\u89c1\u7b97\u5b50\u652f\u6301\u5217\u8868\uff1b"}),"\n",(0,o.jsx)(e.li,{children:"\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u5347\u7cbe\u5ea6\uff0c\u7528\u6237\u53ef\u4e00\u9009\u62e9\u5f02\u6784\u6a21\u5f0f\u90e8\u7f72\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u79cd\u65b9\u5f0f\u5bf9\u6027\u80fd\u5f71\u54cd\u8f83\u5927\u3002"}),"\n"]})]}),"\n",(0,o.jsx)(e.h2,{id:"\u91cf\u5316\u90e8\u7f72-pt-\u6a21\u578b\u7684\u8de8\u8bbe\u5907-inference-\u8bf4\u660e",children:"\u91cf\u5316\u90e8\u7f72 PT \u6a21\u578b\u7684\u8de8\u8bbe\u5907 Inference \u8bf4\u660e"}),"\n",(0,o.jsx)(e.p,{children:"\u91cf\u5316\u90e8\u7f72\u7684 pt \u6a21\u578b\u8981\u6c42 trace \u65f6\u4f7f\u7528\u7684 device \u548c\u540e\u7eed infer \u65f6\u4f7f\u7528\u7684 device \u4e00\u81f4\u3002"}),"\n",(0,o.jsxs)(e.p,{children:["\u82e5\u7528\u6237\u8bd5\u56fe\u76f4\u63a5\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"to(device)"})," \u64cd\u4f5c\u4fee\u6539 pt \u6a21\u578b\u7684 device\uff0c\u53ef\u80fd\u4f1a\u51fa\u73b0\u6a21\u578b forward \u62a5\u9519\u7684\u95ee\u9898\uff0ctorch \u5b98\u65b9\u5bf9\u6b64\u8fdb\u884c\u4e86\u89e3\u91ca\uff0c\u89c1 ",(0,o.jsx)(e.a,{href:"https://pytorch.org/docs/stable/jit.html#frequently-asked-questions",children:(0,o.jsx)(e.strong,{children:"TorchScript-Frequently Asked Questions \u2014 PyTorch documentation"})}),"\u3002"]}),"\n",(0,o.jsx)(e.p,{children:"\u4e0b\u9762\u4e3e\u4f8b\u8bf4\u660e\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import torch\n\n\nclass Net(torch.nn.Module):\n    def forward(self, x: torch.Tensor):\n        y = torch.ones(x.shape, device=x.device)\n        z = torch.zeros_like(x)\n\n        return y + z\n\n\nscript_mod = torch.jit.trace(\n    Net(), torch.rand(2, 3, 3, 3, device=torch.device("cpu"))\n)\nscript_mod.to(torch.device("cuda"))\nprint(script_mod.graph)\n\n# graph(%self : __torch__.Net,\n#       %x : Float(2, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu)):\n#   %4 : int = prim::Constant[value=0]()\n#   %5 : int = aten::size(%x, %4)\n#   %6 : Long(device=cpu) = prim::NumToTensor(%5)\n#   %16 : int = aten::Int(%6)\n#   %7 : int = prim::Constant[value=1]()\n#   %8 : int = aten::size(%x, %7)\n#   %9 : Long(device=cpu) = prim::NumToTensor(%8)\n#   %17 : int = aten::Int(%9)\n#   %10 : int = prim::Constant[value=2]()\n#   %11 : int = aten::size(%x, %10)\n#   %12 : Long(device=cpu) = prim::NumToTensor(%11)\n#   %18 : int = aten::Int(%12)\n#   %13 : int = prim::Constant[value=3]()\n#   %14 : int = aten::size(%x, %13)\n#   %15 : Long(device=cpu) = prim::NumToTensor(%14)\n#   %19 : int = aten::Int(%15)\n#   %20 : int[] = prim::ListConstruct(%16, %17, %18, %19)\n#   %21 : NoneType = prim::Constant()\n#   %22 : NoneType = prim::Constant()\n#   %23 : Device = prim::Constant[value="cpu"]()\n#   %24 : bool = prim::Constant[value=0]()\n#   %y : Float(2, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu) = aten::ones(%20, %21, %22, %23, %24)\n#   %26 : int = prim::Constant[value=6]()\n#   %27 : int = prim::Constant[value=0]()\n#   %28 : Device = prim::Constant[value="cpu"]()\n#   %29 : bool = prim::Constant[value=0]()\n#   %30 : NoneType = prim::Constant()\n#   %z : Float(2, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu) = aten::zeros_like(%x, %26, %27, %28, %29, %30)\n#   %32 : int = prim::Constant[value=1]()\n#   %33 : Float(2, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu) = aten::add(%y, %z, %32)\n#   return (%33)\n'})}),"\n",(0,o.jsxs)(e.p,{children:["\u53ef\u4ee5\u770b\u5230\uff0c\u5728\u8c03\u7528 ",(0,o.jsx)(e.code,{children:'to(torch.device("cuda"))'})," \u540e\uff0c\u6a21\u578b\u7684 graph \u4e2d\u8bb0\u5f55\u7684 ",(0,o.jsx)(e.code,{children:"aten::ones"})," \u548c ",(0,o.jsx)(e.code,{children:"aten::zeros_like"})," \u7684 device \u53c2\u6570\u4ecd\u4e3a ",(0,o.jsx)(e.code,{children:'prim::Constant[value="cpu"]()'}),"\uff0c\u56e0\u6b64\u5728\u6a21\u578b forward \u65f6\uff0c\u5b83\u4eec\u7684\u8f93\u51fa\u4ecd\u4e3a cpu Tensor\u3002\u8fd9\u662f\u56e0\u4e3a ",(0,o.jsx)(e.code,{children:"to(device)"})," \u53ea\u80fd\u79fb\u52a8\u6a21\u578b\u4e2d\u7684 buffer\uff08weight\u3001bias \u7b49\uff09\uff0c\u65e0\u6cd5\u4fee\u6539 ",(0,o.jsx)(e.code,{children:"ScriptModule"})," \u7684 graph\u3002"]}),"\n",(0,o.jsx)(e.p,{children:"torch \u5b98\u65b9\u5bf9\u4ee5\u4e0a\u9650\u5236\u7ed9\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u662f\uff0c\u5728 trace \u524d\u5c31\u786e\u5b9a\u597d pt \u6a21\u578b\u5c06\u8981\u5728\u54ea\u4e2a device \u4e0a\u6267\u884c\uff0c\u5e76\u5728\u5bf9\u5e94\u7684 device \u4e0a trace \u5373\u53ef\u3002"}),"\n",(0,o.jsx)(e.p,{children:"\u9488\u5bf9\u4ee5\u4e0a\u9650\u5236\uff0c\u8bad\u7ec3\u5de5\u5177\u5efa\u8bae\u6839\u636e\u5177\u4f53\u573a\u666f\u9009\u62e9\u4ee5\u4e0b\u89e3\u51b3\u65b9\u6848\uff1a"}),"\n",(0,o.jsx)(e.h3,{id:"pt-\u6a21\u578b\u6267\u884c\u4f7f\u7528\u7684-device-\u548c-trace-\u4e0d\u4e00\u81f4",children:"PT \u6a21\u578b\u6267\u884c\u4f7f\u7528\u7684 device \u548c trace \u4e0d\u4e00\u81f4"}),"\n",(0,o.jsxs)(e.p,{children:["\u5bf9\u4e8e\u53ef\u4ee5\u786e\u5b9a pt \u6a21\u578b\u5c06\u4ec5\u5728 GPU \u4e0a\u6267\u884c\uff0c\u53ea\u9700\u8981\u4fee\u6539\u5361\u53f7\u7684\u60c5\u51b5\uff0c\u6211\u4eec\u9996\u5148\u63a8\u8350\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"cuda:0"}),"\uff0c\u5373\u96f6\u53f7\u5361\u8fdb\u884c trace\u3002\u5728\u4f7f\u7528\u6a21\u578b\u65f6\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"torch.cuda.set_device"})," \u63a5\u53e3\uff0c\u5c06\u7269\u7406\u4e0a\u7684\u4efb\u610f\u5361\u6620\u5c04\u4e3a\u903b\u8f91\u4e0a\u7684\u201c\u96f6\u5361\u201d\uff0c\u6b64\u65f6\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"cuda:0"})," trace \u51fa\u7684\u6a21\u578b\u5b9e\u9645\u5c06\u5728\u6307\u5b9a\u7684\u7269\u7406\u5361\u4e0a\u8fd0\u884c\u3002"]}),"\n",(0,o.jsxs)(e.p,{children:["\u82e5 trace \u65f6\u4f7f\u7528\u7684 device \u548c\u6267\u884c\u65f6\u4f7f\u7528\u7684 device \u5b58\u5728 CPU\u3001GPU \u7684\u4e0d\u4e00\u81f4\uff0c\u7528\u6237\u53ef\u4ee5\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"horizon_plugin_pytorch.jit.to_device"})," \u63a5\u53e3\u5b9e\u73b0 pt \u6a21\u578b\u7684 device \u8fc1\u79fb\u3002\u6b64\u63a5\u53e3\u4f1a\u5bfb\u627e\u6a21\u578b graph \u4e2d\u7684 device \u53c2\u6570\uff0c\u5e76\u5c06\u5b83\u4eec\u66ff\u6362\u4e3a\u9700\u8981\u7684\u503c\u3002\u6548\u679c\u5982\u4e0b\uff1a"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from horizon_plugin_pytorch.jit import to_device\n\nscript_mod = to_device(script_mod, torch.device("cuda"))\nprint(script_mod.graph)\n\n# graph(%self : __torch__.Net,\n#       %x.1 : Tensor):\n#   %38 : bool = prim::Constant[value=0]()\n#   %60 : Device = prim::Constant[value="cuda"]()\n#   %34 : NoneType = prim::Constant()\n#   %3 : int = prim::Constant[value=0]()\n#   %10 : int = prim::Constant[value=1]()\n#   %17 : int = prim::Constant[value=2]()\n#   %24 : int = prim::Constant[value=3]()\n#   %41 : int = prim::Constant[value=6]()\n#   %4 : int = aten::size(%x.1, %3)\n#   %5 : Tensor = prim::NumToTensor(%4)\n#   %8 : int = aten::Int(%5)\n#   %11 : int = aten::size(%x.1, %10)\n#   %12 : Tensor = prim::NumToTensor(%11)\n#   %15 : int = aten::Int(%12)\n#   %18 : int = aten::size(%x.1, %17)\n#   %19 : Tensor = prim::NumToTensor(%18)\n#   %22 : int = aten::Int(%19)\n#   %25 : int = aten::size(%x.1, %24)\n#   %26 : Tensor = prim::NumToTensor(%25)\n#   %32 : int = aten::Int(%26)\n#   %33 : int[] = prim::ListConstruct(%8, %15, %22, %32)\n#   %y.1 : Tensor = aten::ones(%33, %34, %34, %60, %38)\n#   %z.1 : Tensor = aten::zeros_like(%x.1, %41, %3, %60, %38, %34)\n#   %50 : Tensor = aten::add(%y.1, %z.1, %10)\n#   return (%50)\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u591a\u5361\u5e76\u884c\u63a8\u7406",children:"\u591a\u5361\u5e76\u884c\u63a8\u7406"}),"\n",(0,o.jsxs)(e.p,{children:["\u5728\u6b64\u573a\u666f\u4e0b\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7 trace \u6216 ",(0,o.jsx)(e.code,{children:"to_device"})," \u7684\u65b9\u5f0f\u53d6\u5f97 ",(0,o.jsx)(e.code,{children:"cuda:0"})," \u4e0a\u7684 pt \u6a21\u578b\uff0c\u5e76\u4e14\u4e3a\u6bcf\u5757\u5361\u5355\u72ec\u5f00\u542f\u4e00\u4e2a\u8fdb\u7a0b\uff0c\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"torch.cuda.set_device"})," \u7684\u65b9\u5f0f\u4e3a\u6bcf\u4e2a\u8fdb\u7a0b\u8bbe\u7f6e\u4e0d\u540c\u7684\u9ed8\u8ba4\u5361\u3002\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b\u5982\u4e0b\uff1a"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import os\nimport torch\nimport signal\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom horizon_plugin_pytorch.jit import to_device\n\nmodel_path = "path_to_pt_model_file"\n\ndef main_func(rank, world_size, device_ids):\n    torch.cuda.set_device(device_ids[rank])\n    dist.init_process_group("nccl", rank=rank, world_size=world_size)\n\n    model = to_device(torch.jit.load(model_path), torch.device("cuda"))\n\n    # \u6570\u636e\u52a0\u8f7d\uff0c\u6a21\u578b forward\uff0c\u7cbe\u5ea6\u8ba1\u7b97\u7b49\u5185\u5bb9\u6b64\u5904\u7701\u7565\n\ndef launch(device_ids):\n    try:\n        world_size = len(device_ids)\n        mp.spawn(\n            main_func,\n            args=(world_size, device_ids),\n            nprocs=world_size,\n            join=True,\n        )\n    # \u5f53\u6309\u4e0b Ctrl+c \u65f6\uff0c\u5173\u95ed\u6240\u6709\u5b50\u8fdb\u7a0b\n    except KeyboardInterrupt:\n        os.killpg(os.getpgid(os.getpid()), signal.SIGKILL)\n\nlaunch([0, 1, 2, 3])\n'})}),"\n",(0,o.jsxs)(e.p,{children:["\u4e0a\u8ff0\u64cd\u4f5c\u5bf9 pt \u6a21\u578b\u7684\u5904\u7406\u548c ",(0,o.jsx)(e.code,{children:"torch.nn.parallel.DistributedDataParallel"})," \u7684\u505a\u6cd5\u4e00\u81f4\uff0c\u6570\u636e\u52a0\u8f7d\u548c\u6a21\u578b\u7cbe\u5ea6\u8ba1\u7b97\u76f8\u5173\u5185\u5bb9\u8bf7\u53c2\u8003 ",(0,o.jsx)(e.a,{href:"https://pytorch.org/tutorials/intermediate/ddp_tutorial.html",children:(0,o.jsx)(e.strong,{children:"Getting Started with Distributed Data Parallel \u2014 PyTorch Tutorials"})}),"\u3002"]}),"\n",(0,o.jsx)(e.h2,{id:"\u5e38\u89c1\u95ee\u9898",children:"\u5e38\u89c1\u95ee\u9898"}),"\n",(0,o.jsx)(e.h3,{id:"import-\u51fa\u9519",children:"import \u51fa\u9519"}),"\n",(0,o.jsxs)(e.p,{children:["\u9519\u8bef\u4e00\uff1a",(0,o.jsx)(e.code,{children:"Cannot find the extension library(_C.so)"})]}),"\n",(0,o.jsx)(e.p,{children:"\u89e3\u51b3\u65b9\u6cd5\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"\u786e\u5b9a horizon_plugin_pytorch \u7248\u672c\u548c cuda \u7248\u672c\u662f\u5bf9\u5e94\u7684"}),"\n",(0,o.jsx)(e.li,{children:"\u5728 python3 \u4e2d\uff0c\u627e\u5230 horizon_plugin_pytorch \u7684\u6267\u884c\u8def\u5f84\uff0c\u68c0\u6d4b\u8be5\u76ee\u5f55\u4e0b\u662f\u5426\u6709 .so \u6587\u4ef6\u3002\u53ef\u80fd\u540c\u65f6\u5b58\u5728\u591a\u4e2a horizon_plugin_pytorch \u7684\u7248\u672c\uff0c\u9700\u8981\u5378\u8f7d\u53ea\u4fdd\u7559\u4e00\u4e2a\u9700\u8981\u7684\u7248\u672c\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsxs)(e.p,{children:["\u9519\u8bef\u4e8c\uff1a",(0,o.jsx)(e.code,{children:"RuntimeError: Cannot load custom ops. Please rebuild the horizon_plugin_pytorch"})]}),"\n",(0,o.jsx)(e.p,{children:"\u89e3\u51b3\u65b9\u6cd5\uff1a\u786e\u8ba4\u672c\u5730 CUDA \u73af\u5883\u662f\u5426\u6b63\u5e38\uff0c\u5982\u8def\u5f84\u3001\u7248\u672c\u7b49"}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h3,{id:"\u65e0\u6cd5\u6b63\u5e38-prepare_calibrationqat",children:"\u65e0\u6cd5\u6b63\u5e38 prepare_calibration/qat"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.code,{children:"RuntimeError: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"})}),"\n",(0,o.jsx)(e.p,{children:"\u89e3\u51b3\u65b9\u6cd5\uff1a\u4e00\u822c\u662f\u6a21\u578b\u4e2d\u5305\u542b non-leaf tensor \u624d\u4f1a\u51fa\u73b0\u8fd9\u6837\u7684\u9519\u8bef\uff0c\u5c1d\u8bd5\u4ee5\u4e0b\u65b9\u6cd5\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"\u5c06 prepare_calibration/qat \u7684 inplace \u8bbe\u4e3a True"}),"\n",(0,o.jsx)(e.li,{children:"\u6b63\u5e38 horizon_plugin_pytorch \u5b9a\u4e49\u7684\u7b97\u5b50\u4e0d\u4f1a\u51fa\u73b0\u8fd9\u79cd\u9519\u8bef\uff0c\u68c0\u67e5\u6a21\u578b\u4e2d\u81ea\u5b9a\u4e49\u7684\u7b97\u5b50\u662f\u5426\u6709 non-leaf tensor \u7684\u5b9a\u4e49\u3002"}),"\n"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h3,{id:"prepare_qat-\u540e-forward-\u62a5\u9519",children:"prepare_qat \u540e forward \u62a5\u9519"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.code,{children:"TypeError: when calling function <built-in method conv2d of type object at >"})}),"\n",(0,o.jsx)(e.p,{children:"\u89e3\u51b3\u65b9\u6cd5\uff1a\u81ea\u5b9a\u4e49\u7b97\u5b50\u7ee7\u627f\u4e86\u67d0\u4e2a torch \u7684 Module \u7b97\u5b50\uff0c\u5bfc\u81f4 prepare_qat \u6ca1\u6709\u88ab\u6210\u529f\u8f6c\u6210 qat module\u3002\u5efa\u8bae\u4f7f\u7528 submodule \u7684\u65b9\u5f0f\u8c03\u7528 conv2d\u3002"}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h3,{id:"\u7f16\u8bd1\u62a5\u9519",children:"\u7f16\u8bd1\u62a5\u9519"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.code,{children:"ValueError 'unsupported node', aten::unbind"})}),"\n",(0,o.jsxs)(e.p,{children:["\u89e3\u51b3\u65b9\u6cd5\uff1a\u5c06 tensor \u5f53\u4f5c list \u4f20\u5165 zip \u5904\u7406\uff0c\u6700\u7ec8\u8c03\u7528\u4e86 tensor \u539f\u751f\u7684 ",(0,o.jsx)(e.code,{children:"iter"}),"\uff0c\u8be5\u65b9\u6cd5\u5185\u90e8\u4f7f\u7528\u4e86 unbind \u64cd\u4f5c\u5bfc\u81f4\u4ee5\u4e0a\u9519\u8bef\u3002\u8bf7\u68c0\u67e5\u60a8\u7684\u4ee3\u7801\u3002"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h3,{id:"\u91cf\u5316\u7cbe\u5ea6\u5f02\u5e38",children:"\u91cf\u5316\u7cbe\u5ea6\u5f02\u5e38"}),"\n",(0,o.jsx)(e.p,{children:"QAT/Quantized \u7cbe\u5ea6\u4e0d\u7b26\u5408\u9884\u671f\u3001\u51fa\u73b0 NAN \u6216 QAT \u521d\u59cb loss \u76f8\u5bf9 float \u660e\u663e\u5f02\u5e38"}),"\n",(0,o.jsxs)(e.p,{children:["\u89e3\u51b3\u65b9\u6cd5\uff1a\u8bf7\u53c2\u8003 ",(0,o.jsx)(e.a,{href:"#debug_precision",children:(0,o.jsx)(e.strong,{children:"\u91cf\u5316\u8bad\u7ec3\u7cbe\u5ea6\u8c03\u4f18\u6307\u5357"})})]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h3,{id:"\u4f7f\u7528-torchjitload-\u52a0\u8f7d-pt-\u6587\u4ef6\u62a5\u9519",children:"\u4f7f\u7528 torch.jit.load \u52a0\u8f7d pt \u6587\u4ef6\u62a5\u9519"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.code,{children:"RuntimeError: Unknown builtin op: horizon::bpu_scale_quantization"})}),"\n",(0,o.jsxs)(e.p,{children:["\u89e3\u51b3\u65b9\u6cd5\uff1a\u8bf7\u68c0\u67e5\u5728\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"torch.jit.load"})," \u524d\u662f\u5426\u6709 ",(0,o.jsx)(e.code,{children:"import horizon_plugin_pytorch"}),"\u3002\u5426\u5219\uff0c\u52a0\u8f7d\u65f6\u627e\u4e0d\u5230\u5bf9\u5e94\u7684 horizon \u7b97\u5b50\u3002\u63a8\u8350\u4f7f\u7528 ",(0,o.jsx)(e.a,{href:"/rdk_doc/Advanced_development/toolchain_development/expert/api_reference",children:(0,o.jsx)(e.strong,{children:"horizon.jit.save/load"})})," \u4fdd\u5b58\u548c\u52a0\u8f7d pt \u6587\u4ef6\uff0c\u907f\u514d\u8fd9\u6837\u7684\u9519\u8bef\u3002\u6b64\u5916\uff0c",(0,o.jsx)(e.code,{children:"horizon.jit.save"})," \u5728\u4fdd\u5b58 pt \u65f6\u8fd8\u4f1a\u989d\u5916\u4fdd\u5b58 horizon_plugin_pytorch \u7684\u7248\u672c\u53f7\uff0c",(0,o.jsx)(e.code,{children:"horizon.jit.load"})," \u4f1a\u68c0\u67e5\u5f53\u524d horizon_plugin_pytorch \u7684\u7248\u672c\u662f\u5426\u548c\u4fdd\u5b58 pt \u65f6\u7684\u517c\u5bb9\uff0c\u82e5\u4e0d\u517c\u5bb9\uff0c\u4f1a\u8f93\u51fa\u76f8\u5e94\u7684\u8b66\u544a\u3002"]}),"\n",(0,o.jsx)(e.h2,{id:"\u5e38\u89c1\u4f7f\u7528\u8bef\u533a",children:"\u5e38\u89c1\u4f7f\u7528\u8bef\u533a"}),"\n",(0,o.jsx)(e.h3,{id:"\u8bbe\u7f6e\u7c7b\u9519\u8bef",children:"\u8bbe\u7f6e\u7c7b\u9519\u8bef"}),"\n",(0,o.jsx)(e.admonition,{title:"\u9519\u8bef",type:"warning",children:(0,o.jsx)(e.p,{children:"\u65e0\u9700\u91cf\u5316\u7684\u6a21\u5757\u8bbe\u7f6e\u4e86\u975e None \u7684 qconfig\uff0c\u4f8b\u5982 \u524d\u540e\u5904\u7406\uff0closs function \u7b49\u3002"})}),"\n",(0,o.jsx)(e.p,{children:"\u6b63\u786e\u505a\u6cd5\uff1a\u53ea\u9700\u8981\u91cf\u5316\u7684\u6a21\u5757\u8bbe\u7f6e qconfig\u3002"}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.admonition,{title:"\u9519\u8bef",type:"warning",children:(0,o.jsx)(e.p,{children:"\u6ca1\u6709\u6b63\u786e\u8bbe\u7f6e march\uff0c\u8fd9\u6837\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u7f16\u8bd1\u5931\u8d25\u6216\u90e8\u7f72\u7cbe\u5ea6\u4e0d\u4e00\u81f4\u3002"})}),"\n",(0,o.jsx)(e.p,{children:"\u6b63\u786e\u505a\u6cd5\uff1a\u6839\u636e\u8981\u90e8\u7f72\u7684\u5904\u7406\u5668\u9009\u62e9\u6b63\u786e\u7684 BPU \u67b6\u6784\uff0c\u4f8b\u5982\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"\n## RDK Ultra \u9700\u8981\u4f7f\u7528 Bayes\nhorizon.march.set_march(horizon.march.March.Bayes)\n\n## RDK X3 \u9700\u8981\u4f7f\u7528 Bernoulli2\nhorizon.march.set_march(horizon.march.March.Bernoulli2)\n\n## RDK X5 \u9700\u8981\u4f7f\u7528 Bayes-e\nhorizon.march.set_march(horizon.march.March.Bayes-e)\n"})}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.admonition,{title:"\u9519\u8bef",type:"warning",children:(0,o.jsx)(e.p,{children:"\u6a21\u578b\u8f93\u51fa\u8282\u70b9\u6ca1\u6709\u8bbe\u7f6e\u6210\u9ad8\u7cbe\u5ea6\u8f93\u51fa\uff0c\u5bfc\u81f4\u91cf\u5316\u7cbe\u5ea6\u4e0d\u7b26\u5408\u9884\u671f\u3002"})}),"\n",(0,o.jsx)(e.p,{children:"\u9519\u8bef\u793a\u4f8b\u5982\u4e0b\uff1a\n\u5047\u8bbe\u6a21\u578b\u5b9a\u4e49\u5982\u4e0b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class ToyNet(nn.Module):\n    def __init__(self):\n        self.conv0 = nn.Conv2d(4,4,3,3)\n        self.relu0 = nn.ReLU()\n        self.classifier = nn.Conv2d(4,4,3,3)\n\n    def forward(self, x):\n        out = self.conv0(x)\n        out = self.relu(out)\n        out = self.classifier(out)\n        return out\n\n# \u9519\u8bef\u7684\u8bbe\u7f6e qconfig \u793a\u4f8b\uff1a\n\nfloat_model = ToyNet()\n\nqat_model = prepare_qat_fx(\n    float_model,\n    {\n        "": default_qat_8bit_fake_quant_qconfig, # \u6574\u7f51\u8bbe\u7f6e\u6210 int8 \u91cf\u5316\n    },\n)\n'})}),"\n",(0,o.jsx)(e.p,{children:"\u6b63\u786e\u505a\u6cd5\uff1a\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u7cbe\u5ea6\uff0c\u6a21\u578b\u8f93\u51fa\u8282\u70b9\u8bbe\u7f6e\u6210\u9ad8\u7cbe\u5ea6\uff0c\u793a\u4f8b\u5982\u4e0b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'qat_model = prepare_qat_fx(\n    float_model,\n    {\n        "module_name": {\n            "classifier": default_qat_out_8bit_fake_quant_qconfig, # \u7f51\u7edc\u8f93\u51fa classifier \u5c42\u8bbe\u7f6e\u4e3a\u9ad8\u7cbe\u5ea6\n        },\n        "": default_qat_8bit_fake_quant_qconfig, # \u5176\u5b83\u5c42\u8bbe\u7f6e\u6210 int8 \u91cf\u5316\n    },\n)\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u65b9\u6cd5\u7c7b\u9519\u8bef",children:"\u65b9\u6cd5\u7c7b\u9519\u8bef"}),"\n",(0,o.jsx)(e.admonition,{title:"\u9519\u8bef",type:"warning",children:(0,o.jsx)(e.p,{children:"Calibration \u8fc7\u7a0b\u4f7f\u7528\u591a\u5361\u3002"})}),"\n",(0,o.jsx)(e.p,{children:"\u7531\u4e8e\u5e95\u5c42\u9650\u5236\uff0cCalibration \u76ee\u524d\u4e0d\u652f\u6301\u591a\u5361\uff0c\u8bf7\u4f7f\u7528\u5355\u5361\u8fdb\u884c Calibration \u64cd\u4f5c\u3002"}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.admonition,{title:"\u9519\u8bef",type:"warning",children:(0,o.jsx)(e.p,{children:"\u6a21\u578b\u8f93\u5165\u56fe\u50cf\u6570\u636e\u91c7\u7528\u6570\u636e\u683c\u5f0f\u4e3a RGB \u7b49\u975e centered YUV444 \u683c\u5f0f\uff0c\u8fd9\u6837\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u90e8\u7f72\u7cbe\u5ea6\u4e0d\u4e00\u81f4\u3002"})}),"\n",(0,o.jsx)(e.p,{children:"\u6b63\u786e\u505a\u6cd5\uff1a\u7531\u4e8e Horizon \u786c\u4ef6\u652f\u6301\u7684\u56fe\u50cf\u683c\u5f0f\u4e3a centered YUV444\uff0c\u56e0\u6b64\u5efa\u8bae\u7528\u6237\u4ece\u6a21\u578b\u8bad\u7ec3\u5f00\u59cb\u5c31\u76f4\u63a5\u4f7f\u7528 YUV444 \u683c\u5f0f\u4f5c\u4e3a\u7f51\u7edc\u8f93\u5165\u8fdb\u884c\u8bad\u7ec3\u3002"}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.admonition,{title:"\u9519\u8bef",type:"warning",children:(0,o.jsx)(e.p,{children:"\u91cf\u5316\u8bad\u7ec3\u4e2d\u4f7f\u7528 qat \u6a21\u578b\u8fdb\u884c\u6a21\u578b\u7cbe\u6d4b\u8bc4\u6d4b\u548c\u76d1\u63a7\uff0c\u5bfc\u81f4\u4e0d\u80fd\u53ca\u65f6\u53d1\u73b0\u90e8\u7f72\u65f6\u7cbe\u5ea6\u5f02\u5e38\u7684\u95ee\u9898\u3002"})}),"\n",(0,o.jsx)(e.p,{children:"\u6b63\u786e\u505a\u6cd5\uff1a\u5bfc\u81f4 QAT \u4e0e Quantized \u8bef\u5dee\u7684\u539f\u56e0\u662f QAT \u9636\u6bb5\u4e0d\u80fd\u5b8c\u5168\u6a21\u62df Quantized \u4e2d\u7eaf\u5b9a\u70b9\u8ba1\u7b97\u903b\u8f91\uff0c\u5efa\u8bae\u4f7f\u7528 quantized \u6a21\u578b\u8fdb\u884c\u6a21\u578b\u7cbe\u5ea6\u8bc4\u6d4b\u548c\u76d1\u63a7\u3002"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"quantized_model = convert_fx(qat_model.eval())\nacc = evaluate(quantized_model, eval_data_loader, device)\n"})}),"\n",(0,o.jsx)(e.h3,{id:"\u7f51\u7edc\u7c7b\u9519\u8bef",children:"\u7f51\u7edc\u7c7b\u9519\u8bef"}),"\n",(0,o.jsx)(e.admonition,{title:"\u9519\u8bef",type:"warning",children:(0,o.jsxs)(e.p,{children:["\u591a\u6b21\u8c03\u7528\u540c\u4e00\u4e2a\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"FloatFunctional()"})," \u5b9a\u4e49\u7684\u6210\u5458\u3002"]})}),"\n",(0,o.jsx)(e.p,{children:"\u9519\u8bef\u793a\u4f8b\u5982\u4e0b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class ToyNet(nn.Module):\n    def __init__(self):\n        self.add = FloatFunctional()\n\n    def forward(self, x, y, z)\n        out = self.add(x, y)\n        return self.add(out, z)\n"})}),"\n",(0,o.jsxs)(e.p,{children:["\u6b63\u786e\u505a\u6cd5\uff1a\u7981\u6b62\u5728 forward \u4e2d\u591a\u6b21\u8c03\u7528\u540c\u4e00\u4e2a\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"FloatFunctional()"})," \u5b9a\u4e49\u7684\u53d8\u91cf\u3002"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class ToyNet(nn.Module):\n    def __init__(self):\n        self.add0 = FloatFunctional()\n        self.add1 = FloatFunctional()\n\n    def forward(self, x, y, z)\n        out = self.add0.add(x, y)\n        return self.add1.add(out, z)\n"})}),"\n",(0,o.jsx)(e.h3,{id:"\u7b97\u5b50\u7c7b\u9519\u8bef",children:"\u7b97\u5b50\u7c7b\u9519\u8bef"}),"\n",(0,o.jsx)(e.admonition,{title:"\u9519\u8bef",type:"warning",children:(0,o.jsx)(e.p,{children:"Quantized \u6a21\u578b\u4e2d\u90e8\u5206\u7b97\u5b50\u6ca1\u6709\u7ecf\u8fc7\u524d\u671f\u7684 calibration \u6216 QAT\uff0c\u5982\u67d0\u540e\u5904\u7406\u7b97\u5b50\u60f3\u8981\u5728 BPU \u4e0a\u52a0\u901f\uff0c\u4f46\u662f\u6ca1\u6709\u7ecf\u8fc7\u91cf\u5316\u9636\u6bb5\uff0c\u8fd9\u65f6\u5019\u4f1a\u5bfc\u81f4\u91cf\u5316 Inference \u5931\u8d25\u6216\u90e8\u7f72\u65f6\u7684\u7cbe\u5ea6\u5f02\u5e38\u3002"})}),"\n",(0,o.jsx)(e.p,{children:"\u6b63\u786e\u505a\u6cd5\uff1aQuantized \u9636\u6bb5\u5e76\u975e\u5b8c\u5168\u4e0d\u80fd\u76f4\u63a5\u6dfb\u52a0\u7b97\u5b50\uff0c\u5982\u989c\u8272\u7a7a\u95f4\u8f6c\u6362\u7b97\u5b50\u7b49\uff0c\u5177\u4f53\u6dfb\u52a0\u6307\u5357\u8be6\u89c1\u6587\u6863\u3002\u4f46\u662f\u5e76\u975e\u6240\u6709\u7b97\u5b50\u90fd\u53ef\u4ee5\u76f4\u63a5\u6dfb\u52a0\uff0c\u6bd4\u5982 cat\uff0c\u8fd9\u79cd\u7b97\u5b50\u5fc5\u987b\u5728 calibration \u6216 QAT \u9636\u6bb5\u7edf\u8ba1\u83b7\u5f97\u7684\u771f\u5b9e\u91cf\u5316\u53c2\u6570\u624d\u80fd\u4e0d\u5f71\u54cd\u6700\u7ec8\u7cbe\u5ea6\uff0c\u6709\u7c7b\u4f3c\u9700\u6c42\u9700\u8981\u8c03\u6574\u7f51\u7edc\u7ed3\u6784\uff0c\u53ef\u4ee5\u54a8\u8be2\u6846\u67b6\u7814\u53d1\u3002"}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h3,{id:"\u6a21\u578b\u7c7b\u9519\u8bef",children:"\u6a21\u578b\u7c7b\u9519\u8bef"}),"\n",(0,o.jsx)(e.admonition,{title:"\u9519\u8bef",type:"warning",children:(0,o.jsx)(e.p,{children:"\u6d6e\u70b9\u6a21\u578b\u8fc7\u62df\u5408\u3002"})}),"\n",(0,o.jsx)(e.p,{children:"\u6a21\u578b\u8fc7\u62df\u5408\u5e38\u89c1\u5224\u5b9a\u65b9\u6cd5\uff1a"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"\u5bf9\u8f93\u5165\u6570\u636e\u7a0d\u52a0\u53d8\u6362\u4e4b\u540e\uff0c\u8f93\u51fa\u7ed3\u679c\u53d8\u5316\u8f83\u5927"}),"\n",(0,o.jsx)(e.li,{children:"\u6a21\u578b\u53c2\u6570\u8d4b\u503c\u8f83\u5927"}),"\n",(0,o.jsx)(e.li,{children:"\u6a21\u578b activation \u8f83\u5927"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"\u6b63\u786e\u505a\u6cd5\uff1a\u81ea\u884c\u89e3\u51b3\u6d6e\u70b9\u6a21\u578b\u8fc7\u62df\u5408\u95ee\u9898\u3002"})]})}function _(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}}}]);