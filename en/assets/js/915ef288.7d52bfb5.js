"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[28951],{28453:(e,n,t)=>{t.d(n,{R:()=>_,x:()=>d});var i=t(96540);const r={},c=i.createContext(r);function _(e){const n=i.useContext(c);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:_(e.components),i.createElement(c.Provider,{value:n},e.children)}},71813:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>d,default:()=>l,frontMatter:()=>_,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"Advanced_development/multimedia_development/S100/codec","title":"Codec","description":"System Overview","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/07_Advanced_development/03_multimedia_development/01_S100/03_codec.md","sourceDirName":"07_Advanced_development/03_multimedia_development/01_S100","slug":"/Advanced_development/multimedia_development/S100/codec","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/S100/codec","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770604318000,"sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Camera Bring-up","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/S100/camera_bringup"},"next":{"title":"Display Subsystem","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/S100/display"}}');var r=t(74848),c=t(28453);const _={sidebar_position:3},d="Codec",s={},a=[{value:"System Overview",id:"system-overview",level:2},{value:"Overview",id:"overview",level:3},{value:"JPU Hardware Features",id:"jpu-hardware-features",level:4},{value:"VPU Hardware Features",id:"vpu-hardware-features",level:4},{value:"Software Features",id:"software-features",level:3},{value:"Overall Framework",id:"overall-framework",level:4},{value:"Bitrate Control Modes",id:"bitrate-control-modes",level:4},{value:"CBR Description",id:"cbr-description",level:5},{value:"VBR Description",id:"vbr-description",level:5},{value:"AVBR Description",id:"avbr-description",level:5},{value:"FixQp Description",id:"fixqp-description",level:5},{value:"QPMAP Description",id:"qpmap-description",level:5},{value:"Debugging Methods",id:"debugging-methods",level:3},{value:"Encoding Quality Tuning",id:"encoding-quality-tuning",level:4},{value:"GOP Structure Description",id:"gop-structure-description",level:4},{value:"Preset GOP Structures",id:"preset-gop-structures",level:5},{value:"VPU Debugging Method",id:"vpu-debugging-method",level:4},{value:"Encoding Status",id:"encoding-status",level:5},{value:"Decoding Status",id:"decoding-status",level:5},{value:"JPU Debugging Method",id:"jpu-debugging-method",level:4},{value:"Encoding Status",id:"encoding-status-1",level:5},{value:"Decoding Status",id:"decoding-status-1",level:5},{value:"Typical Scenarios",id:"typical-scenarios",level:3},{value:"Single-Stream Encoding",id:"single-stream-encoding",level:4},{value:"Single-Stream Decoding",id:"single-stream-decoding",level:4},{value:"Multi-Stream Encoding",id:"multi-stream-encoding",level:4},{value:"Multi-Stream Decoding",id:"multi-stream-decoding",level:4},{value:"Codec API",id:"codec-api",level:2},{value:"MediaCodec Interface Description",id:"mediacodec-interface-description",level:3},{value:"GOP",id:"gop",level:4},{value:"GOP Structure Table",id:"gop-structure-table",level:5},{value:"Predefined GOP Structures",id:"predefined-gop-structures",level:5},{value:"Long-term Reference Frames",id:"long-term-reference-frames",level:4},{value:"Intra Refresh",id:"intra-refresh",level:4},{value:"Rate Control",id:"rate-control",level:4},{value:"ROI",id:"roi",level:4},{value:"Input/Output Buffer Management",id:"inputoutput-buffer-management",level:4},{value:"Frame Rate Control",id:"frame-rate-control",level:4},{value:"Frame Skip Configuration",id:"frame-skip-configuration",level:4},{value:"JPEG Codec Limitations",id:"jpeg-codec-limitations",level:4},{value:"API Reference",id:"api-reference",level:3},{value:"hb_mm_mc_get_descriptor",id:"hb_mm_mc_get_descriptor",level:4},{value:"hb_mm_mc_get_default_context",id:"hb_mm_mc_get_default_context",level:4},{value:"hb_mm_mc_initialize",id:"hb_mm_mc_initialize",level:4},{value:"hb_mm_mc_set_callback",id:"hb_mm_mc_set_callback",level:4},{value:"hb_mm_mc_configure",id:"hb_mm_mc_configure",level:4},{value:"hb_mm_mc_start",id:"hb_mm_mc_start",level:4},{value:"hb_mm_mc_stop",id:"hb_mm_mc_stop",level:4},{value:"hb_mm_mc_pause",id:"hb_mm_mc_pause",level:4},{value:"hb_mm_mc_flush",id:"hb_mm_mc_flush",level:4},{value:"hb_mm_mc_release",id:"hb_mm_mc_release",level:4},{value:"hb_mm_mc_get_state",id:"hb_mm_mc_get_state",level:4},{value:"hb_mm_mc_get_status",id:"hb_mm_mc_get_status",level:4},{value:"hb_mm_mc_queue_input_buffer",id:"hb_mm_mc_queue_input_buffer",level:4},{value:"hb_mm_mc_dequeue_input_buffer",id:"hb_mm_mc_dequeue_input_buffer",level:4},{value:"hb_mm_mc_queue_output_buffer",id:"hb_mm_mc_queue_output_buffer",level:4},{value:"hb_mm_mc_dequeue_output_buffer",id:"hb_mm_mc_dequeue_output_buffer",level:4},{value:"hb_mm_mc_get_longterm_ref_mode",id:"hb_mm_mc_get_longterm_ref_mode",level:4},{value:"hb_mm_mc_set_longterm_ref_mode",id:"hb_mm_mc_set_longterm_ref_mode",level:4},{value:"hb_mm_mc_get_intra_refresh_config",id:"hb_mm_mc_get_intra_refresh_config",level:4},{value:"hb_mm_mc_set_intra_refresh_config",id:"hb_mm_mc_set_intra_refresh_config",level:4},{value:"hb_mm_mc_get_rate_control_config",id:"hb_mm_mc_get_rate_control_config",level:4},{value:"hb_mm_mc_set_rate_control_config",id:"hb_mm_mc_set_rate_control_config",level:4},{value:"hb_mm_mc_get_deblk_filter_config",id:"hb_mm_mc_get_deblk_filter_config",level:4},{value:"hb_mm_mc_set_deblk_filter_config",id:"hb_mm_mc_set_deblk_filter_config",level:4},{value:"hb_mm_mc_get_sao_config",id:"hb_mm_mc_get_sao_config",level:4},{value:"hb_mm_mc_set_sao_config",id:"hb_mm_mc_set_sao_config",level:4},{value:"hb_mm_mc_get_entropy_config",id:"hb_mm_mc_get_entropy_config",level:4},{value:"hb_mm_mc_set_entropy_config",id:"hb_mm_mc_set_entropy_config",level:4},{value:"hb_mm_mc_get_vui_timing_config",id:"hb_mm_mc_get_vui_timing_config",level:4},{value:"hb_mm_mc_set_vui_timing_config",id:"hb_mm_mc_set_vui_timing_config",level:4},{value:"hb_mm_mc_get_slice_config",id:"hb_mm_mc_get_slice_config",level:4},{value:"hb_mm_mc_set_slice_config",id:"hb_mm_mc_set_slice_config",level:4},{value:"hb_mm_mc_insert_user_data",id:"hb_mm_mc_insert_user_data",level:4},{value:"hb_mm_mc_request_idr_frame",id:"hb_mm_mc_request_idr_frame",level:4},{value:"hb_mm_mc_skip_pic",id:"hb_mm_mc_skip_pic",level:4},{value:"hb_mm_mc_get_smart_bg_enc_config",id:"hb_mm_mc_get_smart_bg_enc_config",level:4},{value:"hb_mm_mc_set_smart_bg_enc_config",id:"hb_mm_mc_set_smart_bg_enc_config",level:4},{value:"hb_mm_mc_get_pred_unit_config",id:"hb_mm_mc_get_pred_unit_config",level:4},{value:"hb_mm_mc_set_pred_unit_config",id:"hb_mm_mc_set_pred_unit_config",level:4},{value:"hb_mm_mc_get_transform_config",id:"hb_mm_mc_get_transform_config",level:4},{value:"hb_mm_mc_set_transform_config",id:"hb_mm_mc_set_transform_config",level:4},{value:"hb_mm_mc_get_roi_config",id:"hb_mm_mc_get_roi_config",level:4},{value:"hb_mm_mc_set_roi_config",id:"hb_mm_mc_set_roi_config",level:4},{value:"hb_mm_mc_get_mode_decision_config",id:"hb_mm_mc_get_mode_decision_config",level:4},{value:"hb_mm_mc_set_mode_decision_config",id:"hb_mm_mc_set_mode_decision_config",level:4},{value:"hb_mm_mc_get_user_data",id:"hb_mm_mc_get_user_data",level:4},{value:"hb_mm_mc_release_user_data",id:"hb_mm_mc_release_user_data",level:4},{value:"hb_mm_mc_get_mjpeg_config",id:"hb_mm_mc_get_mjpeg_config",level:4},{value:"hb_mm_mc_set_mjpeg_config",id:"hb_mm_mc_set_mjpeg_config",level:4},{value:"hb_mm_mc_get_jpeg_config",id:"hb_mm_mc_get_jpeg_config",level:4},{value:"hb_mm_mc_set_jpeg_config",id:"hb_mm_mc_set_jpeg_config",level:4},{value:"hb_mm_mc_get_fd",id:"hb_mm_mc_get_fd",level:4},{value:"hb_mm_mc_close_fd",id:"hb_mm_mc_close_fd",level:4},{value:"hb_mm_mc_set_camera",id:"hb_mm_mc_set_camera",level:4},{value:"hb_mm_mc_get_vui_config",id:"hb_mm_mc_get_vui_config",level:4},{value:"hb_mm_mc_set_vui_config",id:"hb_mm_mc_set_vui_config",level:4},{value:"hb_mm_mc_get_3dnr_enc_config",id:"hb_mm_mc_get_3dnr_enc_config",level:4},{value:"hb_mm_mc_set_3dnr_enc_config",id:"hb_mm_mc_set_3dnr_enc_config",level:4},{value:"hb_mm_mc_request_idr_header",id:"hb_mm_mc_request_idr_header",level:4},{value:"hb_mm_mc_enable_idr_frame",id:"hb_mm_mc_enable_idr_frame",level:4},{value:"hb_mm_mc_register_audio_encoder",id:"hb_mm_mc_register_audio_encoder",level:4},{value:"hb_mm_mc_unregister_audio_encoder",id:"hb_mm_mc_unregister_audio_encoder",level:4},{value:"hb_mm_mc_register_audio_decoder",id:"hb_mm_mc_register_audio_decoder",level:4},{value:"hb_mm_mc_unregister_audio_decoder",id:"hb_mm_mc_unregister_audio_decoder",level:4},{value:"hb_mm_mc_get_explicit_header_config",id:"hb_mm_mc_get_explicit_header_config",level:4},{value:"hb_mm_mc_set_explicit_header_config",id:"hb_mm_mc_set_explicit_header_config",level:4},{value:"hb_mm_mc_get_roi_avg_qp",id:"hb_mm_mc_get_roi_avg_qp",level:4},{value:"hb_mm_mc_set_roi_avg_qp",id:"hb_mm_mc_set_roi_avg_qp",level:4},{value:"Main Parameter Descriptions",id:"main-parameter-descriptions",level:3},{value:"media_codec_state_t",id:"media_codec_state_t",level:4},{value:"media_codec_id_t",id:"media_codec_id_t",level:4},{value:"mc_video_rate_control_mode_t",id:"mc_video_rate_control_mode_t",level:4},{value:"mc_h264_cbr_params_t",id:"mc_h264_cbr_params_t",level:4},{value:"mc_h264_vbr_params_t",id:"mc_h264_vbr_params_t",level:4},{value:"mc_h264_avbr_params_t",id:"mc_h264_avbr_params_t",level:4},{value:"mc_h264_fix_qp_params_t",id:"mc_h264_fix_qp_params_t",level:4},{value:"mc_h264_qp_map_params_t",id:"mc_h264_qp_map_params_t",level:4},{value:"mc_h265_cbr_params_t",id:"mc_h265_cbr_params_t",level:4},{value:"mc_h265_vbr_params_t",id:"mc_h265_vbr_params_t",level:4},{value:"mc_h265_avbr_params_t",id:"mc_h265_avbr_params_t",level:4},{value:"mc_h265_fix_qp_params_t",id:"mc_h265_fix_qp_params_t",level:4},{value:"mc_h265_qp_map_params_t",id:"mc_h265_qp_map_params_t",level:4},{value:"mc_mjpeg_fix_qp_params_t",id:"mc_mjpeg_fix_qp_params_t",level:4},{value:"mc_video_custom_gop_pic_params_t",id:"mc_video_custom_gop_pic_params_t",level:4},{value:"mc_inter_status_t",id:"mc_inter_status_t",level:4},{value:"media_codec_context_t",id:"media_codec_context_t",level:4},{value:"mc_video_codec_enc_params_t",id:"mc_video_codec_enc_params_t",level:4},{value:"mc_video_codec_dec_params_t",id:"mc_video_codec_dec_params_t",level:4},{value:"mc_audio_codec_enc_params_t",id:"mc_audio_codec_enc_params_t",level:4},{value:"mc_audio_codec_dec_params_t",id:"mc_audio_codec_dec_params_t",level:4},{value:"Return Value Description",id:"return-value-description",level:3},{value:"Codec Sample",id:"codec-sample",level:2},{value:"Encoding Example",id:"encoding-example",level:3},{value:"Function Overview",id:"function-overview",level:4},{value:"Software Architecture Description",id:"software-architecture-description",level:5},{value:"Hardware Data Flow Description",id:"hardware-data-flow-description",level:5},{value:"Code Location and Directory Structure",id:"code-location-and-directory-structure",level:5},{value:"Compilation",id:"compilation",level:4},{value:"Compilation Environment",id:"compilation-environment",level:5},{value:"Compilation Instructions",id:"compilation-instructions",level:5},{value:"Execution",id:"execution",level:4},{value:"Supported Platforms",id:"supported-platforms",level:5},{value:"Board Deployment and Configuration",id:"board-deployment-and-configuration",level:5},{value:"Running Instructions",id:"running-instructions",level:5},{value:"Command-line Argument Description",id:"command-line-argument-description",level:6},{value:"Help Menu",id:"help-menu",level:6},{value:"Running Method",id:"running-method",level:6},{value:"Execution Result Description",id:"execution-result-description",level:6},{value:"Decoding Examples",id:"decoding-examples",level:3},{value:"Function Overview",id:"function-overview-1",level:4},{value:"Software Architecture",id:"software-architecture",level:5},{value:"Hardware Data Flow Description",id:"hardware-data-flow-description-1",level:5},{value:"Code Location and Directory Structure",id:"code-location-and-directory-structure-1",level:5},{value:"Compilation",id:"compilation-1",level:4},{value:"Compilation Environment",id:"compilation-environment-1",level:5},{value:"Compilation Instructions",id:"compilation-instructions-1",level:5},{value:"Execution",id:"execution-1",level:4},{value:"Supported Platforms",id:"supported-platforms-1",level:5},{value:"Board Deployment and Configuration",id:"board-deployment-and-configuration-1",level:5},{value:"Running Guide",id:"running-guide",level:5},{value:"Parameter Description",id:"parameter-description",level:6},{value:"Help Menu",id:"help-menu-1",level:6},{value:"How to Run",id:"how-to-run",level:6},{value:"Explanation of Execution Results",id:"explanation-of-execution-results",level:6}];function o(e){const n={a:"a",blockquote:"blockquote",br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",h6:"h6",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,c.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"codec",children:"Codec"})}),"\n",(0,r.jsx)(n.h2,{id:"system-overview",children:"System Overview"}),"\n",(0,r.jsx)(n.h3,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Codec (Coder-Decoder) refers to a codec used to compress or decompress media data such as video, images, and audio. The S100 SoC includes two hardware codec units: VPU (Video Processing Unit) and JPU (JPEG Processing Unit), providing 4K@90fps video codec capability and 4K@90fps image codec capability."}),"\n",(0,r.jsx)(n.h4,{id:"jpu-hardware-features",children:"JPU Hardware Features"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"HW Feature"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Feature Indicator"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"HW number"}),(0,r.jsx)(n.td,{children:"1"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"maximum input"}),(0,r.jsx)(n.td,{children:"8192x8192"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"minimum input"}),(0,r.jsx)(n.td,{children:"32x32"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"performance"}),(0,r.jsx)(n.td,{children:"4K@90fps"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max instance"}),(0,r.jsx)(n.td,{children:"64"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"input image format"}),(0,r.jsx)(n.td,{children:"4:0:0, 4:2:0, 4:2:2, 4:4:0, and 4:4:4 color format"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"output image format"}),(0,r.jsx)(n.td,{children:"4:0:0, 4:2:0, 4:2:2, 4:4:0, and 4:4:4 color format"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"input crop"}),(0,r.jsx)(n.td,{children:"Supports"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"bitrate control"}),(0,r.jsx)(n.td,{children:"FIXQP(MJPEG)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"rotation"}),(0,r.jsx)(n.td,{children:"90, 180, 270"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"mirror"}),(0,r.jsx)(n.td,{children:"Vertical, Horizontal, Vertical+Horizontal"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"quantization table"}),(0,r.jsx)(n.td,{children:"Supports Custom Settings"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"huffman table"}),(0,r.jsx)(n.td,{children:"Supports Custom Settings"})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"vpu-hardware-features",children:"VPU Hardware Features"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"HW Feature"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Feature Indicator"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"HW number"}),(0,r.jsx)(n.td,{children:"1"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"maximum input"}),(0,r.jsx)(n.td,{children:"8192x4096"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"minimum input"}),(0,r.jsx)(n.td,{children:"256x128"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"input alignment required"}),(0,r.jsx)(n.td,{children:"width 32, height 8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"performance"}),(0,r.jsx)(n.td,{children:"4K@90fps"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max instance"}),(0,r.jsx)(n.td,{children:"32"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"input image format"}),(0,r.jsx)(n.td,{children:"4:2:0, 4:2:2 color format"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"output image format"}),(0,r.jsx)(n.td,{children:"4:2:0, 4:2:2 color format"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"input crop"}),(0,r.jsx)(n.td,{children:"Supports"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"bitrate control"}),(0,r.jsx)(n.td,{children:"CBR, VBR, AVBR, FIXQP, QPMAP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"rotation"}),(0,r.jsx)(n.td,{children:"90, 180, 270"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"mirror"}),(0,r.jsx)(n.td,{children:"Vertical, Horizontal, Vertical+Horizontal"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"long-term reference prediction"}),(0,r.jsx)(n.td,{children:"Supports Custom Settings"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"intra refresh"}),(0,r.jsx)(n.td,{children:"Supports"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"deblocking filter"}),(0,r.jsx)(n.td,{children:"Supports"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"request IDR"}),(0,r.jsx)(n.td,{children:"Supports"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ROI mode"}),(0,r.jsx)(n.td,{children:"mode1: Users can set multiple zones\u2019(up to 64) qp value(0-51), should not work with CBR or AVBR mode mode2: Users can set multiple zones\u2019(up to 64) important level(0-8), should work with CBR or AVBR mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"GOP mode"}),(0,r.jsx)(n.td,{children:"0: Custom GOP 1 : I-I-I-I,..I (all intra, gop_size=1) 2 : I-P-P-P,\u2026 P (consecutive P, gop_size=1) 3 : I-B-B-B,\u2026B (consecutive B, gop_size=1) 4 : I-B-P-B-P,\u2026 (gop_size=2) 5 : I-B-B-B-P,\u2026 (gop_size=4) 6 : I-P-P-P-P,\u2026 (consecutive P, gop_size=4) 7 : I-B-B-B-B,\u2026 (consecutive B, gop_size=4) 8 : I-B-B-B-B-B-B-B-B,\u2026 (random access, gop_size=8) 9 : I-P-P-P,\u2026 P (consecutive P, gop_size = 1, with single reference)"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"software-features",children:"Software Features"}),"\n",(0,r.jsx)(n.h4,{id:"overall-framework",children:"Overall Framework"}),"\n",(0,r.jsx)(n.p,{children:"The MediaCodec subsystem provides components for audio/video and image codec, raw stream packaging, and video recording. This system primarily encapsulates underlying codec hardware resources and software codec libraries to offer codec capabilities to upper layers. Developers can implement H.265 and H.264 video encoding/decoding functionalities using the provided codec APIs, use JPEG encoding to save camera data as JPEG images, or utilize the video recording feature to record camera data."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/2f8364ee5efbb8cb14136e0dc942248e.png",alt:""})}),"\n",(0,r.jsx)(n.h4,{id:"bitrate-control-modes",children:"Bitrate Control Modes"}),"\n",(0,r.jsx)(n.p,{children:"MediaCodec supports bitrate control for H.264/H.265 and MJPEG protocols, offering five bitrate control methods for H.264/H.265 encoding channels\u2014CBR, VBR, AVBR, FixQp, and QpMap\u2014and FixQp bitrate control for MJPEG encoding channels."}),"\n",(0,r.jsx)(n.h5,{id:"cbr-description",children:"CBR Description"}),"\n",(0,r.jsx)(n.p,{children:"CBR stands for Constant Bitrate, ensuring stable overall encoding bitrate. Below are parameter descriptions for CBR mode:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Parameter"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Description"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Range"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Default"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"intra_period"}),(0,r.jsx)(n.td,{children:"I-frame interval"}),(0,r.jsx)(n.td,{children:"[0,2047]"}),(0,r.jsx)(n.td,{children:"28"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"intra_qp"}),(0,r.jsx)(n.td,{children:"QP value for I-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"bit_rate"}),(0,r.jsx)(n.td,{children:"Target average bitrate, in kbps"}),(0,r.jsx)(n.td,{children:"[0,700000]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"frame_rate"}),(0,r.jsx)(n.td,{children:"Target frame rate, in fps"}),(0,r.jsx)(n.td,{children:"[1,240]"}),(0,r.jsx)(n.td,{children:"30"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"initial_rc_qp"}),(0,r.jsx)(n.td,{children:"Initial QP value for rate control; if outside [0,51], the encoder internally determines the initial value"}),(0,r.jsx)(n.td,{children:"[0,63]"}),(0,r.jsx)(n.td,{children:"63"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"vbv_buffer_size"}),(0,r.jsx)(n.td,{children:"VBV buffer size in ms; actual VBV buffer size = bit_rate * vbv_buffer_size / 1000 (kb). Buffer size affects encoding quality and bitrate control accuracy: smaller buffers yield higher bitrate control precision but lower image quality; larger buffers improve image quality but increase bitrate fluctuation."}),(0,r.jsx)(n.td,{children:"[10,3000]"}),(0,r.jsx)(n.td,{children:"10"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ctu_level_rc_enable"}),(0,r.jsx)(n.td,{children:"H.264/H.265 rate control can operate at CTU level for higher bitrate control precision at the cost of encoding quality. This mode cannot be used with ROI encoding; it is automatically disabled when ROI encoding is enabled."}),(0,r.jsx)(n.td,{children:"[0,1]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"min_qp_I"}),(0,r.jsx)(n.td,{children:"Minimum QP value for I-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max_qp_I"}),(0,r.jsx)(n.td,{children:"Maximum QP value for I-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"51"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"min_qp_P"}),(0,r.jsx)(n.td,{children:"Minimum QP value for P-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max_qp_P"}),(0,r.jsx)(n.td,{children:"Maximum QP value for P-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"51"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"min_qp_B"}),(0,r.jsx)(n.td,{children:"Minimum QP value for B-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max_qp_B"}),(0,r.jsx)(n.td,{children:"Maximum QP value for B-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"51"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"hvs_qp_enable"}),(0,r.jsx)(n.td,{children:"H.264/H.265 rate control can operate at sub-CTU level, adjusting sub-macroblock QP values to improve subjective image quality."}),(0,r.jsx)(n.td,{children:"[0,1]"}),(0,r.jsx)(n.td,{children:"1"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"hvs_qp_scale"}),(0,r.jsx)(n.td,{children:"Effective when hvs_qp_enable is enabled; represents QP scaling factor."}),(0,r.jsx)(n.td,{children:"[0,4]"}),(0,r.jsx)(n.td,{children:"2"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max_delta_qp"}),(0,r.jsx)(n.td,{children:"Effective when hvs_qp_enable is enabled; specifies maximum allowable deviation for HVS QP values."}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"10"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"qp_map_enable"}),(0,r.jsx)(n.td,{children:"Enables QP map for ROI encoding."}),(0,r.jsx)(n.td,{children:"[0,1]"}),(0,r.jsx)(n.td,{children:"0"})]})]})]}),"\n",(0,r.jsx)(n.h5,{id:"vbr-description",children:"VBR Description"}),"\n",(0,r.jsx)(n.p,{children:"VBR stands for Variable Bitrate, allocating higher QP (lower quality, higher compression) for simple scenes and lower QP (higher quality) for complex scenes to maintain consistent visual quality. Below are parameter descriptions for VBR mode:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Parameter"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Description"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Range"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Default"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"intra_period"}),(0,r.jsx)(n.td,{children:"I-frame interval"}),(0,r.jsx)(n.td,{children:"[0,2047]"}),(0,r.jsx)(n.td,{children:"28"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"intra_qp"}),(0,r.jsx)(n.td,{children:"QP value for I-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"frame_rate"}),(0,r.jsx)(n.td,{children:"Target frame rate, in fps"}),(0,r.jsx)(n.td,{children:"[1,240]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"qp_map_enable"}),(0,r.jsx)(n.td,{children:"Enables QP map for ROI encoding"}),(0,r.jsx)(n.td,{children:"[0,1]"}),(0,r.jsx)(n.td,{children:"0"})]})]})]}),"\n",(0,r.jsx)(n.h5,{id:"avbr-description",children:"AVBR Description"}),"\n",(0,r.jsx)(n.p,{children:"AVBR stands for Average Variable Bitrate, allocating lower bitrates for simple scenes and sufficient bitrates for complex scenes\u2014similar to VBR\u2014while maintaining an average bitrate close to the target over time, thus controlling output file size\u2014similar to CBR. It is a compromise between CBR and VBR, producing relatively stable bitrate and image quality. Below are parameter descriptions for AVBR mode:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Parameter"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Description"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Range"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Default"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"intra_period"}),(0,r.jsx)(n.td,{children:"I-frame interval"}),(0,r.jsx)(n.td,{children:"[0,2047]"}),(0,r.jsx)(n.td,{children:"28"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"intra_qp"}),(0,r.jsx)(n.td,{children:"QP value for I-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"bit_rate"}),(0,r.jsx)(n.td,{children:"Target average bitrate, in kbps"}),(0,r.jsx)(n.td,{children:"[0,700000]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"frame_rate"}),(0,r.jsx)(n.td,{children:"Target frame rate, in fps"}),(0,r.jsx)(n.td,{children:"[1,240]"}),(0,r.jsx)(n.td,{children:"30"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"initial_rc_qp"}),(0,r.jsx)(n.td,{children:"Initial QP value for rate control; if outside [0,51], the encoder internally determines the initial value"}),(0,r.jsx)(n.td,{children:"[0,63]"}),(0,r.jsx)(n.td,{children:"63"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"vbv_buffer_size"}),(0,r.jsx)(n.td,{children:"VBV buffer size in ms; actual VBV buffer size = bit_rate * vbv_buffer_size / 1000 (kb). Buffer size affects encoding quality and bitrate control accuracy: smaller buffers yield higher bitrate control precision but lower image quality; larger buffers improve image quality but increase bitrate fluctuation."}),(0,r.jsx)(n.td,{children:"[10,3000]"}),(0,r.jsx)(n.td,{children:"3000"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ctu_level_rc_enable"}),(0,r.jsx)(n.td,{children:"H.264/H.265 rate control can operate at CTU level for higher bitrate control precision at the cost of encoding quality. This mode cannot be used with ROI encoding; it is automatically disabled when ROI encoding is enabled."}),(0,r.jsx)(n.td,{children:"[0,1]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"min_qp_I"}),(0,r.jsx)(n.td,{children:"Minimum QP value for I-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max_qp_I"}),(0,r.jsx)(n.td,{children:"Maximum QP value for I-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"51"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"min_qp_P"}),(0,r.jsx)(n.td,{children:"Minimum QP value for P-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max_qp_P"}),(0,r.jsx)(n.td,{children:"Maximum QP value for P-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"51"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"min_qp_B"}),(0,r.jsx)(n.td,{children:"Minimum QP value for B-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max_qp_B"}),(0,r.jsx)(n.td,{children:"Maximum QP value for B-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"51"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"hvs_qp_enable"}),(0,r.jsx)(n.td,{children:"H.264/H.265 rate control can operate at sub-CTU level, adjusting sub-macroblock QP values to improve subjective image quality."}),(0,r.jsx)(n.td,{children:"[0,1]"}),(0,r.jsx)(n.td,{children:"1"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"hvs_qp_scale"}),(0,r.jsx)(n.td,{children:"Effective when hvs_qp_enable is enabled; represents QP scaling factor."}),(0,r.jsx)(n.td,{children:"[0,4]"}),(0,r.jsx)(n.td,{children:"2"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"max_delta_qp"}),(0,r.jsx)(n.td,{children:"Effective when hvs_qp_enable is enabled; specifies maximum allowable deviation for HVS QP values."}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"10"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"qp_map_enable"}),(0,r.jsx)(n.td,{children:"Enables QP map for ROI encoding."}),(0,r.jsx)(n.td,{children:"[0,1]"}),(0,r.jsx)(n.td,{children:"0"})]})]})]}),"\n",(0,r.jsx)(n.h5,{id:"fixqp-description",children:"FixQp Description"}),"\n",(0,r.jsx)(n.p,{children:"FixQp assigns fixed QP values to each I-frame and P-frame, with separate values allowed for I/P frames. Below are parameter descriptions for FixQp mode:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Parameter"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Description"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Range"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Default"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"intra_period"}),(0,r.jsx)(n.td,{children:"I-frame interval"}),(0,r.jsx)(n.td,{children:"[0,2047]"}),(0,r.jsx)(n.td,{children:"28"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"frame_rate"}),(0,r.jsx)(n.td,{children:"Target frame rate, in fps"}),(0,r.jsx)(n.td,{children:"[1,240]"}),(0,r.jsx)(n.td,{children:"30"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"force_qp_I"}),(0,r.jsx)(n.td,{children:"Forced QP value for I-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"force_qp_P"}),(0,r.jsx)(n.td,{children:"Forced QP value for P-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"force_qp_B"}),(0,r.jsx)(n.td,{children:"Forced QP value for B-frames"}),(0,r.jsx)(n.td,{children:"[0,51]"}),(0,r.jsx)(n.td,{children:"0"})]})]})]}),"\n",(0,r.jsx)(n.h5,{id:"qpmap-description",children:"QPMAP Description"}),"\n",(0,r.jsx)(n.p,{children:"QPMAP allows specifying QP values for each block within a frame: 32x32 for H.265 and 16x16 for H.264. Below are parameter descriptions for QPMAP mode:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Parameter"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Description"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Range"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Default"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"intra_period"}),(0,r.jsx)(n.td,{children:"I-frame interval"}),(0,r.jsx)(n.td,{children:"[0,2047]"}),(0,r.jsx)(n.td,{children:"28"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"frame_rate"}),(0,r.jsx)(n.td,{children:"Target frame rate, in fps"}),(0,r.jsx)(n.td,{children:"[1,240]"}),(0,r.jsx)(n.td,{children:"30"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"qp_map_array"}),(0,r.jsx)(n.td,{children:"Specifies QP map table; for H.265, sub-CTU size is 32x32\u2014each sub-CTU requires one QP value (1 byte), ordered in raster scan."}),(0,r.jsx)(n.td,{children:"Pointer address"}),(0,r.jsx)(n.td,{children:"NULL"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"qp_map_array_count"}),(0,r.jsx)(n.td,{children:"Specifies size of QP map table."}),(0,r.jsx)(n.td,{children:"[0, MC_VIDEO_MAX_SUB_CTU_NUM] && (ALIGN64(picWidth)>>5) * (ALIGN64(picHeight)>>5)"}),(0,r.jsx)(n.td,{children:"0"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"debugging-methods",children:"Debugging Methods"}),"\n",(0,r.jsx)(n.h4,{id:"encoding-quality-tuning",children:"Encoding Quality Tuning"}),"\n",(0,r.jsx)(n.p,{children:"In current customer usage scenarios involving video encoding with the codec, CBR mode is commonly selected. In complex scenes, hardware automatically increases bitrate to maintain video quality, resulting in larger-than-expected output files. To balance video quality and actual bitrate, settings for bit_rate and max_qp_I/P must be coordinated. Below shows actual bitrate and QP under all-I-frame mode with a target bitrate of 15000 kbps across different scene complexities and max_qp_I values (data due to varying scene complexity):"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Scene & Parameters"}),(0,r.jsx)(n.th,{children:"Outdoor Daytime Complex Scene bitrate(15000) max_qp_I(35)"}),(0,r.jsx)(n.th,{children:"Outdoor Daytime Complex Scene bitrate(15000) max_qp_I(38)"}),(0,r.jsx)(n.th,{children:"Outdoor Daytime Complex Scene bitrate(15000) max_qp_I(39)"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Bit allocation (bps) (higher = better quality)"}),(0,r.jsx)(n.td,{children:"60300045"}),(0,r.jsx)(n.td,{children:"42186920"}),(0,r.jsx)(n.td,{children:"35898230"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Avg QP (lower = better quality)"}),(0,r.jsx)(n.td,{children:"35"}),(0,r.jsx)(n.td,{children:"38"}),(0,r.jsx)(n.td,{children:"39"})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"gop-structure-description",children:"GOP Structure Description"}),"\n",(0,r.jsx)(n.p,{children:"H.264/H.265 encoding supports configurable GOP structures, allowing users to select from three preset GOP structures or define custom GOP structures."}),"\n",(0,r.jsx)(n.p,{children:"A GOP structure table defines a periodic GOP pattern applied throughout the encoding process. Elements within a single structure table are described below. Reference frames for each picture can be specified; if frames after an IDR reference frames before the IDR, the encoder internally handles this to prevent cross-IDR referencing\u2014users need not manage this. When defining custom GOP structures, users must specify the number of structure tables (up to 3), ordered by decoding sequence."}),"\n",(0,r.jsx)(n.p,{children:"Below describes elements within the structure table:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Element"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Type"}),(0,r.jsx)(n.td,{children:"Frame type (I, P, B)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"POC"}),(0,r.jsx)(n.td,{children:"Display order within GOP, range [1, gop_size]."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"QPoffset"}),(0,r.jsx)(n.td,{children:"Quantization parameter for pictures in custom GOP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"NUM_REF_PIC_L0"}),(0,r.jsx)(n.td,{children:"Indicates multi-reference pictures for P-frames; valid only when PIC_TYPE is P."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"temporal_id"}),(0,r.jsx)(n.td,{children:"Temporal layer of frame; frames cannot predict from frames with higher temporal_id (0~6)."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1st_ref_POC"}),(0,r.jsx)(n.td,{children:"POC of first reference picture in L0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2nd_ref_POC"}),(0,r.jsx)(n.td,{children:"For B-frames, first reference picture POC is in L1; for P-frames, second reference picture POC is in L0. reference_L1 and reference_L0 may share the same POC in B-slices, but different POCs are recommended for compression efficiency."})]})]})]}),"\n",(0,r.jsx)(n.h5,{id:"preset-gop-structures",children:"Preset GOP Structures"}),"\n",(0,r.jsx)(n.p,{children:"Nine preset GOP structures are supported:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"GOP Structure"}),(0,r.jsx)(n.th,{children:"Low Latency (encoding order = display order)"}),(0,r.jsx)(n.th,{children:"GOP Size"}),(0,r.jsx)(n.th,{children:"Encoding Order"}),(0,r.jsx)(n.th,{children:"Min Source Frame Buffer Count"}),(0,r.jsx)(n.th,{children:"Min Decoded Picture Buffer Count"}),(0,r.jsx)(n.th,{children:"Period Requirement (I-frame interval)"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"I"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"I0-I1-I2\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"P"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"P0-P1-P2\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"B"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"B0-B1-B2\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"BP"}),(0,r.jsx)(n.td,{children:"No"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"B1-P0-B3-P2\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"BBBP"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"B2-B1-B3-P0\u2026"}),(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"PPPP"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"P0-P1-P2-P3\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"BBBB"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"B0-B1-B2-B3\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"BBBB BBBB"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"B3-B2-B4-B1-B6-B5-B7-B0\u2026"}),(0,r.jsx)(n.td,{children:"12"}),(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"9"}),(0,r.jsx)(n.td,{children:"P"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"P0"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 1"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames with no inter-frame referencing;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/b02cc41ab083664ba3f8a3bef1543afa.png",alt:""})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/fa1da95bc8801b2d6225b2abf1b2f2d3.png",alt:""}),"GOP Preset 2"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and P-frames;"}),"\n",(0,r.jsx)(n.li,{children:"P-frames reference 2 forward reference frames;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/e3c2f773a89f6ee2fe2dab03200b6fd0.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/8fa5f892bd7282e82ac8ed96011c943d.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 3"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference 2 forward reference frames;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/03bbdf35dc3e2a1b38f9e05d7038d064.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/e1b5707ea0c32b6a0c1658527a6186dd.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 4"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames, P-frames, and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"P-frames reference 2 forward reference frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference 1 forward reference frame and 1 backward reference frame;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/17e10e6a27db202fe9a0c2b5f3d5dd50.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/972bbe22d2e7364c1c0a3db03f57343e.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 5"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames, P-frames, and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"P-frames reference 2 forward reference frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference 1 forward reference frame and 1 backward reference frame, where the backward reference frame can be either a P-frame or a B-frame;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/16ad2d15f0b22a91fda1450747a18422.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/8ff1393cdbb997c8768ea2f9f00c3c8b.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 6"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and P-frames;"}),"\n",(0,r.jsx)(n.li,{children:"P-frames reference 2 forward reference frames;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/a5fbffa7c85a3423729f06d45f83a601.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/1e88c6cbacb8fff86f5d5fc301e01abd.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 7"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference 2 forward reference frames;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/40cd6c4fa7cf66f9bf14c3675cb7ef20.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/be7fe30d2685e27e2b36f305ef745eb4.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 8"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference 1 forward reference frame and 1 backward reference frame;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/9c46efaf2a9106bcee2468098e209b1f.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/d016b90fa0a06e183b6871bc430a8714.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 9"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and P-frames;"}),"\n",(0,r.jsx)(n.li,{children:"P-frames reference 1 forward reference frame;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/0bc1b9d3e73b4037b64236650738b5cd.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/937b45950423ff5006e378cb510d695d.png",alt:""})}),"\n",(0,r.jsx)(n.h4,{id:"vpu-debugging-method",children:"VPU Debugging Method"}),"\n",(0,r.jsx)(n.p,{children:"The VPU (Video Processing Unit) is a dedicated visual processing unit capable of efficiently handling video content. The VPU can perform encoding and decoding of H.265 video formats. Users can obtain the encoded/decoded bitstream through the interfaces provided by Codec."}),"\n",(0,r.jsx)(n.h5,{id:"encoding-status",children:"Encoding Status"}),"\n",(0,r.jsx)(n.p,{children:"Encoding Debug Information"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"cat /sys/kernel/debug/vpu/venc\nroot@ubuntu:~# cat /sys/kernel/debug/vpu/venc\n----encode enc param----\nenc_idx  enc_id     profile       level width height pix_fmt fbuf_count extern_buf_flag bsbuf_count bsbuf_size mirror rotate\n      0    h265        Main unspecified  4096   2160       0          5               1           5   13271040      0      0\n\n----encode h265cbr param----\nenc_idx rc_mode intra_period intra_qp bit_rate frame_rate initial_rc_qp vbv_buffer_size ctu_level_rc_enalbe min_qp_I max_qp_I min_qp_P max_qp_P min_qp_B max_qp_B hvs_qp_enable hvs_qp_scale qp_map_enable max_delta_qp\n      0 h265cbr           20       30     5000         30            30            3000                   1        8       50        8       50        8       50             1            2             0           10\n----encode gop param----\nenc_idx  enc_id gop_preset_idx custom_gop_size decoding_refresh_type\n      0    h265              2               0                     2\n----encode intra refresh----\nenc_idx  enc_id intra_refresh_mode intra_refresh_arg\n      0    h265                  0                 0\n\n----encode longterm ref----\nenc_idx  enc_id use_longterm longterm_pic_period longterm_pic_using_period\n      0    h265            0                   0                         0\n----encode roi_params----\nenc_idx  enc_id roi_enable roi_map_array_count\n      0    h265          0                   0\n----encode mode_decision 1----\nenc_idx  enc_id mode_decision_enable pu04_delta_rate pu08_delta_rate pu16_delta_rate pu32_delta_rate pu04_intra_planar_delta_rate pu04_intra_dc_delta_rate pu04_intra_angle_delta_rate pu08_intra_planar_delta_rate pu08_intra_dc_delta_rate pu08_intra_angle_delta_rate pu16_intra_planar_delta_rate pu16_intra_dc_delta_rate pu16_intra_angle_delta_rate\n      0    h265                    0               0               0               0               0                            0                        0                           0                            0                        0                           0                            0                        0                           0\n\n----encode mode_decision 2----\nenc_idx  enc_id pu32_intra_planar_delta_rate pu32_intra_dc_delta_rate pu32_intra_angle_delta_rate cu08_intra_delta_rate cu08_inter_delta_rate cu08_merge_delta_rate cu16_intra_delta_rate cu16_inter_delta_rate cu16_merge_delta_rate cu32_intra_delta_rate cu32_inter_delta_rate cu32_merge_delta_rate\n      0    h265                            0                        0                           0                     0                     0                     0                     0                     0                     0                     0                     0                     0\n----encode h265_transform----\nenc_idx  enc_id chroma_cb_qp_offset chroma_cr_qp_offset user_scaling_list_enable\n      0    h265                   0                   0                        0\n----encode h265_pred_unit----\nenc_idx  enc_id intra_nxn_enable constrained_intra_pred_flag strong_intra_smoothing_enabled_flag max_num_merge\n      0    h265                1                           0                                   1             2\n----encode h265 timing----\nenc_idx  enc_id vui_num_units_in_tick vui_time_scale vui_num_ticks_poc_diff_one_minus1\n      0    h265                  1000          30000                                 0\n----encode h265 slice params----\nenc_idx  enc_id h265_independent_slice_mode h265_independent_slice_arg h265_dependent_slice_mode h265_dependent_slice_arg\n      0    h265                           0                          0                         0                        0\n----encode h265 deblk filter----\nenc_idx  enc_id slice_deblocking_filter_disabled_flag slice_beta_offset_div2 slice_tc_offset_div2 slice_loop_filter_across_slices_enabled_flag\n      0    h265                                     0                      0                    0                                            1\n\n----encode h265 sao param----\nenc_idx  enc_id sample_adaptive_offset_enabled_flag\n\n      0    h265                              1\n----encode status----\nenc_idx  enc_id cur_input_buf_cnt cur_output_buf_cnt left_recv_frame left_enc_frame total_input_buf_cnt total_output_buf_cnt     fps\n      0    h265                 4                  1               0              0                1093                 1089      35\n"})}),"\n",(0,r.jsx)(n.p,{children:"Parameter Explanation"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Debug Info Group"}),(0,r.jsx)(n.th,{children:"Status Parameter"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode enc param"}),(0,r.jsx)(n.td,{children:"Basic Encoding Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"profile: Profile type",(0,r.jsx)("br",{}),"level: H.265 level type",(0,r.jsx)("br",{}),"width: Encoding width",(0,r.jsx)("br",{}),"height: Encoding height",(0,r.jsx)("br",{}),"pix_fmt: Input frame pixel format",(0,r.jsx)("br",{}),"fbuf_count: Number of input frame buffers",(0,r.jsx)("br",{}),"extern_buf_flag: Whether external input buffers are used",(0,r.jsx)("br",{}),"bsbuf_count: Number of bitstream buffers",(0,r.jsx)("br",{}),"bsbuf_size: Bitstream buffer size",(0,r.jsx)("br",{}),"mirror: Whether mirroring is enabled",(0,r.jsx)("br",{}),"rotate: Whether rotation is enabled"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode h265cbr param"}),(0,r.jsx)(n.td,{children:"CBR Rate Control Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"rc_mode: Rate control mode",(0,r.jsx)("br",{}),"intra_period: I-frame interval",(0,r.jsx)("br",{}),"intra_qp: QP value for I-frames",(0,r.jsx)("br",{}),"bit_rate: Bitrate",(0,r.jsx)("br",{}),"frame_rate: Frame rate",(0,r.jsx)("br",{}),"initial_rc_qp: Initial QP value",(0,r.jsx)("br",{}),"vbv_buffer_size: VBV buffer size",(0,r.jsx)("br",{}),"ctu_level_rc_enalbe: Whether rate control operates at CTU level",(0,r.jsx)("br",{}),"min_qp_I: Minimum QP for I-frames",(0,r.jsx)("br",{}),"max_qp_I: Maximum QP for I-frames",(0,r.jsx)("br",{}),"min_qp_P: Minimum QP for P-frames",(0,r.jsx)("br",{}),"max_qp_P: Maximum QP for P-frames",(0,r.jsx)("br",{}),"min_qp_B: Minimum QP for B-frames",(0,r.jsx)("br",{}),"max_qp_B: Maximum QP for B-frames",(0,r.jsx)("br",{}),"hvs_qp_enable: Whether rate control operates at sub-CTU level",(0,r.jsx)("br",{}),"hvs_qp_scale: QP scaling factor",(0,r.jsx)("br",{}),"qp_map_enable: Enable QP map for ROI encoding",(0,r.jsx)("br",{}),"max_delta_qp: Maximum allowable deviation for HVS QP values"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode gop param"}),(0,r.jsx)(n.td,{children:"GOP Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"gop_preset_idx: Selected preset GOP structure",(0,r.jsx)("br",{}),"custom_gop_size: GOP size when using custom GOP",(0,r.jsx)("br",{}),"decoding_refresh_type: Specific type of IDR frame"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode intra refresh"}),(0,r.jsx)(n.td,{children:"Intra Refresh Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"intra_refresh_mode: Intra refresh mode",(0,r.jsx)("br",{}),"intra_refresh_arg: Intra refresh argument"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode longterm ref"}),(0,r.jsx)(n.td,{children:"Long-Term Reference Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"use_longterm: Enable long-term reference frames",(0,r.jsx)("br",{}),"longterm_pic_period: Period for long-term reference frames",(0,r.jsx)("br",{}),"longterm_pic_using_period: Period for referencing long-term reference frames"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode roi_params"}),(0,r.jsx)(n.td,{children:"ROI Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"roi_enable: Enable ROI encoding",(0,r.jsx)("br",{}),"roi_map_array_count: Number of elements in ROI map"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode mode_decision 1"}),(0,r.jsx)(n.td,{children:"Block Mode Decision Parameters 1"}),(0,r.jsx)(n.td,{children:"Various mode selection parameter values, including pu04_delta_rate, pu08_delta_rate, etc."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode mode_decision 2"}),(0,r.jsx)(n.td,{children:"Block Mode Decision Parameters 2"}),(0,r.jsx)(n.td,{children:"Various mode selection parameter values, including pu32_intra_planar_delta_rate, pu32_intra_dc_delta_rate, etc."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode h265_transform"}),(0,r.jsx)(n.td,{children:"Transform Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"chroma_cb_qp_offset: QP offset for Cb component",(0,r.jsx)("br",{}),"chroma_cr_qp_offset: QP offset for Cr component",(0,r.jsx)("br",{}),"user_scaling_list_enable: Enable user-defined scaling list"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode h265_pred_unit"}),(0,r.jsx)(n.td,{children:"Prediction Unit Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"intra_nxn_enable: Enable intra NXN PUs",(0,r.jsx)("br",{}),"constrained_intra_pred_flag: Whether intra prediction is constrained",(0,r.jsx)("br",{}),"strong_intra_smoothing_enabled_flag: Whether bidirectional linear interpolation is used in filtering",(0,r.jsx)("br",{}),"max_num_merge: Number of merge candidates"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode h265 timing"}),(0,r.jsx)(n.td,{children:"Timing Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"vui_num_units_in_tick: Number of time units per tick",(0,r.jsx)("br",{}),"vui_time_scale: Number of time units per second",(0,r.jsx)("br",{}),"vui_num_ticks_poc_diff_one_minus1: Number of clock ticks corresponding to a picture order count difference of 1"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode h265 slice params"}),(0,r.jsx)(n.td,{children:"Slice Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"h265_independent_slice_mode: Independent slice encoding mode",(0,r.jsx)("br",{}),"h265_independent_slice_arg: Size of independent slices",(0,r.jsx)("br",{}),"h265_dependent_slice_mode: Dependent slice encoding mode",(0,r.jsx)("br",{}),"h265_dependent_slice_arg: Size of dependent slices"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode h265 deblk filter"}),(0,r.jsx)(n.td,{children:"Deblocking Filter Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"slice_deblocking_filter_disabled_flag: Whether in-slice deblocking filtering is disabled",(0,r.jsx)("br",{}),"slice_beta_offset_div2: \u03b2 deblocking parameter offset for current slice",(0,r.jsx)("br",{}),"slice_tc_offset_div2: tC deblocking parameter offset for current slice",(0,r.jsx)("br",{}),"slice_loop_filter_across_slices_enabled_flag: Whether cross-slice boundary filtering is enabled"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode h265 sao param"}),(0,r.jsx)(n.td,{children:"SAO Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"sample_adaptive_offset_enabled_flag: Whether sample adaptive offset is applied to reconstructed pictures after deblocking"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode status"}),(0,r.jsx)(n.td,{children:"Current Encoding Status Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance index",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"cur_input_buf_cnt: Number of currently used input buffers",(0,r.jsx)("br",{}),"cur_output_buf_cnt: Number of currently used output buffers",(0,r.jsx)("br",{}),"left_recv_frame: Remaining frames to receive (valid only when receive_frame_number is set)",(0,r.jsx)("br",{}),"left_enc_frame: Remaining frames to encode (valid only when receive_frame_number is set)",(0,r.jsx)("br",{}),"total_input_buf_cnt: Total number of input buffers used so far",(0,r.jsx)("br",{}),"total_output_buf_cnt: Total number of output buffers used so far",(0,r.jsx)("br",{}),"fps: Current frame rate"]})]})]})]}),"\n",(0,r.jsx)(n.h5,{id:"decoding-status",children:"Decoding Status"}),"\n",(0,r.jsx)(n.p,{children:"Decoding Debug Information"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"cat /sys/kernel/debug/vpu/vdec\nroot@ubuntu:~# cat /sys/kernel/debug/vpu/vdec\n----decode param----\ndec_idx dec_id feed_mode pix_fmt bitstream_buf_size bitstream_buf_count frame_buf_count\n   0   h265     1      0     13271040          6   6\n----h265 decode param----\ndec_idx dec_id reorder_enable skip_mode bandwidth_Opt cra_as_bla dec_temporal_id_mode target_dec_temporal_id_plus1\n   0   h265        1          0          1            0        0                      0\n----decode frameinfo----\ndec_idx dec_id display_width display_height\n    0   h265       4096       2160\n----decode status----\ndec_idx dec_id cur_input_buf_cnt cur_output_buf_cnt total_input_buf_cnt total_output_buf_cnt fps\n   0   h265          5                1              458       453         53\n"})}),"\n",(0,r.jsx)(n.p,{children:"Parameter Explanation"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Debug Info Group"}),(0,r.jsx)(n.th,{children:"Status Parameter"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"decode param"}),(0,r.jsx)(n.td,{children:"Basic Decoding Parameters"}),(0,r.jsxs)(n.td,{children:["dec_idx: Decoding instance index",(0,r.jsx)("br",{}),"dec_id: Decoding type",(0,r.jsx)("br",{}),"feed_mode: Data feeding mode",(0,r.jsx)("br",{}),"pix_fmt: Output pixel format",(0,r.jsx)("br",{}),"bitstream_buf_size: Input bitstream buffer size",(0,r.jsx)("br",{}),"bitstream_buf_count: Number of input bitstream buffers",(0,r.jsx)("br",{}),"frame_buf_count: Number of output frame buffers"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"h265 decode param"}),(0,r.jsx)(n.td,{children:"H.265 Decoding Basic Parameters"}),(0,r.jsxs)(n.td,{children:["dec_idx: Decoding instance index",(0,r.jsx)("br",{}),"dec_id: Decoding type",(0,r.jsx)("br",{}),"reorder_enable: Enable decoder to output frames in display order",(0,r.jsx)("br",{}),"skip_mode: Enable frame decode skip mode",(0,r.jsx)("br",{}),"bandwidth_Opt: Enable bandwidth optimization mode",(0,r.jsx)("br",{}),"cra_as_bla: Treat CRA as BLA",(0,r.jsx)("br",{}),"dec_temporal_id_mode: Temporal ID selection mode",(0,r.jsx)("br",{}),"target_dec_temporal_id_plus1: Specified temporal ID value"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"decode frameinfo"}),(0,r.jsx)(n.td,{children:"Decoded Output Frame Info"}),(0,r.jsxs)(n.td,{children:["dec_idx: Decoding instance index",(0,r.jsx)("br",{}),"dec_id: Decoding type",(0,r.jsx)("br",{}),"display_width: Display width",(0,r.jsx)("br",{}),"display_height: Display height"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"decode status"}),(0,r.jsx)(n.td,{children:"Current Decoding Status Parameters"}),(0,r.jsxs)(n.td,{children:["dec_idx: Decoding instance index",(0,r.jsx)("br",{}),"dec_id: Decoding type",(0,r.jsx)("br",{}),"cur_input_buf_cnt: Number of currently used input buffers",(0,r.jsx)("br",{}),"cur_output_buf_cnt: Number of currently used output buffers",(0,r.jsx)("br",{}),"total_input_buf_cnt: Total number of input buffers used so far",(0,r.jsx)("br",{}),"total_output_buf_cnt: Total number of output buffers used so far",(0,r.jsx)("br",{}),"fps: Current frame rate"]})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"jpu-debugging-method",children:"JPU Debugging Method"}),"\n",(0,r.jsx)(n.p,{children:"The JPU (JPEG Processing Unit) is primarily used to perform JPEG/MJPEG encoding and decoding. Users can input YUV data for encoding or JPEG images for decoding via the CODEC interface, and obtain the encoded JPEG images or decoded YUV data after JPU processing."}),"\n",(0,r.jsx)(n.h5,{id:"encoding-status-1",children:"Encoding Status"}),"\n",(0,r.jsx)(n.p,{children:"Encoding Debug Information"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"cat /sys/kernel/debug/jpu/jenc\nroot@ubuntu:~# cat /sys/kernel/debug/jpu/jenc\n----encode param----\nenc_idx  enc_id width height pix_fmt fbuf_count extern_buf_flag bsbuf_count bsbuf_size mirror rotate\n      0    jpeg  1920   1088       1          5               0           5    3137536      0      0\n\n----encode rc param----\nenc_idx   rc_mode frame_rate quality_factor\n      0 noratecontrol          0              0\n----encode status----\nenc_idx  enc_id cur_input_buf_cnt cur_output_buf_cnt left_recv_frame left_enc_frame total_input_buf_cnt total_output_buf_cnt     fps\n      0    jpeg                 4                  1               0              0                4344                 4340     287\n"})}),"\n",(0,r.jsx)(n.p,{children:"Parameter Explanation"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Debug Info Group"}),(0,r.jsx)(n.th,{children:"Status Parameter"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode param"}),(0,r.jsx)(n.td,{children:"Basic Encoding Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"width: Image width",(0,r.jsx)("br",{}),"height: Image height",(0,r.jsx)("br",{}),"pix_fmt: Pixel format",(0,r.jsx)("br",{}),"fbuf_count: Number of input framebuffer buffers",(0,r.jsx)("br",{}),"extern_buf_flag: Whether user-allocated input buffers are used",(0,r.jsx)("br",{}),"bsbuf_count: Number of output bitstream buffers",(0,r.jsx)("br",{}),"bsbuf_size: Size of output bitstream buffer",(0,r.jsx)("br",{}),"mirror: Whether mirroring is enabled",(0,r.jsx)("br",{}),"rotate: Whether rotation is enabled"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode rc param"}),(0,r.jsx)(n.td,{children:"MJPEG Rate Control Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance",(0,r.jsx)("br",{}),"rc_mode: Rate control mode",(0,r.jsx)("br",{}),"frame_rate: Target frame rate",(0,r.jsx)("br",{}),"quality_factor: Quantization factor"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"encode status"}),(0,r.jsx)(n.td,{children:"Current Encoding Status Parameters"}),(0,r.jsxs)(n.td,{children:["enc_idx: Encoding instance ID",(0,r.jsx)("br",{}),"enc_id: Encoding type",(0,r.jsx)("br",{}),"cur_input_buf_cnt: Number of currently used input buffers",(0,r.jsx)("br",{}),"cur_output_buf_cnt: Number of currently used output buffers",(0,r.jsx)("br",{}),"left_recv_frame: Remaining frames to receive (valid only if receive_frame_number is set)",(0,r.jsx)("br",{}),"left_enc_frame: Remaining frames to encode (valid only if receive_frame_number is set)",(0,r.jsx)("br",{}),"total_input_buf_cnt: Total number of input buffers used so far",(0,r.jsx)("br",{}),"total_output_buf_cnt: Total number of output buffers used so far",(0,r.jsx)("br",{}),"fps: Current frame rate"]})]})]})]}),"\n",(0,r.jsx)(n.h5,{id:"decoding-status-1",children:"Decoding Status"}),"\n",(0,r.jsx)(n.p,{children:"Decoding Debug Information"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"cat /sys/kernel/debug/jpu/jdec\nroot@ubuntu:~# cat /sys/kernel/debug/jpu/jdec\n\n----decode param----\ndec_idx  dec_id feed_mode pix_fmt bitstream_buf_size bitstream_buf_count frame_buf_count mirror rotate\n      0    jpeg         1       1            3133440                   5               5      0      0\n\n----decode frameinfo----\ndec_idx  dec_id display_width display_height\n      0    jpeg          1920           1088\n\n----decode status----\ndec_idx  dec_id cur_input_buf_cnt cur_output_buf_cnt total_input_buf_cnt total_output_buf_cnt     fps\n      0    jpeg                 0                  1                3779                 3779     264\n"})}),"\n",(0,r.jsx)(n.p,{children:"Parameter Explanation"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Debug Info Group"}),(0,r.jsx)(n.th,{children:"Status Parameter"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"decode param"}),(0,r.jsx)(n.td,{children:"Basic Decoding Parameters"}),(0,r.jsxs)(n.td,{children:["dec_idx: Decoding instance",(0,r.jsx)("br",{}),"dec_id: Decoding type",(0,r.jsx)("br",{}),"feed_mode: Feed mode",(0,r.jsx)("br",{}),"pix_fmt: Pixel format",(0,r.jsx)("br",{}),"bitstream_buf_size: Size of input bitstream buffer",(0,r.jsx)("br",{}),"bitstream_buf_count: Number of input bitstream buffers",(0,r.jsx)("br",{}),"frame_buf_count: Number of output framebuffer buffers",(0,r.jsx)("br",{}),"mirror: Whether mirroring is enabled",(0,r.jsx)("br",{}),"rotate: Whether rotation is enabled"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"decode frameinfo"}),(0,r.jsx)(n.td,{children:"Decoded Frame Info"}),(0,r.jsxs)(n.td,{children:["dec_idx: Decoding instance ID",(0,r.jsx)("br",{}),"dec_id: Decoding type",(0,r.jsx)("br",{}),"display_width: Display width",(0,r.jsx)("br",{}),"display_height: Display height"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"decode status"}),(0,r.jsx)(n.td,{children:"Current Decoding Status Parameters"}),(0,r.jsxs)(n.td,{children:["dec_idx: Decoding instance ID",(0,r.jsx)("br",{}),"dec_id: Decoding type",(0,r.jsx)("br",{}),"cur_input_buf_cnt: Number of currently used input buffers",(0,r.jsx)("br",{}),"cur_output_buf_cnt: Number of currently used output buffers",(0,r.jsx)("br",{}),"total_input_buf_cnt: Total number of input buffers used so far",(0,r.jsx)("br",{}),"total_output_buf_cnt: Total number of output buffers used so far",(0,r.jsx)("br",{}),"fps: Current frame rate"]})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"typical-scenarios",children:"Typical Scenarios"}),"\n",(0,r.jsx)(n.h4,{id:"single-stream-encoding",children:"Single-Stream Encoding"}),"\n",(0,r.jsx)(n.p,{children:"The single-stream encoding scenario is illustrated below. Scenario 0 is a simple case: YUV video/image files are read from eMMC, encoded by VPU hardware into H.26x bitstreams or by JPU hardware into JPEG images, and finally saved back to eMMC as files. Scenario 1 is a more complex pipeline where camera-captured data is encoded, compressed, and either stored or transmitted over network/PCIe."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/788c1e3b839232111ccd53d35d25e278.png",alt:""})}),"\n",(0,r.jsx)(n.h4,{id:"single-stream-decoding",children:"Single-Stream Decoding"}),"\n",(0,r.jsx)(n.p,{children:"The single-stream decoding scenario is illustrated below. Scenario 0 is a simple case: H.26x bitstreams or JPEG image files are read from eMMC, decoded by VPU or JPU hardware into YUV data, and saved back to eMMC as files. Scenario 1 is a complex pipeline where encoded video or image data is received via network or PCIe, decoded by VPU or JPU hardware, and displayed via IDE."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/e50f9bf3c4d1ecfbd36b354f9009e8bc.png",alt:""})}),"\n",(0,r.jsx)(n.h4,{id:"multi-stream-encoding",children:"Multi-Stream Encoding"}),"\n",(0,r.jsx)(n.p,{children:"The multi-stream encoding scenario is shown below. Scenario 0 is a simple file-input case. Scenario 1 is a complex pipeline involving multiple modules. Note that in Scenario 1, the capabilities and limitations of all modules in the pipeline must be carefully considered."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/272e3467c640af379d1b4c0a1de27eae.png",alt:""})}),"\n",(0,r.jsx)(n.h4,{id:"multi-stream-decoding",children:"Multi-Stream Decoding"}),"\n",(0,r.jsx)(n.p,{children:"The multi-stream decoding scenario is shown below. Scenario 0 is a simple file-input case. Scenario 1 is a complex pipeline involving multiple modules. Note that in Scenario 1, the capabilities and limitations of all modules in the pipeline must be carefully considered."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/04f0aba90a1d65017dfeb90f9afa43e2.png",alt:""})}),"\n",(0,r.jsx)(n.h2,{id:"codec-api",children:"Codec API"}),"\n",(0,r.jsx)(n.h3,{id:"mediacodec-interface-description",children:"MediaCodec Interface Description"}),"\n",(0,r.jsxs)(n.p,{children:["The MediaCodec module is primarily used for audio, video, and JPEG image encoding/decoding. This module provides a set of interfaces to facilitate user input of data to be processed and retrieval of processed data. It supports multiple concurrent encoding or decoding instances. Video and JPEG image encoding/decoding are hardware-accelerated, requiring users to link against ",(0,r.jsx)(n.code,{children:"libmultimedia.so"}),". Audio encoding/decoding is software-based using FFmpeg interfaces, requiring users to link against ",(0,r.jsx)(n.code,{children:"libffmedia.so"}),". The table below lists the video and audio codecs supported on RDK S100. Note that AAC encoding/decoding requires a license; users must obtain proper authorization before enabling related features."]}),"\n",(0,r.jsx)(n.p,{children:"H.265 supports up to Main profile and Level 5.1, with Main-tier support. H.264 supports up to High profile and Level 5.2. MJPEG/JPEG supports ISO/IEC 10918-1 Baseline sequential. Supported audio codecs include: G.711 A-law/Mu-law, G.729 ADPCM, ADPCM IMA WAV, FLAC, AAC LC, AAC Main, AAC SSR, AAC LTP, AAC LD, AAC HE, and AAC HEv2 (AAC requires a license)."}),"\n",(0,r.jsx)(n.p,{children:"Additionally, video and image sources include two types: images from VIO input and user-provided YUV data (which may be loaded from files or received over a network). Audio sources include two types: audio from MIC input (digitized by the Audio Codec) and user-provided PCM data (which may be loaded from files or received over a network)."}),"\n",(0,r.jsx)(n.h4,{id:"gop",children:"GOP"}),"\n",(0,r.jsx)(n.p,{children:"H.264/H.265 encoding supports GOP structure configuration. Users can select from nine predefined GOP structures or define custom GOP structures."}),"\n",(0,r.jsx)(n.h5,{id:"gop-structure-table",children:"GOP Structure Table"}),"\n",(0,r.jsx)(n.p,{children:"A GOP structure table defines a periodic GOP pattern used throughout the encoding process. Elements in a single structure table are described below. Users can specify reference frames for each picture. If a frame after an IDR references a frame before the IDR, the encoder automatically handles this to avoid invalid references\u2014users need not worry about such cases. When defining a custom GOP, users must specify the number of structure tables (up to 3), and tables must be ordered in decoding sequence."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Element"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Type"}),(0,r.jsx)(n.td,{children:"Slice type (I, P)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"POC"}),(0,r.jsx)(n.td,{children:"Display order of the frame within a GOP, ranging from 1 to GOP size"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"QPoffset"}),(0,r.jsx)(n.td,{children:"Quantization parameter offset for the picture in the custom GOP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"NUM_REF_PIC_L0"}),(0,r.jsx)(n.td,{children:"Flag to enable multi-reference pictures for P frames. Valid only if PIC_TYPE is P"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"temporal_id"}),(0,r.jsx)(n.td,{children:"Temporal layer of the frame. A frame cannot reference another frame with a higher temporal_id (range: 0\u20136)."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1st_ref_POC"}),(0,r.jsx)(n.td,{children:"POC of the first reference picture in L0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2nd_ref_POC"}),(0,r.jsx)(n.td,{children:"POC of the first reference picture in L1 if Type is B; POC of the second reference picture in L0 if Type is P. Note that reference_L1 can share the same POC as reference_L0 in B slices, but for better compression efficiency, it is recommended that reference_L1 and reference_L0 have different POCs."})]})]})]}),"\n",(0,r.jsx)(n.h5,{id:"predefined-gop-structures",children:"Predefined GOP Structures"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"GOP Structure"}),(0,r.jsx)(n.th,{children:"Low Delay (encoding order = display order)"}),(0,r.jsx)(n.th,{children:"GOP Size"}),(0,r.jsx)(n.th,{children:"Encoding Order"}),(0,r.jsx)(n.th,{children:"Minimum Source Frame Buffer"}),(0,r.jsx)(n.th,{children:"Minimum Decoded Picture Buffer"}),(0,r.jsx)(n.th,{children:"Intra Period (I Frame Interval) Requirement"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"I"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"I0-I1-I2\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"P"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"P0-P1-P2\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"B"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"B0-B1-B2\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"BP"}),(0,r.jsx)(n.td,{children:"No"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"B1-P0-B3-P2\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"Multiple of 2"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"BBBP"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"B2-B1-B3-P0\u2026"}),(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"Multiple of 4"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"PPPP"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"P0-P1-P2-P3\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"BBBB"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"B0-B1-B2-B3\u2026"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"BBBB BBBB"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"B3-B2-B4-B1-B6-B5-B7-B0\u2026"}),(0,r.jsx)(n.td,{children:"12"}),(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"Multiple of 8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"9"}),(0,r.jsx)(n.td,{children:"P"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"P0"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"The following describes the nine predefined GOP structures."}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 1"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames with no inter-frame references;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop1.png",alt:"gop1"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop2.png",alt:"gop2"})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 2"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and P-frames;"}),"\n",(0,r.jsx)(n.li,{children:"P-frames reference two previous frames;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop3.png",alt:"gop3"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop4.png",alt:"gop4"})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 3"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference two previous frames;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop5.png",alt:"gop5"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop6.png",alt:"gop6"})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 4"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains I-, P-, and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"P-frames reference two previous frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference one previous and one future frame;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop7.png",alt:"gop7"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop8.png",alt:"gop8"})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 5"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains I-, P-, and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"P-frames reference two previous frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference one previous and one future frame (which can be either P or B);"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop9.png",alt:"gop9"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop10.png",alt:"gop10"})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 6"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and P-frames;"}),"\n",(0,r.jsx)(n.li,{children:"P-frames reference two previous frames;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop11.png",alt:"gop11"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop12.png",alt:"gop12"})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 7"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference two previous frames;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop13.png",alt:"gop13"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop14.png",alt:"gop14"})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 8"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and B-frames;"}),"\n",(0,r.jsx)(n.li,{children:"B-frames reference one previous and one future frame;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop15.png",alt:"gop15"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop16.png",alt:"gop16"})}),"\n",(0,r.jsx)(n.p,{children:"GOP Preset 9"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains only I-frames and P-frames;"}),"\n",(0,r.jsx)(n.li,{children:"Each P-frame references one forward reference frame;"}),"\n",(0,r.jsx)(n.li,{children:"Low latency;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop17.png",alt:"gop17"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/gop18.png",alt:"gop18"})}),"\n",(0,r.jsx)(n.h4,{id:"long-term-reference-frames",children:"Long-term Reference Frames"}),"\n",(0,r.jsx)(n.p,{children:"Users can specify the interval for long-term reference frames and the interval at which frames reference long-term reference frames, as shown in the figure below:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/reference_frame.png",alt:"reference_frame"})}),"\n",(0,r.jsx)(n.h4,{id:"intra-refresh",children:"Intra Refresh"}),"\n",(0,r.jsx)(n.p,{children:"Intra Refresh mode enhances error resilience by periodically inserting intra-coded MBs/CTUs within non-I frames. It provides the decoder with more recovery points to prevent image corruption caused by temporal errors. Users can specify the number of consecutive rows, columns, or step size of MBs/CTUs to force the encoder to insert intra-coded units. Additionally, users may specify the size of intra-coded units, allowing the encoder to internally determine which blocks require intra coding."}),"\n",(0,r.jsx)(n.h4,{id:"rate-control",children:"Rate Control"}),"\n",(0,r.jsx)(n.p,{children:"MediaCodec supports bitrate control for H.264, H.265, and MJPEG codecs. For H.264 and H.265 encoding channels, it supports five rate control modes: CBR, VBR, AVBR, FixQp, and QpMap. For MJPEG encoding channels, it supports FixQp mode."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"CBR ensures a stable overall encoded bitrate;"}),"\n",(0,r.jsx)(n.li,{children:"VBR maintains consistent visual quality;"}),"\n",(0,r.jsx)(n.li,{children:"AVBR balances both bitrate and quality, producing a relatively stable stream in terms of both bitrate and image quality;"}),"\n",(0,r.jsx)(n.li,{children:"FixQp fixes the QP value for every I-frame and P-frame;"}),"\n",(0,r.jsx)(n.li,{children:"QpMap assigns a specific QP value to each block within a frame (block size is 32\xd732 for H.265 and 16\xd716 for H.264)."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"For CBR and AVBR, the encoder internally determines an appropriate QP value for each frame to maintain constant bitrate. The encoder supports three levels of rate control: frame-level, CTU/MB-level, and subCTU/subMB-level."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Frame-level control calculates a single QP per frame based on the target bitrate to ensure bitrate stability."}),"\n",(0,r.jsx)(n.li,{children:"CTU/MB-level control assigns a QP to each 64\xd764 CTU or 16\xd716 MB according to its target bitrate, achieving finer bitrate control, though frequent QP adjustments may cause visual quality instability."}),"\n",(0,r.jsx)(n.li,{children:"subCTU/subMB-level control assigns a QP to each 32\xd732 subCTU or 8\xd78 subMB. Complex blocks receive higher QP values, while static blocks receive lower QP values\u2014since the human eye is more sensitive to static regions than complex ones. Detection of complex vs. static regions relies on internal hardware modules. This level aims to improve subjective visual quality while maintaining bitrate stability, resulting in higher SSIM scores but potentially lower PSNR scores."}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"roi",children:"ROI"}),"\n",(0,r.jsx)(n.p,{children:"ROI encoding works similarly to QpMap: users must assign a QP value to each block in raster-scan order, as illustrated below:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/roi_map.png",alt:"roi_map"})}),"\n",(0,r.jsx)(n.p,{children:"For H.264, each block is 16\xd716; for H.265, it is 32\xd732. In the ROI map, each QP value occupies one byte, ranging from 0 to 51. ROI encoding can operate alongside CBR or AVBR."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"When CBR/AVBR is disabled, the actual QP for each block equals the value specified in the ROI map."}),"\n",(0,r.jsxs)(n.li,{children:["When CBR/AVBR is enabled, the actual QP for block ",(0,r.jsx)(n.em,{children:"i"})," is calculated as:"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"QP(i) = MQP(i) + RQP(i) - ROIAvgQP"}),"\n",(0,r.jsx)(n.p,{children:"where:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"MQP is the value from the ROI map,"}),"\n",(0,r.jsx)(n.li,{children:"RQP is the QP determined by the encoder\u2019s internal rate control,"}),"\n",(0,r.jsx)(n.li,{children:"ROIAvgQP is the average QP value across the entire ROI map."}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"inputoutput-buffer-management",children:"Input/Output Buffer Management"}),"\n",(0,r.jsxs)(n.p,{children:["MediaCodec uses two types of buffers: input and output. Typically, these buffers are allocated uniformly by MediaCodec via the ION interface, so users do not need to manage allocation directly. Instead, users should call ",(0,r.jsx)(n.code,{children:"dequeue"})," to obtain an available buffer before use and ",(0,r.jsx)(n.code,{children:"queue"})," to return it after processing."]}),"\n",(0,r.jsxs)(n.p,{children:["However, to reduce unnecessary buffer copying in certain scenarios\u2014e.g., when using PYM\u2019s output buffer directly as MediaCodec input (since PYM allocates this buffer internally via ION)\u2014MediaCodec also supports user-allocated input buffers. In such cases, users must allocate physically contiguous buffers via the ION interface and set the ",(0,r.jsx)(n.code,{children:"external_frame_buf"})," field in ",(0,r.jsx)(n.code,{children:"media_codec_context_t"})," before configuring MediaCodec."]}),"\n",(0,r.jsxs)(n.p,{children:["Note: Even when providing external input buffers, users must still perform ",(0,r.jsx)(n.code,{children:"dequeue"})," to retrieve buffer metadata (e.g., virtual and physical addresses), populate this information, and then call ",(0,r.jsx)(n.code,{children:"queue"}),"."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/buffer.png",alt:"buffer"})}),"\n",(0,r.jsx)(n.h4,{id:"frame-rate-control",children:"Frame Rate Control"}),"\n",(0,r.jsx)(n.p,{children:"MediaCodec does not currently support internal frame rate control."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["If users do ",(0,r.jsx)(n.strong,{children:"not"})," enable direct VIO\u2013MediaCodec interaction via ",(0,r.jsx)(n.code,{children:"hb_mm_mc_set_camera"}),", they must manually control the input buffer frame rate."]}),"\n",(0,r.jsxs)(n.li,{children:["If VIO\u2013MediaCodec interaction ",(0,r.jsx)(n.strong,{children:"is"})," enabled, users only manage output buffers; input buffering is handled automatically. In this mode, MediaCodec performs no frame rate control on input buffers. If encoding stalls or the input buffer queue becomes full, MediaCodec will wait until space becomes available before proceeding."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"frame-skip-configuration",children:"Frame Skip Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["Users can call ",(0,r.jsx)(n.code,{children:"hb_mm_mc_skip_pic"}),' to set the next queued input frame to "skip" mode. This mode applies only to non-I frames. In skip mode, the encoder ignores the input frame and instead generates the reconstructed frame by reusing the previous frame\u2019s reconstruction, encoding the current input as a P-frame.']}),"\n",(0,r.jsx)(n.h4,{id:"jpeg-codec-limitations",children:"JPEG Codec Limitations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["For JPEG/MJPEG ",(0,r.jsx)(n.strong,{children:"encoding"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"With YUV420/YUV422 input: width must be 16-byte aligned, height 8-byte aligned."}),"\n",(0,r.jsx)(n.li,{children:"With YUV440/YUV444/YUV400 input: both width and height must be 8-byte aligned."}),"\n",(0,r.jsx)(n.li,{children:"If cropping is applied, the crop origin (x, y) must also be 8-byte aligned."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["For JPEG/MJPEG ",(0,r.jsx)(n.strong,{children:"encoding with 90\xb0/270\xb0 rotation"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"YUV420: width 16-aligned, height 8-aligned."}),"\n",(0,r.jsx)(n.li,{children:"YUV422/YUV440: width 16-aligned, height 16-aligned."}),"\n",(0,r.jsx)(n.li,{children:"YUV444/YUV400: width and height 8-aligned."}),"\n",(0,r.jsxs)(n.li,{children:["With cropping:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"YUV420: crop width 16-aligned, crop height 8-aligned."}),"\n",(0,r.jsx)(n.li,{children:"YUV422/YUV440: crop width 16-aligned, crop height 16-aligned."}),"\n",(0,r.jsx)(n.li,{children:"YUV444/YUV400: crop width and height 8-aligned."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["For JPEG/MJPEG ",(0,r.jsx)(n.strong,{children:"encoding with 90\xb0/270\xb0 rotation"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"YUV422 input becomes YUV440 after rotation."}),"\n",(0,r.jsx)(n.li,{children:"YUV440 input becomes YUV422 after rotation."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["For JPEG/MJPEG ",(0,r.jsx)(n.strong,{children:"decoding with rotation or mirroring"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Output YUV format must match input format, ",(0,r.jsx)(n.strong,{children:"except"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"When decoding YUV422 JPEG/MJPEG with 90\xb0/270\xb0 rotation, output format must be YUV440p, YUYV, YVYU, UYVY, or VYUY."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["JPEG/MJPEG ",(0,r.jsx)(n.strong,{children:"decoding"}),": Rotation/mirroring cannot be used simultaneously with cropping."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["JPEG/MJPEG ",(0,r.jsx)(n.strong,{children:"decoding"}),": Output buffer dimensions must align with the input format\u2019s MCU width and height. If cropping is enabled, all crop parameters (origin x/y and width/height) must also align with the MCU dimensions.",(0,r.jsx)(n.br,{}),"\n","(MCU sizes: 420 \u2192 16\xd716, 422 \u2192 16\xd78, 440 \u2192 8\xd716, 400 \u2192 8\xd78, 444 \u2192 8\xd78.)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["JPEG/MJPEG ",(0,r.jsx)(n.strong,{children:"decoding"}),": Output format Packed YUV444 requires input in YUV444 format."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["JPEG/MJPEG ",(0,r.jsx)(n.strong,{children:"decoding"}),": Only supports ",(0,r.jsx)(n.code,{children:"MC_FEEDING_MODE_FRAME_SIZE"})," mode."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["JPEG ",(0,r.jsx)(n.strong,{children:"encoding"}),": If the user specifies the bitstream buffer size, an additional 4KB must be allocated."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["JPEG ",(0,r.jsx)(n.strong,{children:"encoding"}),": Since the encoder processes data in 16\xd716 units, non-aligned input may result in padding differences in the final encoded data. This does not affect valid pixel data but is a hardware limitation; caution is advised when performing MD5 comparisons."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"api-reference",children:"API Reference"}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_descriptor",children:"hb_mm_mc_get_descriptor"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"const media_codec_descriptor_t* hb_mm_mc_get_descriptor(media_codec_id_t codec_id);"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameters\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_id_t codec_id: Specifies the codec type."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Non-null: Codec descriptor containing information."}),"\n",(0,r.jsx)(n.li,{children:"NULL: No descriptor found for the given codec ID."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Retrieves codec information supported by MediaCodec based on ",(0,r.jsx)(n.code,{children:"codec_id"}),", including codec name, detailed description, MIME type, and supported profiles."]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\nint main(int argc, char *argv[])\n{\n    const media_codec_descriptor_t *desc = NULL;\n    desc = hb_mm_mc_get_descriptor(MEDIA_CODEC_ID_H265);\n    return 0;\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_default_context",children:"hb_mm_mc_get_default_context"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_default_context(media_codec_id_t codec_id, hb_bool encoder, media_codec_context_t *context);"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameters\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_id_t codec_id: Specifies the codec type."}),"\n",(0,r.jsxs)(n.li,{children:["[IN] hb_bool encoder: Indicates whether the codec is an encoder (",(0,r.jsx)(n.code,{children:"true"}),") or decoder (",(0,r.jsx)(n.code,{children:"false"}),")."]}),"\n",(0,r.jsx)(n.li,{children:"[OUT] media_codec_context_t *context: Receives the default context for the specified codec."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Success."}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Obtains the default configuration attributes for a specified codec."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\nint main(int argc, char *argv[])\n{\n    int ret = 0;\n    media_codec_context_t context;\n    memset(&context, 0x00, sizeof(context));\n    ret = hb_mm_mc_get_default_context(MEDIA_CODEC_ID_H265, 1, &context);\n    return 0;\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_initialize",children:"hb_mm_mc_initialize"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_initialize(media_codec_context_t *context)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameters\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context configuration for the codec."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Success."}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error."}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters."}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not permitted."}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INSUFFICIENT_RES: Insufficient internal memory resources."}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_NO_FREE_INSTANCE: No free instance available (max: 32 for Video, 64 for MJPEG/JPEG, 32 for Audio)."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Initializes an encoder or decoder. Upon success, MediaCodec enters the ",(0,r.jsx)(n.code,{children:"MEDIA_CODEC_STATE_INITIALIZED"})," state."]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\nstatic Uint64 osal_gettime(void)\n{\n    struct timespec tp;\n    clock_gettime(CLOCK_MONOTONIC, &tp);\n    return ((Uint64)tp.tv_sec*1000 + tp.tv_nsec/1000000);\n}\ntypedef struct MediaCodecTestContext {\n    media_codec_context_t *context;\n    char *inputFileName;\n    char *outputFileName;\n} MediaCodecTestContext;\ntypedef struct AsyncMediaCtx {\n    media_codec_context_t *ctx;\n    FILE *inFile;\n    FILE *outFile;\n    int lastStream;\n    Uint64 startTime;\n    int32_t duration;\n} AsyncMediaCtx;\nstatic void on_encoder_input_buffer_available(hb_ptr userdata,\nmedia_codec_buffer_t *inputBuffer) {\n    AsyncMediaCtx *asyncCtx = (AsyncMediaCtx *)userdata;\n    Int noMoreInput = 0;\n    hb_s32 ret = 0;\n    Uint64 curTime = 0;\n    if (!noMoreInput) {\n        curTime = osal_gettime();\n        if ((curTime - asyncCtx->startTime)/1000 < (uint32_t)asyncCtx->duration) {\n            ret = fread(inputBuffer->vframe_buf.vir_ptr[0], 1,\n            inputBuffer->vframe_buf.size, asyncCtx->inFile);\n            if (ret <= 0) {\n                if(fseek(asyncCtx->inFile, 0, SEEK_SET)) {\n                printf("Failed to rewind input file\\n");\n            } else {\n                ret = fread(inputBuffer->vframe_buf.vir_ptr[0], 1,\n                inputBuffer->vframe_buf.size, asyncCtx->inFile);\n                if (ret <= 0) {\n                    printf("Failed to read input file\\n");\n                }\n            }\n        }\n    }\n    if (!ret) {\n        printf("%s There is no more input data!\\n", TAG);\n        inputBuffer->vframe_buf.frame_end = TRUE;\n        noMoreInput = 1;\n    } else {\n        inputBuffer->vframe_buf.frame_end = TRUE;\n        inputBuffer->vframe_buf.size = 0;\n    }\n}\nstatic void on_encoder_output_buffer_available(hb_ptr userdata,\nmedia_codec_buffer_t *outputBuffer,\nmedia_codec_output_buffer_info_t *extraInfo) {\n    AsyncMediaCtx *asyncCtx = (AsyncMediaCtx *)userdata;\n    mc_265_output_stream_info_t info = extraInfo->video_stream_info;\n    fwrite(outputBuffer->vstream_buf.vir_ptr,\n    outputBuffer->vstream_buf.size, 1, asyncCtx->outFile);\n    if (outputBuffer->vstream_buf.stream_end) {\n        printf("There is no more output data!\\n");\n        asyncCtx->lastStream = 1;\n    }\n}\nstatic void on_encoder_media_codec_message(hb_ptr userdata, hb_s32\n       error) {\n    AsyncMediaCtx *asyncCtx = (AsyncMediaCtx *)userdata;\n    if (error) {\n        asyncCtx->lastStream = 1;\n        printf("ERROR happened!\\n");\n    }\n}\nstatic void on_vlc_buffer_message(hb_ptr userdata, hb_s32 * vlc_buf)\n{\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)userdata;\n    printf("%s %s VLC Buffer size = %d; Reset to %d.\\n", TAG,\n    __FUNCTION__,\n    *vlc_buf, ctx->vlc_buf_size);\n    *vlc_buf = ctx->vlc_buf_size;\n}\nstatic void do_async_encoding(void *arg) {\n    hb_s32 ret = 0;\n    FILE *outFile;\n    FILE *inFile;\n    int step = 0;\n    AsyncMediaCtx asyncCtx;\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)arg;\n    media_codec_context_t *context = ctx->context;\n    char *inputFileName = ctx->inputFileName;\n    char *outputFileName = ctx->outputFileName;\n    media_codec_state_t state = MEDIA_CODEC_STATE_NONE;\n    inFile = fopen(inputFileName, "rb");\n    if (!inFile) {\n        goto ERR;\n    }\n    outFile = fopen(outputFileName, "wb");\n    if (!outFile) {\n        goto ERR;\n    }\n    memset(&asyncCtx, 0x00, sizeof(AsyncMediaCtx));\n    asyncCtx.ctx = context;\n    asyncCtx.inFile = inFile;\n    asyncCtx.outFile = outFile;\n    asyncCtx.lastStream = 0;\n    asyncCtx.duration = 5;\n    asyncCtx.startTime = osal_gettime();\n    ret = hb_mm_mc_initialize(context);\n    if (ret) {\n        goto ERR;\n    }\n    media_codec_callback_t callback;\n    callback.on_input_buffer_available =\n    on_encoder_input_buffer_available;\n    callback.on_output_buffer_available =\n    on_encoder_output_buffer_available;\n    callback.on_media_codec_message = on_encoder_media_codec_message;\n    ret = hb_mm_mc_set_callback(context, &callback, &asyncCtx);\n    if (ret) {\n        goto ERR;\n    }\n    media_codec_callback_t callback2;\n    callback2.on_vlc_buffer_message = on_vlc_buffer_message;\n    if (ctx->vlc_buf_size > 0) {\n        ret = hb_mm_mc_set_vlc_buffer_listener(context, &callback2, ctx);\n        if (ret) {\n            goto ERR;\n        }\n    }\n    ret = hb_mm_mc_configure(context);\n    if (ret) {\n        goto ERR;\n    }\n    mc_av_codec_startup_params_t startup_params;\n    startup_params.video_enc_startup_params.receive_frame_number = 0;\n    ret = hb_mm_mc_start(context, &startup_params);\n    if (ret) {\n        goto ERR;\n    }\n    while(!asyncCtx.lastStream) {\n        sleep(1);\n    }\n    hb_mm_mc_stop(context);\n    hb_mm_mc_release(context);\n    context = NULL;\nERR:\n    hb_mm_mc_get_state(context, &state);\n    if (context && state !=\n    MEDIA_CODEC_STATE_UNINITIALIZED) {\n        hb_mm_mc_stop(context);\n        hb_mm_mc_release(context);\n    }\n    if (inFile)\n        fclose(inFile);\n    if (outFile)\n        fclose(outFile);\n}\nint main(int argc, char *argv[])\n{\n    int ret = 0;\n    char outputFileName[MAX_FILE_PATH] = "./tmp.yuv";\n    char inputFileName[MAX_FILE_PATH] = "./output.h265";\n    mc_video_codec_enc_params_t *params = NULL;\n    media_codec_context_t context;\n    memset(&context, 0x00, sizeof(media_codec_context_t));\n    context.codec_id = MEDIA_CODEC_ID_H265;\n    context.encoder = 1;\n    params = &context.video_enc_params;\n    params->width = 640;\n    params->height = 480;\n    params->pix_fmt = MC_PIXEL_FORMAT_YUV420P;\n    params->frame_buf_count = 5;\n    params->external_frame_buf = 0;\n    params->bitstream_buf_count = 5;\n    params->rc_params.mode = MC_AV_RC_MODE_H265CBR;\n    ret = hb_mm_mc_get_rate_control_config(&context, &params->rc_params);\n    if (ret) {\n        return -1;\n    }\n    params->rc_params.h265_cbr_params.bit_rate = 5000;\n    params->rc_params.h265_cbr_params.frame_rate = 30;\n    params->rc_params.h265_cbr_params.intra_period = 30;\n    params->gop_params.decoding_refresh_type = 2;\n    params->gop_params.gop_preset_idx = 2;\n    params->rot_degree = MC_CCW_0;\n    params->mir_direction = MC_DIRECTION_NONE;\n    params->frame_cropping_flag = FALSE;\n    MediaCodecTestContext ctx;\n    memset(&ctx, 0x00, sizeof(ctx));\n    ctx.context = &context;\n    ctx.inputFileName = inputFileName;\n    ctx.outputFileName = outputFileName;\n    do_async_encoding(&ctx);\n    return 0;\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_callback",children:"hb_mm_mc_set_callback"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_callback(media_codec_context_t *context,\nconst media_codec_callback_t *callback, hb_ptr userdata)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const media_codec_callback_t *callback: User-defined callback functions"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_ptr userdata: Pointer to user data, which will be passed as an argument when the callback function is invoked"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets the callback function pointers. After calling this function, MediaCodec enters asynchronous operation mode."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_initialize",children:"hb_mm_mc_initialize"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_configure",children:"hb_mm_mc_configure"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_configure(media_codec_context_t *context)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INSUFFICIENT_RES: Insufficient internal memory resources"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Configures the encoder or decoder based on the input information. Upon successful invocation, MediaCodec enters the MEDIA_CODEC_STATE_CONFIGURED state."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_initialize",children:"hb_mm_mc_initialize"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_start",children:"hb_mm_mc_start"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_start(media_codec_context_t *context, const",(0,r.jsx)(n.br,{}),"\n","mc_av_codec_startup_params_t *info)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] mc_av_codec_startup_params_t *info: Startup parameters for audio/video encoding or decoding"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INSUFFICIENT_RES: Insufficient internal memory resources"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Starts the encoding/decoding process. MediaCodec will create the codec instance, set up sequences or parse the data stream, register Framebuffers, encode header information, etc. Upon successful invocation, MediaCodec enters the MEDIA_CODEC_STATE_STARTED state."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_initialize",children:"hb_mm_mc_initialize"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_stop",children:"hb_mm_mc_stop"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_stop(media_codec_context_t *context)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Stops the encoding/decoding process, terminates all child threads, and releases associated resources. Upon successful invocation, MediaCodec returns to the MEDIA_CODEC_STATE_INITIALIZED state."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_initialize",children:"hb_mm_mc_initialize"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_pause",children:"hb_mm_mc_pause"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_pause(media_codec_context_t *context)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Pauses the encoding/decoding process and suspends all child threads. Upon successful invocation, MediaCodec enters the MEDIA_CODEC_STATE_PAUSED state."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_queue_input_buffer",children:"hb_mm_mc_queue_input_buffer"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_flush",children:"hb_mm_mc_flush"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_flush(media_codec_context_t *context)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Flushes the input and output buffer queues, forcing the encoder/decoder to flush any unprocessed input or output buffers. After this function is called, MediaCodec enters the MEDIA_CODEC_STATE_FLUSHING state. Upon successful completion, MediaCodec returns to the MEDIA_CODEC_STATE_STARTED state."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_queue_input_buffer",children:"hb_mm_mc_queue_input_buffer"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_release",children:"hb_mm_mc_release"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_release(media_codec_context_t *context)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Releases all internal resources held by MediaCodec. The user must call hb_mm_mc_stop to stop encoding/decoding before invoking this function. Upon successful completion, MediaCodec enters the MEDIA_CODEC_STATE_UNINITIALIZED state."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_initialize",children:"hb_mm_mc_initialize"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_state",children:"hb_mm_mc_get_state"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_state(media_codec_context_t *context,",(0,r.jsx)(n.br,{}),"\n","media_codec_state_t *state)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] media_codec_state_t *state: Current state of MediaCodec"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves the current state of MediaCodec."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_initialize",children:"hb_mm_mc_initialize"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_status",children:"hb_mm_mc_get_status"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_status(media_codec_context_t *context,",(0,r.jsx)(n.br,{}),"\n","mc_inter_status_t *status)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_inter_status_t *status: Current internal status of MediaCodec"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Obtain the current internal state information of MediaCodec."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_fd",children:"hb_mm_mc_get_fd"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_queue_input_buffer",children:"hb_mm_mc_queue_input_buffer"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_queue_input_buffer(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, media_codec_buffer_t *buffer, hb_s32 timeout)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_buffer_t *buffer: Input buffer information"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 timeout: Timeout duration"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_BUFFER: Invalid buffer"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_WAIT_TIMEOUT: Wait timeout"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Submit a buffer requiring processing into MediaCodec."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n\n#include "hb_media_error.h"\ntypedef struct MediaCodecTestContext {\n    media_codec_context_t *context;\n    char *inputFileName;\n    char *outputFileName;\n    int32_t duration; // s\n} MediaCodecTestContext;\nUint64 osal_gettime(void)\n{\n    struct timespec tp;\n    clock_gettime(CLOCK_MONOTONIC, &tp);\n    return ((Uint64)tp.tv_sec*1000 + tp.tv_nsec/1000000);\n}\nstatic void do_sync_encoding(void *arg) {\n    hb_s32 ret = 0;\n    FILE *inFile;\n    FILE *outFile;\n    int noMoreInput = 0;\n    int lastStream = 0;\n    Uint64 lastTime = 0;\n    Uint64 curTime = 0;\n    int needFlush = 1;\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)arg;\n    media_codec_context_t *context = ctx->context;\n    char *inputFileName = ctx->inputFileName;\n    char *outputFileName = ctx->outputFileName;\n    media_codec_state_t state = MEDIA_CODEC_STATE_NONE;\n    inFile = fopen(inputFileName, "rb");\n    if (!inFile) {\n        goto ERR;\n    }\n    outFile = fopen(outputFileName, "wb");\n    if (!outFile) {\n        goto ERR;\n    }\n    //get current time\n    lastTime = osal_gettime();\n    ret = hb_mm_mc_initialize(context);\n    if (ret) {\n        goto ERR;\n    }\n    ret = hb_mm_mc_configure(context);\n    if (ret) {\n        goto ERR;\n    }\n    mc_av_codec_startup_params_t startup_params;\n    startup_params.video_enc_startup_params.receive_frame_number = 0;\n    ret = hb_mm_mc_start(context, &startup_params);\n    if (ret) {\n        goto ERR;\n    }\n    ret = hb_mm_mc_pause(context);\n    if (ret) {\n        goto ERR;\n    }\n    do {\n        if (!noMoreInput) {\n            media_codec_buffer_t inputBuffer;\n            memset(&inputBuffer, 0x00, sizeof(media_codec_buffer_t));\n            ret = hb_mm_mc_dequeue_input_buffer(context, &inputBuffer, 100);\n            if (!ret) {\n                curTime = osal_gettime();\n                if ((curTime - lastTime)/1000 < (uint32_t)ctx->duration) {\n                    ret = fread(inputBuffer.vframe_buf.vir_ptr[0], 1,\n                    inputBuffer.vframe_buf.size, inFile);\n                    if (ret <= 0) {\n                        if(fseek(inFile, 0, SEEK_SET)) {\n                            printf("Failed to rewind input file\\n");\n                        } else {\n                        ret = fread(inputBuffer.vframe_buf.vir_ptr[0], 1,\n                        inputBuffer.vframe_buf.size, inFile);\n                        if (ret <= 0) {\n                            printf("Failed to read input file\\n");\n                        }\n                }\n            }\n        } else {\n            printf("Time up(%d)\\n",ctx->duration);\n            ret = 0;\n        }\n        if (!ret) {\n            printf("There is no more input data!\\n");\n            inputBuffer.vframe_buf.frame_end = TRUE;\n            noMoreInput = 1;\n        }\n        ret = hb_mm_mc_queue_input_buffer(context, &inputBuffer, 100);\n        if (ret) {\n            printf("Queue input buffer fail.\\n");\n            break;\n        } else {\n            if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                printf("Dequeue input buffer fail.\\n");\n                break;\n            }\n        }\n\n        if (!lastStream) {\n            media_codec_buffer_t outputBuffer;\n            media_codec_output_buffer_info_t info;\n            memset(&outputBuffer, 0x00, sizeof(media_codec_buffer_t));\n            memset(&info, 0x00, sizeof(media_codec_output_buffer_info_t));\n            ret = hb_mm_mc_dequeue_output_buffer(context, &outputBuffer, &info,\n            3000);\n            if (!ret && outFile) {\n                fwrite(outputBuffer.vstream_buf.vir_ptr,\n                outputBuffer.vstream_buf.size, 1, outFile);\n                ret = hb_mm_mc_queue_output_buffer(context, &outputBuffer, 100);\n                if (ret) {\n                    printf("Queue output buffer fail.\\n");\n                    break;\n                }\n                if (outputBuffer.vstream_buf.stream_end) {\n                    printf("There is no more output data!\\n");\n                    lastStream = 1;\n                    break;\n                }\n            } else {\n                if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                    printf("Dequeue output buffer fail.\\n");\n                    break;\n                }\n            }\n        }\n        if (needFlush) {\n            ret = hb_mm_mc_flush(context);\n            needFlush = 0;\n            if (ret) {\n                break;\n            }\n        }\n    }while(TRUE);\n    hb_mm_mc_stop(context);\n    hb_mm_mc_release(context);\n    context = NULL;\nERR:\n    hb_mm_mc_get_state(context, &state);\n    if (context && state !=\n        MEDIA_CODEC_STATE_UNINITIALIZED) {\n        hb_mm_mc_stop(context);\n        hb_mm_mc_release(context);\n    }\n    if (inFile)\n        fclose(inFile);\n    if (outFile)\n    fclose(outFile);\n}\nint main(int argc, char *argv[])\n{\n    hb_s32 ret = 0;\n    char outputFileName[MAX_FILE_PATH] = "./tmp.yuv";\n    char inputFileName[MAX_FILE_PATH] = "./output.stream";\n    mc_video_codec_enc_params_t *params;\n    media_codec_context_t context;\n    memset(&context, 0x00, sizeof(media_codec_context_t));\n    context.codec_id = MEDIA_CODEC_ID_H265;\n    context.encoder = TRUE;\n    params = &context.video_enc_params;\n    params->width = 640;\n    params->height = 480;\n    params->pix_fmt = MC_PIXEL_FORMAT_YUV420P;\n    params->frame_buf_count = 5;\n    params->external_frame_buf = FALSE;\n    params->bitstream_buf_count = 5;\n    params->rc_params.mode = MC_AV_RC_MODE_H265CBR;\n    ret = hb_mm_mc_get_rate_control_config(&context, &params->rc_params);\n    if (ret) {\n        return -1;\n    }\n    params->rc_params.h265_cbr_params.bit_rate = 5000;\n    params->rc_params.h265_cbr_params.frame_rate = 30;\n    params->rc_params.h265_cbr_params.intra_period = 30;\n    params->gop_params.decoding_refresh_type = 2;\n    params->gop_params.gop_preset_idx = 2;\n    params->rot_degree = MC_CCW_0;\n    params->mir_direction = MC_DIRECTION_NONE;\n    params->frame_cropping_flag = FALSE;\n    MediaCodecTestContext ctx;\n    memset(&ctx, 0x00, sizeof(ctx));\n    ctx.context = &context;\n    ctx.inputFileName = inputFileName;\n    ctx.outputFileName = outputFileName;\n    ctx.duration = 5;\n    do_sync_encoding(&ctx);\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_dequeue_input_buffer",children:"hb_mm_mc_dequeue_input_buffer"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_dequeue_input_buffer(media_codec_context_t\n*context, media_codec_buffer_t *buffer, hb_s32 timeout)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 timeout: Timeout duration"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] media_codec_buffer_t *buffer: Input buffer information"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_BUFFER: Invalid buffer"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_WAIT_TIMEOUT: Wait timeout"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Obtain an input buffer."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_queue_input_buffer",children:"hb_mm_mc_queue_input_buffer"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_queue_output_buffer",children:"hb_mm_mc_queue_output_buffer"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_queue_output_buffer(media_codec_context_t\n*context, media_codec_buffer_t *buffer, hb_s32 timeout)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_buffer_t *buffer: Output buffer information"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 timeout: Timeout duration"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_BUFFER: Invalid buffer"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_WAIT_TIMEOUT: Wait timeout"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Return a processed output buffer back to MediaCodec."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_queue_input_buffer",children:"hb_mm_mc_queue_input_buffer"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_dequeue_output_buffer",children:"hb_mm_mc_dequeue_output_buffer"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_dequeue_output_buffer(media_codec_context_t\n*context, media_codec_buffer_t *buffer,\nmedia_codec_output_buffer_info_t *info, hb_s32 timeout)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 timeout: Timeout duration"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] media_codec_buffer_t *buffer: Output buffer information"}),"\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_output_buffer_info_t\n*info: Information of the output bitstream"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_BUFFER: Invalid buffer"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_WAIT_TIMEOUT: Wait timeout"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Obtain an output buffer."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_queue_input_buffer",children:"hb_mm_mc_queue_input_buffer"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_longterm_ref_mode(media_codec_context_t\n*context, mc_video_longterm_ref_mode_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_longterm_ref_mode_t\n*params: Long-term reference frame mode parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieve parameters of the long-term reference frame mode, applicable to H.264/H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\n\ntypedef enum ENC_CONFIG_MESSAGE {\n    ENC_CONFIG_NONE = (0 << 0),\n    ENC_CONFIG_LONGTERM_REF = (1 << 0),\n    ENC_CONFIG_INTRA_REFRESH = (1 << 1),\n    ENC_CONFIG_RATE_CONTROL = (1 << 2),\n    ENC_CONFIG_DEBLK_FILTER = (1 << 3),\n    ENC_CONFIG_SAO = (1 << 4),\n    ENC_CONFIG_ENTROPY = (1 << 5),\n    ENC_CONFIG_VUI_TIMING = (1 << 6),\n    ENC_CONFIG_SLICE = (1 << 7),\n    ENC_CONFIG_REQUEST_IDR = (1 << 8),\n    ENC_CONFIG_SKIP_PIC = (1 << 9),\n    ENC_CONFIG_SMART_BG = (1 << 10),\n    ENC_CONFIG_MONOCHROMA = (1 << 11),\n    ENC_CONFIG_PRED_UNIT = (1 << 12),\n    ENC_CONFIG_TRANSFORM = (1 << 13),\n    ENC_CONFIG_ROI = (1 << 14),\n    ENC_CONFIG_MODE_DECISION = (1 << 15),\n    ENC_CONFIG_USER_DATA = (1 << 16),\n    ENC_CONFIG_MJPEG = (1 << 17),\n    ENC_CONFIG_JPEG = (1 << 18),\n    ENC_CONFIG_CAMERA = (1 << 19),\n    ENC_CONFIG_INSERT_USERDATA = (1 << 20),\n    ENC_CONFIG_VUI = (1 << 21),\n    ENC_CONFIG_3DNR = (1 << 22),\n    ENC_CONFIG_REQUEST_IDR_HEADER = (1 << 23),\n    ENC_CONFIG_ENABLE_IDR = (1 << 24),\n    ENC_CONFIG_TOTAL = (1 << 25),\n} ENC_CONFIG_MESSAGE;\n\ntypedef struct MediaCodecTestContext {\n    media_codec_context_t *context;\n    char *inputFileName;\n    char *outputFileName;\n    int32_t duration; // seconds\n    ENC_CONFIG_MESSAGE message;\n    mc_video_longterm_ref_mode_t ref_mode;\n    mc_rate_control_params_t rc_params;\n    mc_video_intra_refresh_params_t intra_refr;\n    mc_video_deblk_filter_params_t deblk_filter;\n    mc_h265_sao_params_t sao;\n    mc_h264_entropy_params_t entropy;\n    mc_video_vui_params_t vui;\n    mc_video_vui_timing_params_t vui_timing;\n    mc_video_slice_params_t slice;\n    mc_video_3dnr_enc_params_t noise_reduction;\n    mc_video_smart_bg_enc_params_t smart_bg;\n    mc_video_pred_unit_params_t pred_unit;\n    mc_video_transform_params_t transform;\n    mc_video_roi_params_t roi;\n    mc_video_mode_decision_params_t mode_decision;\n} MediaCodecTestContext;\n\nUint64 osal_gettime(void)\n{\n    struct timespec tp;\n\n    clock_gettime(CLOCK_MONOTONIC, &tp);\n\n    return ((Uint64)tp.tv_sec*1000 + tp.tv_nsec/1000000);\n}\nuint8_t uuid[] =\n    "dc45e9bd-e6d948b7-962cd820-d923eeef+HorizonAI";\nstatic void set_message(MediaCodecTestContext *ctx) {\n    int ret = 0;\n    media_codec_context_t *context = ctx->context;\n\n    mc_video_longterm_ref_mode_t *ref_mode = &ctx->ref_mode;\n    hb_mm_mc_get_longterm_ref_mode(context, ref_mode);\n    ref_mode->use_longterm = TRUE;\n    ref_mode->longterm_pic_using_period = 20;\n    ref_mode->longterm_pic_period = 30;\n    //ctx->message = ENC_CONFIG_LONGTERM_REF;\n    if (ctx->message & ENC_CONFIG_LONGTERM_REF) {\n        ret = hb_mm_mc_set_longterm_ref_mode(context, &ctx->ref_mode);\n    }\nif (ctx->message & ENC_CONFIG_INTRA_REFRESH) {\nhb_mm_mc_get_intra_refresh_config(context, &ctx->intra_refr)\n        ret = hb_mm_mc_set_intra_refresh_config(context, &ctx->intra_refr);\n}\nif (ctx->message & ENC_CONFIG_SAO) {\nhb_mm_mc_get_sao_config(context, &ctx->sao);\n        ret = hb_mm_mc_set_sao_config(context, &ctx->sao);\n    }\n\nif (ctx->message & ENC_CONFIG_ENTROPY) {\nhb_mm_mc_get_entropy_config(context, &ctx->entropy);\n        ret = hb_mm_mc_set_entropy_config(context, &ctx->entropy);\n    }\n\nif (ctx->message & ENC_CONFIG_VUI) {\nhb_mm_mc_get_vui_config(context, &ctx->vui);\n    ret = hb_mm_mc_set_vui_config(context, &ctx->vui);\n    }\n\nif (ctx->message & ENC_CONFIG_VUI_TIMING) {\nhb_mm_mc_get_vui_timing_config(context, &ctx->vui_timing);\n        ret = hb_mm_mc_set_vui_timing_config(context, &ctx->vui_timing);\n    }\n    mc_rate_control_params_t *rc_params = &ctx->rc_params;\n    rc_params->mode = context->video_enc_params.rc_params.mode;\n    hb_mm_mc_get_rate_control_config(context, rc_params);\n    switch (rc_params->mode) {\n    case MC_AV_RC_MODE_H264CBR:\n        rc_params->h264_cbr_params.bit_rate = 5000;\n        rc_params->h264_cbr_params.intra_period = 60;\n        break;\n    case MC_AV_RC_MODE_H264VBR:\n        rc_params->h264_vbr_params.intra_qp = 20;\n        rc_params->h264_vbr_params.intra_period = 30;\n        break;\n    case MC_AV_RC_MODE_H264AVBR:\n        rc_params->h264_avbr_params.intra_period = 15;\n        rc_params->h264_avbr_params.intra_qp = 25;\n        rc_params->h264_avbr_params.bit_rate = 2000;\n        rc_params->h264_avbr_params.vbv_buffer_size = 3000;\n        rc_params->h264_avbr_params.min_qp_I = 15;\n        rc_params->h264_avbr_params.max_qp_I = 50;\n        rc_params->h264_avbr_params.min_qp_P = 15;\n        rc_params->h264_avbr_params.max_qp_P = 45;\n        rc_params->h264_avbr_params.min_qp_B = 15;\n        rc_params->h264_avbr_params.max_qp_B = 48;\n        rc_params->h264_avbr_params.hvs_qp_enable = 0;\n        rc_params->h264_avbr_params.hvs_qp_scale = 2;\n        rc_params->h264_avbr_params.max_delta_qp = 5;\n        rc_params->h264_avbr_params.qp_map_enable = 0;\n        break;\n    case MC_AV_RC_MODE_H264FIXQP:\n        rc_params->h264_fixqp_params.force_qp_I = 23;\n        rc_params->h264_fixqp_params.force_qp_P = 23;\n        rc_params->h264_fixqp_params.force_qp_B = 23;\n        rc_params->h264_fixqp_params.intra_period = 23;\n        break;\n    case MC_AV_RC_MODE_H264QPMAP:\n        break;\n    case MC_AV_RC_MODE_H265CBR:\n        rc_params->h265_cbr_params.bit_rate = 5000;\n        rc_params->h265_cbr_params.intra_period = 60;\n        break;\n    case MC_AV_RC_MODE_H265VBR:\n        rc_params->h265_vbr_params.intra_qp = 20;\n        rc_params->h265_vbr_params.intra_period = 30;\n        break;\n    case MC_AV_RC_MODE_H265AVBR:\n        rc_params->h265_avbr_params.intra_period = 15;\n        rc_params->h265_avbr_params.intra_qp = 25;\n        rc_params->h265_avbr_params.bit_rate = 2000;\n        rc_params->h265_avbr_params.vbv_buffer_size = 3000;\n        rc_params->h265_avbr_params.min_qp_I = 15;\n        rc_params->h265_avbr_params.max_qp_I = 50;\n        rc_params->h265_avbr_params.min_qp_P = 15;\n        rc_params->h265_avbr_params.max_qp_P = 45;\n        rc_params->h265_avbr_params.min_qp_B = 15;\n        rc_params->h265_avbr_params.max_qp_B = 48;\n        rc_params->h265_avbr_params.hvs_qp_enable = 0;\n        rc_params->h265_avbr_params.hvs_qp_scale = 2;\n        rc_params->h265_avbr_params.max_delta_qp = 5;\n        rc_params->h265_avbr_params.qp_map_enable = 0;\n        break;\n    case MC_AV_RC_MODE_H265FIXQP:\n        rc_params->h265_fixqp_params.force_qp_I = 23;\n        rc_params->h265_fixqp_params.force_qp_P = 23;\n        rc_params->h265_fixqp_params.force_qp_B = 23;\n        rc_params->h265_fixqp_params.intra_period = 23;\n        break;\n    case MC_AV_RC_MODE_H265QPMAP:\n        break;\n    default:\n        break;\n    }\n    //ctx->message = ENC_CONFIG_RATE_CONTROL;\n    if (ctx->message & ENC_CONFIG_RATE_CONTROL) {\n        ret = hb_mm_mc_set_rate_control_config(context, &ctx->rc_params);\n    }\n\n    mc_video_deblk_filter_params_t *deblk_filter = &ctx->deblk_filter;\n    hb_mm_mc_get_deblk_filter_config(context, deblk_filter);\n    if (context->codec_id == MEDIA_CODEC_ID_H264) {\n        deblk_filter->h264_deblk.disable_deblocking_filter_idc = 2;\n        deblk_filter->h264_deblk.slice_alpha_c0_offset_div2 = 6;\n        deblk_filter->h264_deblk.slice_beta_offset_div2 = 6;\n    } else {\n        deblk_filter->h265_deblk.slice_deblocking_filter_disabled_flag = 1;\n        deblk_filter->h265_deblk.slice_beta_offset_div2 = 6;\n        deblk_filter->h265_deblk.slice_tc_offset_div2 = 6;\n        deblk_filter->h265_deblk.slice_loop_filter_across_slices_enabled_flag = 1;\n    }\n    //ctx->message = ENC_CONFIG_DEBLK_FILTER;\n    if (ctx->message & ENC_CONFIG_DEBLK_FILTER) {\n        ret = hb_mm_mc_set_deblk_filter_config(context, &ctx->deblk_filter);\n    }\n\n    if (context->codec_id == MEDIA_CODEC_ID_H264) {\n        mc_h264_entropy_params_t *entropy = &ctx->entropy;\n        hb_mm_mc_get_entropy_config(context, entropy);\n        entropy->entropy_coding_mode = 0;\n        ctx->message = ENC_CONFIG_ENTROPY;\n        if (ctx->message & ENC_CONFIG_ENTROPY) {\n            ret = hb_mm_mc_set_entropy_config(context, &ctx->entropy);\n        }\n    }\n\n    //ctx->message = ENC_CONFIG_SKIP_PIC;\n    if (ctx->message & ENC_CONFIG_SKIP_PIC) {\n        ret = hb_mm_mc_skip_pic(context, 0), (int32_t)0);\n    }\n\n    //ctx->message = ENC_CONFIG_REQUEST_IDR;\n    if (ctx->message & ENC_CONFIG_REQUEST_IDR) {\n        ret = hb_mm_mc_request_idr_frame(context);\n    }\n\n    mc_video_slice_params_t *slice = &ctx->slice;\n    hb_mm_mc_get_slice_config(context, slice);\n    if (context->codec_id == MEDIA_CODEC_ID_H264) {\n        slice->h264_slice.h264_slice_mode = 0;\n        slice->h264_slice.h264_slice_arg = 60;\n    } else {\n        slice->h265_slice.h265_dependent_slice_mode = 0;\n        slice->h265_slice.h265_dependent_slice_arg = 80;\n        slice->h265_slice.h265_independent_slice_mode = 1;\n        slice->h265_slice.h265_independent_slice_arg = 100;\n    }\n    //ctx->message = ENC_CONFIG_SLICE;\n    if (ctx->message & ENC_CONFIG_SLICE) {\n        ret = hb_mm_mc_set_slice_config(context, &ctx->slice);\n    }\n\n    mc_video_smart_bg_enc_params_t *smart_bg = &ctx->smart_bg;\n    hb_mm_mc_get_smart_bg_enc_config(context, smart_bg);\n    smart_bg->bg_detect_enable = 0;\n    smart_bg->bg_threshold_diff = 8;\n    smart_bg->bg_threshold_mean_diff = 1;\n    smart_bg->bg_lambda_qp = 32;\n    smart_bg->bg_delta_qp = 3;\n    smart_bg->s2fme_disable = 0;\n    //ctx->message = ENC_CONFIG_SMART_BG;\n    if (ctx->message & ENC_CONFIG_SMART_BG) {\n        ret = hb_mm_mc_set_smart_bg_enc_config(context, &ctx->smart_bg);\n    }}\n\n    mc_video_pred_unit_params_t *pred_unit = &ctx->pred_unit;\n    hb_mm_mc_get_pred_unit_config(context, pred_unit);\n    if (context->codec_id == MEDIA_CODEC_ID_H264) {\n        pred_unit->h264_intra_pred.constrained_intra_pred_flag = 1;\n    } else {\n        pred_unit->h265_pred_unit.intra_nxn_enable = 1;\n        pred_unit->h265_pred_unit.constrained_intra_pred_flag = 1;\n        pred_unit->h265_pred_unit.strong_intra_smoothing_enabled_flag = 0;\n        pred_unit->h265_pred_unit.max_num_merge = 2;\n    }\n    //ctx->message = ENC_CONFIG_PRED_UNIT;\n    if (ctx->message & ENC_CONFIG_PRED_UNIT) {\n        ret = hb_mm_mc_set_pred_unit_config(context, &ctx->pred_unit);\n    }\n\n    mc_video_transform_params_t *transform = &ctx->transform;\n    hb_mm_mc_get_transform_config(context, transform);\n    if (context->codec_id == MEDIA_CODEC_ID_H264) {\n        transform->h264_transform.transform_8x8_enable = 1;\n        transform->h264_transform.chroma_cb_qp_offset = 4;\n        transform->h264_transform.chroma_cr_qp_offset = 3;\n        transform->h264_transform.user_scaling_list_enable = 0;\n    } else {\n        transform->h265_transform.chroma_cb_qp_offset = 6;\n        transform->h265_transform.chroma_cr_qp_offset = 5;\n        transform->h265_transform.user_scaling_list_enable = 0;\n    }\n    //ctx->message = ENC_CONFIG_TRANSFORM;\n    if (ctx->message & ENC_CONFIG_TRANSFORM) {\n        ret = hb_mm_mc_set_transform_config(context, &ctx->transform);\n    }\n\n    mc_video_roi_params_t *roi = &ctx->roi;\n    hb_mm_mc_get_roi_config(context, roi);\n    roi->roi_enable = 0;\n    //ctx->message = ENC_CONFIG_ROI;\n    if (ctx->message & ENC_CONFIG_ROI) {\n        ret = hb_mm_mc_set_roi_config(context, &ctx->roi);\n    }\n\n    mc_video_mode_decision_params_t *mode_decision = &ctx->mode_decision;\n    hb_mm_mc_get_mode_decision_config(context, mode_decision);\n    mode_decision->mode_decision_enable = FALSE;\n    mode_decision->pu04_delta_rate = 76;\n    mode_decision->pu08_delta_rate = 80;\n    mode_decision->pu16_delta_rate = 86;\n    mode_decision->pu32_delta_rate = 87;\n    mode_decision->pu04_intra_planar_delta_rate = 0;\n    mode_decision->pu04_intra_dc_delta_rate = 0;\n    mode_decision->pu04_intra_angle_delta_rate = 0;\n    mode_decision->pu08_intra_planar_delta_rate = 0;\n    mode_decision->pu08_intra_dc_delta_rate = 0;\n    mode_decision->pu08_intra_angle_delta_rate = 0;\n    mode_decision->pu16_intra_planar_delta_rate = 0;\n    mode_decision->pu16_intra_dc_delta_rate = 0;\n    mode_decision->pu16_intra_angle_delta_rate = 0;\n    mode_decision->pu32_intra_planar_delta_rate = 0;\n    mode_decision->pu32_intra_dc_delta_rate = 0;\n    mode_decision->pu32_intra_angle_delta_rate = 0;\n    mode_decision->cu08_intra_delta_rate = 0;\n    mode_decision->cu08_inter_delta_rate = 0;\n    mode_decision->cu08_merge_delta_rate = 0;\n    mode_decision->cu16_intra_delta_rate = 0;\n    mode_decision->cu16_inter_delta_rate = 0;\n    mode_decision->cu16_merge_delta_rate = 0;\n    mode_decision->cu32_intra_delta_rate = 0;\n    mode_decision->cu32_inter_delta_rate = 0;\n    mode_decision->cu32_merge_delta_rate = 0;\n    //ctx->message = ENC_CONFIG_MODE_DECISION;\n    if (ctx->message & ENC_CONFIG_MODE_DECISION) {\n        ret = hb_mm_mc_set_mode_decision_config(context, &ctx->mode_decision);\n    }\n    if (ctx->message & ENC_CONFIG_INSERT_USERDATA) {\n        hb_u32 length = sizeof(uuid)/sizeof(uuid[0]);\n        ret = hb_mm_mc_insert_user_data(context, uuid, length);\n    }\nif (ctx->message & ENC_CONFIG_3DNR) {\n        hb_mm_mc_get_3dnr_enc_config(context, &ctx->noise_reduction);\n        ret = hb_mm_mc_set_3dnr_enc_config(context, &ctx->noise_reduction);\n    }\n    if (ctx->message & ENC_CONFIG_ENABLE_IDR) {\n        // disable idr frame first\n        if (ctx->enable_idr_num) {\n            ret = hb_mm_mc_enable_idr_frame(context, 0);\n        }\n    }\n\n    if (ctx->message & ENC_CONFIG_REQUEST_IDR_HEADER) {\n        ret = hb_mm_mc_request_idr_header(context, ctx->force_idr_header);\n    }\n}\n\nstatic void do_sync_encoding(void *arg) {\n    hb_s32 ret = 0;\n    FILE *inFile;\n    FILE *outFile;\n    int noMoreInput = 0;\n    int lastStream = 0;\n    Uint64 lastTime = 0;\n    Uint64 curTime = 0;\n    int needFlush = 1;\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)arg;\n    media_codec_context_t *context = ctx->context;\n    char *inputFileName = ctx->inputFileName;\n    char *outputFileName = ctx->outputFileName;\n    media_codec_state_t state = MEDIA_CODEC_STATE_NONE;\n    inFile = fopen(inputFileName, "rb");\n    if (!inFile) {\n        goto ERR;\n    }\n    outFile = fopen(outputFileName, "wb");\n    if (!outFile) {\n        goto ERR;\n    }\n\n    //get current time\n    lastTime = osal_gettime();\n\n    ret = hb_mm_mc_initialize(context);\n    if (ret) {\n        goto ERR;\n    }\n\n    ret = hb_mm_mc_configure(context);\n    if (ret) {\n        goto ERR;\n    }\n\n    mc_av_codec_startup_params_t startup_params;\n    startup_params.video_enc_startup_params.receive_frame_number = 0;\n    ret = hb_mm_mc_start(context, &startup_params);\n    if (ret) {\n        goto ERR;\n    }\n\n    ret = hb_mm_mc_pause(context);\n    if (ret) {\n        goto ERR;\n    }\n\n    do {\n        set_message(ctx);\n        if (!noMoreInput) {\n            media_codec_buffer_t inputBuffer;\n            memset(&inputBuffer, 0x00, sizeof(media_codec_buffer_t));\n            ret = hb_mm_mc_dequeue_input_buffer(context, &inputBuffer, 100);\n            if (!ret) {\n                curTime = osal_gettime();\n                if ((curTime - lastTime)/1000 < (uint32_t)ctx->duration) {\n                    ret = fread(inputBuffer.vframe_buf.vir_ptr[0], 1,\n                        inputBuffer.vframe_buf.size, inFile);\n                    if (ret <= 0) {\n                        if(fseek(inFile, 0, SEEK_SET)) {\n                            printf("Failed to rewind input file\\n");\n                        } else {\n                            ret = fread(inputBuffer.vframe_buf.vir_ptr[0], 1,\n                                inputBuffer.vframe_buf.size, inFile);\n                            if (ret <= 0) {\n                                printf("Failed to read input file\\n");\n                            }\n                        }\n                    }\n                } else {\n                    printf("Time up(%d)\\n",ctx->duration);\n                    ret = 0;\n                }\n                if (!ret) {\n                    printf("There is no more input data!\\n");\n                    inputBuffer.vframe_buf.frame_end = TRUE;\n                    noMoreInput = 1;\n                }\n                ret = hb_mm_mc_queue_input_buffer(context, &inputBuffer, 100);\n                if (ret) {\n                    printf("Queue input buffer fail.\\n");\n                    break;\n                }\n            } else {\n                if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                    printf("Dequeue input buffer fail.\\n");\n                    break;\n                }\n            }\n        }\n\n        if (!lastStream) {\n            media_codec_buffer_t outputBuffer;\n            media_codec_output_buffer_info_t info;\n            memset(&outputBuffer, 0x00, sizeof(media_codec_buffer_t));\n            memset(&info, 0x00, sizeof(media_codec_output_buffer_info_t));\n            ret = hb_mm_mc_dequeue_output_buffer(context, &outputBuffer, &info, 3000);\n            if (!ret && outFile) {\n                fwrite(outputBuffer.vstream_buf.vir_ptr, outputBuffer.vstream_buf.size, 1, outFile);\n\n                ret = hb_mm_mc_queue_output_buffer(context, &outputBuffer, 100);\n                if (ret) {\n                    printf("Queue output buffer fail.\\n");\n                    break;\n                }\n            }\n        }\n    } while (/* condition */);\n}if (outputBuffer.vstream_buf.stream_end) {\n                    printf("There is no more output data!\\n");\n                    lastStream = 1;\n                    break;\n                }\n            } else {\n                if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                    printf("Dequeue output buffer fail.\\n");\n                    break;\n                }\n            }\n        }\n        if (needFlush) {\n            ret = hb_mm_mc_flush(context);\n            needFlush = 0;\n            if (ret) {\n                break;\n            }\n        }\n    }while(TRUE);\n\n    hb_mm_mc_stop(context);\n\n    hb_mm_mc_release(context);\n    context = NULL;\n\nERR:\n    hb_mm_mc_get_state(context, &state);\n    if (context && state != MEDIA_CODEC_STATE_UNINITIALIZED) {\n        hb_mm_mc_stop(context);\n        hb_mm_mc_release(context);\n    }\n\n    if (inFile)\n        fclose(inFile);\n\n    if (outFile)\n        fclose(outFile);\n}\n\nint main(int argc, char *argv[])\n{\n    hb_s32 ret = 0;\n    char outputFileName[MAX_FILE_PATH] = "./tmp.yuv";\n    char inputFileName[MAX_FILE_PATH] = "./output.stream";\n    mc_video_codec_enc_params_t *params;\n    media_codec_context_t context;\n\n    memset(&context, 0x00, sizeof(media_codec_context_t));\n    context.codec_id = MEDIA_CODEC_ID_H265;\n    context.encoder = TRUE;\n    params = &context.video_enc_params;\n    params->width = 640;\n    params->height = 480;\n    params->pix_fmt = MC_PIXEL_FORMAT_YUV420P;\n    params->frame_buf_count = 5;\n    params->external_frame_buf = FALSE;\n    params->bitstream_buf_count = 5;\n    params->rc_params.mode = MC_AV_RC_MODE_H265CBR;\n    ret = hb_mm_mc_get_rate_control_config(&context, &params->rc_params);\n    if (ret) {\n        return -1;\n    }\n    params->rc_params.h265_cbr_params.bit_rate = 5000;\n    params->rc_params.h265_cbr_params.frame_rate = 30;\n    params->rc_params.h265_cbr_params.intra_period = 30;\n    params->gop_params.decoding_refresh_type = 2;\n    params->gop_params.gop_preset_idx = 2;\n    params->rot_degree = MC_CCW_0;\n    params->mir_direction = MC_DIRECTION_NONE;\n    params->frame_cropping_flag = FALSE;\n\n    MediaCodecTestContext ctx;\n    memset(&ctx, 0x00, sizeof(ctx));\n    ctx.context = &context;\n    ctx.inputFileName = inputFileName;\n    ctx.outputFileName = outputFileName;\n    ctx.duration = 5;\n    do_sync_encoding(&ctx);\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_longterm_ref_mode",children:"hb_mm_mc_set_longterm_ref_mode"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_longterm_ref_mode(media_codec_context_t\n*context, const mc_video_longterm_ref_mode_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_longterm_ref_mode_t\n*params: Long-term reference frame mode parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets long-term reference frame mode parameters. These parameters are dynamic and applicable to H.264/H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_intra_refresh_config",children:"hb_mm_mc_get_intra_refresh_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_intra_refresh_config(media_codec_context_t\n*context, mc_video_intra_refresh_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_intra_refresh_params_t *params: Intra refresh parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves intra refresh parameters, applicable to H.264/H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_intra_refresh_config",children:"hb_mm_mc_set_intra_refresh_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_intra_refresh_config(media_codec_context_t\n*context, const mc_video_intra_refresh_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_intra_refresh_params_t\n*params: Intra refresh parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets intra refresh mode parameters. These parameters are static and applicable to H.264/H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_rate_control_config",children:"hb_mm_mc_get_rate_control_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_rate_control_config(media_codec_context_t\n*context, mc_rate_control_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_rate_control_params_t *params: Rate control parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves rate control parameters. These parameters are dynamic and applicable to H.264/H.265/MJPEG."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_rate_control_config",children:"hb_mm_mc_set_rate_control_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_rate_control_config(media_codec_context_t\n*context, const mc_rate_control_params_t *params)\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_rate_control_params_t *params: Rate control parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets rate control parameters. These parameters are dynamic and applicable to H264/H265/MJPEG."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_deblk_filter_config",children:"hb_mm_mc_get_deblk_filter_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_deblk_filter_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, mc_video_deblk_filter_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_deblk_filter_params_t *params: Deblocking filter parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves deblocking filter parameters, applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_deblk_filter_config",children:"hb_mm_mc_set_deblk_filter_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_set_deblk_filter_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, const mc_video_deblk_filter_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_deblk_filter_params_t\n*params: Deblocking filter parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets deblocking filter parameters. These parameters are dynamic and applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_sao_config",children:"hb_mm_mc_get_sao_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_sao_config(media_codec_context_t *context,",(0,r.jsx)(n.br,{}),"\n","mc_h265_sao_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_h265_sao_params_t *params: SAO parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves SAO parameters, applicable to H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_sao_config",children:"hb_mm_mc_set_sao_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_set_sao_config(media_codec_context_t *context,",(0,r.jsx)(n.br,{}),"\n","const mc_h265_sao_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_h265_sao_params_t *params: SAO parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets SAO parameters. These parameters are static and applicable to H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_entropy_config",children:"hb_mm_mc_get_entropy_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_entropy_config(media_codec_context_t *context, mc_h264_entropy_params_t *params);"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] mc_h264_entropy_params_t *params: Entropy parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves entropy parameters, applicable to H264."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_entropy_config",children:"hb_mm_mc_set_entropy_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"extern hb_s32 hb_mm_mc_set_entropy_config(media_codec_context_t *context, const mc_h264_entropy_params_t *params);"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_h264_entropy_params_t *params: Entropy parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets entropy parameters, applicable to H264."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_vui_timing_config",children:"hb_mm_mc_get_vui_timing_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_vui_timing_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, mc_video_vui_timing_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_vui_timing_params_t *params: VUI Timing parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Gets VUI Timing parameters, applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_vui_timing_config",children:"hb_mm_mc_set_vui_timing_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_vui_timing_config(media_codec_context_t *context, const mc_video_vui_timing_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_vui_timing_params_t *params: VUI Timing parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets VUI Timing parameters. These parameters are static and applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_slice_config",children:"hb_mm_mc_get_slice_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_slice_config(media_codec_context_t *context, mc_video_slice_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_slice_params_t *params: Slice encoding parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Gets slice encoding parameters, applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_slice_config",children:"hb_mm_mc_set_slice_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_slice_config(media_codec_context_t *context, const mc_video_slice_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_slice_params_t *params: Slice encoding parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets slice encoding parameters. These parameters are dynamic and applicable to H264/H265. The number of slices per frame must not exceed 1500."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_insert_user_data",children:"hb_mm_mc_insert_user_data"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_insert_user_data(media_codec_context_t *context, hb_u8 *data, hb_u32 length)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_u8 *data: User data"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_u32 length: Length of user data"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Inserts user data into the encoded bitstream. This parameter is dynamic and applicable to H264/H265/MJPG/JPG."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_request_idr_frame",children:"hb_mm_mc_request_idr_frame"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_request_idr_frame(media_codec_context_t *context)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Requests an IDR frame. This interface supports dynamic configuration and is applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_skip_pic",children:"hb_mm_mc_skip_pic"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_skip_pic(media_codec_context_t *context, hb_s32 src_idx)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 src_idx: Source buffer index"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Enables skip-mode encoding for the specified picture. This interface supports dynamic configuration and is applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_smart_bg_enc_config",children:"hb_mm_mc_get_smart_bg_enc_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["extern hb_s32",(0,r.jsx)(n.br,{}),"\n","hb_mm_mc_get_smart_bg_enc_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, mc_video_smart_bg_enc_params_t *params);"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsxs)(n.li,{children:["[OUT] mc_video_smart_bg_enc_params_t",(0,r.jsx)(n.br,{}),"\n","*params: Smart background encoding mode parameters"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Value\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Get smart background encoding parameters, applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_smart_bg_enc_config",children:"hb_mm_mc_set_smart_bg_enc_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_set_smart_bg_enc_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, const mc_video_smart_bg_enc_params_t *params);"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsxs)(n.li,{children:["[IN] const mc_video_smart_bg_enc_params_t",(0,r.jsx)(n.br,{}),"\n","*params: Smart background encoding mode parameters"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Set smart background encoding parameters. These parameters are dynamic and applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_pred_unit_config",children:"hb_mm_mc_get_pred_unit_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_pred_unit_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, mc_video_pred_unit_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_pred_unit_params_t *params: Prediction unit parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Get prediction unit parameters, applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_pred_unit_config",children:"hb_mm_mc_set_pred_unit_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_set_pred_unit_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, const mc_video_pred_unit_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_pred_unit_params_t *params: Prediction unit parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Set prediction unit parameters. These parameters are dynamic and applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_transform_config",children:"hb_mm_mc_get_transform_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_transform_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, mc_video_transform_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_transform_params_t *params: Transform parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Get Transform parameters, applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_transform_config",children:"hb_mm_mc_set_transform_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_set_transform_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, const mc_video_transform_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsxs)(n.li,{children:["[IN] const mc_video_transform_params_t *params:",(0,r.jsx)(n.br,{}),"\n","Transform parameters"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Set Transform parameters. These parameters are dynamic and applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_roi_config",children:"hb_mm_mc_get_roi_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_roi_config(media_codec_context_t *context,",(0,r.jsx)(n.br,{}),"\n","mc_video_roi_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_roi_params_t *params: ROI encoding parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Get ROI encoding parameters, applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_roi_config",children:"hb_mm_mc_set_roi_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_set_roi_config(media_codec_context_t *context,",(0,r.jsx)(n.br,{}),"\n","const mc_video_roi_params_t *params)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_roi_params_t *params: ROI encoding parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011Set ROI encoding parameters. This parameter is a dynamic parameter and applies to H.264/H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_mode_decision_config",children:"hb_mm_mc_get_mode_decision_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_mode_decision_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, mc_video_mode_decision_params_t *params);"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_mode_decision_params_t *params: Mode decision parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieve mode decision parameters. This function applies to H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_mode_decision_config",children:"hb_mm_mc_set_mode_decision_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_set_mode_decision_config(media_codec_context_t",(0,r.jsx)(n.br,{}),"\n","*context, const mc_video_mode_decision_params_t *params);"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_mode_decision_params_t *params: Mode decision parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Set mode decision parameters. This parameter is a dynamic parameter and applies to H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_user_data",children:"hb_mm_mc_get_user_data"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_user_data(media_codec_context_t *context,",(0,r.jsx)(n.br,{}),"\n","mc_user_data_buffer_t *params , hb_s32 timeout)"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_user_data_buffer_t *params: User data"}),"\n",(0,r.jsx)(n.li,{children:"[IN] timeout: Timeout duration"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieve user data from the decoded stream. This function applies to H.264/H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\nstatic int check_and_init_test(MediaCodecTestContext *ctx) {\n    int32_t ret = 0;\n    char *inputFileName, *outputFileName, *inputMd5FileName;\n    EXPECT_NE(ctx, nullptr);\n    EXPECT_NE(ctx->context, nullptr);\n    if (ctx == NULL || ctx->context == NULL) {\n        return -1;\n    }\n    inputFileName = ctx->inputFileName;\n    outputFileName = ctx->outputFileName;\n    inputMd5FileName = ctx->inputMd5FileName;\n    printf("%s[%d:%d] Thread work in %s mode\\n", TAG, getpid(), gettid(),\n    ctx->workMode == THREAD_WORK_MODE_SYNC ? "sync" :\n        (ctx->workMode == THREAD_WORK_MODE_ASYNC ? "async" : "poll"));\n    printf("%s[%d:%d] InputFileName = %s\\n", TAG, getpid(), gettid(), inputFileName);\n    printf("%s[%d:%d] OutputFileName = %s\\n", TAG, getpid(), gettid(), outputFileName);\n    printf("%s[%d:%d] InputMd5File = %s\\n", TAG, getpid(), gettid(), inputMd5FileName);\n    EXPECT_NE(inputFileName, nullptr);\n    EXPECT_NE(outputFileName, nullptr);\n    if (inputFileName == NULL || outputFileName == NULL) {\n        return -1;\n    }\n    ctx->inFile = fopen(inputFileName, "rb");\n    EXPECT_NE(ctx->inFile, nullptr);\n    ctx->outFile = fopen(outputFileName, "wb+");\n    EXPECT_NE(ctx->outFile, nullptr);\n    if (ctx->inFile == NULL || ctx->outFile == NULL) {\n        return -1;\n    }\n    if (ctx->md5Test == TRUE) {\n        if (inputMd5FileName) {\n            ctx->inMd5File = fopen(inputMd5FileName, "rb");\n        }\n        EXPECT_NE(ctx->inMd5File, nullptr);\n        if (ctx->inMd5File == NULL) {\n            return -1;\n        }\n    }\n    // allocate ion buffers\n    ctx->ionFd = ion_open();\n    EXPECT_GT(ctx->ionFd, 0);\n    if (ctx->ionFd <= 0) {\n        return -1;\n    }\n    if (ctx->context->encoder == TRUE) {\n        printf("%s[%d:%d] Thread use %s buffer mode, %d rc mode\\n", TAG, getpid(), gettid(),\n        ctx->context->video_enc_params.external_frame_buf ?\n        "external" : "internal",\n        ctx->context->video_enc_params.rc_params.mode);\n        if (ctx->context->video_enc_params.external_frame_buf) {\n            ctx->exFb = (ExternalFrameBuffer *) malloc(\n            ctx->context->video_enc_params.frame_buf_count * sizeof(ExternalFrameBuffer));\n            EXPECT_NE(ctx->exFb, nullptr);\n            if (ctx->exFb == NULL) {\n                return -1;\n            }\n            for (Uint32 i=0; i<ctx->context->video_enc_params.frame_buf_count; i++) {\n                ctx->exFb[i].buf.size = ctx->context->video_enc_params.width\n                * ctx->context->video_enc_params.height * 3/2; // only for yuv420;\n                ret = allocate_ion_mem(ctx->ionFd, &ctx->exFb[i].buf);\n                EXPECT_EQ(ret, 0);\n                if (ret != 0) {\n                    return ret;\n                }\n                ctx->exFb[i].valid = 1;\n                ctx->exFb[i].src_idx = i;\n            }\n        }\n    } else {\n        printf("%s[%d:%d] Thread use %s buffer mode, %d feed mode.\\n", TAG, getpid(), gettid(),\n        ctx->context->video_dec_params.external_bitstream_buf ?\n        "external" : "internal",\n        ctx->context->video_dec_params.feed_mode);\n        if (ctx->context->video_dec_params.external_bitstream_buf) {\n            ctx->exBs = (ExternalStreamBuffer *) malloc(\n            ctx->context->video_dec_params.bitstream_buf_count * sizeof(ExternalStreamBuffer));\n            EXPECT_NE(ctx->exBs, nullptr);\n            if (ctx->exBs == NULL) {\n                return -1;\n            }\n            for (Uint32 i=0; i<ctx->context->video_dec_params.bitstream_buf_count; i++) {\n                ctx->exBs[i].buf.size = ctx->context->video_dec_params.bitstream_buf_size;\n                ret = allocate_ion_mem(ctx->ionFd, &ctx->exBs[i].buf);\n                EXPECT_EQ(ret, 0);\n                if (ret != 0) {\n                    return ret;\n                }\n                ctx->exBs[i].valid = 1;\n                ctx->exBs[i].src_idx = i;\n            }\n        }\n    }\n// open decode files\n    if (ctx->context->encoder != TRUE) {\n    if (ctx->context->video_dec_params.feed_mode == MC_FEEDING_MODE_FRAME_SIZE) {\n        ret = avformat_open_input(&ctx->avContext, ctx->inputFileName, 0, 0);\n        EXPECT_GE(ret, 0);\n        if (ret < 0) {\n            return ret;\n        }\n        ret = avformat_find_stream_info(ctx->avContext, 0);\n        EXPECT_GE(ret, 0);\n        if (ret < 0) {\n            return ret;\n        }\n        ctx->videoIndex = av_find_best_stream(ctx->avContext, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);\n        EXPECT_GE(ctx->videoIndex, 0);\n        if (ctx->videoIndex < 0) {\n            return -1;\n        }\n        av_init_packet(&ctx->avpacket);\n    } else {\n        if (ctx->feedingSize == 0) {\n            uint32_t KB = 1024;\n            int32_t probability10;\n            srand((uint32_t)time(NULL));\n            ctx->feedingSize = rand() % MAX_FEEDING_SIZE;\n            probability10 = (ctx->feedingSize % 100) < 10;\n            if (ctx->feedingSize < KB) {\n                if (probability10 == FALSE)\n                    ctx->feedingSize *= 100;\n                }\n            }\n            printf("%s[%d:%d] Feeding size = %d\\n", TAG,\n            getpid(), gettid(), ctx->feedingSize);\n        }\n        ctx->firstPacket = 1;\n    }\n    return 0;\n}\nstatic int check_and_release_test(MediaCodecTestContext *ctx) {\n    int32_t ret = 0;\n    int md5Match, wholeFileSize = 0;\n    uint8_t *md5Buffer = NULL;\n    EXPECT_NE(ctx, nullptr);\n    EXPECT_NE(ctx->context, nullptr);\n    EXPECT_NE(ctx->inFile, nullptr);\n    EXPECT_NE(ctx->outFile, nullptr);\n    if (ctx == NULL || ctx->context == NULL || ctx->inFile == NULL ||\n        ctx->outFile == NULL) {\n        return -1;\n    }\n    if (ctx->context->encoder != TRUE) {\n        if (ctx->context->video_dec_params.feed_mode == MC_FEEDING_MODE_FRAME_SIZE) {\n            if (ctx->avContext) {\n                avformat_close_input(&ctx->avContext);\n            }\n        }\n    }\n    if (ctx->context->encoder == TRUE) {\n        if (ctx->context->video_enc_params.external_frame_buf) {\n            if (ctx->exFb) {\n                for (Uint32 i=0; i<ctx->context->video_enc_params.frame_buf_count; i++) {\n                    ret = release_ion_mem(ctx->ionFd, &ctx->exFb[i].buf);\n                    EXPECT_EQ(ret, 0);\n                }\n                free(ctx->exFb);\n            }\n        }\n    } else {\n        if (ctx->context->video_dec_params.external_bitstream_buf) {\n            if (ctx->exBs) {\n                for (Uint32 i=0; i<ctx->context->video_dec_params.bitstream_buf_count; i++) {\n                    ret = release_ion_mem(ctx->ionFd, &ctx->exBs[i].buf);\n                    EXPECT_EQ(ret, 0);\n                }\n                free(ctx->exBs);\n            }\n        }\n    }\n    if (ctx->ionFd)\n        ion_close(ctx->ionFd);\n    if (ctx->md5Test && ctx->inMd5File) {\n        fseek(ctx->outFile, 0, SEEK_END);\n        wholeFileSize = ftell(ctx->outFile);\n        fseek(ctx->outFile, 0, SEEK_SET);\n        md5Buffer = (uint8_t *)malloc(wholeFileSize);\n        EXPECT_NE(md5Buffer, nullptr);\n        if (md5Buffer == NULL) {\n            return -1;\n        }\n        fread(md5Buffer, wholeFileSize, 1, ctx->outFile);\n        md5Match = compare_md5_value(MD5_SIZE, ctx->inMd5File,\n        md5Buffer, wholeFileSize);\n        free(md5Buffer);\n        fclose(ctx->inMd5File);\n        EXPECT_EQ(md5Match, 1);\n        if (md5Match != 1) {\n            return -1;\n        }\n    }\n    if (ctx->outFile)\n        fclose(ctx->outFile);\n    if (ctx->inFile)\n        fclose(ctx->inFile);\n    return 0;\n}\nstatic void on_vlc_buffer_message(hb_ptr userdata, hb_s32 * vlc_buf) {\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)userdata;\n    ASSERT_NE(vlc_buf, nullptr);\n    ASSERT_NE(ctx, nullptr);\n    ASSERT_GE(ctx->vlc_buf_size, 0);\n    if (ctx->testLog) {\n        printf("%s %s VLC Buffer size = %d; Reset to %d.\\n", TAG, __FUNCTION__,\n        *vlc_buf, ctx->vlc_buf_size);\n    }\n    *vlc_buf = ctx->vlc_buf_size;\n}\nstatic int read_input_streams(MediaCodecTestContext *ctx,\n    media_codec_buffer_t *inputBuffer) {\n    Uint64 curTime = 0;\n    int ret = 0, ret2 = 0;\n    Uint32 bufIdx = 0, srcIdx = 0;\n    Int32 doRead = TRUE, doRewind = FALSE;\n    uint8_t *seqHeader = NULL;\n    int seqHeaderSize = 0;\n    void *bufPtr = NULL;\n    int avalBufSize = 0;\n    EXPECT_NE(ctx, nullptr);\n    EXPECT_NE(ctx->context, nullptr);\n    EXPECT_NE(ctx->inFile, nullptr);\n    EXPECT_NE(ctx->outFile, nullptr);\n    EXPECT_NE(inputBuffer, nullptr);\n    if (ctx == NULL || ctx->context == NULL || ctx->inFile == NULL ||\n        ctx->outFile == NULL || inputBuffer == NULL) {\n        printf("%s[%d:%d] Invalid parameters(%s).\\n",\n        TAG, getpid(), gettid(), __FUNCTION__);\n        return -1;\n    }\n    if (ctx->stabilityTest || ctx->pfTest) {\n        doRewind = TRUE;\n        curTime = osal_gettime();\n        if ((curTime - ctx->testStartTime)/1000 < (uint32_t)ctx->duration) {\n            doRead = TRUE;\n        } else {\n            printf("%s[%d:%d] Time up(%d)\\n",\n            TAG, getpid(), gettid(), ctx->duration);\n            doRead = FALSE;\n            ret = 0;\n        }\n    }\n    if (ctx->context->video_dec_params.external_bitstream_buf) {\n        // release input buffer and take it as the new input buffer\n        for (bufIdx = 0;\n            bufIdx < ctx->context->video_dec_params.bitstream_buf_count;\n            bufIdx++) {\n            if (ctx->exBs[bufIdx].valid &&\n                ctx->exBs[bufIdx].src_idx == inputBuffer->vstream_buf.src_idx) {\n                srcIdx = inputBuffer->vstream_buf.src_idx;\n                break;\n            }\n        }\n        EXPECT_NE(bufIdx, ctx->context->video_dec_params.bitstream_buf_count);\n        if (bufIdx == ctx->context->video_dec_params.bitstream_buf_count) {\n            return -1;\n        }\n        bufPtr = (void *)ctx->exBs[srcIdx].buf.virt_addr;\n        if (ctx->context->video_dec_params.feed_mode ==\n            MC_FEEDING_MODE_FRAME_SIZE) {\n            avalBufSize = ctx->exBs[srcIdx].buf.size;\n        } else {\n            avalBufSize = (ctx->exBs[srcIdx].buf.size < (int)ctx->feedingSize) ?\n            ctx->exBs[srcIdx].buf.size : ctx->feedingSize;\n        }\n        inputBuffer->vstream_buf.fd = ctx->exBs[srcIdx].buf.fd;\n        inputBuffer->vstream_buf.phy_ptr =\n        ctx->exBs[srcIdx].buf.phys_addr;\n        inputBuffer->vstream_buf.vir_ptr =\n        (hb_u8 *)ctx->exBs[srcIdx].buf.virt_addr;\n    } else {\n        bufPtr = (void *)inputBuffer->vstream_buf.vir_ptr;\n        if (ctx->context->video_dec_params.feed_mode ==\n            MC_FEEDING_MODE_FRAME_SIZE) {\n            avalBufSize = inputBuffer->vstream_buf.size;\n        } else {\n            avalBufSize = (inputBuffer->vstream_buf.size < ctx->feedingSize) ?\n            inputBuffer->vstream_buf.size : ctx->feedingSize;\n        }\n    }\n    if (doRead == FALSE) {\n        return ret;\n    }\n    // MC_FEEDING_MODE_FRAME_SIZE mode\n    if (ctx->context->video_dec_params.feed_mode == MC_FEEDING_MODE_FRAME_SIZE) {\n        do {\n            if (ctx->avpacket.size == 0) {\n                ret = av_read_frame(ctx->avContext, &ctx->avpacket);\n                if (ret < 0 && doRewind == FALSE) {\n                    printf("%s[%d:%d] Failed to read input file (error=0x%x)\\n",\n                        TAG, getpid(), gettid(), ret);\n                }\n                if (ret < 0 && doRewind == TRUE) {\n                    avformat_close_input(&ctx->avContext);\n                    ret2 = avformat_open_input(&ctx->avContext, ctx->inputFileName, 0, 0);\n                    EXPECT_GE(ret2, 0);\n                    if (ret2 < 0) {\n                        ret = ret2;\n                        break;\n                    }\n                    /*ret = avformat_find_stream_info(ctx->avContext, 0);\n                    EXPECT_GE(ret, 0);\n                    if (ret < 0) {\n                        break;\n                    }\n                    ctx->videoIndex = av_find_best_stream(ctx->avContext, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);\n                    EXPECT_GE(ctx->videoIndex, 0);\n                    if (ctx->videoIndex < 0) {\n                        ret = -1;break;\n                    }*/\n                    av_init_packet(&ctx->avpacket);\n                }\n            } else {\n                if (ctx->testLog) {\n                    printf("%s[%d:%d] Reuse previous stream packet size %d\\n",\n                    TAG, getpid(), gettid(), ctx->avpacket.size);\n                }\n            }\n        } while (ret < 0 && doRewind == TRUE);\n        if (ret < 0) {\n            if (ret == AVERROR_EOF || ctx->avContext->pb->eof_reached == TRUE) {\n                printf("%s[%d:%d] End of file!\\n", TAG, getpid(), gettid());\n                ret = 0;\n            } else {\n                printf("%s[%d:%d] Failed to av_read_frame error(0x%08x)\\n",\n                TAG, getpid(), gettid(), ret);\n            }\n            return ret;\n        }\n        if (ctx->testLog) {\n            printf("%s[%d:%d] Read packet size %d\\n",\n                TAG, getpid(), gettid(), ctx->avpacket.size);\n        }\n        seqHeaderSize = 0;\n        if (ctx->firstPacket) {\n            AVCodecParameters* codec;\n            int retSize = 0;\n            codec = ctx->avContext->streams[ctx->videoIndex]->codecpar;\n            seqHeader = (uint8_t*)malloc(codec->extradata_size + 1024);\n            if (seqHeader == NULL) {\n                printf("%s[%d:%d] Failed to malloc seqHeader\\n",\n                TAG, getpid(), gettid());\n                ret = -1;\n                return ret;\n            }\n            memset((void*)seqHeader, 0x00, codec->extradata_size + 1024);\n            seqHeaderSize = build_dec_seq_header(seqHeader,\n            ctx->context->codec_id,\n            ctx->avContext->streams[ctx->videoIndex], &retSize);\n            if (seqHeaderSize < 0) {\n                printf("%s[%d:%d] Failed to build seqHeader\\n",\n                TAG, getpid(), gettid());\n                ret = -1;\n                return ret;\n            }\n            ctx->firstPacket = 0;\n        }\n        if ((ctx->avpacket.size <= avalBufSize)\n            && (seqHeaderSize <= avalBufSize)) {\n            int bufSize = 0;\n            if (seqHeaderSize) {\n                memcpy(bufPtr, seqHeader, seqHeaderSize);\n                bufSize = seqHeaderSize;\n                /*memcpy((char *)bufPtr+bufSize,ctx->avpacket.data, ctx->avpacket.size);\n                bufSize += ctx->avpacket.size;\n                av_packet_unref(&ctx->avpacket);\n                ctx->avpacket.size = 0;*/\n            } else {\n                memcpy(bufPtr,ctx->avpacket.data, ctx->avpacket.size);\n                bufSize = ctx->avpacket.size;\n                av_packet_unref(&ctx->avpacket);\n                ctx->avpacket.size = 0;\n            }\n            inputBuffer->vstream_buf.size = bufSize;\n        } else {\n            printf("%s[%d:%d] The stream buffer is too "\n            "small!\\n", TAG, getpid(), gettid());\n            return -1;\n        }\n        if (seqHeader) {\n            free(seqHeader);\n            seqHeader = NULL;\n        }\n        return 1;\n    }\n    // MC_FEEDING_MODE_STREAM_SIZE mode\n    do {\n        ret = fread(bufPtr, 1, avalBufSize, ctx->inFile);\n        if (ret <= 0 && doRewind == FALSE) {\n            printf("%s[%d:%d] Failed to read input file (error=0x%x)\\n",\n                TAG, getpid(), gettid(), ret);\n        }\n        if (ret <= 0 && doRewind == TRUE) {\n            if(fseek(ctx->inFile, 0, SEEK_SET)) {\n                printf("%s Failed to rewind input file (pid=%d, tid=%d)\\n",\n                    TAG, getpid(), gettid());\n                break;\n            }\n        }\n    } while (ret == 0 && doRewind == TRUE);\n    inputBuffer->vstream_buf.size = ret > 0 ? ret : 0;\n    return ret;\n}\nstatic int write_output_frames(MediaCodecTestContext *ctx,\n    media_codec_buffer_t *outputBuffer) {\n    int32_t ret = 0;\n    EXPECT_NE(ctx, nullptr);\n    EXPECT_NE(ctx->context, nullptr);\n    EXPECT_NE(ctx->inFile, nullptr);\n    EXPECT_NE(ctx->outFile, nullptr);\n    EXPECT_NE(outputBuffer, nullptr);\n    if (ctx == NULL || ctx->context == NULL || ctx->inFile == NULL ||\n        ctx->outFile == NULL || outputBuffer == NULL) {\n        printf("%s[%d:%d] Invalid parameters(%s).\\n",\n        TAG, getpid(), gettid(), __FUNCTION__);\n        return -1;\n    }\n    if (!ctx->stabilityTest && !ctx->pfTest) {\n        fwrite(outputBuffer->vframe_buf.vir_ptr[0], outputBuffer->vframe_buf.size,\n            1, ctx->outFile);\n    }\n    return ret;\n}\nstatic int do_decode_params_checking(MediaCodecTestContext *ctx,\n    media_codec_buffer_t *outputBuffer) {\n    media_codec_context_t *context;\n    int32_t ret = 0;\n    EXPECT_NE(ctx, nullptr);\n    EXPECT_NE(ctx->context, nullptr);\n    if (ctx == NULL || ctx->context == NULL || ctx->inFile == NULL ||\n        ctx->outFile == NULL || outputBuffer == NULL) {\n        printf("%s[%d:%d] Invalid parameters(%s).\\n",\n        TAG, getpid(), gettid(), __FUNCTION__);\n        return -1;\n    }\n    context = ctx->context;\n    if (ctx->enable_get_userdata) {\n        mc_user_data_buffer_t userdata = {0};\n        ret = hb_mm_mc_get_user_data(context, &userdata, 0);\n        if (!ret) {\n            printf("%s[%d:%d] Get userdata %d:\\n", TAG, getpid(), gettid(), userdata.size);\n            for (uint32_t i = 0; i < userdata.size; i++) {\n                if (i < 16) {\n                    printf("%s[%d:%d] userdata[i]:%x\\n", TAG, getpid(), gettid(), userdata.virt_addr[i]);\n                } else {\n                    printf("%s[%d:%d] userdata[i]:%c\\n", TAG, getpid(), gettid(), userdata.virt_addr[i]);\n                }\n            }\n            ret = hb_mm_mc_release_user_data(context, &userdata);\n        } else {\n            ret = 0;\n        }\n    }\n    return ret;\n}\nstatic void do_sync_decoding(void *arg) {\n    int ret = 0;\n    int step = 0;\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)arg;\n    media_codec_context_t *context;\n    media_codec_callback_t callback;\n    media_codec_buffer_t inputBuffer;\n    media_codec_buffer_t outputBuffer;\n    media_codec_output_buffer_info_t info;\n    int32_t decStartTime = 0, decFinishTime = 0;\n    ctx->workMode = THREAD_WORK_MODE_SYNC;\n    ASSERT_EQ(check_and_init_test(ctx), 0);\n    context = ctx->context;\n    //get current time\n    ctx->testStartTime = osal_gettime();\n    if (ctx->testLog) {\n        printf("%s[%d:%d] Step %d initialize (outFile=%s, FileFd=%p)\\n",\n            TAG, getpid(), gettid(), step++, ctx->outputFileName, ctx->outFile);\n    }\n    ret = hb_mm_mc_initialize(context);\n    ASSERT_EQ(ret, (int32_t)0);\n    callback.on_vlc_buffer_message = on_vlc_buffer_message;\n    if (ctx->vlc_buf_size > 0) {\n        ret = hb_mm_mc_set_vlc_buffer_listener(context, &callback, ctx);\n        ASSERT_EQ(ret, (int32_t)0);\n    }\n    if (ctx->testLog) {\n        printf("%s[%d:%d] Step %d configure\\n", TAG, getpid(), gettid(), step++);\n    }\n    ret = hb_mm_mc_configure(context);\n    EXPECT_EQ(ret, (int32_t)0);\n    if (ctx->testLog) {\n        printf("%s[%d:%d] Step %d start\\n", TAG, getpid(), gettid(), step++);\n    }\n    mc_av_codec_startup_params_t startup_params;\n    memset(&startup_params, 0x00, sizeof(mc_av_codec_startup_params_t));\n    ret = hb_mm_mc_start(context, &startup_params);\n    EXPECT_EQ(ret, (int32_t)0);\n    do {\n        if (!ctx->lastStream) {\n            if (ctx->testLog) {\n                printf("%s[%d:%d] Step %d dequeue input\\n", TAG, getpid(), gettid(), step++);\n            }\n            // process input buffers\n            ret = hb_mm_mc_dequeue_input_buffer(context, &inputBuffer, 3000);\n            //EXPECT_EQ(ret, (int32_t)0);\n            if (!ret) {\n                if (ctx->testLog) {\n                    printf("%s[%d:%d] input buffer viraddr %p phy addr %x, size = %d\\n",\n                    TAG, getpid(), gettid(), inputBuffer.vstream_buf.vir_ptr,\n                    inputBuffer.vstream_buf.phy_ptr,\n                    inputBuffer.vstream_buf.size);\n                }if (ctx->testLog) {\n                    printf("%s[%d:%d] Step %d feed input (pid=%d, tid=%d)\\n", TAG, getpid(), gettid(), step++);\n                }\n                ret = read_input_streams(ctx, &inputBuffer);\n                if (ret <= 0) {\n                    printf("%s[%d:%d] There is no more input data(ret=%d)!\\n",\n                    TAG, getpid(), gettid(), ret);\n                    inputBuffer.vstream_buf.stream_end = TRUE;\n                    inputBuffer.vstream_buf.size = 0;\n                    ctx->lastStream = 1;\n                }\n                //EXPECT_EQ(ret, (int32_t)TRUE);\n                if (ctx->testLog) {\n                    printf("%s[%d:%d] Step %d queue input(size=%d)\\n",\n                    TAG, getpid(), gettid(), step++, inputBuffer.vstream_buf.size);\n                }\n                ret = hb_mm_mc_queue_input_buffer(context, &inputBuffer, 100);\n                EXPECT_EQ(ret, (int32_t)0);\n                if (ret != 0) {\n                    break;\n                }\n                if (ctx->delaytest) {\n                    decStartTime = osal_gettime();\n                }\n            } else {\n                if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                    EXPECT_EQ(ret, (int32_t)0);\n                    char info[256];\n                    hb_mm_strerror(ret, info, 256);\n                    printf("%s[%d:%d] dequeue input buffer fail.(%s)\\n", TAG, getpid(), gettid(), info);\n                    break;\n                }\n            }\n        }\n        if (!ctx->lastFrame) {\n            if (ctx->testLog) {\n            printf("%s[%d:%d] Step %d dequeue output\\n", TAG, getpid(), gettid(), step++);\n            }\n            // process output buffers\n            memset(&outputBuffer, 0x00, sizeof(media_codec_buffer_t));\n            memset(&info, 0x00, sizeof(media_codec_output_buffer_info_t));\n            ret = hb_mm_mc_dequeue_output_buffer(context, &outputBuffer, &info, 100);\n            //EXPECT_EQ(ret, (int32_t)0);\n            if (!ret) {\n                if (ctx->testLog) {\n                    printf("%s[%d:%d] output bufferviraddr %p phy addr %x, size = %d, outFile = %p\\n",\n                    TAG, getpid(), gettid(), outputBuffer.vframe_buf.vir_ptr[0],\n                    outputBuffer.vframe_buf.phy_ptr[0],\n                    outputBuffer.vframe_buf.size, ctx->outFile);\n                }\n                if (ctx->testLog) {\n                    printf("%s[%d:%d] Step %d write output file\\n", TAG, getpid(), gettid(), step++);\n                }\n                if (ctx->delaytest) {\n                    decFinishTime = osal_gettime();\n                    if ((decFinishTime - decStartTime) >= ctx->delaytime) {\n                        printf("%s[%d:%d] Decoding time is %d, more than %dms\\n",\n                        TAG, getpid(), gettid(), (decFinishTime - decStartTime), ctx->delaytime);\n                        ASSERT_LE((decFinishTime - decStartTime), ctx->delaytime);\n                    }\n                }\n                ASSERT_EQ(write_output_frames(ctx, &outputBuffer), 0);\n                if (ctx->testLog) {\n                    printf("%s[%d:%d] Step %d queue output\\n", TAG, getpid(), gettid(), step++);\n                }\n                ASSERT_EQ(do_decode_params_checking(ctx, &outputBuffer), 0);\n                ret = hb_mm_mc_queue_output_buffer(context, &outputBuffer, 100);\n                EXPECT_EQ(ret, (int32_t)0);\n                if (outputBuffer.vframe_buf.frame_end) {\n                    printf("%s[%d:%d] There is no more output data!\\n", TAG, getpid(), gettid());\n                    ctx->lastFrame = 1;\n                    break;\n                }\n                if (ret) {\n                    break;\n                }\n            } else {\n                char info[256];\n                hb_mm_strerror(ret, info, 256);\n                printf("%s[%d:%d] dequeue output buffer fail.(%s)\\n", TAG, getpid(), gettid(), info);\n                if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                    EXPECT_EQ(ret, (int32_t)0);\n                    break;\n                }\n                if (ctx->stabilityTest && ctx->lastStream ==1) {\n                    break;\n                }\n            }\n        }\n    }while(TRUE);\n    ret = hb_mm_mc_stop(context);\n    EXPECT_EQ(ret, (int32_t)0);\n    ret = hb_mm_mc_release(context);\n    EXPECT_EQ(ret, (int32_t)0);\n    ASSERT_EQ(check_and_release_test(ctx), 0);\n}\nint main(int argc, char *argv[])\n{\n    char outputFileName[MAX_FILE_PATH] = "input.h265";\n    char inputFileName[MAX_FILE_PATH] = "output.yuv";\n    mTestWidth = 640;\n    mTestHeight = 480;\n    mTestPixFmt = MC_PIXEL_FORMAT_YUV420P;\n    mTestFeedMode = MC_FEEDING_MODE_FRAME_SIZE;\n    mTestCodec = TEST_CODEC_ID_H265;\n    mc_video_codec_dec_params_t *params;\n    media_codec_context_t *context = (media_codec_context_t *)malloc(sizeof(media_codec_context_t ));\n    ASSERT_NE(context, nullptr);\n    memset(context, 0x00, sizeof(media_codec_context_t));\n    context->codec_id = get_codec_id(mTestCodec);\n    context->encoder = FALSE;\n    params = &context->video_dec_params;\n    params->feed_mode = mTestFeedMode;\n    params->pix_fmt = mTestPixFmt;\n    params->bitstream_buf_size = mTestWidth * mTestHeight * 3 / 2;\n    params->bitstream_buf_count = 6;\n    params->frame_buf_count = 8;\n    if (context->codec_id == MEDIA_CODEC_ID_H265) {\n        params->h265_dec_config.bandwidth_Opt = TRUE;\n        params->h265_dec_config.reorder_enable = TRUE;\n        params->h265_dec_config.skip_mode = 0;\n        params->h265_dec_config.cra_as_bla = FALSE;\n        params->h265_dec_config.dec_temporal_id_mode = 0;\n        params->h265_dec_config.target_dec_temporal_id_plus1 = 0;\n    }\n    MediaCodecTestContext ctx;\n    memset(&ctx, 0x00, sizeof(ctx));\n    ctx.context = context;\n    ctx.inputFileName = inputFileName;\n    ctx.outputFileName = outputFileName;\n    char inputMd5FileName[MAX_FILE_PATH];\n    if (ctx.md5Test) {\n        char inputMd5Suffix[MAX_FILE_PATH] = ".md5";\n        snprintf(dedicatedSuffix, MAX_FILE_PATH, "%s", "dec");\n        snprintf(inputMd5FileName, MAX_FILE_PATH, "%s%s_%s_%s%s",\n        dedicatedInputPrefix, mGlobalPixFmtName[mTestPixFmt],\n        dedicatedSuffix, mGlobalCodecName[mTestCodec], inputMd5Suffix);\n        ctx.inputMd5FileName = inputMd5FileName;\n    }\n    do_sync_decoding(&ctx);\n    if (context != NULL) {\n        free(context);\n    }\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_release_user_data",children:"hb_mm_mc_release_user_data"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_release_user_data(media_codec_context_t *context, const mc_user_data_buffer_t * params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_user_data_buffer_t * params: User data"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Releases user data from the decoded stream. Applicable to H.264/H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_user_data",children:"hb_mm_mc_get_user_data"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_mjpeg_config",children:"hb_mm_mc_get_mjpeg_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_mjpeg_config(media_codec_context_t *context, mc_mjpeg_enc_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_mjpeg_enc_params_t *params: MJPEG encoding parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves MJPEG encoding parameters. Applicable to MJPEG."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-#",metastring:'include "hb_media_codec.h"',children:'# include "hb_media_error.h"\nint main(int argc, char *argv[])\n{\n    int ret = 0;\n    char outputFileName[MAX_FILE_PATH];\n    char inputFileName[MAX_FILE_PATH];\n    mTestCodec = TEST_CODEC_ID_MJPEG;\n    mTestPixFmt = MC_PIXEL_FORMAT_NV12;\n    char dedicatedSuffix[MAX_FILE_PATH] = "_test";\n    char inputSuffix[MAX_FILE_PATH] = ".yuv";\n    char outputSuffixJpeg[MAX_FILE_PATH] = ".jpg";\n    char outputSuffixMjpg[MAX_FILE_PATH] = ".mjpg";\n    snprintf(inputFileName, MAX_FILE_PATH, "%s%s%s",\n        mInputSpecPrefix, mTest12Bit ? mGlobal12BPixFmtName[mTestPixFmt]\n        : mGlobalPixFmtName[mTestPixFmt], inputSuffix);\n    snprintf(outputFileName, MAX_FILE_PATH, "%s%s%s%s",\n        mOutputSpecPrefix, mTest12Bit ? mGlobal12BPixFmtName[mTestPixFmt]\n        : mGlobalPixFmtName[mTestPixFmt], dedicatedSuffix,\n    mTestCodec == TEST_CODEC_ID_JPEG ? outputSuffixJpeg : outputSuffixMjpg);\n    mc_video_codec_enc_params_t *params;\n    media_codec_context_t *context = (media_codec_context_t *)malloc(sizeof(media_codec_context_t ));\n    ASSERT_NE(context, nullptr);\n    memset(context, 0x00, sizeof(media_codec_context_t));\n    context->codec_id = mTestCodec == TEST_CODEC_ID_JPEG ?\n        MEDIA_CODEC_ID_JPEG : MEDIA_CODEC_ID_MJPEG;\n    context->encoder = TRUE;\n    params = &context->video_enc_params;\n    params->width = mTestWidth;\n    params->height = mTestHeight;\n    params->pix_fmt = mTestPixFmt;\n    params->frame_buf_count = 5;\n    params->bitstream_buf_count = 5;\n    params->rot_degree = MC_CCW_0;\n    params->mir_direction = MC_DIRECTION_NONE;\n    params->frame_cropping_flag = FALSE;\n    params->external_frame_buf = FALSE;\n    if (context->codec_id == MEDIA_CODEC_ID_MJPEG) {\n        params->rc_params.mode = MC_AV_RC_MODE_MJPEGFIXQP;\n        ret = hb_mm_mc_get_rate_control_config(context, &params->rc_params);\n        ASSERT_EQ(ret, (int32_t)0);\n        params->mjpeg_enc_config.restart_interval = mTestWidth/16;\n        params->mjpeg_enc_config.extended_sequential = mTest12Bit;\n    } else {\n        params->jpeg_enc_config.restart_interval = mTestWidth/16;\n        params->jpeg_enc_config.extended_sequential = mTest12Bit;\n    }\n    mc_mjpeg_enc_params_t mjpeg_params;\n    memset(&mjpeg_params, 0x00, sizeof(mjpeg_params));\n    ret = hb_mm_mc_get_mjpeg_config(context, &mjpeg_params);\n    ASSERT_EQ(ret, (int32_t)0);\n    ret = hb_mm_mc_initialize(context);\n    ASSERT_EQ(ret, (int32_t)0);\n    ret = hb_mm_mc_set_mjpeg_config(context, &mjpeg_params);\n    ASSERT_EQ(ret, (int32_t)0);\n    ret = hb_mm_mc_stop(context);\n    ASSERT_EQ(ret, (int32_t)0);\n    ret = hb_mm_mc_release(context);\n    ASSERT_EQ(ret, (int32_t)0);\n    if (context != NULL) {\n        free(context);\n    }\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_mjpeg_config",children:"hb_mm_mc_set_mjpeg_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_mjpeg_config(media_codec_context_t\n*context, const mc_mjpeg_enc_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_mjpeg_enc_params_t *params: MJPEG encoding parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets MJPEG encoding parameters. These parameters are dynamic and applicable to MJPEG."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_mjpeg_config",children:"hb_mm_mc_get_mjpeg_config"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_jpeg_config",children:"hb_mm_mc_get_jpeg_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_jpeg_config(media_codec_context_t\n*context, mc_jpeg_enc_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_jpeg_enc_params_t *params: JPEG encoding parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves JPEG encoding parameters, applicable to JPEG."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\nint main(int argc, char *argv[])\n{\n    int ret = 0;\n    char outputFileName[MAX_FILE_PATH];\n    char inputFileName[MAX_FILE_PATH];\n    mTestCodec = TEST_CODEC_ID_JPEG;\n    mTestPixFmt = MC_PIXEL_FORMAT_NV12;\n    char dedicatedSuffix[MAX_FILE_PATH] = "_test";\n    char inputSuffix[MAX_FILE_PATH] = ".yuv";\n    char outputSuffixJpeg[MAX_FILE_PATH] = ".jpg";\n    char outputSuffixMjpg[MAX_FILE_PATH] = ".mjpg";\n    snprintf(inputFileName, MAX_FILE_PATH, "%s%s%s",\n        mInputSpecPrefix, mTest12Bit ? mGlobal12BPixFmtName[mTestPixFmt]\n        : mGlobalPixFmtName[mTestPixFmt], inputSuffix);\n    snprintf(outputFileName, MAX_FILE_PATH, "%s%s%s%s",\n        mOutputSpecPrefix, mTest12Bit ? mGlobal12BPixFmtName[mTestPixFmt]\n        : mGlobalPixFmtName[mTestPixFmt], dedicatedSuffix,\n        mTestCodec == TEST_CODEC_ID_JPEG ? outputSuffixJpeg : outputSuffixMjpg);\n    mc_video_codec_enc_params_t *params;\n    media_codec_context_t *context = (media_codec_context_t *)malloc(sizeof(media_codec_context_t ));\n    ASSERT_NE(context, nullptr);\n    memset(context, 0x00, sizeof(media_codec_context_t));\n    context->codec_id = mTestCodec == TEST_CODEC_ID_JPEG ?\n    MEDIA_CODEC_ID_JPEG : MEDIA_CODEC_ID_MJPEG;\n    context->encoder = TRUE;\n    params = &context->video_enc_params;\n    params->width = mTestWidth;\n    params->height = mTestHeight;\n    params->pix_fmt = mTestPixFmt;\n    params->frame_buf_count = 5;\n    params->bitstream_buf_count = 5;\n    params->rot_degree = MC_CCW_0;\n    params->mir_direction = MC_DIRECTION_NONE;\n    params->frame_cropping_flag = FALSE;\n    params->external_frame_buf = FALSE;\n    if (context->codec_id == MEDIA_CODEC_ID_MJPEG) {\n        params->rc_params.mode = MC_AV_RC_MODE_MJPEGFIXQP;\n        ret = hb_mm_mc_get_rate_control_config(context, &params->rc_params);\n        ASSERT_EQ(ret, (int32_t)0);\n        params->mjpeg_enc_config.restart_interval = mTestWidth/16;\n        params->mjpeg_enc_config.extended_sequential = mTest12Bit;\n    } else {\n        params->jpeg_enc_config.restart_interval = mTestWidth/16;\n        params->jpeg_enc_config.extended_sequential = mTest12Bit;\n    }\n    mc_jpeg_enc_params_t jpeg_params;\n    memset(&jpeg_params, 0x00, sizeof(jpeg_params));\n    ret = hb_mm_mc_get_jpeg_config(context, &jpeg_params);\n    ASSERT_EQ(ret, (int32_t)0);\n    ret = hb_mm_mc_initialize(context);\n    ASSERT_EQ(ret, (int32_t)0);\n    jpeg_params.quality_factor = 30;\n    jpeg_params.restart_interval = (((params->width+15)>>4) *\n        ((params->height+15)>>4) * 2) + 1;\n    jpeg_params.crop_en = FALSE;\n    ret = hb_mm_mc_set_jpeg_config(context, &jpeg_params);\n    ASSERT_EQ(ret, (int32_t)HB_MEDIA_ERR_INVALID_PARAMS);\n    jpeg_params.restart_interval = 70;\n    ret = hb_mm_mc_set_jpeg_config(context, &jpeg_params);\n    ASSERT_EQ(ret, (int32_t)0);\n    ret = hb_mm_mc_stop(context);\n    ASSERT_EQ(ret, (int32_t)0);\n    ret = hb_mm_mc_release(context);\n    ASSERT_EQ(ret, (int32_t)0);\n    if (context != NULL) {\n        free(context);\n    }\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_jpeg_config",children:"hb_mm_mc_set_jpeg_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_jpeg_config(media_codec_context_t\n*context, const mc_jpeg_enc_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_jpeg_enc_params_t *params: JPEG encoding parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets JPEG encoding parameters. These parameters are dynamic and applicable to JPEG encoding."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_jpeg_config",children:"hb_mm_mc_get_jpeg_config"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_fd",children:"hb_mm_mc_get_fd"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Function Declaration"})}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_fd(media_codec_context_t * context, hb_s32 *fd)"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameter Description"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] hb_s32 *fd: File descriptor of the device node"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Return Values"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Function Description"})}),"\n",(0,r.jsx)(n.p,{children:"Obtains the file descriptor (fd) of the device node, which can be used with the select() operation to monitor codec results."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example Code"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\n\ntypedef struct MediaCodecTestContext {\n    media_codec_context_t *context;\n    char *inputFileName;\n    char *outputFileName;\n    int abnormal;\n    int32_t duration; // s\n} MediaCodecTestContext;\n\nUint64 osal_gettime(void)\n{\n    struct timespec tp;\n\n    clock_gettime(CLOCK_MONOTONIC, &tp);\n\n    return ((Uint64)tp.tv_sec*1000 + tp.tv_nsec/1000000);\n}\n\nstatic void do_poll_encoding_select(void *arg) {\n    hb_s32 ret = 0;\n    int pollFd = -1;\n    FILE *outFile;\n    int lastStream = 0;\n    fd_set readFds;\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)arg;\n    media_codec_context_t *context = ctx->context;\n    char *outputFileName = ctx->outputFileName;\n    mc_inter_status_t status;\n\n    outFile = fopen(outputFileName, "wb");\n    if (!outFile) {\n        goto ERR;\n    }\n\n    ret = hb_mm_mc_get_fd(context, &pollFd);\n    if (ret) {\n        goto ERR;\n    }\n\n    do {\n        FD_ZERO(&readFds);\n        FD_SET(pollFd, &readFds);\n        ret = select(pollFd+1, &readFds, NULL, NULL, NULL);\n        if (ret < 0) {\n            printf("Failed to select fd = %d.(err %s)\\n", pollFd, strerror(errno));\n            ctx->abnormal = TRUE;\n            break;\n        } else if (ret == 0) {\n            printf("Time out to select fd = %d.\\n", pollFd);\n            ctx->abnormal = TRUE;\n            break;\n        } else {\n            if (FD_ISSET(pollFd, &readFds)) {\n                ASSERT_EQ(hb_mm_mc_get_status(context, &status), (int32_t)0);\n                if (ctx->testLog) {\n                    printf("%s[%d:%d] output count %d input count %d\\n", TAG, getpid(), gettid(),\n                    status.cur_output_buf_cnt, status.cur_input_buf_cnt);\n                }\n                media_codec_buffer_t outputBuffer;\n                media_codec_output_buffer_info_t info;\n                memset(&outputBuffer, 0x00, sizeof(media_codec_buffer_t));\n                memset(&info, 0x00, sizeof(media_codec_output_buffer_info_t));\n                ret = hb_mm_mc_dequeue_output_buffer(context, &outputBuffer, &info, 100);\n                if (!ret && outFile) {\n                    fwrite(outputBuffer.vstream_buf.vir_ptr, outputBuffer.vstream_buf.size, 1, outFile);\n                    ret = hb_mm_mc_queue_output_buffer(context, &outputBuffer, 100);\n\n                    if (outputBuffer.vstream_buf.stream_end) {\n                        printf("There is no more output data!\\n");\n                        lastStream = 1;\n                        break;\n                    }\n                    if (ret) {\n                        ctx->abnormal = TRUE;\n                        break;\n                    }\n                } else {\n                    if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                        printf("Dequeue output buffer fail.\\n");\n                        break;\n                    }\n                }\n            }\n        }\n    } while (!lastStream && !ctx->abnormal);\n\nERR:\n    if (pollFd) {\n        hb_mm_mc_close_fd(context, pollFd)\n    }\n    if (outFile)\n        fclose(outFile);\n}\n\nstatic void do_poll_encoding(void *arg) {\n    pthread_t thread_id;\n    void* retVal;\n    hb_s32 ret = 0;\n    FILE *inFile;\n    int noMoreInput = 0;\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)arg;\n    media_codec_context_t *context = ctx->context;\n\n    char *inputFileName = ctx->inputFileName;\n    char *outputFileName = ctx->outputFileName;\n    media_codec_state_t state = MEDIA_CODEC_STATE_NONE;\n    inFile = fopen(inputFileName, "rb");\n    if (!inFile) {\n        goto ERR;\n    }\n\n    ret = hb_mm_mc_initialize(context);\n    if (ret) {\n        goto ERR;\n    }\n\n    ret = hb_mm_mc_configure(context);\n    if (ret) {\n        goto ERR;\n    }\n\n    mc_av_codec_startup_params_t startup_params;\n    startup_params.video_enc_startup_params.receive_frame_number = 0;\n    ret = hb_mm_mc_start(context, &startup_params);\n    if (ret) {\n        goto ERR;\n    }\n\n    pthread_create(&thread_id, NULL, (void* (*)(void*))do_poll_encoding_select, ctx);\n\n    do {\n        media_codec_buffer_t inputBuffer;\n        memset(&inputBuffer, 0x00, sizeof(media_codec_buffer_t));\n        ret = hb_mm_mc_dequeue_input_buffer(context, &inputBuffer, 100);\n        if (!ret) {\n            ret = fread(inputBuffer.vframe_buf.vir_ptr[0], 1,\n                inputBuffer.vframe_buf.size, inFile);\n            if (!ret) {\n                printf("There is no more input data!\\n");\n                inputBuffer.vframe_buf.frame_end = TRUE;\n                noMoreInput = 1;\n            }\n            ret = hb_mm_mc_queue_input_buffer(context, &inputBuffer, 100);\n            if (ret) {\n                printf("Queue input buffer fail.\\n");\n                break;\n            }\n        } else {\n            if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                printf("Dequeue input buffer fail.\\n");\n                break;\n            }\n        }\n    }while(!noMoreInput && !ctx->abnormal);\n    pthread_join(thread_id, &retVal);\n\n    hb_mm_mc_stop(context);\n\n    hb_mm_mc_release(context);\n    context = NULL;\n\nERR:\n    hb_mm_mc_get_state(context, &state);\n    if (context && state != MEDIA_CODEC_STATE_UNINITIALIZED) {\n        hb_mm_mc_stop(context);\n        hb_mm_mc_release(context);\n    }\n\n    if (inFile)\n        fclose(inFile);\n}\n\nint main(int argc, char *argv[])\n{\n    hb_s32 ret = 0;\n    char outputFileName[MAX_FILE_PATH] = "./tmp.yuv";\n    char inputFileName[MAX_FILE_PATH] = "./output.stream";\n    mc_video_codec_enc_params_t *params;\n    media_codec_context_t context;\n\n    memset(&context, 0x00, sizeof(media_codec_context_t));\n    context.codec_id = MEDIA_CODEC_ID_H265;\n    context.encoder = TRUE;\n    params = &context.video_enc_params;\n    params->width = 640;\n    params->height = 480;\n    params->pix_fmt = MC_PIXEL_FORMAT_YUV420P;\n    params->frame_buf_count = 5;\n    params->external_frame_buf = FALSE;\n    params->bitstream_buf_count = 5;\n    params->rc_params.mode = MC_AV_RC_MODE_H265CBR;\n    ret = hb_mm_mc_get_rate_control_config(&context, &params->rc_params);\n    if (ret) {\n        return -1;\n    }\n    params->rc_params.h265_cbr_params.bit_rate = 5000;\n    params->rc_params.h265_cbr_params.frame_rate = 30;\n    params->rc_params.h265_cbr_params.intra_period = 30;\n    params->gop_params.decoding_refresh_type = 2;\n    params->gop_params.gop_preset_idx = 2;\n    params->rot_degree = MC_CCW_0;\n    params->mir_direction = MC_DIRECTION_NONE;\n    params->frame_cropping_flag = FALSE;\n\n    MediaCodecTestContext ctx;\n    memset(&ctx, 0x00, sizeof(ctx));\n    ctx.context = &context;\n    ctx.inputFileName = inputFileName;\n    ctx.outputFileName = outputFileName;\n    ctx.duration = 5;\n    do_poll_encoding(&ctx);\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_close_fd",children:"hb_mm_mc_close_fd"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_close_fd(media_codec_context_t * context,\nhb_s32 fd)"}),"\n",(0,r.jsx)(n.p,{children:"**\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 fd: File descriptor of the device node"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Closes the device node."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_fd",children:"hb_mm_mc_get_fd"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_camera",children:"hb_mm_mc_set_camera"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_camera(media_codec_context_t *context,\nhb_s32 pipeline, hb_s32 channel_port_id)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 pipeline: Pipeline"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 channel_port_id: Channel port ID"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets VIO camera information. This parameter is static and applicable to H.264/H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\ntypedef struct _media_codec_context {\n    media_codec_id_t codec_id;\n    hb_bool encoder;\n    hb_s32 instance_index;\n    union {\n        mc_video_codec_enc_params_t video_enc_params;\n        mc_video_codec_dec_params_t video_dec_params;\n        mc_audio_codec_enc_params_t audio_enc_params;\n        mc_audio_codec_dec_params_t audio_dec_params;\n    };\n} media_codec_context_t;\nvoid MediaCodecAPITest::init_params_H265() {\n    memset(&context, 0x00, sizeof(media_codec_context_t));\n    context.codec_id = MEDIA_CODEC_ID_H265;\n    context.encoder = TRUE;\n    params = &context.video_enc_params;\n    params->width = mGlobalWidth;\n    params->height = mGlobalHeight;\n    params->pix_fmt = mGlobalPixFmt;\n    params->frame_buf_count = 5;\n    params->external_frame_buf = FALSE;\n    params->bitstream_buf_count = 5;\n    params->rc_params.mode = MC_AV_RC_MODE_H265CBR;\n    EXPECT_EQ(hb_mm_mc_get_rate_control_config(&context, &params->rc_params), (int32_t)0);\n    params->rc_params.h265_cbr_params.bit_rate = 5000;\n    params->rc_params.h265_cbr_params.frame_rate = 30;\n    params->rc_params.h265_cbr_params.intra_period = 6;\n    params->gop_params.decoding_refresh_type = 2;\n    params->gop_params.gop_preset_idx = 2;\n    params->rot_degree = MC_CCW_0;\n    params->mir_direction = MC_DIRECTION_NONE;\n    params->frame_cropping_flag = FALSE;\n}\nint main(int argc, char *argv[])\n{\n    init_params_H265();\n    EXPECT_EQ(hb_mm_mc_initialize(&context), (int32_t)0);\n    EXPECT_EQ(hb_mm_mc_set_camera(&context, 1, 1), (int32_t)0);\n    EXPECT_EQ(hb_mm_mc_release(&context), (int32_t)0);\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_vui_config",children:"hb_mm_mc_get_vui_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_vui_config(media_codec_context_t *context,\nmc_video_vui_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] mc_video_vui_ params_t *params: VUI parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves VUI parameters."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Additional Notes\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Currently, during video encoding, the default color range in the header information is set to full range mode. To set it to limited range, you must explicitly call the hb_mm_mc_set_vui_config interface."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\ntypedef enum ENC_CONFIG_MESSAGE {\n    ENC_CONFIG_NONE = (0 << 0),\n    ENC_CONFIG_LONGTERM_REF = (1 << 0),\n    ENC_CONFIG_INTRA_REFRESH = (1 << 1),\n    ENC_CONFIG_RATE_CONTROL = (1 << 2),\n    ENC_CONFIG_DEBLK_FILTER = (1 << 3),\n    ENC_CONFIG_SAO = (1 << 4),\n    ENC_CONFIG_ENTROPY = (1 << 5),\n    ENC_CONFIG_VUI_TIMING = (1 << 6),\n    ENC_CONFIG_SLICE = (1 << 7),\n    ENC_CONFIG_REQUEST_IDR = (1 << 8),\n    ENC_CONFIG_SKIP_PIC = (1 << 9),\n    ENC_CONFIG_SMART_BG = (1 << 10),\n    ENC_CONFIG_MONOCHROMA = (1 << 11),\n    ENC_CONFIG_PRED_UNIT = (1 << 12),\n    ENC_CONFIG_TRANSFORM = (1 << 13),\n    ENC_CONFIG_ROI = (1 << 14),\n    ENC_CONFIG_MODE_DECISION = (1 << 15),\n    ENC_CONFIG_USER_DATA = (1 << 16),\n    ENC_CONFIG_MJPEG = (1 << 17),\n    ENC_CONFIG_JPEG = (1 << 18),\n    ENC_CONFIG_CAMERA = (1 << 19),\n    ENC_CONFIG_INSERT_USERDATA = (1 << 20),\n    ENC_CONFIG_VUI = (1 << 21),\n    ENC_CONFIG_3DNR = (1 << 22),\n    ENC_CONFIG_REQUEST_IDR_HEADER = (1 << 23),\n    ENC_CONFIG_ENABLE_IDR = (1 << 24),\n    ENC_CONFIG_TOTAL = (1 << 25),\n} ENC_CONFIG_MESSAGE;\ntypedef struct MediaCodecTestContext {\n    media_codec_context_t *context;\n    char *inputFileName;\n    char *outputFileName;\n    int32_t duration; // s\n    ENC_CONFIG_MESSAGE message;\n    mc_video_longterm_ref_mode_t ref_mode;\n    mc_rate_control_params_t rc_params;\n    mc_video_intra_refresh_params_t intra_refr;\n    mc_video_deblk_filter_params_t deblk_filter;\n    mc_h265_sao_params_t sao;\n    mc_h264_entropy_params_t entropy;\n    mc_video_vui_params_t vui;\n    mc_video_vui_timing_params_t vui_timing;\n    mc_video_slice_params_t slice;\n    mc_video_3dnr_enc_params_t noise_reduction;\n    mc_video_smart_bg_enc_params_t smart_bg;\n    mc_video_pred_unit_params_t pred_unit;\n    mc_video_transform_params_t transform;\n    mc_video_roi_params_t roi;\n    mc_video_mode_decision_params_t mode_decision;\n} MediaCodecTestContext;\nUint64 osal_gettime(void)\n{\n    struct timespec tp;\n    clock_gettime(CLOCK_MONOTONIC, &tp);\n    return ((Uint64)tp.tv_sec*1000 + tp.tv_nsec/1000000);\n}\nuint8_t uuid[] =\n"dc45e9bd-e6d948b7-962cd820-d923eeef+HorizonAI";\nstatic void set_message(MediaCodecTestContext *ctx) {\n    int ret = 0;\n    media_codec_context_t *context = ctx->context;\n    if (ctx->message & ENC_CONFIG_VUI) {\n        hb_mm_mc_get_vui_config(context, &ctx->vui);\n        ret = hb_mm_mc_set_vui_config(context, &ctx->vui);\n    }\n}\nstatic void do_sync_encoding(void *arg) {\n    hb_s32 ret = 0;\n    FILE *inFile;\n    FILE *outFile;\n    int noMoreInput = 0;\n    int lastStream = 0;\n    Uint64 lastTime = 0;\n    Uint64 curTime = 0;\n    int needFlush = 1;\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)arg;\n    media_codec_context_t *context = ctx->context;\n    char *inputFileName = ctx->inputFileName;\n    char *outputFileName = ctx->outputFileName;\n    media_codec_state_t state = MEDIA_CODEC_STATE_NONE;\n    inFile = fopen(inputFileName, "rb");\n    if (!inFile) {\n        goto ERR;\n    }\n    outFile = fopen(outputFileName, "wb");\n    if (!outFile) {\n        goto ERR;\n    }\n    //get current time\n    lastTime = osal_gettime();\n    ret = hb_mm_mc_initialize(context);\n    if (ret) {\n        goto ERR;\n    }\n    ret = hb_mm_mc_configure(context);\n    if (ret) {\n        goto ERR;\n    }\n    mc_av_codec_startup_params_t startup_params;\n    startup_params.video_enc_startup_params.receive_frame_number = 0;\n    ret = hb_mm_mc_start(context, &startup_params);\n    if (ret) {\n        goto ERR;\n    }\n    ret = hb_mm_mc_pause(context);\n    if (ret) {\n        goto ERR;\n    }\n    do {\n    set_message(ctx);\n    if (!noMoreInput) {\n        media_codec_buffer_t inputBuffer;\n        memset(&inputBuffer, 0x00, sizeof(media_codec_buffer_t));\n        ret = hb_mm_mc_dequeue_input_buffer(context, &inputBuffer, 100);\n        if (!ret) {\n            curTime = osal_gettime();\n            if ((curTime - lastTime)/1000 < (uint32_t)ctx->duration) {\n                ret = fread(inputBuffer.vframe_buf.vir_ptr[0], 1,\n                inputBuffer.vframe_buf.size, inFile);\n                if (ret <= 0) {\n                    if(fseek(inFile, 0, SEEK_SET)) {\n                        printf("Failed to rewind input file\\n");\n                    } else {\n                        ret = fread(inputBuffer.vframe_buf.vir_ptr[0], 1,\n                        inputBuffer.vframe_buf.size, inFile);\n                        if (ret <= 0) {\n                            printf("Failed to read input file\\n");\n                        }\n                    }\n                }\n            } else {\n                printf("Time up(%d)\\n",ctx->duration);\n                ret = 0;\n            }\n            if (!ret) {\n                printf("There is no more input data!\\n");\n                inputBuffer.vframe_buf.frame_end = TRUE;\n                noMoreInput = 1;\n            }\n            ret = hb_mm_mc_queue_input_buffer(context, &inputBuffer, 100);\n            if (ret) {\n                printf("Queue input buffer fail.\\n");\n                break;\n            }\n        } else {\n            if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                printf("Dequeue input buffer fail.\\n");\n                break;\n            }\n        }\n    }\n    if (!lastStream) {\n        media_codec_buffer_t outputBuffer;\n        media_codec_output_buffer_info_t info;\n        memset(&outputBuffer, 0x00, sizeof(media_codec_buffer_t));\n        memset(&info, 0x00, sizeof(media_codec_output_buffer_info_t));\n        ret = hb_mm_mc_dequeue_output_buffer(context, &outputBuffer, &info,\n        3000);\n        if (!ret && outFile) {\n            fwrite(outputBuffer.vstream_buf.vir_ptr,\n                outputBuffer.vstream_buf.size, 1, outFile);\n            ret = hb_mm_mc_queue_output_buffer(context, &outputBuffer, 100);\n            if (ret) {\n                printf("Queue output buffer fail.\\n");\n                break;\n            }\n            if (outputBuffer.vstream_buf.stream_end) {\n                printf("There is no more output data!\\n");\n                lastStream = 1;\n                break;\n            }\n        } else {\n            if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                printf("Dequeue output buffer fail.\\n");\n                break;\n            }\n        }\n    }\n    if (needFlush) {\n        ret = hb_mm_mc_flush(context);\n        needFlush = 0;\n        if (ret) {\n            break;\n        }\n    }\n}while(TRUE);\nhb_mm_mc_stop(context);\nhb_mm_mc_release(context);\ncontext = NULL;\nERR:\nhb_mm_mc_get_state(context, &state);\nif (context && state!=\n    MEDIA_CODEC_STATE_UNINITIALIZED) {\n    hb_mm_mc_stop(context);\n    hb_mm_mc_release(context);\n}\nif (inFile)\n    fclose(inFile);\nif (outFile)\n    fclose(outFile);\n}\nint main(int argc, char *argv[]){\n    hb_s32 ret = 0;\n    char outputFileName[MAX_FILE_PATH] = "./tmp.yuv";\n    char inputFileName[MAX_FILE_PATH] = "./output.stream";\n    mc_video_codec_enc_params_t *params;\n    media_codec_context_t context;\n    memset(&context, 0x00, sizeof(media_codec_context_t));\n    context.codec_id = MEDIA_CODEC_ID_H265;\n    context.encoder = TRUE;\n    params = &context.video_enc_params;\n    params->width = 640;\n    params->height = 480;\n    params->pix_fmt = MC_PIXEL_FORMAT_YUV420P;\n    params->frame_buf_count = 5;\n    params->external_frame_buf = FALSE;\n    params->bitstream_buf_count = 5;\n    params->rc_params.mode = MC_AV_RC_MODE_H265CBR;\n    ret = hb_mm_mc_get_rate_control_config(&context, &params->rc_params);\n    if (ret) {\n        return -1;\n    }\n    params->rc_params.h265_cbr_params.bit_rate = 5000;\n    params->rc_params.h265_cbr_params.frame_rate = 30;\n    params->rc_params.h265_cbr_params.intra_period = 30;\n    params->gop_params.decoding_refresh_type = 2;\n    params->gop_params.gop_preset_idx = 2;\n    params->rot_degree = MC_CCW_0;\n    params->mir_direction = MC_DIRECTION_NONE;\n    params->frame_cropping_flag = FALSE;\n    MediaCodecTestContext ctx;\n    memset(&ctx, 0x00, sizeof(ctx));\n    ctx.context = &context;\n    ctx.inputFileName = inputFileName;\n    ctx.outputFileName = outputFileName;\n    mc_video_vui_params_t *vui = &ctx.vui;\n    ret = hb_mm_mc_get_vui_config(context, vui);\n    if (ret != 0) {\n        return -1;\n    }\n    vui->h265_vui.video_signal_type_present_flag = 1;\n    vui->h265_vui.video_format = 0;\n    vui->h265_vui.video_full_range_flag = 0;\n    ctx.message = ENC_CONFIG_VUI;\n    do_sync_encoding(&ctx);\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_vui_config",children:"hb_mm_mc_set_vui_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_vui_config(media_codec_context_t *context,\nconst mc_video_vui_params_t *params)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_vui_params_t *params: VUI parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Sets VUI parameters, which are static parameters."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_vui_config",children:"hb_mm_mc_get_vui_config"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_3dnr_enc_config",children:"hb_mm_mc_get_3dnr_enc_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_get_3dnr_enc_config(media_codec_context_t\n*context, mc_video_3dnr_enc_params_t *params);"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] mc_video_3dnr_enc_params_t *params: 3DNR parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Retrieves 3DNR parameters, which are dynamic parameters applicable to H.265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\ntypedef enum ENC_CONFIG_MESSAGE {\n    ENC_CONFIG_NONE = (0 << 0),\n    ENC_CONFIG_LONGTERM_REF = (1 << 0),\n    ENC_CONFIG_INTRA_REFRESH = (1 << 1),\n    ENC_CONFIG_RATE_CONTROL = (1 << 2),\n    ENC_CONFIG_DEBLK_FILTER = (1 << 3),\n    ENC_CONFIG_SAO = (1 << 4),\n    ENC_CONFIG_ENTROPY = (1 << 5),\n    ENC_CONFIG_VUI_TIMING = (1 << 6),\n    ENC_CONFIG_SLICE = (1 << 7),\n    ENC_CONFIG_REQUEST_IDR = (1 << 8),\n    ENC_CONFIG_SKIP_PIC = (1 << 9),\n    ENC_CONFIG_SMART_BG = (1 << 10),\n    ENC_CONFIG_MONOCHROMA = (1 << 11),\n    ENC_CONFIG_PRED_UNIT = (1 << 12),\n    ENC_CONFIG_TRANSFORM = (1 << 13),\n    ENC_CONFIG_ROI = (1 << 14),\n    ENC_CONFIG_MODE_DECISION = (1 << 15),\n    ENC_CONFIG_USER_DATA = (1 << 16),\n    ENC_CONFIG_MJPEG = (1 << 17),\n    ENC_CONFIG_JPEG = (1 << 18),\n    ENC_CONFIG_CAMERA = (1 << 19),\n    ENC_CONFIG_INSERT_USERDATA = (1 << 20),\n    ENC_CONFIG_VUI = (1 << 21),\n    ENC_CONFIG_3DNR = (1 << 22),\n    ENC_CONFIG_REQUEST_IDR_HEADER = (1 << 23),\n    ENC_CONFIG_ENABLE_IDR = (1 << 24),\n    ENC_CONFIG_TOTAL = (1 << 25),\n} ENC_CONFIG_MESSAGE;\ntypedef struct MediaCodecTestContext {\n    media_codec_context_t *context;\n    char *inputFileName;\n    char *outputFileName;\n    int32_t duration; // s\n    ENC_CONFIG_MESSAGE message;\n    mc_video_longterm_ref_mode_t ref_mode;\n    mc_rate_control_params_t rc_params;\n    mc_video_intra_refresh_params_t intra_refr;\n    mc_video_deblk_filter_params_t deblk_filter;\n    mc_h265_sao_params_t sao;\n    mc_h264_entropy_params_t entropy;\n    mc_video_vui_params_t vui;\n    mc_video_vui_timing_params_t vui_timing;\n    mc_video_slice_params_t slice;\n    mc_video_3dnr_enc_params_t noise_reduction;\n    mc_video_smart_bg_enc_params_t smart_bg;\n    mc_video_pred_unit_params_t pred_unit;\n    mc_video_transform_params_t transform;\n    mc_video_roi_params_t roi;\n    mc_video_mode_decision_params_t mode_decision;\n} MediaCodecTestContext;\nUint64 osal_gettime(void)\n{\n    struct timespec tp;\n    clock_gettime(CLOCK_MONOTONIC, &tp);\n    return ((Uint64)tp.tv_sec*1000 + tp.tv_nsec/1000000);\n}\nuint8_t uuid[] =\n"dc45e9bd-e6d948b7-962cd820-d923eeef+HorizonAI";\nstatic void set_message(MediaCodecTestContext *ctx) {\n    int ret = 0;\n    media_codec_context_t *context = ctx->context;\n    if (ctx->message & ENC_CONFIG_VUI) {\n        hb_mm_mc_get_vui_config(context, &ctx->vui);\n        ret = hb_mm_mc_set_vui_config(context, &ctx->vui);\n    }\n}\nstatic void do_sync_encoding(void *arg) {\n    hb_s32 ret = 0;\n    FILE *inFile;\n    FILE *outFile;\n    int noMoreInput = 0;\n    int lastStream = 0;\n    Uint64 lastTime = 0;\n    Uint64 curTime = 0;\n    int needFlush = 1;\n    MediaCodecTestContext *ctx = (MediaCodecTestContext *)arg;\n    media_codec_context_t *context = ctx->context;\n    char *inputFileName = ctx->inputFileName;\n    char *outputFileName = ctx->outputFileName;\n    media_codec_state_t state = MEDIA_CODEC_STATE_NONE;\n    inFile = fopen(inputFileName, "rb");\n    if (!inFile) {\n        goto ERR;\n    }\n    outFile = fopen(outputFileName, "wb");\n    if (!outFile) {\n        goto ERR;\n    }\n    //get current time\n    lastTime = osal_gettime();\n    ret = hb_mm_mc_initialize(context);\n    if (ret) {\n        goto ERR;\n    }\n    ret = hb_mm_mc_configure(context);if (ret) {\n        goto ERR;\n    }\n    mc_av_codec_startup_params_t startup_params;\n    startup_params.video_enc_startup_params.receive_frame_number = 0;\n    ret = hb_mm_mc_start(context, &startup_params);\n    if (ret) {\n        goto ERR;\n    }\n    ret = hb_mm_mc_pause(context);\n    if (ret) {\n        goto ERR;\n    }\n    do {\n    set_message(ctx);\n    if (!noMoreInput) {\n        media_codec_buffer_t inputBuffer;\n        memset(&inputBuffer, 0x00, sizeof(media_codec_buffer_t));\n        ret = hb_mm_mc_dequeue_input_buffer(context, &inputBuffer, 100);\n        if (!ret) {\n            curTime = osal_gettime();\n            if ((curTime - lastTime)/1000 < (uint32_t)ctx->duration) {\n                ret = fread(inputBuffer.vframe_buf.vir_ptr[0], 1,\n                inputBuffer.vframe_buf.size, inFile);\n                if (ret <= 0) {\n                    if(fseek(inFile, 0, SEEK_SET)) {\n                        printf("Failed to rewind input file\\n");\n                    } else {\n                        ret = fread(inputBuffer.vframe_buf.vir_ptr[0], 1,\n                        inputBuffer.vframe_buf.size, inFile);\n                        if (ret <= 0) {\n                            printf("Failed to read input file\\n");\n                        }\n                    }\n                }\n            } else {\n                printf("Time up(%d)\\n",ctx->duration);\n                ret = 0;\n            }\n            if (!ret) {\n                printf("There is no more input data!\\n");\n                inputBuffer.vframe_buf.frame_end = TRUE;\n                noMoreInput = 1;\n            }\n            ret = hb_mm_mc_queue_input_buffer(context, &inputBuffer, 100);\n            if (ret) {\n                printf("Queue input buffer fail.\\n");\n                break;\n            }\n        } else {\n            if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                printf("Dequeue input buffer fail.\\n");\n                break;\n            }\n        }\n    }\n    if (!lastStream) {\n        media_codec_buffer_t outputBuffer;\n        media_codec_output_buffer_info_t info;\n        memset(&outputBuffer, 0x00, sizeof(media_codec_buffer_t));\n        memset(&info, 0x00, sizeof(media_codec_output_buffer_info_t));\n        ret = hb_mm_mc_dequeue_output_buffer(context, &outputBuffer, &info,\n        3000);\n        if (!ret && outFile) {\n            fwrite(outputBuffer.vstream_buf.vir_ptr,\n                outputBuffer.vstream_buf.size, 1, outFile);\n            ret = hb_mm_mc_queue_output_buffer(context, &outputBuffer, 100);\n            if (ret) {\n                printf("Queue output buffer fail.\\n");\n                break;\n            }\n            if (outputBuffer.vstream_buf.stream_end) {\n                printf("There is no more output data!\\n");\n                lastStream = 1;\n                break;\n            }\n        } else {\n            if (ret != (int32_t)HB_MEDIA_ERR_WAIT_TIMEOUT) {\n                printf("Dequeue output buffer fail.\\n");\n                break;\n            }\n        }\n    }\n    if (needFlush) {\n        ret = hb_mm_mc_flush(context);\n        needFlush = 0;\n        if (ret) {\n            break;\n        }\n    }\n}while(TRUE);\nhb_mm_mc_stop(context);\nhb_mm_mc_release(context);\ncontext = NULL;\nERR:\nhb_mm_mc_get_state(context, &state);\nif (context && state!=\n    MEDIA_CODEC_STATE_UNINITIALIZED) {\n    hb_mm_mc_stop(context);\n    hb_mm_mc_release(context);\n}\nif (inFile)\n    fclose(inFile);\nif (outFile)\n    fclose(outFile);\n}\nint main(int argc, char *argv[])\n{\n    hb_s32 ret = 0;\n    char outputFileName[MAX_FILE_PATH] = "./tmp.yuv";\n    char inputFileName[MAX_FILE_PATH] = "./output.stream";\n    mc_video_codec_enc_params_t *params;\n    media_codec_context_t context;\n    memset(&context, 0x00, sizeof(media_codec_context_t));\n    context.codec_id = MEDIA_CODEC_ID_H265;\n    context.encoder = TRUE;\n    params = &context.video_enc_params;\n    params->width = 640;\n    params->height = 480;\n    params->pix_fmt = MC_PIXEL_FORMAT_YUV420P;\n    params->frame_buf_count = 5;\n    params->external_frame_buf = FALSE;\n    params->bitstream_buf_count = 5;\n    params->rc_params.mode = MC_AV_RC_MODE_H265CBR;\n    ret = hb_mm_mc_get_rate_control_config(&context, &params->rc_params);\n    if (ret) {\n        return -1;\n    }\n    params->rc_params.h265_cbr_params.bit_rate = 5000;\n    params->rc_params.h265_cbr_params.frame_rate = 30;\n    params->rc_params.h265_cbr_params.intra_period = 30;\n    params->gop_params.decoding_refresh_type = 2;\n    params->gop_params.gop_preset_idx = 2;\n    params->rot_degree = MC_CCW_0;\n    params->mir_direction = MC_DIRECTION_NONE;\n    params->frame_cropping_flag = FALSE;\n    MediaCodecTestContext ctx;\n    memset(&ctx, 0x00, sizeof(ctx));\n    ctx.context = &context;\n    ctx.inputFileName = inputFileName;\n    ctx.outputFileName = outputFileName;\n    mc_video_3dnr_enc_params_t *noise_rd = &ctx.noise_reduction;\n    ret = hb_mm_mc_get_3dnr_enc_config(context, noise_rd);\n    noise_rd->nr_y_enable = 0;\n    noise_rd->nr_cb_enable = 0;\n    noise_rd->nr_cr_enable = 0;\n    noise_rd->nr_est_enable = 0;\n    ctx.message = ENC_CONFIG_3DNR;\n    do_sync_encoding(&ctx);\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_3dnr_enc_config",children:"hb_mm_mc_set_3dnr_enc_config"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_set_3dnr_enc_config(media_codec_context_t\n*context, const mc_video_3dnr_enc_params_t *params);"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context\uff1aContext specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] const mc_video_3dnr_enc_params_t *params\uff1a3DNR parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0\uff1aOperation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN\uff1a Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED\uff1aOperation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE\uff1aInvalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS\uff1aInvalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Set the 3DNR parameters. This parameter is a dynamic one and is applicable to H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to  ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_3dnr_enc_config",children:"hb_mm_mc_get_3dnr_enc_config"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_request_idr_header",children:"hb_mm_mc_request_idr_header"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_request_idr_header(media_codec_context_t\n*context, hb_u32 force_header)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"[IN] media_codec_context_t *context\uff1aContext specifying the codec type"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"[IN] hb_u32 force_header\uff1a"}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"0 : No froced header(VPS/SPS/PPS)"}),"\n",(0,r.jsx)(n.p,{children:"1 : Forced header before IDR frame"}),"\n",(0,r.jsx)(n.p,{children:"2 : Forced header before I frame for H264 or forced header before\nCRA and IDR frame for H265"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0\uff1aOperation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN\uff1a Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED\uff1aOperation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE\uff1aInvalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS\uff1aInvalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Request the IDR frame header information of the frame header ID, applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["\u53c2\u8003 ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_enable_idr_frame",children:"hb_mm_mc_enable_idr_frame"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_enable_idr_frame(media_codec_context_t\n*context, hb_bool enable)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context\uff1aContext specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_bool enable\uff1a0: Disable\uff1b1: Enable\uff1b"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0\uff1aOperation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN\uff1a Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED\uff1aOperation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE\uff1aInvalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS\uff1aInvalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Enable IDR frames, applicable for H264/H265."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to  ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_register_audio_encoder",children:"hb_mm_mc_register_audio_encoder"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_register_audio_encoder(hb_s32 *handle,\nmc_audio_encode_param_t *encoder)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 *handle\uff1aEncoder handle"}),"\n",(0,r.jsx)(n.li,{children:"[IN] mc_audio_encode_param_t *encoder\uff1aAudio encoder descriptor"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0\uff1aOperation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN\uff1a Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED\uff1aOperation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE\uff1aInvalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS\uff1aInvalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Register the audio encoder, applicable for Audio."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\n#include "include/aac.h"\nint main(int argc, char *argv[])\n{\n    mc_audio_codec_enc_params_t *params;\n    media_codec_context_t context;\n    memset(&context, 0x00, sizeof(media_codec_context_t));\n    context.codec_id = MEDIA_CODEC_ID_AAC;\n    context.encoder = TRUE;\n    params = &context.audio_enc_params;\n    params->bit_rate = 128000;\n    params->frame_buf_count = 5;\n    params->packet_count = 5;\n    params->sample_fmt = MC_AV_SAMPLE_FMT_S16;\n    params->sample_rate = MC_AV_SAMPLE_RATE_16000;\n    params->channel_layout = MC_AV_CHANNEL_LAYOUT_STEREO;\n    params->channels = 2;\n    mc_aac_enc_config_t config;\n    config.profile = MC_AAC_PROFILE_LOW;\n    config.type = MC_AAC_DATA_TYPE_ADTS;\n    params->enc_config = &config;\n    int ret;\n    int handle;\n    mc_audio_encode_param_t encoder;\n    encoder.ff_type = MEDIA_CODEC_ID_AAC;\n    snprintf(encoder.ff_codec_name, sizeof(encoder.ff_codec_name), "aacenc");\n    encoder.ff_audio_open_encoder = ff_audio_aac_open_encoder;\n    encoder.ff_audio_encode_frame = ff_audio_aac_encode_frm;\n    encoder.ff_audio_close_encoder = ff_audio_aac_close_encoder;\n    ret = hb_mm_mc_register_audio_encoder(&handle, &encoder);\n    printf("handle = %d\\n", handle);\n    ASSERT_EQ(ret, 0);\n    ret = hb_mm_mc_unregister_audio_encoder(handle);\n    ASSERT_EQ(ret, 0);\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_unregister_audio_encoder",children:"hb_mm_mc_unregister_audio_encoder"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_unregister_audio_encoder(hb_s32 handle)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 *handle\uff1aencoder handle"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0\uff1aOperation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN\uff1a Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED\uff1aOperation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE\uff1aInvalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS\uff1aInvalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Unregister the audio encoder, applicable for Audio."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsxs)(n.p,{children:["\u53c2\u8003 ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_register_audio_encoder",children:"hb_mm_mc_register_audio_encoder"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_register_audio_decoder",children:"hb_mm_mc_register_audio_decoder"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_register_audio_decoder(hb_s32 *handle,\nmc_audio_decode_param_t *decoder)"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Parameter Description\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 *handle\uff1aDecoder handle"}),"\n",(0,r.jsx)(n.li,{children:"[IN] mc_audio_decode_param_t *decoder\uff1aAudio decoder descriptor"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Return Values\u3011"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0\uff1aOperation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN\uff1a Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED\uff1aOperation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE\uff1aInvalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS\uff1a Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Register the audio decoder, applicable for Audio."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Example Code\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\n#include "include/aac.h"\nint main(int argc, char *argv[])\n{\n    mc_audio_codec_dec_params_t *params;\n    media_codec_context_t context;\n    memset(&context, 0x00, sizeof(media_codec_context_t));\n    context.codec_id = MEDIA_CODEC_ID_AAC;\n    context.encoder = FALSE;\n    params = &context.audio_dec_params;\n    params->feed_mode = MC_FEEDING_MODE_FRAME_SIZE;\n    params->packet_buf_size = 1024;\n    params->packet_count = 5;\n    params->frame_cache_size = 5;\n    params->frame_buf_count = 5;\n    mc_aac_dec_config_t config;\n    config.sample_rate = MC_AV_SAMPLE_RATE_8000;\n    config.channels = 1;\n    config.sample_fmt = MC_AV_SAMPLE_FMT_S16;\n    params->dec_config = &config;\n    mc_audio_decode_param_t decoder;\n    decoder.ff_type = MEDIA_CODEC_ID_AAC;\n    snprintf(decoder.ff_codec_name, sizeof(decoder.ff_codec_name), "aacdec");\n    decoder.ff_audio_open_decoder = ff_audio_aac_open_decoder;\n    decoder.ff_audio_decode_frame = ff_audio_aac_decode_frm;\n    decoder.ff_audio_close_decoder = ff_audio_aac_close_decoder;\n    ret = hb_mm_mc_register_audio_decoder(&handle, &decoder);\n    ASSERT_EQ(ret, 0);\n    ret = hb_mm_mc_unregister_audio_decoder(handle);\n    ASSERT_EQ(ret, 0);\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_unregister_audio_decoder",children:"hb_mm_mc_unregister_audio_decoder"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Function Declaration\u3011"}),"\n",(0,r.jsx)(n.p,{children:"hb_s32 hb_mm_mc_unregister_audio_decoder(hb_s32 handle)"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Parameter Description]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 *handle: Decoder handle;"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Return Values]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Function Description]"})}),"\n",(0,r.jsx)(n.p,{children:"Unregisters an audio decoder. Applicable to Audio."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Example Code]"})}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_register_audio_decoder",children:"hb_mm_mc_register_audio_decoder"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_explicit_header_config",children:"hb_mm_mc_get_explicit_header_config"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Function Declaration]"})}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_explicit_header_config",(0,r.jsx)(n.br,{}),"\n","(media_codec_context_t *context, hb_s32 *status)"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Parameter Description]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] hb_s32 *status: Enable/disable encoding header information and IDR frame into a single frame"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Return Values]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Function Description]"})}),"\n",(0,r.jsxs)(n.p,{children:["Gets the configuration indicating whether header information and the IDR frame are encoded into a single frame.",(0,r.jsx)(n.br,{}),"\n","0: IDR and header information are separate",(0,r.jsx)(n.br,{}),"\n","1: IDR and header information are combined into one frame",(0,r.jsx)(n.br,{}),"\n","Applicable to H264/H265."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Example Code]"})}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_explicit_header_config",children:"hb_mm_mc_set_explicit_header_config"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Function Declaration]"})}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_set_explicit_header_config",(0,r.jsx)(n.br,{}),"\n","(media_codec_context_t *context, hb_s32 status)"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Parameter Description]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_s32 status: Enable/disable encoding header information and I-frame into a single frame"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Return Values]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Function Description]"})}),"\n",(0,r.jsxs)(n.p,{children:["Enables/disables encoding header information and I-frame into a single frame. This is a static parameter.",(0,r.jsx)(n.br,{}),"\n","0: IDR and header information are separate",(0,r.jsx)(n.br,{}),"\n","1: IDR and header information are combined into one frame",(0,r.jsx)(n.br,{}),"\n","Applicable to H264/H265."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Example Code]"})}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_get_roi_avg_qp",children:"hb_mm_mc_get_roi_avg_qp"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Function Declaration]"})}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_get_roi_avg_qp(media_codec_context_t *",(0,r.jsx)(n.br,{}),"\n","context, hb_u32 * params)"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Parameter Description]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[OUT] hb_u32 *params: ROI average QP"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Return Values]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Function Description]"})}),"\n",(0,r.jsx)(n.p,{children:"Gets the ROI average QP value. 0 indicates that the value is determined by the user-defined QP map. Applicable to H264/H265."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Example Code]"})}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h4,{id:"hb_mm_mc_set_roi_avg_qp",children:"hb_mm_mc_set_roi_avg_qp"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Function Declaration]"})}),"\n",(0,r.jsxs)(n.p,{children:["hb_s32 hb_mm_mc_set_roi_avg_qp(media_codec_context_t *",(0,r.jsx)(n.br,{}),"\n","context, hb_u32 params)"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Parameter Description]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"[IN] media_codec_context_t *context: Context specifying the codec type"}),"\n",(0,r.jsx)(n.li,{children:"[IN] hb_u32 params: ROI average QP value"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Return Values]"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"0: Operation succeeded"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_UNKNOWN: Unknown error"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED: Operation not allowed"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_INSTANCE: Invalid instance"}),"\n",(0,r.jsx)(n.li,{children:"HB_MEDIA_ERR_INVALID_PARAMS: Invalid parameters"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Function Description]"})}),"\n",(0,r.jsxs)(n.p,{children:["Sets the ROI average QP value for encoding. This is a dynamic parameter.",(0,r.jsx)(n.br,{}),"\n","0: Indicates using the average of all values in the configured QP map.",(0,r.jsx)(n.br,{}),"\n","This setting takes effect only when the rate control (RC) mode is CBR or AVBR.",(0,r.jsx)(n.br,{}),"\n","Applicable to H264/H265."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Example Code]"})}),"\n",(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.a,{href:"#hb_mm_mc_get_longterm_ref_mode",children:"hb_mm_mc_get_longterm_ref_mode"})]}),"\n",(0,r.jsx)(n.h3,{id:"main-parameter-descriptions",children:"Main Parameter Descriptions"}),"\n",(0,r.jsx)(n.h4,{id:"media_codec_state_t",children:"media_codec_state_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Description]"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the internal operational states of the Media codec."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Definition]"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef enum _media_codec_state {\n    MEDIA_CODEC_STATE_NONE = -1,\n    MEDIA_CODEC_STATE_UNINITIALIZED,\n    MEDIA_CODEC_STATE_INITIALIZED,\n    MEDIA_CODEC_STATE_CONFIGURED,\n    MEDIA_CODEC_STATE_STARTED,\n    MEDIA_CODEC_STATE_PAUSED,\n    MEDIA_CODEC_STATE_FLUSHING,\n    MEDIA_CODEC_STATE_ERROR,\n    MEDIA_CODEC_STATE_TOTAL,\n} media_codec_state_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"media_codec_id_t",children:"media_codec_id_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Description]"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the codec IDs supported by MediaCodec."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[Definition]"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef enum _media_codec_id {\n    MEDIA_CODEC_ID_NONE = -1,\n    /* Video Codecs */\n    MEDIA_CODEC_ID_H264,\n    MEDIA_CODEC_ID_H265,\n    MEDIA_CODEC_ID_MJPEG,\n    MEDIA_CODEC_ID_JPEG,\n    /* Audio Codecs */\n    MEDIA_CODEC_ID_FLAC,\n    MEDIA_CODEC_ID_PCM_MULAW,\n    MEDIA_CODEC_ID_PCM_ALAW,\n    MEDIA_CODEC_ID_ADPCM_G726,\n    MEDIA_CODEC_ID_ADPCM,\n    MEDIA_CODEC_ID_AAC,\n    MEDIA_CODEC_ID_MP3,\n    MEDIA_CODEC_ID_MP2,\n    MEDIA_CODEC_ID_TAK,\n    MEDIA_CODEC_ID_AC3,\n    MEDIA_CODEC_ID_WMA,\n    MEDIA_CODEC_ID_AMR,\n    MEDIA_CODEC_ID_APE,\n    MEDIA_CODEC_ID_G729,\n    MEDIA_CODEC_ID_G723,\n    MEDIA_CODEC_ID_G722,\n    MEDIA_CODEC_ID_IAC,\n    MEDIA_CODEC_ID_RALF,\n    MEDIA_CODEC_ID_QDMC,\n    MEDIA_CODEC_ID_DTS,\n    MEDIA_CODEC_ID_GSM,\n    MEDIA_CODEC_ID_TTA,\n    MEDIA_CODEC_ID_QCELP,\n    MEDIA_CODEC_ID_MLP,\n    MEDIA_CODEC_ID_ATRAC1,\n    MEDIA_CODEC_ID_IMC,\n    MEDIA_CODEC_ID_EAC,\n    MEDIA_CODEC_ID_MP1,\n    MEDIA_CODEC_ID_SIPR,\n    MEDIA_CODEC_ID_OPUS,\n    MEDIA_CODEC_ID_CELT,\n    MEDIA_CODEC_ID_MOV_TEXT,\n    MEDIA_CODEC_ID_TOTAL,\n} media_codec_id_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_video_rate_control_mode_t",children:"mc_video_rate_control_mode_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Description"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the bitrate control modes for video. Currently, only H.264/H.265 and MJPEG encoding channels support bitrate control."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Definition"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef enum _mc_video_rate_control_mode {\n    MC_AV_RC_MODE_NONE = -1,\n    MC_AV_RC_MODE_H264CBR,\n    MC_AV_RC_MODE_H264VBR,\n    MC_AV_RC_MODE_H264AVBR,\n    MC_AV_RC_MODE_H264FIXQP,\n    MC_AV_RC_MODE_H264QPMAP,\n    MC_AV_RC_MODE_H265CBR,\n    MC_AV_RC_MODE_H265VBR,\n    MC_AV_RC_MODE_H265AVBR,\n    MC_AV_RC_MODE_H265FIXQP,\n    MC_AV_RC_MODE_H265QPMAP,\n    MC_AV_RC_MODE_MJPEGFIXQP,\n    MC_AV_RC_MODE_TOTAL,\n} mc_video_rate_control_mode_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h264_cbr_params_t",children:"mc_h264_cbr_params_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Description"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set under H.264 CBR (Constant Bitrate) control mode."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Definition"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h264_cbr_params {\n    hb_u32 intra_period;\n    hb_u32 intra_qp;\n    hb_u32 bit_rate;\n    hb_u32 frame_rate;\n    hb_u32 initial_rc_qp;\n    hb_s32 vbv_buffer_size;\n    hb_u32 mb_level_rc_enalbe;\n    hb_u32 min_qp_I;\n    hb_u32 max_qp_I;\n    hb_u32 min_qp_P;\n    hb_u32 max_qp_P;\n    hb_u32 min_qp_B;\n    hb_u32 max_qp_B;\n    hb_u32 hvs_qp_enable;\n    hb_s32 hvs_qp_scale;\n    hb_u32 max_delta_qp;\n    hb_bool qp_map_enable;\n} mc_h264_cbr_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h264_vbr_params_t",children:"mc_h264_vbr_params_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Description"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set under H.264 VBR (Variable Bitrate) control mode."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Definition"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h264_vbr_params {\n    hb_u32 intra_period;\n    hb_u32 intra_qp;\n    hb_u32 frame_rate;\n    hb_bool qp_map_enable;\n} mc_h264_vbr_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h264_avbr_params_t",children:"mc_h264_avbr_params_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Description"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set under H.264 AVBR (Adaptive Variable Bitrate) control mode."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Definition"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h264_avbr_params {\n    hb_u32 intra_period;\n    hb_u32 intra_qp;\n    hb_u32 bit_rate;\n    hb_u32 frame_rate;\n    hb_u32 initial_rc_qp;\n    hb_s32 vbv_buffer_size;\n    hb_u32 mb_level_rc_enalbe;\n    hb_u32 min_qp_I;\n    hb_u32 max_qp_I;\n    hb_u32 min_qp_P;\n    hb_u32 max_qp_P;\n    hb_u32 min_qp_B;\n    hb_u32 max_qp_B;\n    hb_u32 hvs_qp_enable;\n    hb_s32 hvs_qp_scale;\n    hb_u32 max_delta_qp;\n    hb_bool qp_map_enable;\n} mc_h264_avbr_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h264_fix_qp_params_t",children:"mc_h264_fix_qp_params_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Description"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set under H.264 FixQP (Fixed Quantization Parameter) control mode."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Definition"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h264_fix_qp_params {\n    hb_u32 intra_period;\n    hb_u32 frame_rate;\n    hb_u32 force_qp_I;\n    hb_u32 force_qp_P;\n    hb_u32 force_qp_B;\n} mc_h264_fix_qp_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h264_qp_map_params_t",children:"mc_h264_qp_map_params_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Description"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set under H.264 QPMAP control mode."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Definition"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h264_qp_map_params {\n    hb_u32 intra_period;\n    hb_u32 frame_rate;\n    hb_byte qp_map_array;\n    hb_u32 qp_map_array_count;\n} mc_h264_qp_map_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h265_cbr_params_t",children:"mc_h265_cbr_params_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Description"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set under H.265 CBR (Constant Bitrate) control mode."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Definition"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h265_cbr_params {\n    hb_u32 intra_period;\n    hb_u32 intra_qp;\n    hb_u32 bit_rate;\n    hb_u32 frame_rate;\n    hb_u32 initial_rc_qp;\n    hb_s32 vbv_buffer_size;\n    hb_u32 ctu_level_rc_enalbe;\n    hb_u32 min_qp_I;\n    hb_u32 max_qp_I;\n    hb_u32 min_qp_P;\n    hb_u32 max_qp_P;\n    hb_u32 min_qp_B;\n    hb_u32 max_qp_B;\n    hb_u32 hvs_qp_enable;\n    hb_s32 hvs_qp_scale;\n    hb_u32 max_delta_qp;\n    hb_bool qp_map_enable;\n} mc_h265_cbr_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h265_vbr_params_t",children:"mc_h265_vbr_params_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Description"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set under H.265 VBR (Variable Bitrate) control mode."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Definition"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h265_vbr_params {\n    hb_u32 intra_period;\n    hb_u32 intra_qp;\n    hb_u32 frame_rate;\n    hb_bool qp_map_enable;\n} mc_h265_vbr_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h265_avbr_params_t",children:"mc_h265_avbr_params_t"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Description"})}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set under H.265 AVBR (Adaptive Variable Bitrate) control mode.\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h265_avbr_params {\n    hb_u32 intra_period;\n    hb_u32 intra_qp;\n    hb_u32 bit_rate;\n    hb_u32 frame_rate;\n    hb_u32 initial_rc_qp;\n    hb_s32 vbv_buffer_size;\n    hb_u32 ctu_level_rc_enalbe;\n    hb_u32 min_qp_I;\n    hb_u32 max_qp_I;\n    hb_u32 min_qp_P;\n    hb_u32 max_qp_P;\n    hb_u32 min_qp_B;\n    hb_u32 max_qp_B;\n    hb_u32 hvs_qp_enable;\n    hb_s32 hvs_qp_scale;\n    hb_u32 max_delta_qp;\n    hb_bool qp_map_enable;\n} mc_h265_avbr_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h265_fix_qp_params_t",children:"mc_h265_fix_qp_params_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set for H.265 under FixQP rate control mode."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h265_fix_qp_params {\n    hb_u32 intra_period;\n    hb_u32 frame_rate;\n    hb_u32 force_qp_I;\n    hb_u32 force_qp_P;\n    hb_u32 force_qp_B;\n} mc_h265_fix_qp_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_h265_qp_map_params_t",children:"mc_h265_qp_map_params_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set for H.265 under QPMAP rate control mode."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_h265_qp_map_params {\n    hb_u32 intra_period;\n    hb_u32 frame_rate;\n    hb_byte qp_map_array;\n    hb_u32 qp_map_array_count;\n} mc_h265_qp_map_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_mjpeg_fix_qp_params_t",children:"mc_mjpeg_fix_qp_params_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines the adjustable parameter set for MJPEG under FixQP rate control mode."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_mjpeg_fix_qp_params {\n    hb_u32 frame_rate;\n    hb_u32 quality_factor;\n} mc_mjpeg_fix_qp_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_video_custom_gop_pic_params_t",children:"mc_video_custom_gop_pic_params_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines the data structure for a custom GOP structure table."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_video_custom_gop_pic_params {\n    hb_u32 pic_type;\n    hb_s32 poc_offset;\n    hb_u32 pic_qp;\n    hb_s32 num_ref_picL0;\n    hb_s32 ref_pocL0;\n    hb_s32 ref_pocL1;\n    hb_u32 temporal_id;\n} mc_video_custom_gop_pic_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_inter_status_t",children:"mc_inter_status_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines internal status information of the media codec."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_inter_status {\n    hb_u32 cur_input_buf_cnt;\n    hb_u64 cur_input_buf_size;\n    hb_u32 cur_output_buf_cnt;\n    hb_u64 cur_output_buf_size;\n    hb_u32 left_recv_frame;\n    hb_u32 left_enc_frame;\n    hb_u32 total_input_buf_cnt;\n    hb_u32 total_output_buf_cnt;\n    hb_s32 pipeline;\n    hb_s32 channel_port_id;\n} mc_inter_status_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"media_codec_context_t",children:"media_codec_context_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines the context of the Media codec."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _media_codec_context {\n    media_codec_id_t codec_id;\n    hb_bool encoder;\n    hb_s32 instance_index;\n    union {\n        mc_video_codec_enc_params_t video_enc_params;\n        mc_video_codec_dec_params_t video_dec_params;\n        mc_audio_codec_enc_params_t audio_enc_params;\n        mc_audio_codec_dec_params_t audio_dec_params;\n    };\n    hb_ptr vpf_context;\n    mc_video_cmd_prio_t priority;\n} media_codec_context_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_video_codec_enc_params_t",children:"mc_video_codec_enc_params_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines encoding parameters for the video encoder. Supported video encoder types include H.264, H.265, MJPEG, and JPEG."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_video_codec_enc_params {\n    hb_s32 width, height;\n    mc_pixel_format_t pix_fmt;\n    hb_u32 frame_buf_count;\n    hb_bool external_frame_buf;\n    hb_u32 bitstream_buf_count;\n    hb_u32 bitstream_buf_size;\n    mc_rate_control_params_t rc_params;\n    mc_video_gop_params_t gop_params;\n    mc_rotate_degree_t rot_degree;\n    mc_mirror_direction_t mir_direction;\n    hb_u32 frame_cropping_flag;\n    mc_av_codec_rect_t crop_rect;\n    hb_bool enable_user_pts;\n    union {\n        mc_h264_enc_config_t h264_enc_config;\n        mc_h265_enc_config_t h265_enc_config;\n        mc_mjpeg_enc_config_t mjpeg_enc_config;\n        mc_jpeg_enc_config_t jpeg_enc_config;\n    };\n} mc_video_codec_enc_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_video_codec_dec_params_t",children:"mc_video_codec_dec_params_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines decoding parameters for the video decoder. Supported video decoder types include H.264, H.265, MJPEG, and JPEG."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_video_codec_dec_params {\n    mc_av_stream_feeding_mode_t feed_mode;\n    mc_pixel_format_t pix_fmt;\n    hb_u32 bitstream_buf_size;\n    hb_u32 bitstream_buf_count;\n    hb_bool external_bitstream_buf;\n    hb_u32 frame_buf_count;\n    union {\n        mc_h264_dec_config_t h264_dec_config;\n        mc_h265_dec_config_t h265_dec_config;\n        mc_mjpeg_dec_config_t mjpeg_dec_config;\n        mc_jpeg_dec_config_t jpeg_dec_config;\n    };\n} mc_video_codec_dec_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_audio_codec_enc_params_t",children:"mc_audio_codec_enc_params_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines the encoding parameters for an audio codec."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_audio_codec_enc_params {\n    hb_u32 bit_rate;\n    hb_s32 frame_size;\n    hb_s32 frame_buf_count;\n    hb_s32 packet_count;\n    mc_audio_sample_format_t sample_fmt;\n    mc_audio_sample_rate_t sample_rate;\n    mc_audio_channel_layout_t channel_layout;\n    hb_s32 channels;\n    hb_ptr enc_config;\n} mc_audio_codec_enc_params_t;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"mc_audio_codec_dec_params_t",children:"mc_audio_codec_dec_params_t"}),"\n",(0,r.jsx)(n.p,{children:"\u3010Description\u3011"}),"\n",(0,r.jsx)(n.p,{children:"Defines the decoding parameters for an audio codec."}),"\n",(0,r.jsx)(n.p,{children:"\u3010Definition\u3011"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"typedef struct _mc_audio_codec_dec_params {\n    mc_av_stream_feeding_mode_t feed_mode;\n    hb_s32 packet_buf_size;\n    hb_s32 packet_count;\n    hb_s32 frame_cache_size;\n    hb_s32 internal_frame_size;\n    hb_s32 frame_buf_count;\n    hb_ptr dec_config;\n} mc_audio_codec_dec_params_t;\n"})}),"\n",(0,r.jsx)(n.h3,{id:"return-value-description",children:"Return Value Description"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Error Code"}),(0,r.jsx)(n.th,{children:"Macro Definition"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000001"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_UNKNOWN"}),(0,r.jsx)(n.td,{children:"Unknown error"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000002"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_CODEC_NOT_FOUND"}),(0,r.jsx)(n.td,{children:"Corresponding codec not found"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000003"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_CODEC_OPEN_FAIL"}),(0,r.jsx)(n.td,{children:"Failed to open codec device"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000004"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_CODEC_RESPONSE_TIMEOUT"}),(0,r.jsx)(n.td,{children:"Codec response timeout"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000005"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_CODEC_INIT_FAIL"}),(0,r.jsx)(n.td,{children:"Codec initialization failed"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000006"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_OPERATION_NOT_ALLOWED"}),(0,r.jsx)(n.td,{children:"Operation not allowed"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000007"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_INSUFFICIENT_RES"}),(0,r.jsx)(n.td,{children:"Insufficient internal memory resources"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000008"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_NO_FREE_INSTANCE"}),(0,r.jsx)(n.td,{children:"No available instance (VPU supports up to 32, JPU up to 64, Audio up to 32)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000009"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_INVALID_PARAMS"}),(0,r.jsx)(n.td,{children:"Invalid parameters"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF000000A"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_INVALID_INSTANCE"}),(0,r.jsx)(n.td,{children:"Invalid instance"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF000000B"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_INVALID_BUFFER"}),(0,r.jsx)(n.td,{children:"Invalid buffer"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF000000C"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_INVALID_COMMAND"}),(0,r.jsx)(n.td,{children:"Invalid command"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF000000D"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_WAIT_TIMEOUT"}),(0,r.jsx)(n.td,{children:"Wait timeout"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF000000E"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_FILE_OPERATION_FAILURE"}),(0,r.jsx)(n.td,{children:"File operation failed"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF000000F"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_PARAMS_SET_FAILURE"}),(0,r.jsx)(n.td,{children:"Parameter setting failed"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000010"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_PARAMS_GET_FAILURE"}),(0,r.jsx)(n.td,{children:"Parameter retrieval failed"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000011"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_CODING_FAILED"}),(0,r.jsx)(n.td,{children:"Encoding/decoding failed"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000012"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_OUTPUT_BUF_FULL"}),(0,r.jsx)(n.td,{children:"Output buffer full"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000013"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_UNSUPPORTED_FEATURE"}),(0,r.jsx)(n.td,{children:"Unsupported feature"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0xF0000014"}),(0,r.jsx)(n.td,{children:"HB_MEDIA_ERR_INVALID_PRIORITY"}),(0,r.jsx)(n.td,{children:"Unsupported priority"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"codec-sample",children:"Codec Sample"}),"\n",(0,r.jsx)(n.h3,{id:"encoding-example",children:"Encoding Example"}),"\n",(0,r.jsx)(n.h4,{id:"function-overview",children:"Function Overview"}),"\n",(0,r.jsx)(n.p,{children:"Encodes YUV images into H.264/H.265 video or JPG images."}),"\n",(0,r.jsx)(n.h5,{id:"software-architecture-description",children:"Software Architecture Description"}),"\n",(0,r.jsxs)(n.p,{children:["Uses MediaCodec's poll mode to decouple input and output, enabling optimal encoding frame rate performance.",(0,r.jsx)(n.br,{}),"\n","In the main thread, YUV data is fed into the encoder: an empty input buffer is acquired, the YUV data's address information (e.g., physical address) is configured, and then the input buffer is queued to notify the encoder to process this frame.",(0,r.jsx)(n.br,{}),"\n","In another thread, encoded output bitstreams are retrieved: upon receiving a hardware encoding completion notification via ",(0,r.jsx)(n.code,{children:"select"}),", a filled output buffer is acquired, the encoded result is written to a file, and then the output buffer is returned."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/encoder2.png",alt:"image"})}),"\n",(0,r.jsx)(n.h5,{id:"hardware-data-flow-description",children:"Hardware Data Flow Description"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/encoder1.png",alt:"image"})}),"\n",(0,r.jsx)(n.h5,{id:"code-location-and-directory-structure",children:"Code Location and Directory Structure"}),"\n",(0,r.jsxs)(n.p,{children:["The sample code is located at ",(0,r.jsx)(n.code,{children:"source/hobot-sp-samples/debian/app/multimedia_demo/codec_demo"})," in the project directory."]}),"\n",(0,r.jsx)(n.p,{children:"Directory structure:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 sample_venc_vdec\n    \u251c\u2500\u2500 input_3840x2160_yuv420p.h264\n    \u251c\u2500\u2500 input_3840x2160_yuv420p.yuv\n    \u251c\u2500\u2500 Makefile\n    \u251c\u2500\u2500 sample.c\n    \u251c\u2500\u2500 sample_common.c\n    \u251c\u2500\u2500 sample.h\n    \u251c\u2500\u2500 sample_vdec.c\n    \u2514\u2500\u2500 sample_venc.c\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The root directory contains ",(0,r.jsx)(n.code,{children:"README.md"}),", which briefly describes compilation commands, runtime help information, and usage instructions."]}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"Makefile"})," under ",(0,r.jsx)(n.code,{children:"sample_venc_vdec"})," is used to compile files in this directory. Specifically:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sample.c"})," contains the main entry point,"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sample_common.c"})," contains shared APIs,"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sample_venc.c"})," contains encoding-related functions,"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sample_vdec.c"})," contains decoding-related functions."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"compilation",children:"Compilation"}),"\n",(0,r.jsx)(n.h5,{id:"compilation-environment",children:"Compilation Environment"}),"\n",(0,r.jsxs)(n.p,{children:["After installing the ",(0,r.jsx)(n.code,{children:"hobot-sp-samples_*.deb"})," package on the board, the ",(0,r.jsx)(n.code,{children:"codec_demo"})," source code will be included."]}),"\n",(0,r.jsx)(n.h5,{id:"compilation-instructions",children:"Compilation Instructions"}),"\n",(0,r.jsxs)(n.p,{children:["This sample primarily depends on API header files provided by ",(0,r.jsx)(n.code,{children:"libmm"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\n'})}),"\n",(0,r.jsx)(n.p,{children:"Compilation dependencies include the following libraries:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"LIBS += -lpthread -ldl -lhbmem -lalog  -lmultimedia\nLIBS += -lavformat -lavcodec -lavutil -lswresample\n"})}),"\n",(0,r.jsx)(n.p,{children:"Compilation command:"}),"\n",(0,r.jsxs)(n.p,{children:["On the board, navigate to ",(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec"})," and run:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"make\n"})}),"\n",(0,r.jsx)(n.h4,{id:"execution",children:"Execution"}),"\n",(0,r.jsx)(n.h5,{id:"supported-platforms",children:"Supported Platforms"}),"\n",(0,r.jsx)(n.p,{children:"RDKS100."}),"\n",(0,r.jsx)(n.h5,{id:"board-deployment-and-configuration",children:"Board Deployment and Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["After flashing the system software image, the sample source code resides at ",(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec"})," on the board."]}),"\n",(0,r.jsx)(n.p,{children:"Required resources may include:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Input YUV images: by default, raw 4K YUV streams and H.264 files are provided; for other tests, users must upload their own files."}),"\n"]}),"\n",(0,r.jsx)(n.h5,{id:"running-instructions",children:"Running Instructions"}),"\n",(0,r.jsx)(n.h6,{id:"command-line-argument-description",children:"Command-line Argument Description"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"sample_codec"}),": application name"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-m"}),": encoding or decoding mode; default is encoding (0: encoder, 1: decoder)"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-c"}),": codec type; default is H.264 (0: H.264, 1: H.265, 2: MJPEG, 3: JPEG)"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-w"}),": image width; default is 3840"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-h"}),": image height; default is 2160"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-p"}),": pixel format for encoding/decoding; default is NV12 (0: YUV420P, 1: NV12, 2: NV21)"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-n"}),": number of test threads; default is 1"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-i"}),": input file path; default is ",(0,r.jsx)(n.code,{children:"./input_${w}x${h}_${pixfmt}<_thread_idx>.yuv"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-o"}),": output file path; default is ",(0,r.jsx)(n.code,{children:"./output_${w}x${h}_${pixfmt}<_thread_idx>.{code_type}"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-H"}),": print help information"]}),"\n",(0,r.jsx)(n.h6,{id:"help-menu",children:"Help Menu"}),"\n",(0,r.jsxs)(n.p,{children:["Run ",(0,r.jsx)(n.code,{children:"./sample_codec --help"})," to display the help menu as follows:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Usage: ./sample_codec\n        -m --samplemode sample mode, default encoder, {0-encoder, 1-decoder}\n        -c --codecid codec id, default h264, {0-h264, 1-h265, 2-mjpeg, 3-jpeg}\n        -w --width width, default 3840\n        -h --height height, default 2160\n        -p --pixfmt pix fmt, default nv12, {0-yuv420p, 1-nv12, ..}\n        -n --threadnum test thread number, default 1\n        -i --inputfile input file name, default ./input_${w}x${h}_${pixfmt}<_thread_idx>.yuv\n        -o --outputfile output file name, default ./output_${w}x${h}_${pixfmt}<_thread_idx>.{code_type}\n        -H --help print usage\n"})}),"\n",(0,r.jsx)(n.h6,{id:"running-method",children:"Running Method"}),"\n",(0,r.jsxs)(n.p,{children:["Prepare input source: place the test file (e.g., ",(0,r.jsx)(n.code,{children:"input_3840x2160_nv12.yuv"}),") in the current directory, or specify the file path using ",(0,r.jsx)(n.code,{children:"-i"}),".Encode a YUV image sequence with resolution 3840x2160 into an H264 video bitstream:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec\n"})}),"\n",(0,r.jsx)(n.p,{children:"Encode a YUV image sequence with resolution 1920x1080 into an H265 video bitstream:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec -c 1 -w 1920 -h 1080\n"})}),"\n",(0,r.jsx)(n.p,{children:"Encode a single YUV image with resolution 1920x1088 into a JPG image:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec -c 3 -w 1920 -h 1088\n"})}),"\n",(0,r.jsx)(n.p,{children:"Encode two YUV image sequences with resolution 3840x2160 into H265 videos:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec -c 1 -n 2\n"})}),"\n",(0,r.jsx)(n.p,{children:"Encode four YUV image sequences with resolution 1920x1080 into H265 videos:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec -c 1 -w 1920 -h 1080 -n 4\n"})}),"\n",(0,r.jsxs)(n.p,{children:["VPU CROP read and encode: Read input data of size 1920x1300 (image dimensions not aligned as required) according to the crop region ",(0,r.jsx)(n.code,{children:"{x=200, y=300, w=1280, h=720}"})," and encode it into an H265 video:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec -c 1 -w 1920 -h 1300\n"})}),"\n",(0,r.jsx)(n.h6,{id:"execution-result-description",children:"Execution Result Description"}),"\n",(0,r.jsx)(n.p,{children:"The following figure shows a successful execution:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/encoder3.png",alt:"image"})}),"\n",(0,r.jsx)(n.p,{children:"Check whether the generated H264/H265/JPG files are valid:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/encoder4.png",alt:"image"})}),"\n",(0,r.jsx)(n.h3,{id:"decoding-examples",children:"Decoding Examples"}),"\n",(0,r.jsx)(n.h4,{id:"function-overview-1",children:"Function Overview"}),"\n",(0,r.jsx)(n.p,{children:"Decode H264/H265 videos or JPG images into YUV images."}),"\n",(0,r.jsx)(n.h5,{id:"software-architecture",children:"Software Architecture"}),"\n",(0,r.jsxs)(n.p,{children:["MediaCodec's poll mode is adopted to decouple input and output, enabling optimal decoding frame rate performance.",(0,r.jsx)(n.br,{}),"\n","In the main thread, bitstream data is fed into the decoder: an empty input buffer is acquired, the physical address and other metadata of the bitstream data are configured, then the input buffer is queued to notify the decoder to process this frame.",(0,r.jsx)(n.br,{}),"\n","In another thread, decoded YUV images are retrieved: upon receiving a hardware decoding completion notification via ",(0,r.jsx)(n.code,{children:"select"}),", a filled output buffer is acquired, the decoded result is written to a file, and the output buffer is released back."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/decoder2.png",alt:"image"})}),"\n",(0,r.jsx)(n.h5,{id:"hardware-data-flow-description-1",children:"Hardware Data Flow Description"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/decoder1.png",alt:"image"})}),"\n",(0,r.jsx)(n.h5,{id:"code-location-and-directory-structure-1",children:"Code Location and Directory Structure"}),"\n",(0,r.jsxs)(n.p,{children:["Sample code is located under ",(0,r.jsx)(n.code,{children:"source/hobot-sp-samples/debian/app/multimedia_demo/codec_demo"})," in the project directory."]}),"\n",(0,r.jsx)(n.p,{children:"Directory structure:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 sample_venc_vdec\n    \u251c\u2500\u2500 input_3840x2160_yuv420p.h264\n    \u251c\u2500\u2500 input_3840x2160_yuv420p.yuv\n    \u251c\u2500\u2500 Makefile\n    \u251c\u2500\u2500 sample.c\n    \u251c\u2500\u2500 sample_common.c\n    \u251c\u2500\u2500 sample.h\n    \u251c\u2500\u2500 sample_vdec.c\n    \u2514\u2500\u2500 sample_venc.c\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The root directory contains ",(0,r.jsx)(n.code,{children:"README.md"}),", which briefly describes compilation commands, runtime help, and usage instructions."]}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"Makefile"})," under ",(0,r.jsx)(n.code,{children:"sample_venc_vdec"})," is used for compiling this directory. Specifically:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sample.c"})," contains the main entry point."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sample_common.c"})," provides common APIs."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sample_venc.c"})," implements encoding-related functions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sample_vdec.c"})," implements decoding-related functions."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"compilation-1",children:"Compilation"}),"\n",(0,r.jsx)(n.h5,{id:"compilation-environment-1",children:"Compilation Environment"}),"\n",(0,r.jsxs)(n.p,{children:["After installing the ",(0,r.jsx)(n.code,{children:"hobot-sp-samples_*.deb"})," package on the board, the ",(0,r.jsx)(n.code,{children:"codec_demo"})," source code will be included."]}),"\n",(0,r.jsx)(n.h5,{id:"compilation-instructions-1",children:"Compilation Instructions"}),"\n",(0,r.jsxs)(n.p,{children:["This sample primarily depends on API header files provided by ",(0,r.jsx)(n.code,{children:"libmm"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'#include "hb_media_codec.h"\n#include "hb_media_error.h"\n'})}),"\n",(0,r.jsx)(n.p,{children:"Compilation requires the following libraries:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"LIBS += -lpthread -ldl -lhbmem -lalog  -lmultimedia\nLIBS += -lavformat -lavcodec -lavutil -lswresample\n"})}),"\n",(0,r.jsx)(n.p,{children:"Compilation command:"}),"\n",(0,r.jsxs)(n.p,{children:["On the board, navigate to ",(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec"})," and run:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"make\n"})}),"\n",(0,r.jsx)(n.h4,{id:"execution-1",children:"Execution"}),"\n",(0,r.jsx)(n.h5,{id:"supported-platforms-1",children:"Supported Platforms"}),"\n",(0,r.jsx)(n.p,{children:"RDKS100."}),"\n",(0,r.jsx)(n.h5,{id:"board-deployment-and-configuration-1",children:"Board Deployment and Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["After flashing the system image, the sample source code resides at ",(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec"})," on the board."]}),"\n",(0,r.jsx)(n.p,{children:"Required resources may include:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Default input YUV streams and H264 files in 4K format; users must upload other test files as needed."}),"\n"]}),"\n",(0,r.jsx)(n.h5,{id:"running-guide",children:"Running Guide"}),"\n",(0,r.jsx)(n.h6,{id:"parameter-description",children:"Parameter Description"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"sample_codec"}),": Application name"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-m"}),": Encoding or decoding mode; default is encoding (",(0,r.jsx)(n.code,{children:"0"}),": encoder, ",(0,r.jsx)(n.code,{children:"1"}),": decoder)"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-c"}),": Codec type; default is H264 (",(0,r.jsx)(n.code,{children:"0"}),": H264, ",(0,r.jsx)(n.code,{children:"1"}),": H265, ",(0,r.jsx)(n.code,{children:"2"}),": mjpg, ",(0,r.jsx)(n.code,{children:"3"}),": jpg)"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-w"}),": Image width; default is 3840"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-h"}),": Image height; default is 2160"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-p"}),": Pixel format; default is nv12 (",(0,r.jsx)(n.code,{children:"0"}),": yuv420p, ",(0,r.jsx)(n.code,{children:"1"}),": nv12, ",(0,r.jsx)(n.code,{children:"2"}),": nv21)"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-n"}),": Number of test threads; default is 1"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-i"}),": Input file path; default is ",(0,r.jsx)(n.code,{children:"./input_${w}x${h}_${pixfmt}<_thread_idx>.yuv"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-o"}),": Output file path; default is ",(0,r.jsx)(n.code,{children:"./output_${w}x${h}_${pixfmt}<_thread_idx>.{code_type}"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"-H"}),": Print help information"]}),"\n",(0,r.jsx)(n.h6,{id:"help-menu-1",children:"Help Menu"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Usage: ./sample_codec\n        -m --samplemode sample mode, default encoder, {0-encoder, 1-decoder}\n        -c --codecid codec id, default h264, {0-h264, 1-h265, 2-mjpeg, 3-jpeg}\n        -w --width width, default 3840\n        -h --height height, default 2160\n        -p --pixfmt pix fmt, default nv12, {0-yuv420p, 1-nv12, ..}\n        -n --threadnum test thread number, default 1\n        -i --inputfile input file name, default ./input_${w}x${h}_${pixfmt}<_thread_idx>.yuv\n        -o --outputfile output file name, default ./output_${w}x${h}_${pixfmt}<_thread_idx>.{code_type}\n        -H --help print usage\n"})}),"\n",(0,r.jsx)(n.h6,{id:"how-to-run",children:"How to Run"}),"\n",(0,r.jsxs)(n.p,{children:["Prepare input sources: place test files (e.g., ",(0,r.jsx)(n.code,{children:"input_3840x2160_nv12.h264"}),") in the current directory, or specify the file path using ",(0,r.jsx)(n.code,{children:"-i"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Decode one H264 video stream with resolution 3840x2160 into YUV images:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec -m 1\n"})}),"\n",(0,r.jsx)(n.p,{children:"Decode one H265 video stream with resolution 1920x1080 into YUV images:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec -m 1 -c 1 -w 1920 -h 1080\n"})}),"\n",(0,r.jsx)(n.p,{children:"Decode one JPG image with resolution 1920x1088 into a YUV image:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec -m 1 -c 3 -w 1920 -h 1088\n"})}),"\n",(0,r.jsx)(n.p,{children:"Decode two H264 video streams with resolution 3840x2160 into YUV images:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec",metastring:"-m 1 -n 2"})}),"\n",(0,r.jsx)(n.p,{children:"Decode four 1920x1080 h265 video streams and generate YUV image files."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"/app/multimedia_demo/codec_demo/sample_venc_vdec/sample_codec -m 1 -c 1 -n 4 -w 1920 -h 1080\n"})}),"\n",(0,r.jsx)(n.h6,{id:"explanation-of-execution-results",children:"Explanation of Execution Results"}),"\n",(0,r.jsx)(n.p,{children:"Successful execution is shown in the figure below:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/decoder3.png",alt:"image"})}),"\n",(0,r.jsx)(n.p,{children:"Use YUVPlayer to verify whether the generated YUV image files are valid."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/codec/decoder4.png",alt:"image"})})]})}function l(e={}){const{wrapper:n}={...(0,c.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}}}]);