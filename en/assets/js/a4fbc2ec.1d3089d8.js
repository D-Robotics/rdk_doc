"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[38287],{28453:(e,n,i)=>{i.d(n,{R:()=>d,x:()=>l});var t=i(96540);const s={},r=t.createContext(s);function d(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),t.createElement(r.Provider,{value:n},e.children)}},55107:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>d,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"Algorithm_Application/Python_Sample/LaneNet","title":"Lane Detection - LaneNet","description":"This example runs the LaneNet model based on hbmruntime to perform instance segmentation and binary segmentation of lane lines, and saves the resulting images locally. The example code is located in the /app/pydevdemo/06lanedetectionsample/01lanenet/ directory.","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/02_Python_Sample/10_LaneNet.md","sourceDirName":"04_Algorithm_Application/02_Python_Sample","slug":"/Algorithm_Application/Python_Sample/LaneNet","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/LaneNet","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1765989934000,"sidebarPosition":10,"frontMatter":{"sidebar_position":10},"sidebar":"tutorialSidebar","previous":{"title":"Instance Segmentation - Ultralytics YOLOE11","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/Ultralytics_YOLOE11_Seg"},"next":{"title":"Automatic Speech Recognition - ASR","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/ASR"}}');var s=i(74848),r=i(28453);const d={sidebar_position:10},l="Lane Detection - LaneNet",a={},c=[{value:"Model Description",id:"model-description",level:2},{value:"Functionality Description",id:"functionality-description",level:2},{value:"Environment Dependencies",id:"environment-dependencies",level:2},{value:"Directory Structure",id:"directory-structure",level:2},{value:"Parameter Description",id:"parameter-description",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Notes",id:"notes",level:2}];function o(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"lane-detection---lanenet",children:"Lane Detection - LaneNet"})}),"\n",(0,s.jsxs)(n.p,{children:["This example runs the LaneNet model based on ",(0,s.jsx)(n.code,{children:"hbm_runtime"})," to perform instance segmentation and binary segmentation of lane lines, and saves the resulting images locally. The example code is located in the ",(0,s.jsx)(n.code,{children:"/app/pydev_demo/06_lane_detection_sample/01_lanenet/"})," directory."]}),"\n",(0,s.jsx)(n.h2,{id:"model-description",children:"Model Description"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Introduction"}),":"]}),"\n",(0,s.jsxs)(n.p,{children:["LaneNet is a semantic segmentation model designed for real-time lane detection. It employs normalization and standardization during image preprocessing, making it suitable for road scene analysis in autonomous driving and ADAS systems. This example uses the quantized model ",(0,s.jsx)(n.code,{children:"lanenet256x512.hbm"}),", which supports BPU inference acceleration."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"HBM Model Name"}),": ",(0,s.jsx)(n.code,{children:"lanenet256x512.hbm"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input Format"}),": RGB, sized 256\xd7512, normalized to [0,1] and then standardized."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Outputs"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"instance_seg_logits"}),": a 3-channel map used to distinguish different lane instances."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"binary_seg_pred"}),": binary segmentation result indicating lane regions."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Download URL"})," (automatically downloaded by the program):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"https://archive.d-robotics.cc/downloads/rdk_model_zoo/rdk_s100/Lanenet/lanenet256x512.hbm\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"functionality-description",children:"Functionality Description"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Model Loading"})}),"\n",(0,s.jsxs)(n.p,{children:["Load the LaneNet model using ",(0,s.jsx)(n.code,{children:"hbm_runtime"}),", which automatically parses input/output information and quantization parameters."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Input Preprocessing"})}),"\n",(0,s.jsx)(n.p,{children:"Convert the input image to RGB format, resize it to 256\xd7512, apply normalization and standardization using ImageNet mean and standard deviation, convert to NCHW format, and add a batch dimension."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Inference Execution"})}),"\n",(0,s.jsxs)(n.p,{children:["Perform inference using the ",(0,s.jsx)(n.code,{children:".run()"})," method. The outputs include the instance feature map and binary mask, with support for setting inference priority and BPU core scheduling."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Post-processing"})}),"\n",(0,s.jsx)(n.p,{children:"Reshape and normalize the output tensors:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"instance_seg_logits"}),": output a 3-channel image for visualizing each lane instance."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"binary_seg_pred"}),": output a single-channel binary image for extracting lane regions."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"environment-dependencies",children:"Environment Dependencies"}),"\n",(0,s.jsxs)(n.p,{children:["This example has no special environment requirements\u2014just ensure the dependencies listed in ",(0,s.jsx)(n.code,{children:"pydev"})," are installed:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install -r ../../requirements.txt\n"})}),"\n",(0,s.jsx)(n.h2,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:".\n\u251c\u2500\u2500 lanenet.py                  # Main inference script\n\u2514\u2500\u2500 README.md                   # Usage instructions\n"})}),"\n",(0,s.jsx)(n.h2,{id:"parameter-description",children:"Parameter Description"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Parameter"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Default Value"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--model-path"})}),(0,s.jsxs)(n.td,{children:["Path to the model file in ",(0,s.jsx)(n.code,{children:".hbm"})," format"]}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/lanenet256x512.hbm"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--priority"})}),(0,s.jsx)(n.td,{children:"Inference priority (range: 0\u2013255; higher value = higher priority)"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"0"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--bpu-cores"})}),(0,s.jsx)(n.td,{children:"BPU core IDs to use for model execution"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"[0]"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--test-img"})}),(0,s.jsx)(n.td,{children:"Path to the test image"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/app/res/assets/input.jpg"})})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Run the Model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["With default parameters:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python lanenet.py\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["With custom parameters:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python lanenet.py \\\n--model-path /opt/hobot/model/s100/basic/lanenet256x512.hbm \\\n--priority 0 \\\n--bpu-cores 0 \\\n--test-img /app/res/assets/input.jpg\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"View Results"})}),"\n",(0,s.jsxs)(n.p,{children:["Upon successful execution, the results will be saved as ",(0,s.jsx)(n.code,{children:"instance_pred.png"})," and ",(0,s.jsx)(n.code,{children:"binary_pred.png"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"Results saved to: instance_pred.png and binary_pred.png\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"If the specified model path does not exist, the program will attempt to download the model automatically."}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}}}]);