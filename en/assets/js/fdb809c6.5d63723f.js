"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[1789],{11470:(e,n,o)=>{o.d(n,{A:()=>S});var t=o(96540),s=o(34164),i=o(23104),r=o(56347),a=o(205),l=o(57485),c=o(31682),d=o(70679);function m(e){return t.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function u(e){const{values:n,children:o}=e;return(0,t.useMemo)(()=>{const e=n??function(e){return m(e).map(({props:{value:e,label:n,attributes:o,default:t}})=>({value:e,label:n,attributes:o,default:t}))}(o);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,o])}function h({value:e,tabValues:n}){return n.some(n=>n.value===e)}function p({queryString:e=!1,groupId:n}){const o=(0,r.W6)(),s=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(s),(0,t.useCallback)(e=>{if(!s)return;const n=new URLSearchParams(o.location.search);n.set(s,e),o.replace({...o.location,search:n.toString()})},[s,o])]}function _(e){const{defaultValue:n,queryString:o=!1,groupId:s}=e,i=u(e),[r,l]=(0,t.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const o=n.find(e=>e.default)??n[0];if(!o)throw new Error("Unexpected error: 0 tabValues");return o.value}({defaultValue:n,tabValues:i})),[c,m]=p({queryString:o,groupId:s}),[_,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[o,s]=(0,d.Dv)(n);return[o,(0,t.useCallback)(e=>{n&&s.set(e)},[n,s])]}({groupId:s}),b=(()=>{const e=c??_;return h({value:e,tabValues:i})?e:null})();(0,a.A)(()=>{b&&l(b)},[b]);return{selectedValue:r,selectValue:(0,t.useCallback)(e=>{if(!h({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),m(e),g(e)},[m,g,i]),tabValues:i}}var g=o(92303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var f=o(74848);function x({className:e,block:n,selectedValue:o,selectValue:t,tabValues:r}){const a=[],{blockElementScrollPositionUntilNextRender:l}=(0,i.a_)(),c=e=>{const n=e.currentTarget,s=a.indexOf(n),i=r[s].value;i!==o&&(l(n),t(i))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const o=a.indexOf(e.currentTarget)+1;n=a[o]??a[0];break}case"ArrowLeft":{const o=a.indexOf(e.currentTarget)-1;n=a[o]??a[a.length-1];break}}n?.focus()};return(0,f.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},e),children:r.map(({value:e,label:n,attributes:t})=>(0,f.jsx)("li",{role:"tab",tabIndex:o===e?0:-1,"aria-selected":o===e,ref:e=>{a.push(e)},onKeyDown:d,onClick:c,...t,className:(0,s.A)("tabs__item",b.tabItem,t?.className,{"tabs__item--active":o===e}),children:n??e},e))})}function v({lazy:e,children:n,selectedValue:o}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===o);return e?(0,t.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,f.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==o}))})}function j(e){const n=_(e);return(0,f.jsxs)("div",{className:(0,s.A)("tabs-container",b.tabList),children:[(0,f.jsx)(x,{...n,...e}),(0,f.jsx)(v,{...n,...e})]})}function S(e){const n=(0,g.A)();return(0,f.jsx)(j,{...e,children:m(e.children)},String(n))}},19365:(e,n,o)=>{o.d(n,{A:()=>r});o(96540);var t=o(34164);const s={tabItem:"tabItem_Ymn6"};var i=o(74848);function r({children:e,hidden:n,className:o}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,t.A)(s.tabItem,o),hidden:n,children:e})}},28453:(e,n,o)=>{o.d(n,{R:()=>r,x:()=>a});var t=o(96540);const s={},i=t.createContext(s);function r(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(i.Provider,{value:n},e.children)}},82906:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>m});const t=JSON.parse('{"id":"Robot_development/boxs/function/mono_edgesam","title":"EdgeSAM Segment Anything","description":"Introduction","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/05_Robot_development/03_boxs/function/mono_edgesam.md","sourceDirName":"05_Robot_development/03_boxs/function","slug":"/Robot_development/boxs/function/mono_edgesam","permalink":"/rdk_doc/en/Robot_development/boxs/function/mono_edgesam","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1755081897000,"sidebarPosition":21,"frontMatter":{"sidebar_position":21},"sidebar":"tutorialSidebar","previous":{"title":"Human Detection and Tracking (Ultralytics YOLO Pose)","permalink":"/rdk_doc/en/Robot_development/boxs/function/mono2d_yolo_pose"},"next":{"title":"Segment Anything","permalink":"/rdk_doc/en/Robot_development/boxs/function/reid"}}');var s=o(74848),i=o(28453),r=o(11470),a=o(19365);const l={sidebar_position:21},c="EdgeSAM Segment Anything",d={},m=[{value:"Introduction",id:"introduction",level:2},{value:"Supported Platforms",id:"supported-platforms",level:2},{value:"Preparation",id:"preparation",level:2},{value:"RDK",id:"rdk",level:3},{value:"Usage",id:"usage",level:2},{value:"RDK",id:"rdk-1",level:3},{value:"Result Analysis",id:"result-analysis",level:2},{value:"Advance",id:"advance",level:2}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"edgesam-segment-anything",children:"EdgeSAM Segment Anything"})}),"\n","\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsxs)(n.p,{children:["The mono edge sam package is a usage example based on ",(0,s.jsx)(n.a,{href:"https://github.com/chongzhou96/EdgeSAM",children:"EdgeSAM"})," quantification deployment. The image data comes from local image feedback and subscribed image msg. SAM relies on the input of the detection box for segmentation, and segments the targets in the detection box without specifying the category information of the targets, only providing the box. The algorithm information will be published through topics and the results will be rendered and visualized on the web page. It also supports saving the rendered images in the result directory during program execution."]}),"\n",(0,s.jsx)(n.p,{children:"In this example, we provide two deployment methods:\n-Regular box for segmentation: A detection box in the center of the image is fixed for segmentation.\n-Subscription box for segmentation: Subscribe to the detection box information output by the upstream detection network and segment the information in the box."}),"\n",(0,s.jsxs)(n.p,{children:["Code repository:  (",(0,s.jsx)(n.a,{href:"https://github.com/D-Robotics/mono_edgesam.git",children:"https://github.com/D-Robotics/mono_edgesam.git"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"Application scenario: Combining detection boxes for obstacle segmentation, water stain area segmentation, etc."}),"\n",(0,s.jsx)(n.h2,{id:"supported-platforms",children:"Supported Platforms"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Platform"}),(0,s.jsx)(n.th,{children:"System"}),(0,s.jsx)(n.th,{children:"Function"})]})}),(0,s.jsx)(n.tbody,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"RDK X5"}),(0,s.jsx)(n.td,{children:"Ubuntu 22.04 (Humble)"}),(0,s.jsx)(n.td,{children:"Start MIPI/USB camera/local image offline, inference rendering results displayed/saved locally on the Web"})]})})]}),"\n",(0,s.jsx)(n.h2,{id:"preparation",children:"Preparation"}),"\n",(0,s.jsx)(n.h3,{id:"rdk",children:"RDK"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The RDK has burned the  Ubuntu 22.04 system image provided by D-Robotics."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The RDK has successfully installed TogetheROS.Bot."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,s.jsx)(n.p,{children:"The package publishes algorithm messages that include semantic segmentation and object detection information, and users can subscribe to these messages for application development."}),"\n",(0,s.jsx)(n.h3,{id:"rdk-1",children:"RDK"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Publishing images from MIPI camera"})}),"\n",(0,s.jsx)(r.A,{groupId:"tros-distro",children:(0,s.jsx)(a.A,{value:"humble",label:"Humble",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n\n# Copy the configuration file required for running the example from the installation path of tros.b.\ncp -r /opt/tros/${TROS_DISTRO}/lib/mono_edgesam/config/ .\n\n# Configuring MIPI camera\nexport CAM_TYPE=mipi\n\n# Start the launch file\nros2 launch mono_edgesam sam.launch.py \n"})})})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Publishing images from USB camera"})}),"\n",(0,s.jsx)(r.A,{groupId:"tros-distro",children:(0,s.jsx)(a.A,{value:"humble",label:"Humble",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n\n# Copy the configuration file required for running the example from the installation path of tros.b.\ncp -r /opt/tros/${TROS_DISTRO}/lib/mono_edgesam/config/ .\n\n# Configuring USB camera\nexport CAM_TYPE=usb\n\n# Start the launch file\nros2 launch mono_edgesam sam.launch.py \n"})})})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Using a single image offline"})}),"\n",(0,s.jsx)(r.A,{groupId:"tros-distro",children:(0,s.jsx)(a.A,{value:"humble",label:"Humble",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n\n# Copy the configuration file required for running the example from the installation path of tros.b.\ncp -r /opt/tros/${TROS_DISTRO}/lib/mono_edgesam/config/ .\n\n# Configure the local playback image.\nexport CAM_TYPE=fb\n\n# Start the launch file\nros2 launch mono_edgesam sam.launch.py \n"})})})}),"\n",(0,s.jsx)(n.h2,{id:"result-analysis",children:"Result Analysis"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Using a image publish tool to publish images"})}),"\n",(0,s.jsx)(n.p,{children:"After the package is initialized, the following information will be displayed in the terminal:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"[INFO] [launch]: All log files can be found below /root/.ros/log/2025-07-28-19-51-28-488985-ubuntu-107175\n[INFO] [launch]: Default logging verbosity is set to INFO\nmono_edgesam basic_path is  /root/install/lib/mono_edgesam/config\ncamera_type is  fb\nusing feedback\nHobot shm pkg enables zero-copy with fastrtps profiles file: /opt/tros/humble/lib/hobot_shm/config/shm_fastdds.xml\nHobot shm pkg sets RMW_FASTRTPS_USE_QOS_FROM_XML: 1\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nwebserver has launch\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nwebserver has launch\n[INFO] [hobot_image_pub-1]: process started with pid [107191]\n[INFO] [hobot_codec_republish-2]: process started with pid [107193]\n[INFO] [mono_edgesam-3]: process started with pid [107195]\n[INFO] [websocket-4]: process started with pid [107197]\n[hobot_codec_republish-2] [WARN] [1753703489.112526140] [hobot_codec_encoder]: Parameters:\n[hobot_codec_republish-2] sub_topic: /hbmem_img\n[hobot_codec_republish-2] pub_topic: /image\n[hobot_codec_republish-2] channel: 1\n[hobot_codec_republish-2] in_mode: shared_mem\n[hobot_codec_republish-2] out_mode: ros\n[hobot_codec_republish-2] in_format: nv12\n[hobot_codec_republish-2] out_format: jpeg\n[hobot_codec_republish-2] enc_qp: 10\n[hobot_codec_republish-2] jpg_quality: 60\n[hobot_codec_republish-2] input_framerate: 30\n[hobot_codec_republish-2] output_framerate: -1\n[hobot_codec_republish-2] dump_output: 0\n[hobot_codec_republish-2] [WARN] [1753703489.118608825] [HobotCodecImpl]: platform x5\n[hobot_codec_republish-2] [WARN] [1753703489.118873534] [hobot_codec_encoder]: Enabling zero-copy\n[websocket-4] [WARN] [1753703489.499688698] [websocket]:\n[websocket-4] Parameter:\n[websocket-4]  image_topic: /image\n[websocket-4]  image_type: mjpeg\n[websocket-4]  only_show_image: 0\n[websocket-4]  smart_topic: perception/segmentation/edgesam\n[websocket-4]  output_fps: 0\n[hobot_image_pub-1] [WARN] [1753703489.864104228] [image_pub_node]: parameter:\n[hobot_image_pub-1] image_source: /root/install/lib/mono_edgesam/config/4.jpg\n[hobot_image_pub-1] source_image_w: 960\n[hobot_image_pub-1] source_image_h: 544\n[hobot_image_pub-1] output_image_w: 1920\n[hobot_image_pub-1] output_image_h: 1080\n[hobot_image_pub-1] fps: 10\n[hobot_image_pub-1] is_shared_mem: 1\n[hobot_image_pub-1] is_loop: 1\n[hobot_image_pub-1] is_compressed_img_pub: 0\n[hobot_image_pub-1] image_format: jpg\n[hobot_image_pub-1] pub_encoding: nv12pub_name_mode: 0\n[hobot_image_pub-1] msg_pub_topic_name: /hbmem_img\n[hobot_image_pub-1] [WARN] [1753703489.864484396] [hobot_image_pub]: Enabling zero-copy\n[mono_edgesam-3] [WARN] [1753703489.948943404] [mono_edgesam]: Parameter:\n[mono_edgesam-3]  cache_len_limit: 8\n[mono_edgesam-3]  dump_render_img: 0\n[mono_edgesam-3]  feed_type(0:local, 1:sub): 1\n[mono_edgesam-3]  image: ./config/4.jpg\n[mono_edgesam-3]  encoder_model_file_name: /root/install/lib/mono_edgesam/config/edgesam_encoder_1024.bin\n[mono_edgesam-3]  decoder_model_file_name: /root/install/lib/mono_edgesam/config/edgesam_decoder_1024.bin\n[mono_edgesam-3]  is_regular_box: 1\n[mono_edgesam-3]  is_padding_seg: 0\n[mono_edgesam-3]  is_shared_mem_sub: 1\n[mono_edgesam-3]  is_sync_mode: 0\n[mono_edgesam-3]  ai_msg_pub_topic_name: /perception/segmentation/edgesam\n[mono_edgesam-3]  ai_msg_sub_topic_name: /hobot_dnn_detection\n[mono_edgesam-3]  ros_img_sub_topic_name: /image\n[mono_edgesam-3] [BPU_PLAT]BPU Platform Version(1.3.6)!\n[mono_edgesam-3] [HBRT] set log level as 0. version = 3.15.55.0\n[mono_edgesam-3] [DNN] Runtime version = 1.24.5_(3.15.55 HBRT)\n[hobot_codec_republish-2] [WARN] [1753703490.160037466] [hobot_codec_encoder]: Loaned messages are only safe with const ref subscription callbacks. If you are using any other kind of subscriptions, set the ROS_DISABLE_LOANED_MESSAGES environment variable to 1 (the default).\n[hobot_codec_republish-2] [WARN] [1753703490.160368467] [HobotVenc]: init_pic_w_: 1920, init_pic_h_: 1080, alined_pic_w_: 1920, alined_pic_h_: 1088, aline_w_: 16, aline_h_: 16\n[mono_edgesam-3] [A][DNN][packed_model.cpp:247][Model](2025-07-28,19:51:31.34.979) [HorizonRT] The model builder version = 1.24.3\n[hobot_codec_republish-2] [WARN] [1753703491.369838914] [hobot_codec_encoder]: sub nv12 1920x1088, fps: 11.9485, pub jpeg, fps: 11.9485, comm delay [1.7692]ms, codec delay [15.5385]ms\n[mono_edgesam-3] [A][DNN][packed_model.cpp:247][Model](2025-07-28,19:51:33.829.850) [HorizonRT] The model builder version = 1.24.3\n[mono_edgesam-3] [WARN] [1753703494.035526230] [mono_edgesam]: Create hbmem_subscription with topic_name: /hbmem_img\n[mono_edgesam-3] [WARN] [1753703494.057170296] [edgesam_node]: Loaned messages are only safe with const ref subscription callbacks. If you are using any other kind of subscriptions, set the ROS_DISABLE_LOANED_MESSAGES environment variable to 1 (the default).\n[mono_edgesam-3] [WARN] [1753703494.213043065] [mono_edgesam]: Smart fps: 9.00, pre process time ms: 14, infer time ms: 92, post process time ms: 48\n[mono_edgesam-3] [WARN] [1753703494.342125459] [mono_edgesam]: Smart fps: 11.00, pre process time ms: 12, infer time ms: 81, post process time ms: 41\n[hobot_codec_republish-2] [WARN] [1753703494.362260146] [hobot_codec_encoder]: Pub img fps [8.45]\n[mono_edgesam-3] [WARN] [1753703494.471613064] [mono_edgesam]: Smart fps: 10.00, pre process time ms: 11, infer time ms: 88, post process time ms: 39\n[mono_edgesam-3] [WARN] [1753703494.592498850] [mono_edgesam]: Smart fps: 11.00, pre process time ms: 12, infer time ms: 81, post process time ms: 38\n[mono_edgesam-3] [WARN] [1753703494.724020335] [mono_edgesam]: Smart fps: 11.00, pre process time ms: 11, infer time ms: 84, post process time ms: 46\n[mono_edgesam-3] [WARN] [1753703494.849518302] [mono_edgesam]: Smart fps: 10.00, pre process time ms: 12, infer time ms: 85, post process time ms: 38\n[mono_edgesam-3] [WARN] [1753703494.973585807] [mono_edgesam]: Smart fps: 11.00, pre process time ms: 13, infer time ms: 82, post process time ms: 40\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Using single image offline"})}),"\n",(0,s.jsxs)(n.p,{children:["The result will be rendered on web. On the PC-side browser, you can view the image and algorithm rendering effect by entering ",(0,s.jsx)(n.a,{href:"http://IP:8000",children:"http://IP:8000"})," (IP is the IP address of the RDK), and open the settings in the upper right corner of the interface."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/03_boxs/function/image/box_adv/render_sam.png",alt:""})}),"\n",(0,s.jsx)(n.h2,{id:"advance",children:"Advance"}),"\n",(0,s.jsx)(n.p,{children:"If you need to adjust the size of the detection box, you can refer to the following method for verification. What's more, the detection results of the other dnn detection node can be used as the input for Sam."}),"\n",(0,s.jsx)(n.p,{children:"Start the launch file with cancel regular box mode, sam_is_regular_box:=0."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"ros2 launch mono_edgesam sam.launch.py sam_is_regular_box:=0\n"})}),"\n",(0,s.jsx)(n.p,{children:"Publish ai msg in another terminal."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:'ros2 topic pub /hobot_dnn_detection ai_msgs/msg/PerceptionTargets \'{"targets": [{"rois": [{"rect": {"x_offset": 160, "y_offset": 120, "width": 320, "height": 240}, "type": "anything"}]}] }\'\n'})}),"\n",(0,s.jsx)(n.p,{children:'Explanation: The topic name published here is "/hobot_dnn_detection". The starting point of the detection box is (96, 96), with a width of 192 and a height of 96. The starting and ending points of the detection box should not exceed the size of the input image. Please check while using it.'})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}}}]);