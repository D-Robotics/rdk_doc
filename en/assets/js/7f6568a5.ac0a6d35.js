"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[95867],{17758:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"Basic_Application/pydev_demo_sample/decode_rtsp_stream","title":"3.3.11 RTSP Stream Decoding Example Introduction","description":"Example Overview","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/03_Basic_Application/03_pydev_demo_sample/08_decode_rtsp_stream.md","sourceDirName":"03_Basic_Application/03_pydev_demo_sample","slug":"/Basic_Application/pydev_demo_sample/decode_rtsp_stream","permalink":"/rdk_doc/en/Basic_Application/pydev_demo_sample/decode_rtsp_stream","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1769600600000,"sidebarPosition":11,"frontMatter":{"sidebar_position":11},"sidebar":"tutorialSidebar","previous":{"title":"3.3.10 Web Display Camera Example Introduction","permalink":"/rdk_doc/en/Basic_Application/pydev_demo_sample/web_display_camera_sample"},"next":{"title":"3.4.1 Using MIPI Camera","permalink":"/rdk_doc/en/Basic_Application/vision/mipi_camera"}}');var i=r(74848),o=r(28453);const s={sidebar_position:11},a="3.3.11 RTSP Stream Decoding Example Introduction",d={},l=[{value:"Example Overview",id:"example-overview",level:2},{value:"Result Display",id:"result-display",level:2},{value:"Hardware Preparation",id:"hardware-preparation",level:2},{value:"Hardware Connection",id:"hardware-connection",level:3},{value:"Quick Start",id:"quick-start",level:2},{value:"Code and Board Location",id:"code-and-board-location",level:3},{value:"Compilation and Execution",id:"compilation-and-execution",level:3},{value:"Execution Result",id:"execution-result",level:3},{value:"Detailed Introduction",id:"detailed-introduction",level:2},{value:"Example Program Parameter Options",id:"example-program-parameter-options",level:3},{value:"Software Architecture Description",id:"software-architecture-description",level:3},{value:"API Flow Description",id:"api-flow-description",level:3},{value:"FAQ",id:"faq",level:3}];function c(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"3311-rtsp-stream-decoding-example-introduction",children:"3.3.11 RTSP Stream Decoding Example Introduction"})}),"\n",(0,i.jsx)(n.h2,{id:"example-overview",children:"Example Overview"}),"\n",(0,i.jsxs)(n.p,{children:["The RTSP stream decoding example is a ",(0,i.jsx)(n.strong,{children:"Python interface"})," development code sample located in ",(0,i.jsx)(n.code,{children:"/app/pydev_demo/08_decode_rtsp_stream/"}),". It demonstrates how to obtain H.264/H.265 streams from an RTSP video stream and implement real-time video decoding and object detection functions through hardware decoding, video processing, and AI inference. This example showcases a complete video processing pipeline, including RTSP stream reception, hardware decoding, video processing, AI inference, and result display."]}),"\n",(0,i.jsx)(n.h2,{id:"result-display",children:"Result Display"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/03_pydev_demo_sample/image/pydev_08_runing.png",alt:"output-img"})}),"\n",(0,i.jsx)(n.h2,{id:"hardware-preparation",children:"Hardware Preparation"}),"\n",(0,i.jsx)(n.h3,{id:"hardware-connection",children:"Hardware Connection"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Prepare an RDK development board"}),"\n",(0,i.jsx)(n.li,{children:"Connect the development board to a display via an HDMI cable"}),"\n",(0,i.jsx)(n.li,{children:"Connect an Ethernet cable to the development board"}),"\n",(0,i.jsxs)(n.li,{children:["Connect the power cable\n",(0,i.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/03_pydev_demo_sample/image/pydev_08_hw_connect.png",alt:"connect-img"})]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,i.jsx)(n.h3,{id:"code-and-board-location",children:"Code and Board Location"}),"\n",(0,i.jsxs)(n.p,{children:["Navigate to the ",(0,i.jsx)(n.code,{children:"/app/pydev_demo/08_decode_rtsp_stream/"})," directory. The RTSP stream decoding example includes the following files:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"root@ubuntu:/app/pydev_demo/08_decode_rtsp_stream# tree\n.\n\u251c\u2500\u2500 1080P_test.h264\n\u251c\u2500\u2500 decode_rtsp_stream.py\n\u2514\u2500\u2500 live555MediaServer\n"})}),"\n",(0,i.jsx)(n.h3,{id:"compilation-and-execution",children:"Compilation and Execution"}),"\n",(0,i.jsxs)(n.p,{children:["First, perform the preparatory steps. If displaying via HDMI, use the ",(0,i.jsx)(n.code,{children:"systemctl stop lightdm"})," command to stop the graphical interface service for optimal display performance.",(0,i.jsx)(n.br,{}),"\n","The example includes a default 1080P_test.h264 file. If you want to try an H.265 format file, you can copy it from elsewhere on the board, such as from the ",(0,i.jsx)(n.code,{children:"/opt/tros/humble/lib/hobot_codec/config/1920x1080.h265"})," directory.\nFirst, start the RTSP streaming media server, then run the Python script:"]}),"\n",(0,i.jsx)(n.h3,{id:"execution-result",children:"Execution Result"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"\n# Stop the graphical interface service for optimal display performance\nsystemctl stop lightdm\n\n# Start the RTSP streaming media server\n./live555MediaServer &\n\n# Run the RTSP stream decoding example (h264)\npython3 decode_rtsp_stream.py -u rtsp://127.0.0.1/1080P_test.h264 -d 1 -a 1\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"After running, the program will connect to the RTSP streaming media server, decode the video stream, perform object detection, and display the results via HDMI:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'root@ubuntu:/app/pydev_demo/08_decode_rtsp_stream#./live555MediaServer &\n        version 1.01 (LIVE555 Streaming Media library version 2020.07.09).\nPlay streams from this server using the URL\n        rtsp://192.168.127.10/<filename>\nwhere <filename> is a file present in the current directory.\nEach file\'s type is inferred from its name suffix:\n        ".264" => a H.264 Video Elementary Stream file\n        ".265" => a H.265 Video Elementary Stream file\n        ".aac" => an AAC Audio (ADTS format) file\n        ".ac3" => an AC-3 Audio file\n        ".amr" => an AMR Audio file\n        ".dv" => a DV Video file\n        ".m4e" => a MPEG-4 Video Elementary Stream file\n        ".mkv" => a Matroska audio+video+(optional)subtitles file\n        ".mp3" => a MPEG-1 or 2 Audio file\n        ".mpg" => a MPEG-1 or 2 Program Stream (audio+video) file\n        ".ogg" or ".ogv" or ".opus" => an Ogg audio and/or video file\n        ".ts" => a MPEG Transport Stream file\n                (a ".tsx" index file - if present - provides server \'trick play\' support)\n        ".vob" => a VOB (MPEG-2 video with AC-3 audio) file\n        ".wav" => a WAV Audio file\n        ".webm" => a WebM audio(Vorbis)+video(VP8) file\nSee http://www.live555.com/mediaServer/ for additional documentation.\n(We use port 80 for optional RTSP-over-HTTP tunneling, or for HTTP live streaming (for indexed Transport Stream files only).)\n\n\nroot@ubuntu:/app/pydev_demo/08_decode_rtsp_stream# ./decode_rtsp_stream.py \n[\'rtsp://127.0.0.1/1080P_test.h264\']\nEncoding detected via FourCC: h264, dec_type: 1\nRTSP stream frame_width:1920, frame_height:1080\nDecoder(0, 1) return:0 frame count: 0\nOpened DRM device: /dev/dri/card0\n\n.............\n.............\n.............\n\n'})}),"\n",(0,i.jsx)(n.p,{children:"To try decoding an H.265 file, refer to the following commands:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"\n# Stop the graphical interface service for optimal display performance\nsystemctl stop lightdm\n\n# Copy the H.265 file to the example directory.\ncp /opt/tros/humble/lib/hobot_codec/config/1920x1080.h265 /app/pydev_demo/08_decode_rtsp_stream/\n\n# Run the RTSP stream decoding example (h265)\npython3 decode_rtsp_stream.py -u rtsp://127.0.0.1/1920x1080.h265 -d 1\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'root@ubuntu:/app/pydev_demo/08_decode_rtsp_stream# systemctl stop lightdm\nroot@ubuntu:/app/pydev_demo/08_decode_rtsp_stream# ./live555MediaServer &\n[1] 4030\nLIVE555 Media Server\n        version 1.01 (LIVE555 Streaming Media library version 2020.07.09).\nroot@ubuntu:/app/pydev_demo/08_decode_rtsp_stream# Play streams from this server using the URL\n        rtsp://10.0.0.32/<filename>\nwhere <filename> is a file present in the current directory.\nEach file\'s type is inferred from its name suffix:\n        ".264" => a H.264 Video Elementary Stream file\n        ".265" => a H.265 Video Elementary Stream file\n        ".aac" => an AAC Audio (ADTS format) file\n        ".ac3" => an AC-3 Audio file\n        ".amr" => an AMR Audio file\n        ".dv" => a DV Video file\n        ".m4e" => a MPEG-4 Video Elementary Stream file\n        ".mkv" => a Matroska audio+video+(optional)subtitles file\n        ".mp3" => a MPEG-1 or 2 Audio file\n        ".mpg" => a MPEG-1 or 2 Program Stream (audio+video) file\n        ".ogg" or ".ogv" or ".opus" => an Ogg audio and/or video file\n        ".ts" => a MPEG Transport Stream file\n                (a ".tsx" index file - if present - provides server \'trick play\' support)\n        ".vob" => a VOB (MPEG-2 video with AC-3 audio) file\n        ".wav" => a WAV Audio file\n        ".webm" => a WebM audio(Vorbis)+video(VP8) file\nSee http://www.live555.com/mediaServer/ for additional documentation.\n(We use port 80 for optional RTSP-over-HTTP tunneling, or for HTTP live streaming (for indexed Transport Stream files only).)\n\nroot@ubuntu:/app/pydev_demo/08_decode_rtsp_stream#\nroot@ubuntu:/app/pydev_demo/08_decode_rtsp_stream#\nroot@ubuntu:/app/pydev_demo/08_decode_rtsp_stream# python3 decode_rtsp_stream.py -u rtsp://127.0.0.1/1920x1080.h265 -d 1\n[\'rtsp://127.0.0.1/1920x1080.h265\']\nEncoding detected via FourCC: hevc, dec_type: 2\nRTSP stream frame_width:1920, frame_height:1080\nDecoder(0, 2) return:0 frame count: 0\nOpened DRM device: /dev/dri/card0\n1920x1080\n1280x800\n1280x720\n720x576\n720x480\n640x480\nResolution 1920x1080 exists in the list.\nOpened DRM device: /dev/dri/card0\nDRM is available, using libdrm for rendering.\n------------------------------------------------------\nPlane 0:\n  Plane ID: 41\n  Src W: 1920\n  Src H: 1080\n......\n......\n......\n\n\n'})}),"\n",(0,i.jsx)(n.h2,{id:"detailed-introduction",children:"Detailed Introduction"}),"\n",(0,i.jsx)(n.h3,{id:"example-program-parameter-options",children:"Example Program Parameter Options"}),"\n",(0,i.jsx)(n.p,{children:"The RTSP stream decoding example supports the following command-line parameters:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"# Basic usage\npython3 decode_rtsp_stream.py [-u <rtsp_url>] [-d] [-a]\n\n# Multi-stream example\npython3 decode_rtsp_stream.py [-u <rtsp_url1;rtsp_url2>] [-d] [-a]\n"})}),"\n",(0,i.jsx)(n.p,{children:"Parameter description:"}),"\n",(0,i.jsx)(n.p,{children:"-u, --rtsp_url: Specify the RTSP stream URL. Supports multiple stream URLs separated by semicolons."}),"\n",(0,i.jsx)(n.p,{children:"-d: Enable display function (0 - disable, 1 - enable)"}),"\n",(0,i.jsx)(n.p,{children:"-a: Enable AI inference function (display function is automatically enabled when this is enabled)"}),"\n",(0,i.jsx)(n.h3,{id:"software-architecture-description",children:"Software Architecture Description"}),"\n",(0,i.jsx)(n.p,{children:"The RTSP stream decoding example is slightly complex as it requires coordination with an RTSP server and uses a multi-threaded architecture internally. Therefore, a component-level architecture diagram is provided for explanation."}),"\n",(0,i.jsx)(n.p,{children:"It includes three core threads:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"RTSP Stream Decoding Thread (DecodeRtspStream):"}),"\n",(0,i.jsxs)(n.p,{children:["Connect to the RTSP streaming media server",(0,i.jsx)(n.br,{}),"\n","Automatically detect stream encoding format (H.264/H.265/MJPEG)",(0,i.jsx)(n.br,{}),"\n","Use hardware decoder to decode the video stream",(0,i.jsx)(n.br,{}),"\n","Manage decoded frame queue"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Video Display Thread (VideoDisplay):"}),"\n",(0,i.jsxs)(n.p,{children:["Initialize HDMI display",(0,i.jsx)(n.br,{}),"\n","Use VPS for video processing (scaling, format conversion)",(0,i.jsx)(n.br,{}),"\n","Send processed video frames to the display queue"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"AI Inference Thread (AiInference):"}),"\n",(0,i.jsxs)(n.p,{children:["Load object detection model (FCOS)",(0,i.jsx)(n.br,{}),"\n","Perform inference on video frames",(0,i.jsx)(n.br,{}),"\n","Post-process and draw detection results"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)("center",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/03_pydev_demo_sample/image/pydev_08_rtsp_sample_software_arch.png",alt:"software_arch"})})}),"\n",(0,i.jsx)(n.h3,{id:"api-flow-description",children:"API Flow Description"}),"\n",(0,i.jsx)("center",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/03_pydev_demo_sample/image/pydev_08_rtsp_sample_api_flow.png",alt:"API_Flow"})})}),"\n",(0,i.jsx)(n.h3,{id:"faq",children:"FAQ"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Q:"}),' What should I do if the example prompts "fail to open rtsp" when running?',(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"A:"})," Ensure the RTSP streaming media server is started correctly and the network connection is normal. You can use ",(0,i.jsx)(n.code,{children:"netstat -tlnp"})," to check the server port status."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Q:"})," How to view supported encoding formats?",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"A:"}),' The program automatically detects the stream encoding format and outputs the detection result in the console,\ne.g., "Encoding detected via FourCC: h264, dec_type: 1".']}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Q:"})," What to do if the video stream has high latency?",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"A:"})," Try reducing the resolution or frame rate of the video stream, or use a lighter object detection model."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Q:"})," How to process multiple RTSP streams simultaneously?",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"A:"})," Use semicolons to separate multiple RTSP addresses, e.g., -u rtsp://url1;rtsp://url2. Each stream will use a different decoding channel."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Q:"})," How to modify the object detection model?",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"A:"})," Modify the model loading path in the code, e.g., ",(0,i.jsx)(n.code,{children:"models = dnn.load('../models/your_model.bin')"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Q:"})," What to do if the display is abnormal or has no output?",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"A:"}),(0,i.jsx)(n.br,{}),"\n","(1) Check the HDMI connection and ensure the display service is stopped (e.g., using ",(0,i.jsx)(n.code,{children:"systemctl stop lightdm"}),").",(0,i.jsx)(n.br,{}),"\n","(2) Check if the display resolution matches the output video resolution. If not, find a suitable source file."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Q:"})," How to save the processed video stream?",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"A:"})," You can add video saving logic in the code, for example, using OpenCV's VideoWriter class to save the video file."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Q:"})," How to adjust the detection threshold?",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"A:"})," Modify the value of ",(0,i.jsx)(n.code,{children:"fcos_postprocess_info.score_threshold"})," in the code. For example, changing it to 0.5 can increase detection sensitivity."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Q:"})," Which RTSP transport protocols are supported?",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"A:"})," TCP and UDP transport protocols are supported, depending on the RTSP server configuration."]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>a});var t=r(96540);const i={},o=t.createContext(i);function s(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);