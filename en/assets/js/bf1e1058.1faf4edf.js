"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[21241],{3779:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>d,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"Advanced_development/multimedia_development/S100/camera_bringup","title":"Camera Bring-up","description":"HBN Sensor Bring-up","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/07_Advanced_development/03_multimedia_development/01_S100/02_camera_bringup.md","sourceDirName":"07_Advanced_development/03_multimedia_development/01_S100","slug":"/Advanced_development/multimedia_development/S100/camera_bringup","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/S100/camera_bringup","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1765534493000,"sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Camsys Subsystem","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/S100/camsys"},"next":{"title":"Codec","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/S100/codec"}}');var r=s(74848),t=s(28453);const d={sidebar_position:2},o="Camera Bring-up",a={},l=[{value:"HBN Sensor Bring-up",id:"hbn-sensor-bring-up",level:2},{value:"Scope",id:"scope",level:3},{value:"Preparation",id:"preparation",level:3},{value:"Steps to Add and Bring Up a New Sensor",id:"steps-to-add-and-bring-up-a-new-sensor",level:3},{value:"DTS Modifications",id:"dts-modifications",level:4},{value:"Sensor GPIO Configuration",id:"sensor-gpio-configuration",level:5},{value:"Sensor I2C Configuration",id:"sensor-i2c-configuration",level:5},{value:"MCLK Configuration",id:"mclk-configuration",level:5},{value:"DTS Modification Verification",id:"dts-modification-verification",level:5},{value:"Adding Sensor Driver Files",id:"adding-sensor-driver-files",level:4},{value:"User Application",id:"user-application",level:4},{value:"MIPI Configuration",id:"mipi-configuration",level:5},{value:"Camera Sensor Configuration",id:"camera-sensor-configuration",level:5},{value:"VIO Configuration",id:"vio-configuration",level:5},{value:"Run Program on Board",id:"run-program-on-board",level:4},{value:"ISP Image Preview",id:"isp-image-preview",level:4},{value:"Error Codes",id:"error-codes",level:3},{value:"FAQ",id:"faq",level:3},{value:"V4L2 Sensor Bring-up",id:"v4l2-sensor-bring-up",level:2},{value:"V4L2 Sensor Driver Development Guide",id:"v4l2-sensor-driver-development-guide",level:3},{value:"Define the Sensor&#39;s Private Structure",id:"define-the-sensors-private-structure",level:4},{value:"Implement V4L2 Callback Functions",id:"implement-v4l2-callback-functions",level:4},{value:"Sensor Probe Function",id:"sensor-probe-function",level:4},{value:"Sensor Device Tree",id:"sensor-device-tree",level:4},{value:"V4L2 GMSL SerDes Interface Usage Guide",id:"v4l2-gmsl-serdes-interface-usage-guide",level:3},{value:"Add New Members to the Sensor Structure",id:"add-new-members-to-the-sensor-structure",level:4},{value:"SerDes Callback Functions",id:"serdes-callback-functions",level:4},{value:"Sensor Device Tree",id:"sensor-device-tree-1",level:4},{value:"Sensor DTBO File Configuration Guide",id:"sensor-dtbo-file-configuration-guide",level:3},{value:"Generating Sensor DTBO Files",id:"generating-sensor-dtbo-files",level:4},{value:"Enabling Sensor DTBO at Boot",id:"enabling-sensor-dtbo-at-boot",level:4},{value:"Sensor Gain LUT Table Implementation Guide",id:"sensor-gain-lut-table-implementation-guide",level:3},{value:"Exposure Synchronization Sensor Driver Instructions",id:"exposure-synchronization-sensor-driver-instructions",level:3}];function c(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"camera-bring-up",children:"Camera Bring-up"})}),"\n",(0,r.jsx)(n.h2,{id:"hbn-sensor-bring-up",children:"HBN Sensor Bring-up"}),"\n",(0,r.jsx)(n.h3,{id:"scope",children:"Scope"}),"\n",(0,r.jsx)(n.p,{children:"This section provides an overview of the RDK-S100 camera bring-up process, helping readers quickly understand and master the RDK-S100 camera framework, how to rapidly add new camera configurations, and successfully bring up the camera."}),"\n",(0,r.jsxs)(n.p,{children:["This documentation uses the RDK-S100 development board with an imx219 camera module as an example for configuration instructions. For other hardware platforms or camera modules, please refer to actual hardware specifications.",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_01-en.jpg",alt:""})]}),"\n",(0,r.jsx)(n.h3,{id:"preparation",children:"Preparation"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Hardware resources"}),": RDK-S100 development board, camera module.",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.strong,{children:"Software resources"}),": System SDK, camera driver source code, sensor datasheet, sensor initialization settings, etc."]}),"\n",(0,r.jsx)(n.p,{children:"The camera-related hardware resources of the RDK-S100 development board are listed below:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"RDK-S100"}),(0,r.jsx)(n.th,{children:"MIPI host"}),(0,r.jsx)(n.th,{children:"I2C"}),(0,r.jsx)(n.th,{children:"gpio_en"}),(0,r.jsx)(n.th,{children:"gpio_lpwm_mclk"}),(0,r.jsx)(n.th,{children:"Others"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:["RX0",(0,r.jsx)("br",{})," Supports imx219 module"]}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.strong,{children:"0"}),(0,r.jsx)("br",{}),"  4 lane"]}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"1"})}),(0,r.jsxs)(n.td,{children:["SPI1_CSN0",(0,r.jsx)("br",{}),"  gpio_number:502"]}),(0,r.jsxs)(n.td,{children:["Selectable via DIP switch",(0,r.jsx)("br",{}),"  \u2022 LPWM0_DOUT0",(0,r.jsx)("br",{}),"  gpio_number:456",(0,r.jsx)("br",{}),"  \u2022 mclk 24MHz"]}),(0,r.jsx)(n.td,{children:"Note: The imx219 module has an external 24MHz crystal oscillator, so SOC-side mclk output is not required"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:["RX1",(0,r.jsx)("br",{})," Supports imx219 module"]}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.strong,{children:"1"}),(0,r.jsx)("br",{}),"   4 lane"]}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"2"})}),(0,r.jsxs)(n.td,{children:["SD_WPROT",(0,r.jsx)("br",{}),"  gpio_number:494"]}),(0,r.jsxs)(n.td,{children:["Selectable via DIP switch",(0,r.jsx)("br",{}),"  \u2022 LPWM0_DOUT1",(0,r.jsx)("br",{})," gpio_number:457",(0,r.jsx)("br",{}),"  \u2022 mclk 24MHz"]}),(0,r.jsx)(n.td,{children:"Note: The imx219 module has an external 24MHz crystal oscillator, so SOC-side mclk output is not required"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:["RX4",(0,r.jsx)("br",{})," For SerDes connection"]}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.strong,{children:"4"}),(0,r.jsx)("br",{}),"  4 lane"]}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"3"})}),(0,r.jsx)(n.td,{children:"Not specified"}),(0,r.jsx)(n.td,{children:"Not specified"}),(0,r.jsx)(n.td,{children:"Deserializer max96712, addr: 0x29; PoC max20087, addr: 0x28"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Hardware connection diagram:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_02.png",alt:""})}),"\n",(0,r.jsx)(n.h3,{id:"steps-to-add-and-bring-up-a-new-sensor",children:"Steps to Add and Bring Up a New Sensor"}),"\n",(0,r.jsxs)(n.p,{children:["When adapting ",(0,r.jsx)(n.strong,{children:"new hardware"})," and a ",(0,r.jsx)(n.strong,{children:"new camera"})," to the RDK-S100 platform, you only need to modify the platform device tree (DTS), camera driver library, and related configuration files. System libraries generally do not require modification."]}),"\n",(0,r.jsx)(n.h4,{id:"dts-modifications",children:"DTS Modifications"}),"\n",(0,r.jsx)(n.h5,{id:"sensor-gpio-configuration",children:"Sensor GPIO Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["Ensure that the GPIOs used by the new sensor hardware are configured in the ",(0,r.jsx)(n.code,{children:"drobot-s100-pinctrl.dtsi --\x3e pinctrl_video --\x3e video_gpio"})," node. This ensures the system configures the corresponding pins as GPIOs during boot-up, allowing user programs to control them."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_03.png",alt:""})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"vcon"})," is the RDK-S100 camera DTS node used to manage sensor hardware. If the sensor requires specific timing signals to start correctly, the corresponding GPIOs must be configured in this node. Configure these settings according to your actual hardware connections; relevant information can be obtained from schematics and pin lists."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"// DTS: Set GPIOs in the corresponding vcon node. Note that vcon port numbers correspond one-to-one with MIPI RX ports:\n// vcon0 -- RX0\n// ....\n// vcon3 -- RX3\n&vin_vcon0 {\n        bus = <2>;\n        gpio_poc = <0>;\n        gpio_des = <0>;\n        sensor_err = <0>;\n        //gpio_oth = <444 445>; // Not needed for imx219, so commented out and left empty\n        lpwm_chn = <0 1 2 3>;\n        rx_phy = <2 0>;\n};\n"})}),"\n",(0,r.jsx)(n.h5,{id:"sensor-i2c-configuration",children:"Sensor I2C Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["The I2C bus number must be bound to the MIPI RX port in the DTS ",(0,r.jsx)(n.code,{children:"vcon"})," node. Configure this according to your actual hardware connections; relevant information can be obtained from schematics."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"// Set I2C bus in the corresponding vcon node; for example, RX0 uses I2C2\n&vin_vcon0 {\n        bus = <2>;\n        gpio_poc = <0>;\n        gpio_des = <0>;\n        sensor_err = <0>;\n        lpwm_chn = <0 1 2 3>;\n        rx_phy = <2 0>;\n};\n"})}),"\n",(0,r.jsx)(n.h5,{id:"mclk-configuration",children:"MCLK Configuration"}),"\n",(0,r.jsx)(n.p,{children:"The RDK-S100 baseboard hardware currently does not support SOC-generated MCLK signals connected directly to the sensor module. Only modules with external crystal oscillators are supported."}),"\n",(0,r.jsx)(n.h5,{id:"dts-modification-verification",children:"DTS Modification Verification"}),"\n",(0,r.jsxs)(n.p,{children:["If the DTS configuration is correct and the hardware is properly connected\u2014with proper sensor power supply and MCLK\u2014you should be able to detect the sensor\u2019s I2C address using ",(0,r.jsx)(n.code,{children:"i2cdetect"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Use the ",(0,r.jsx)(n.code,{children:"echo"})," command to control sensor power-on or reset (note: for the imx219 module, GPIO operations are not required):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"echo 502 > /sys/class/gpio/export\necho out > /sys/class/gpio/gpio502/direction\necho 1 > /sys/class/gpio/gpio502/value\necho 502 > /sys/class/gpio/unexport\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Use ",(0,r.jsx)(n.code,{children:"i2cdetect"})," to scan for the sensor\u2019s I2C address. If the correct address appears as shown below, the DTS configuration is correct; otherwise, review your DTS settings."]}),"\n",(0,r.jsx)(n.table,{children:(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_04.png",alt:""})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_05.png",alt:""})})]})})}),"\n",(0,r.jsx)(n.h4,{id:"adding-sensor-driver-files",children:"Adding Sensor Driver Files"}),"\n",(0,r.jsxs)(n.p,{children:["Sensors from different manufacturers come with varying driver styles and settings. Therefore, you must convert the original sensor driver into RDK-S100-compatible camera driver code, compile it into a shared library (.so), and copy it to ",(0,r.jsx)(n.code,{children:"/usr/hobot/lib/sensor/"})," on the device. ",(0,r.jsx)(n.strong,{children:"Note: Before MIPI starts, ensure the sensor stream is not active."})]}),"\n",(0,r.jsxs)(n.p,{children:["The system SDK includes a sensor driver template file (",(0,r.jsx)(n.code,{children:"imx219_utility.c"}),") and adapted drivers for other sensors under ",(0,r.jsx)(n.code,{children:"hobot-camera/drivers/sensor/"}),". When adding support for a new camera sensor, refer to and modify these files accordingly."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:' #ifdef CAMERA_FRAMEWORK_HBN\n SENSOR_MODULE_F(imx219, CAM_MODULE_FLAG_A16D8);\n sensor_module_t imx219 = {\n         .module = SENSOR_MNAME(imx219),\n #else\n sensor_module_t imx219 = {\n         .module = "imx219",\n #endif\n         .init = sensor_init,\n         .start = sensor_start,\n         .stop = sensor_stop,\n         .deinit = sensor_deinit,\n         .aexp_gain_control = sensor_aexp_gain_control,\n         .aexp_line_control = sensor_aexp_line_control,\n         .power_on = sensor_poweron,\n         .power_off = sensor_poweroff,\n         .userspace_control = sensor_userspace_control,\n };\n'})}),"\n",(0,r.jsxs)(n.p,{children:["As shown above, the sensor driver interface in the RDK-S100 camera framework is encapsulated in the ",(0,r.jsx)(n.code,{children:"sensor_module_t"})," structure. The filename, structure name, and ",(0,r.jsx)(n.code,{children:"module"})," field must be consistent. For example, if the filename is ",(0,r.jsx)(n.code,{children:"imx219_utility.c"}),", both the structure name and ",(0,r.jsx)(n.code,{children:"module"})," field must be ",(0,r.jsx)(n.code,{children:"imx219"}),". When bringing up a new sensor, users must implement the following functions:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"init"}),": Sensor initialization and setting configuration"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"deinit"}),": Sensor de-initialization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"start"}),": Start sensor streaming"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"stop"}),": Stop sensor streaming"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"power_on"}),": Power on the sensor"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"power_off"}),": Power off the sensor"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"aexp_gain_control"}),": Sensor gain control"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"aexp_line_control"}),": Sensor line exposure control"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"userspace_control"}),": Enable user callback functionality"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"For 3A control, the system supports both driver registration and application-layer callbacks. By default, application-layer callbacks are used. The interface definitions are as follows:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Function"}),(0,r.jsx)(n.th,{children:"Purpose"}),(0,r.jsx)(n.th,{children:"Input Parameters"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"aexp_gain_control"}),(0,r.jsx)(n.td,{children:"Sensor gain control"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"info"}),": Sensor bus info; ",(0,r.jsx)(n.code,{children:"mode"}),": Sensor operation mode (linear/hdr/pwl); ",(0,r.jsx)(n.code,{children:"again"}),": Sensor analog gain (up to 4 values); ",(0,r.jsx)(n.code,{children:"dgain"}),": Sensor digital gain (up to 4 values); ",(0,r.jsx)(n.code,{children:"gain_num"}),": Number of gain parameters"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"aexp_line_control"}),(0,r.jsx)(n.td,{children:"Sensor exposure control"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"info"}),": Sensor bus info; ",(0,r.jsx)(n.code,{children:"mode"}),": Sensor operation mode (linear/hdr/pwl); ",(0,r.jsx)(n.code,{children:"line"}),": Sensor exposure lines (up to 4 values); ",(0,r.jsx)(n.code,{children:"line_num"}),": Number of line parameters"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"awb_control"}),(0,r.jsx)(n.td,{children:"Sensor-side AWB control"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"info"}),": Sensor bus info; ",(0,r.jsx)(n.code,{children:"mode"}),": Sensor operation mode (linear/hdr/pwl); ",(0,r.jsx)(n.code,{children:"rgain"}),": Sensor red gain; ",(0,r.jsx)(n.code,{children:"bgain"}),": Sensor blue gain; ",(0,r.jsx)(n.code,{children:"grgain"}),": Sensor green-red gain; ",(0,r.jsx)(n.code,{children:"gbgain"}),": Sensor green-blue gain"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"userspace_control"}),(0,r.jsx)(n.td,{children:"HAL-layer control switches"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"port"}),": Sensor port number; ",(0,r.jsx)(n.code,{children:"enable"}),": Enable user callback control (disabled by default). Bit definitions: ",(0,r.jsx)("br",{}),(0,r.jsx)(n.code,{children:"#define HAL_LINE_CONTROL 0x00000001"}),(0,r.jsx)("br",{}),(0,r.jsx)(n.code,{children:"#define HAL_GAIN_CONTROL 0x00000002"}),(0,r.jsx)("br",{}),(0,r.jsx)(n.code,{children:"#define HAL_AWB_CONTROL 0x00000004"})]})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"The following code demonstrates initialization of the main sensor driver structure, which must be filled in according to each sensor\u2019s specific characteristics:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"// Actual output width of the sensor\nturning_data->sensor_data.active_width = 1920;\n// Actual output height of the sensor\nturning_data.sensor_data.active_height = 1080;\n\n// Lines per second, calculated as 1/(time per line) or (fps * vts). Note that vts may be named differently across sensors\n// (e.g., frame_length, vts, etc.), but always represents total lines per frame (including active and blanking lines).\n// lines_per_second can also be interpreted as HMAX. Note: Some sensors do not have an HMAX concept.\nturning_data.sensor_data.lines_per_second = vts * sensor_info->fps;\n\n// Maximum short exposure time (i.e., maximum exposure lines per frame for short exposure).\n// Calculated as (frame exposure time) / (line exposure time) = (1/fps) / (1/lines_per_second)\nturning_data.sensor_data.exposure_time_max = vts;\n\n// Maximum analog gain multiplier. For example, if turning_data.sensor_data.analog_gain_max = 126,\n// the maximum gain ratio is calculated as 2^(X/32), where X = 126. This X value varies by sensor manufacturer\n// and should be obtained from the sensor datasheet or vendor. Alternatively, obtain the sensor\u2019s maximum gain,\n// then look up the corresponding index in the J5-ISP gain table\u2014the index value represents the maximum gain ratio.\nturning_data.sensor_data.analog_gain_max = 109;\nturning_data.sensor_data.digital_gain_max = 0;\n\n// Minimum short exposure time (minimum exposure lines per frame for short exposure).\n// Exposure time per line can be calculated using the formula: 1 second / (frame rate * (active lines + blanking)), i.e., 1 / lines_per_second.\nturning_data.sensor_data.exposure_time_min = 1;\n\n// Maximum long exposure time (maximum exposure lines per frame for long exposure).\nturning_data.sensor_data.exposure_time_long_max = vts;\n\n// Fill in sensor bit width (data_width), bayer_start (RGGB pattern start: R/Gr/Gb/B),\n// and bayer_pattern (RGGB/RCCC/RIrGB/RGIrB) information.\nsensor_data_bayer_fill(&turning_data.sensor_data, 10, (uint32_t)BAYER_START_R, (uint32_t)BAYER_PATTERN_RGGB);\n\n// Fill in exposure_max_bit_width (pwl mode bits) information.\nsensor_data_bits_fill(&turning_data.sensor_data, 12);\n\n// setting stream ctrl\n// Stream ON/OFF\nturning_data.stream_ctrl.data_length = 1;\n\n// again LUT table: firmware uses the index to look up the LUT table and find the corresponding sensor register values.\n// LUT tables are separated for a_gain and d_gain.\n// LUT table sizes: again_lut[again_control_num][256], dgain_lut[dgain_control_num][256].\nturning_data.normal.again_lut = malloc(256 * sizeof(uint32_t));\nif (turning_data.normal.again_lut != NULL)\n{\n    memset(turning_data.normal.again_lut, 0xff, 256 * sizeof(uint32_t));\n    memcpy(turning_data.normal.again_lut, imx219_gain_lut,\n           sizeof(imx219_gain_lut));\n}\n\nturning_data.normal.dgain_lut = malloc(256*sizeof(uint32_t));\nif (turning_data.normal.dgain_lut != NULL) {\n        memset(turning_data.normal.dgain_lut, 0xff, 256*sizeof(uint32_t));\n        memcpy(turning_data.normal.dgain_lut, imx219_dgain_lut,\n                sizeof(imx219_dgain_lut));\n}\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u2022 turning_data.sensor_data.active_width: Actual output width of the sensor."}),"\n",(0,r.jsx)(n.p,{children:"\u2022 turning_data.sensor_data.active_height: Actual output height of the sensor."}),"\n",(0,r.jsxs)(n.p,{children:["\u2022 turning_data.sensor_data.analog_gain_max: Maximum analog gain multiplier.",(0,r.jsx)(n.br,{}),"\n","For example, if turning_data.sensor_data.analog_gain_max = 126, the maximum gain is calculated as 2^(X/32), where X = 126.This X value varies by sensor manufacturer and must be obtained from the sensor datasheet or the sensor vendor."]}),"\n",(0,r.jsx)(n.p,{children:"\u2022 turning_data.sensor_data.digital_gain_max: Maximum digital gain multiplier."}),"\n",(0,r.jsxs)(n.p,{children:["\u2022 turning_data.sensor_data.exposure_time_min: Minimum short exposure time (minimum exposure lines per frame for short exposure).",(0,r.jsx)(n.br,{}),"\n","Exposure time per line can be derived using the formula: 1 second / (frame rate * (active lines + blanking)), i.e., 1 / lines_per_second."]}),"\n",(0,r.jsx)(n.p,{children:"\u2022 turning_data.sensor_data.exposure_time_max: Maximum short exposure time (maximum exposure lines per frame for short exposure).The maximum short exposure lines per frame can be calculated as: single-frame exposure time / exposure time per line = (1/fps) / (1/lines_per_second)."}),"\n",(0,r.jsx)(n.p,{children:"\u2022 turning_data.sensor_data.exposure_time_long_max: Maximum long exposure time (maximum exposure lines per frame for long exposure), used for HDR sensors."}),"\n",(0,r.jsxs)(n.p,{children:['\u2022 turning_data.sensor_data.lines_per_second: Number of exposure lines per second, calculated as 1 / line time or (fps * vts).The term "vts" may differ across sensors\u2014it might be called frame_length, vts, etc.\u2014but always represents the total number of lines per frame, including active lines and blanking.',(0,r.jsx)(n.br,{}),"\n","lines_per_second can also be interpreted as HMAX. Note that some sensors do not have an HMAX concept."]}),"\n",(0,r.jsxs)(n.p,{children:["\u2022 turning_data.normal.again_lut: Analog gain LUT table. Firmware uses an index to look up this LUT table to find the corresponding sensor register values.",(0,r.jsx)(n.br,{}),"\n","LUT tables are separated for a_gain and d_gain, with table sizes: again_lut[again_control_num][256], dgain_lut[dgain_control_num][256]."]}),"\n",(0,r.jsxs)(n.p,{children:["Note 1: When a certain gain value does not exist, fill the entry with 0xffffffff. During gain allocation, the program searches downward until a valid gain is found.",(0,r.jsx)(n.br,{}),"\n","The LUT table sent to the kernel must already have undergone high/low byte swapping to avoid performing this operation in kernel space.",(0,r.jsx)(n.br,{}),"\n","For example, if gain = 0x1234 and it is written to registers 0x3012 and 0x3013, some sensors write 0x12 to 0x3012 while others write 0x12 to 0x3013. This difference should be handled and abstracted in the HAL layer."]}),"\n",(0,r.jsxs)(n.p,{children:["Note 2: The LUT represents 256 gain control points in the range [0, 255]. The conversion formula is 2^(x/32), so the actual gain range is [2^(0/32), 2^(255/32)].",(0,r.jsx)(n.br,{}),"\n","The gain control curve is logarithmic. Any sensor\u2019s gain control is discretized into 256 control points because current 3A control algorithms provide exactly 256 control points.",(0,r.jsx)(n.br,{}),"\n","Providing more control points would not improve gain control precision."]}),"\n",(0,r.jsx)(n.p,{children:"Before MIPI start, ensure the sensor stream is OFF. This should be configured in the camera sensor initialization settings."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"static uint32_t imx219_linear_init_setting[] = {\n    ....\n    // 0x0100,0x01,  // Stream ON configuration should NOT be included at the end of the settings.\n}\n"})}),"\n",(0,r.jsxs)(n.p,{children:["After completing the sensor driver and settings, copy *_utility.c and *_setting.h to the corresponding SDK directory and recompile the SDK to generate the sensor driver library.",(0,r.jsx)(n.br,{}),"\n","The generated files will be located in: out/deploy/rootfs/usr/hobot/lib/sensor."]}),"\n",(0,r.jsxs)(n.p,{children:["Generally, if the code structure is correct, the framework can successfully load the sensor driver even if some tuning_data parameters are misconfigured.",(0,r.jsx)(n.br,{}),"\n",'If logcat shows "sensor so check failed" or "load failed", verify that the code structure strictly follows the HBN framework.']}),"\n",(0,r.jsx)(n.h4,{id:"user-application",children:"User Application"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to existing user applications in the SDK, which include CIM and ISP parameter configurations. These configurations must be tailored according to the specific sensor\u2019s resolution, frame rate, and data format.",(0,r.jsx)(n.br,{}),"\n","Below are the fields that require individual configuration; other fields can remain at their default values and do not need attention."]}),"\n",(0,r.jsx)(n.h5,{id:"mipi-configuration",children:"MIPI Configuration"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Field"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"rx_enable"}),(0,r.jsx)(n.td,{children:"Enable MIPI RX device. Enable the corresponding MIPI RX port. Default value is 1. Note: This field enables MIPI RX but does NOT specify the MIPI RX port number."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"phy"}),(0,r.jsx)(n.td,{children:"0: Represents MIPI D-PHY."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"lane"}),(0,r.jsx)(n.td,{children:"Number of MIPI lanes. Currently, each MIPI RX supports up to 4 lanes by default."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"datatype"}),(0,r.jsx)(n.td,{children:"MIPI input data format, which must match the sensor configuration. Common values: RAW8: 0x2A, RAW10: 0x2B, RAW12: 0x2C, YUV422 8-bit: 0x1E."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"fps"}),(0,r.jsx)(n.td,{children:"Frame rate, used for calculating certain MIPI configurations. Enter the sensor\u2019s output frame rate (obtain from FAE)."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"mipiclk"}),(0,r.jsx)(n.td,{children:"Total MIPI transmission rate (across all lanes). Obtain from FAE; typically provided alongside sensor init settings."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"width"}),(0,r.jsx)(n.td,{children:"Input image width in pixels."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"height"}),(0,r.jsx)(n.td,{children:"Input image height in pixels."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"linelength"}),(0,r.jsx)(n.td,{children:"MIPI line length. Configure based on actual sensor specifications\u2014read from sensor registers or measure on hardware."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"framelength"}),(0,r.jsx)(n.td,{children:"MIPI frame length. Configure based on actual sensor specifications\u2014read from sensor registers or measure on hardware."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"settle"}),(0,r.jsx)(n.td,{children:"MIPI settle time for PHY. Configure based on hardware measurement. Adjust if MIPI PHY errors occur; valid range: 0\u2013120."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"channel_num"}),(0,r.jsx)(n.td,{children:"MIPI virtual channel number: set to 1 for linear mode, 2 for HDR DOL2 mode."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"channel_sel[MIPIHOST_CHANNEL_NUM]"}),(0,r.jsx)(n.td,{children:"Mapping of MIPI virtual channels to IPI channels."})]})]})]}),"\n",(0,r.jsxs)(n.admonition,{type:"tip",children:[(0,r.jsx)(n.p,{children:"The commercial version offers more comprehensive feature support, deeper hardware capability access, and exclusive customization. To ensure compliance and secure delivery, access to the commercial version will be granted through the following process:"}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Commercial Version Access Process:"})}),(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Complete a questionnaire"}),": Submit your organization\u2019s information and intended use case."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sign an NDA"}),": We will contact you based on your submission to finalize and sign a confidentiality agreement."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Content release"}),": After NDA execution, we will provide access to commercial version materials via a private channel."]}),"\n"]}),(0,r.jsx)(n.p,{children:"If you wish to obtain the commercial version, please complete the questionnaire below. We will contact you within 3\u20135 business days:"}),(0,r.jsxs)(n.p,{children:["Questionnaire link: ",(0,r.jsx)(n.a,{href:"https://horizonrobotics.feishu.cn/share/base/form/shrcnJQBMIkRm6K79rjXR0hr0Fg",children:"https://horizonrobotics.feishu.cn/share/base/form/shrcnJQBMIkRm6K79rjXR0hr0Fg"})]})]}),"\n",(0,r.jsx)(n.h5,{id:"camera-sensor-configuration",children:"Camera Sensor Configuration"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Field"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"name[CAMERA_MODULE_NAME_LEN]"}),(0,r.jsx)(n.td,{children:'Camera module name, which must match the sensor library name. For example, if the sensor driver is named libimx219.so, then name should be "imx219".'})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"addr"}),(0,r.jsx)(n.td,{children:"Sensor device address, typically a 7-bit I2C address."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"sensor_mode"}),(0,r.jsx)(n.td,{children:"Sensor operating mode: 1: NORMAL_M (linear mode), 2: DOL2_M (HDR, 2 frames merged into 1), 3: DOL3_M (HDR, 3 frames merged into 1), 4: DOL4_M (HDR, 4 frames merged into 1), 5: PWL_M (HDR mode with internal sensor merging)."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"gpio_enable"}),(0,r.jsxs)(n.td,{children:["Whether to use GPIO to control camera sensor pins to meet power-up/down timing requirements (e.g., controlling the sensor\u2019s XSHUTDN pin via GPIO). ",(0,r.jsx)(n.strong,{children:"Note"}),": Corresponding GPIO numbers must be configured in the DTS. 0: Do not use GPIO. Non-zero: Use GPIO; GPIO count is enabled by bits. For example, 0x07 enables GPIOs [a, b, c]."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"gpio_level"}),(0,r.jsxs)(n.td,{children:["If gpio_enable is set, configure gpio_level to control pin logic levels. The relationship between a GPIO bit and sensor pin level is: 0: Output low first, sleep 1s (sleep duration can be customized via usleep in the sensor driver\u2019s power_on function), then output high. 1: Output high first, sleep 1s, then output low. Example: 0x05 = 101 (binary). From bit0 to bit2: GPIO a outputs high\u2192low, GPIO b outputs low\u2192high, GPIO c outputs high\u2192low. ",(0,r.jsx)(n.strong,{children:"Note"}),": Customize according to the sensor\u2019s power-up timing in its datasheet."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"fps"}),(0,r.jsx)(n.td,{children:"Sensor frame rate configuration."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"width"}),(0,r.jsx)(n.td,{children:"Sensor output image width in pixels."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"height"}),(0,r.jsx)(n.td,{children:"Sensor output image height in pixels."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"format"}),(0,r.jsx)(n.td,{children:"Sensor MIPI data type. Common values: RAW8: 0x2A, RAW10: 0x2B, RAW12: 0x2C, YUV422 8-bit: 0x1E."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"extra_mode"}),(0,r.jsx)(n.td,{children:"Module index configuration, used in some sensor drivers."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"config_index"}),(0,r.jsx)(n.td,{children:"Feature configuration, used in some sensor drivers."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"calib_lname"}),(0,r.jsx)(n.td,{children:"Path to the sensor tuning library. Default path: /usr/hobot/lib/sensor."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"end_flag"}),(0,r.jsx)(n.td,{children:"Fixed value: CAMERA_CONFIG_END_FLAG."})]})]})]}),"\n",(0,r.jsx)(n.h5,{id:"vio-configuration",children:"VIO Configuration"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Field 1"}),(0,r.jsx)(n.th,{children:"Field 2"}),(0,r.jsx)(n.th,{children:"Field 3"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"VIN"}),(0,r.jsx)(n.td,{children:"cim"}),(0,r.jsx)(n.td,{children:"mipi_en"}),(0,r.jsx)(n.td,{children:"Enable MIPI interface"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"mipi_rx"}),(0,r.jsx)(n.td,{children:"MIPI RX port number"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"vc_index"}),(0,r.jsx)(n.td,{children:"MIPI virtual channel index, default is 0"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"ipi_channel"}),(0,r.jsx)(n.td,{children:"IPI channel number, 1 for linear mode, 2 for HDR mode DOL2"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"cim_isp_flyby"}),(0,r.jsx)(n.td,{children:"CIM/SIF online to ISP. 0: SIF offline to ISP, data passes through DDR. 1: SIF online to ISP, data doesn't pass through DDR."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"input channel"}),(0,r.jsx)(n.td,{children:"format"}),(0,r.jsx)(n.td,{children:"VIN format, sensor output format"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"width"}),(0,r.jsx)(n.td,{children:"Sensor output resolution width (pixels)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"height"}),(0,r.jsx)(n.td,{children:"Sensor output resolution height (pixels)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"output channel / ddr"}),(0,r.jsx)(n.td,{children:"ddr_en"}),(0,r.jsx)(n.td,{children:"Whether data is dumped to DDR"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"wstride"}),(0,r.jsx)(n.td,{children:"Set to 0, driver will automatically calculate wstride"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"format"}),(0,r.jsx)(n.td,{children:"Sensor format set when dumping to DDR"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"buffers_num"}),(0,r.jsx)(n.td,{children:"CIM/SIF buffer number for DDR dumping, set to 1-6"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"flags"}),(0,r.jsx)(n.td,{children:"Usually set in the program"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"HB_MEM_USAGE_CPU_READ_OFTEN | HB_MEM_USAGE_CPU_WRITE_OFTEN | HB_MEM_USAGE_CACHED"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ISP"}),(0,r.jsx)(n.td,{children:"base"}),(0,r.jsx)(n.td,{children:"hw_id and slot_id"}),(0,r.jsx)(n.td,{children:"CIM hardware direct connection to ISP: hw_id needs to correspond one-to-one with cim's rx_index. When sched_mode is set to 1, CIM online ISP slot_id ranges from 0 to 3, corresponding one-to-one with cim vc_index. When sched_mode is set to 2, slot_id is fixed at 0, and cim vc_index can be set from 0 to 3 based on actual sensor connection. CIM DDR connection to ISP: hw_id has no restrictions and can be selected based on actual sensor connection and project requirements. slot id only needs to start from 4 to 11. Note: In multi-channel stress scenarios using CIM DDR connection, large resolution sensor channels should try to connect to ISP channels with smaller slot id values to ensure real-time sensor control."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"sched_mode"}),(0,r.jsx)(n.td,{children:"ISP working mode, 1: manual mode (software scheduling), 2: passthru mode (full online exclusive ISP working mode)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"width"}),(0,r.jsx)(n.td,{children:"Input image width"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"height"}),(0,r.jsx)(n.td,{children:"Input image height"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"frame_rate"}),(0,r.jsx)(n.td,{children:"Input frame rate, no actual effect"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"algo_state"}),(0,r.jsx)(n.td,{children:"2A switch parameter"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"output channel"}),(0,r.jsx)(n.td,{children:"stream_output_mode and axi_output_mode"}),(0,r.jsx)(n.td,{children:"ISP mode"})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"run-program-on-board",children:"Run Program on Board"}),"\n",(0,r.jsx)(n.p,{children:"Execute the corresponding test program"}),"\n",(0,r.jsx)(n.h4,{id:"isp-image-preview",children:"ISP Image Preview"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Add Tuning Program in SDK Code"})}),"\n",(0,r.jsx)(n.p,{children:"Modify the /app/tuning_tool/scripts/tuning_menu.sh file, following the existing sensor examples to add new configurations."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:'ITEM_IMX219_RGGB="module:Raw10_IMX219_RDK-S100"\nIMX219_RGGB_Raw10_IMX219_RDK-S100()\n{\n        IDESC="imx219 rggb raw10 RDK-S100"\n        setup_case ${folder}/tuning_imx219_cim_isp_1080p\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:"Create the tuning_imx219_cim_isp_1080p folder under the /app/tuning_tool/cfg/matrix directory, and add the corresponding three files: hb_j6dev.json, mipi.json, and vpm_config.json."}),"\n",(0,r.jsx)(n.p,{children:"Compile the SDK system code to ensure the board includes the modified and added files."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Execute Tuning Program on Board"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"cd /app/tuning_tool/scripts\nbash run_tuning.sh \n# Follow the interactive prompts to select the corresponding sensor\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Image Preview"})}),"\n",(0,r.jsx)(n.p,{children:'Open hbplayer and set the network address (ensure the PC can ping the board). Click "Apply" to apply the settings, then click "Connect" to view the real-time video stream. The real-time preview operation is illustrated in the figure below.'}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_06.png",alt:""})}),"\n",(0,r.jsx)(n.h3,{id:"error-codes",children:"Error Codes"}),"\n",(0,r.jsx)(n.p,{children:"Below are common sensor error codes and basic troubleshooting directions:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Error Code"}),(0,r.jsx)(n.th,{children:"Definition"}),(0,r.jsx)(n.th,{children:"Troubleshooting Direction"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"203"}),(0,r.jsx)(n.td,{children:"HB_CAM_INIT_FAIL"}),(0,r.jsx)(n.td,{children:"Sensor initialization failed; typically caused by I2C communication failure or unsupported sensor mode configuration"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"205"}),(0,r.jsx)(n.td,{children:"HB_CAM_START_FAIL"}),(0,r.jsx)(n.td,{children:"Sensor start failed; typically caused by I2C communication failure or unsupported sensor mode configuration"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"207"}),(0,r.jsx)(n.td,{children:"HB_CAM_I2C_WRITE_FAIL"}),(0,r.jsx)(n.td,{children:"Sensor I2C communication failed."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"217"}),(0,r.jsx)(n.td,{children:"HB_CAM_SENSOR_POWERON_FAIL"}),(0,r.jsx)(n.td,{children:"Sensor power-on failed; possibly due to incorrect sensor GPIO configuration."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"218"}),(0,r.jsx)(n.td,{children:"HB_CAM_SENSOR_POWEROFF_FAIL"}),(0,r.jsx)(n.td,{children:"Sensor power-off failed; possibly due to incorrect sensor GPIO configuration."})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"faq",children:"FAQ"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"control-tool Usage Instructions"})}),"\n",(0,r.jsxs)(n.p,{children:["Navigate to the tuning directory:",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.code,{children:"cd /app/tuning_tool/control_tool"})]}),"\n",(0,r.jsxs)(n.p,{children:["Follow the interactive prompts and execute the startup script: ",(0,r.jsx)(n.code,{children:"sh server_isp*_8000.sh"}),".",(0,r.jsx)(n.br,{}),"\n","The ISP hardware contains two IP cores, each of which can run independently. To enable ISP control, run the script: ",(0,r.jsx)(n.code,{children:"sh server_isp0_8000.sh"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"The startup method is shown in the figure below."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_07.png",alt:""})}),"\n",(0,r.jsxs)(n.p,{children:["The script automatically detects the board's IP address, checking the ",(0,r.jsx)(n.code,{children:"eth1"})," network interface by default. To switch to ",(0,r.jsx)(n.code,{children:"eth0"}),", modify the script by setting ",(0,r.jsx)(n.code,{children:"eth_id=eth0"}),". The modification location is shown in the figure below."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_08.png",alt:""})}),"\n",(0,r.jsx)(n.p,{children:"Diagram illustrating how to modify the communication address:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_09.png",alt:""})}),"\n",(0,r.jsx)(n.h2,{id:"v4l2-sensor-bring-up",children:"V4L2 Sensor Bring-up"}),"\n",(0,r.jsx)(n.h3,{id:"v4l2-sensor-driver-development-guide",children:"V4L2 Sensor Driver Development Guide"}),"\n",(0,r.jsx)(n.p,{children:"The S100 Camsys sensor V4L2 driver software framework follows the standard V4L2 sub-device driver model."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_10.png",alt:""})}),"\n",(0,r.jsxs)(n.p,{children:["Using the IMX219 driver as an example, the following describes the V4L2 driver development process for a MIPI-direct-connected sensor. The IMX219 driver source code is located at: ",(0,r.jsx)(n.code,{children:"kernel/drivers/media/i2c/imx219.c"}),"."]}),"\n",(0,r.jsx)(n.h4,{id:"define-the-sensors-private-structure",children:"Define the Sensor's Private Structure"}),"\n",(0,r.jsx)(n.p,{children:"The IMX219 private structure is as follows:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"struct imx219 {\n        struct v4l2_subdev sd;\n        struct media_pad pad;\n        struct i2c_client *i2c_client;\n        ...\n        struct v4l2_ctrl *xxx_ctrl;\n        ...\n};\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sd"}),": V4L2 sub-device handle, used to operate subdev ops;"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"pad"}),": Media pad, used to establish media links with downstream modules;"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"i2c_client"}),": I2C client handle, used to communicate with the sensor over the I2C bus;"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"xxx_ctrl"}),": V4L2 control attributes (e.g., exposure, flip, blank); implementation is optional;"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"implement-v4l2-callback-functions",children:"Implement V4L2 Callback Functions"}),"\n",(0,r.jsx)(n.p,{children:"A V4L2-compliant sensor driver must implement certain ops functions, which the V4L2 framework uses to control the sensor:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"static const struct v4l2_subdev_ops imx219_subdev_ops = {\n        .core = &imx219_core_ops,\n        .video = &imx219_video_ops,\n        .pad = &imx219_pad_ops,\n};\n"})}),"\n",(0,r.jsx)(n.p,{children:"This implements the V4L2 subdev ops callbacks, including core ops, video ops, and pad ops."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"static const struct v4l2_subdev_pad_ops imx219_pad_ops = {\n        .enum_mbus_code = imx219_enum_mbus_code,\n        .get_fmt = imx219_get_pad_format,\n        .set_fmt = imx219_set_pad_format,\n        .enum_frame_size = imx219_enum_frame_size,\n};\n"})}),"\n",(0,r.jsx)(n.p,{children:"The pad ops define callback interfaces for format configuration and negotiation, which must be implemented."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"static const struct v4l2_subdev_video_ops imx219_video_ops = {\n        .s_stream = imx219_set_stream,\n};\n"})}),"\n",(0,r.jsx)(n.p,{children:"The video ops primarily define the sensor stream start/stop interface, which must be implemented."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"static const struct v4l2_subdev_core_ops imx219_core_ops = {\n        .subscribe_event = v4l2_ctrl_subdev_subscribe_event,\n        .unsubscribe_event = v4l2_event_subdev_unsubscribe,\n};\n"})}),"\n",(0,r.jsx)(n.p,{children:"The core ops define functionalities such as ioctl event handling, which are optional."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"static const struct v4l2_subdev_internal_ops imx219_internal_ops = {\n        .open = imx219_open,\n};\n"})}),"\n",(0,r.jsx)(n.p,{children:"The internal ops define callbacks for managing the sub-device's lifecycle (e.g., open, close, release), implemented as needed."}),"\n",(0,r.jsx)(n.h4,{id:"sensor-probe-function",children:"Sensor Probe Function"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"static int imx219_probe(struct i2c_client *client)\n{\n        imx219 = devm_kzalloc(&client->dev, sizeof(*imx219), GFP_KERNEL); // 1\n        if (!imx219)\n                return -ENOMEM;\n        ...        \n        v4l2_i2c_subdev_init(&imx219->sd, client, &imx219_subdev_ops);  // 2\n\n        imx219->sd.flags |= V4L2_SUBDEV_FL_HAS_DEVNODE |\n                        \u2506   V4L2_SUBDEV_FL_HAS_EVENTS;\n        imx219->sd.entity.function = MEDIA_ENT_F_CAM_SENSOR;\n        imx219->pad.flags = MEDIA_PAD_FL_SOURCE;\n        ret = media_entity_pads_init(&imx219->sd.entity, 1, &imx219->pad);  // 3\n\n        ret = v4l2_async_register_subdev_sensor(&imx219->sd);  // 4\n        \n        ...\n}\n"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Initialize the sensor structure and allocate memory;"}),"\n",(0,r.jsx)(n.li,{children:"Initialize a V4L2 subdev and bind it to the I2C client;"}),"\n",(0,r.jsx)(n.li,{children:"Initialize the media entity's pad information so the media controller knows the sensor has one output pad that can connect to downstream modules;"}),"\n",(0,r.jsx)(n.li,{children:"Asynchronously register the sensor subdev with the V4L2 framework;"}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"sensor-device-tree",children:"Sensor Device Tree"}),"\n",(0,r.jsx)(n.p,{children:"By default, S100 loads the IMX219 device tree. The device tree format is shown below. To connect a different MIPI sensor, override the IMX219 DTS using a DTS overlay."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:'&i2c1 {\n        status = "okay";\n\n        imx219@10 {\n                status = "okay";\n                compatible = "sony,imx219";\n                ...\n                reg = <0x10>; // Sensor I2C address\n                ...\n                port {\n                        cam_to_mipi_csi0: endpoint {  // MIPI-related properties\n                                remote-endpoint = <&rdk_s100_mipi_csi0_from_cam>;  // Connected to MIPI RX0\n                                clock-lanes = <0>;\n                                data-lanes = <1 2>;\n                                link-frequencies =\n                                        /bits/ 64 <456000000>;\n                                virtual-channel = <0>;\n                        };\n                };\n        };\n};\n\n&mipi_host0 {\n        ports {\n                port@0 {\n                        rdk_s100_mipi_csi0_from_sensor0: endpoint {\n                                remote-endpoint = <&sensor0_to_mipi_csi0>;\n                                clock-lanes = <0>;\n                                data-lanes = <1 2>;    // MIPI data lanes: 2-lane\n                                lane-rate = <1728>;    // MIPI data rate\n                                vc_id = <0>;            // Virtual channel ID from sensor\n                                emb-en = <1>;            // Whether sensor output includes embedded data\n                        };\n                };\n        };\n};\n'})}),"\n",(0,r.jsx)(n.h3,{id:"v4l2-gmsl-serdes-interface-usage-guide",children:"V4L2 GMSL SerDes Interface Usage Guide"}),"\n",(0,r.jsx)(n.p,{children:"The S100 Camsys supports sensors connected via Maxim's serializer. The camera daughterboard includes the Maxim deserializer MAX96712 by default. GMSL sensors are also integrated into the V4L2 framework as V4L2 subdevs. The serializer and deserializer drivers provide function sets for GMSL sensor drivers but are not implemented as V4L2 subdevs themselves."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_11.png",alt:""})}),"\n",(0,r.jsxs)(n.p,{children:["SerDes-related data structures and callback function definitions are located in ",(0,r.jsx)(n.code,{children:"kernel/include/media/i2c/serdes_core.h"}),". Include this header file: ",(0,r.jsx)(n.code,{children:"#include <media/i2c/serdes_core.h>"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"This section uses the AR0820C GMSL sensor as an example to illustrate Camsys GMSL sensor development."}),"\n",(0,r.jsx)(n.h4,{id:"add-new-members-to-the-sensor-structure",children:"Add New Members to the Sensor Structure"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"struct ar0820 {\n        ...\n        struct serdes_device *ser_dev;\n        struct serdes_device *dser_dev;\n        struct serdes_ctx g_ctx;\n        ..\n};\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The sensor driver needs to include two structures, ",(0,r.jsx)(n.code,{children:"ser_dev"})," and ",(0,r.jsx)(n.code,{children:"dser_dev"}),", for operating the serializer and deserializer.It must also include the ",(0,r.jsx)(n.code,{children:"serdes context"})," member ",(0,r.jsx)(n.code,{children:"g_ctx"})," to store SerDes-related properties. The main structure members are described as follows:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"struct serdes_ctx {\n        u32 serdes_csi_link;    // Stores the deserializer's port value in the sensor driver\n        u32 ser_reg;            // Target value for serializer I2C address mapping\n        u32 sdev_reg;           // Actual I2C address of the sensor\n        u32 sdev_def;           // Target value for sensor I2C address mapping\n        struct device *sen_dev;\n        u32 lane_num;           // Stores the number of MIPI data lanes connecting the sensor to the serializer in the sensor driver\n        u32 data_type;          // Stores the data type output by the sensor in the sensor driver\n        u32 dst_vc;             // Stores the virtual channel of the sensor output in the sensor driver\n};\n"})}),"\n",(0,r.jsx)(n.h4,{id:"serdes-callback-functions",children:"SerDes Callback Functions"}),"\n",(0,r.jsxs)(n.p,{children:["Both the serializer and deserializer provide the following callback functions for use in the sensor driver. These callbacks must be invoked using the ",(0,r.jsx)(n.code,{children:"SERDES_OP"})," macro."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"/* By default, a return value >= 0 indicates success; a return value < 0 indicates failure */\nstruct serdes_ops {\n        /* Initialize serializer and deserializer with basic configurations only */\n        int (*init)(struct serdes_device *serdes_dev);\n        /* Currently used for additional initialization of d457 -> MAX9295A, enabling all 4 pipes of MAX9295A */\n        int (*init_ex)(struct serdes_device *serdes_dev);\n        /* Reserved */\n        int (*reset)(struct serdes_device *dev);\n        /* Pass DTS-parsed values to the serializer and deserializer via serdes_ctx */\n        int (*set_ctx)(struct serdes_device *serdes_dev,\n                       struct serdes_ctx *ctx);\n        /* Used by the deserializer to establish a link. By default, link is disabled; this op enables it */\n        int (*setup_link)(struct serdes_device *serdes_dev,\n                          struct device *sen_dev);\n        /* remote_contrl_get -> map_addr -> remote_contrl_put are used together to ensure stability of sensor/serializer during I2C address remapping */\n        int (*remote_contrl_get)(struct serdes_device *serdes_dev,\n                                 struct device *sen_dev);\n        int (*remote_contrl_put)(struct serdes_device *serdes_dev);\n        /* Called by the serializer to remap I2C addresses of both serializer and sensor */\n        int (*map_addr)(struct serdes_device *serdes_dev);\n        /* Serializer pulls high a specific MFP */\n        int (*enable_mfp)(struct serdes_device *serdes_dev, uint8_t gpio_index);\n        /* Serializer pulls low a specific MFP */\n        int (*clear_mfp)(struct serdes_device *serdes_dev, uint8_t gpio_index);\n        /* Deserializer enables MIPI TX to start streaming. Serializer TX is enabled by default, so no explicit call is needed */\n        int (*set_stream)(struct serdes_device *serdes_dev,\n                          struct device *sen_dev, int enable);\n        /* Configure GMSL video pipe attributes for both serializer and deserializer, parsed from DTS. By default, configures pipe-Z */\n        int (*set_pipe)(struct serdes_device *serdes_dev,\n                        struct device *sen_dev);\n        /* For complex scenarios, configure GMSL video pipe data flexibly per pipe */\n        int (*set_pipe_ex)(struct serdes_device *serdes_dev, struct device *sen_dev,\n                           uint8_t pipe, uint8_t vc_id, uint8_t data_type);\n        /* Check if the deserializer has an available pipe based on virtual channel ID. Returns available pipe ID (0-3).\n           Used by D457 sensor before streaming, paired with release_pipe_id */\n        int (*get_pipe_id)(struct serdes_device *serdes_dev,\n                           uint8_t vc_id);\n        /* Release the deserializer's video pipe after use */\n        int (*release_pipe_id)(struct serdes_device *serdes_dev,\n                               uint8_t pipe_id);\n};\n"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["In the sensor probe function, certain SerDes ops must be called to perform software initialization, parse DTS values, and pass them via ",(0,r.jsx)(n.code,{children:"set_ctx"})," to both serializer and deserializer drivers."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"ret = SERDES_OP(priv->ser_dev, set_ctx, priv->ser_dev, &priv->g_ctx);\nret = SERDES_OP(priv->dser_dev, set_ctx, priv->dser_dev, &priv->g_ctx);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["These calls establish a software-level link between the sensor driver and both serializer/deserializer by invoking their respective ",(0,r.jsx)(n.code,{children:"set_ctx"})," functions."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"        ret = SERDES_OP(priv->dser_dev, init, priv->dser_dev);\n        ret = SERDES_OP(priv->dser_dev, setup_link, priv->dser_dev, sen_dev);\n        ret = SERDES_OP(priv->dser_dev, remote_contrl_get, priv->dser_dev,\n        ret = SERDES_OP(priv->ser_dev, map_addr, priv->ser_dev);\n        ret = SERDES_OP(priv->dser_dev, remote_contrl_put, priv->dser_dev);\n        ret = SERDES_OP(priv->ser_dev, init, priv->ser_dev);\n        ret = SERDES_OP(priv->ser_dev, set_pipe, priv->ser_dev, sen_dev);\n        ret = SERDES_OP(priv->dser_dev, set_pipe, priv->dser_dev, sen_dev);\n        ret = SERDES_OP(priv->ser_dev, clear_mfp, priv->ser_dev,\n                        priv->mfp_reset);\n        ret = SERDES_OP(priv->ser_dev, enable_mfp, priv->ser_dev,\n                        priv->mfp_reset);\n"})}),"\n",(0,r.jsx)(n.p,{children:"These ops perform initialization of SerDes link, address mapping, pipe configuration, MFP control, etc."}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsxs)(n.li,{children:["In ",(0,r.jsx)(n.code,{children:"s_stream"}),", configure the deserializer to start streaming and enable the serializer's MFP:"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"SERDES_OP(priv->ser_dev, enable_mfp, priv->ser_dev, priv->mfp_trigger);\nSERDES_OP(priv->dser_dev, set_stream, priv->dser_dev, sen_dev, 1);\n"})}),"\n",(0,r.jsx)(n.h4,{id:"sensor-device-tree-1",children:"Sensor Device Tree"}),"\n",(0,r.jsx)(n.p,{children:"The S100 V4L2 GMSL sensor loads the AR0820C DTS by default. The GMSL sensor device tree is organized as follows:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:'ar0820@11 {\n                compatible="d-robotics,ar0820";\n                reg = <0x11>;     // Mapped address\n                addr = <0x10>;    // Actual sensor I2C address\n                ......\n                mfp-reset = <0>;  // Reset pin connected to serializer\'s MFP\n                mfp-trigger = <7>;// Trigger pin connected to serializer\'s MFP\n                d-robotics,serdes-ser-device = <&ser_a>;  // Linked to serializer on Link A\n                d-robotics,serdes-dser-device = <&dser>;  // Connected to deserializer\n                status = "okay";\n\n                port {\n                        cam_0_to_mipi_csi4: endpoint {    // Connected to MIPI RX4\n                                remote-endpoint = <&mipi_csi4_from_cam_0>;\n                                virtual-channel = <0>;\n                        };\n                };\n};\n'})}),"\n",(0,r.jsx)(n.h3,{id:"sensor-dtbo-file-configuration-guide",children:"Sensor DTBO File Configuration Guide"}),"\n",(0,r.jsx)(n.p,{children:"The S100 Uboot supports Device Tree Blob Overlay (DTBO) functionality, allowing users to add or modify (but not delete) nodes in the currently loaded DTB without changing the original DTS file."}),"\n",(0,r.jsx)(n.h4,{id:"generating-sensor-dtbo-files",children:"Generating Sensor DTBO Files"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Write a ",(0,r.jsx)(n.code,{children:".dtso"})," file:"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:'#include <dt-bindings/gpio/gpio.h>\n\n/dts-v1/;\n/plugin/;\n\n/ {\n    fragment@1 {\n        target-path = "/soc/i2c@39450000/";\n            __overlay__ {\n                status = "okay";\n                d457@11 {\n                    compatible="intel,d4xx";\n                    reg = <0x11>;\n                    def-addr = <0x10>;\n                    width = <640>;\n                    height = <480>;\n                    cam-type = "Depth";\n                    data_type = <0x2e>;\n                    lane_num = <2>;\n                    vc_id = <0>;\n                    d-robotics,serdes-ser-device = <&ser_a>;\n                    d-robotics,serdes-dser-device = <&dser>;\n                    status = "okay";\n\n                    port {\n                        sensor_0_to_mipi_csi4: endpoint {\n                            remote-endpoint = <&mipi_csi4_from_sensor_0>;\n                            virtual-channel = <0>;\n                        };\n                    };\n                };\n           };\n      };\n};\n'})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsx)(n.li,{children:"Compile the DTBO on the board:"}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Install the ",(0,r.jsx)(n.code,{children:"dtc"})," tool:"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"sudo apt install device-tree-compiler -y\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Preprocess the ",(0,r.jsx)(n.code,{children:".dtso"})," file (only needed if the ",(0,r.jsx)(n.code,{children:".dtso"})," includes headers or macros):"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:'# Get DTS header path\nHEADER_DIR=$(find /usr/src -maxdepth 1 -type d -name "linux-headers-*" | sort -Vr | head -n 1)\nDTS_HEAD_PATH="$HEADER_DIR/include"\n\n# Preprocess .dtso to generate .dtbi\ncpp -nostdinc -I "$DTS_HEAD_PATH" sample.dtso > sample.dtbi\n'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Compile to generate the final ",(0,r.jsx)(n.code,{children:".dtbo"})," file:"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["If you have a ",(0,r.jsx)(n.code,{children:".dtbi"})," file:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"dtc -q -@ -I dts -O dtb -o sample.dtbo sample.dtbi\n"})}),"\n",(0,r.jsxs)(n.p,{children:["If you don\u2019t have a ",(0,r.jsx)(n.code,{children:".dtbi"})," file:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"dtc -q -@ -I dts -O dtb -o sample.dtbo sample.dtso\n"})}),"\n",(0,r.jsx)(n.h4,{id:"enabling-sensor-dtbo-at-boot",children:"Enabling Sensor DTBO at Boot"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Place the compiled ",(0,r.jsx)(n.code,{children:".dtbo"})," file in ",(0,r.jsx)(n.code,{children:"/boot/overlays"}),".",(0,r.jsx)(n.br,{}),"\n","If the ",(0,r.jsx)(n.code,{children:"/boot/overlays"})," directory doesn\u2019t exist, create it manually or install ",(0,r.jsx)(n.code,{children:"hobot-camera.deb"})," to obtain the directory and example D457 sensor DTBO files."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_12.png",alt:""})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsxs)(n.li,{children:["Modify ",(0,r.jsx)(n.code,{children:"config.txt"})," to specify the DTBO file to load.",(0,r.jsx)(n.br,{}),"\n","If ",(0,r.jsx)(n.code,{children:"config.txt"})," doesn\u2019t exist, create it manually."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_13.png",alt:""})}),"\n",(0,r.jsxs)(n.p,{children:["Edit ",(0,r.jsx)(n.code,{children:"config.txt"})," as follows:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"dtbo_file_path=/overlays/v0p5_d457_2v_depth_color.dtbo\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"3",children:["\n",(0,r.jsx)(n.li,{children:"Reboot the board to apply the DTBO configuration. In debug builds of Uboot, you can verify DTBO loading from the boot logs."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/03_multimedia_development/02_S100/camera_bringup/camera_bringup_14.png",alt:""})}),"\n",(0,r.jsx)(n.h3,{id:"sensor-gain-lut-table-implementation-guide",children:"Sensor Gain LUT Table Implementation Guide"}),"\n",(0,r.jsxs)(n.p,{children:["For RAW-format sensors interfaced with the S100 ISP imaging system, in addition to writing the V4L2 sensor driver, you must also create a shared object (",(0,r.jsx)(n.code,{children:".so"}),") containing the sensor gain LUT (Look-Up Table), including analog gain (again) LUT, digital gain (dgain) LUT, etc."]}),"\n",(0,r.jsxs)(n.p,{children:["Human perception of brightness is closer to a logarithmic scale than linear, and the dB unit better matches this perception. Therefore, the gain arrays stored in the S100 ISP sensor gain LUT must contain ",(0,r.jsx)(n.strong,{children:"continuous dB-unit sensor gain values"})," corresponding to actual sensor register settings. This allows the ISP to look up the correct register values when adjusting sensor gain and send them to the sensor."]}),"\n",(0,r.jsxs)(n.p,{children:["Below is an example using the IMX219 sensor to illustrate how to build the V4L2 sensor LUT ",(0,r.jsx)(n.code,{children:".so"})," file."]}),"\n",(0,r.jsxs)(n.p,{children:["The IMX219 sensor gain LUT implementation directory in the SDK is:",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.code,{children:"hobot-camera/v4l2/v4l2_helper/imx219_v4l2"})]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Add the following files:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"<sensor_name>_camera_helper.c"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"Makefile"})}),"\n",(0,r.jsx)(n.li,{children:"Version file `version.mk"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"imx219_v4l2\n\u251c\u2500\u2500 imx219_camera_helper.c\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 version.mk\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsxs)(n.li,{children:["In the ",(0,r.jsx)(n.code,{children:"xxx_helper.c"})," file, create the ",(0,r.jsx)(n.code,{children:"again"})," LUT table and the ",(0,r.jsx)(n.code,{children:"dgain"})," LUT table. Each LUT is an array of type ",(0,r.jsx)(n.code,{children:"uint32_t"}),", containing up to 256 entries. Each entry holds the register configuration value corresponding to a specific gain. The dB values corresponding to adjacent entries must be continuous. Taking ",(0,r.jsx)(n.code,{children:"imx219"})," as an example:"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"static uint32_t imx219_again_lut[] = {\n        0x00,   // 0 dB\n        0x05,   // approx. 0.2 dB\n        0x0B,   // approx. 0.4 dB\n        0x0F,   // approx. 0.6 dB\n        0x15,   // approx. 0.8 dB\n        ......\n        0xE7,   // approx. 20.4 dB\n        0xE8,   // approx. 20.6 dB\n        0xffff, // end flag\n};\n\nstatic uint32_t imx219_dgain_lut[] = {\n        0x0100,  // 0 dB\n        0x0106,  // approx. 0.2 dB\n        0x010c,  // approx. 0.4 dB\n        0x0112,  // approx. 0.6 dB\n        ......\n        0x0f53,  // approx. 23.6 dB\n        0x0fa9,  // approx. 23.8 dB\n        0x0fd9,  // approx. 24.0 dB\n        0xffff,  // end flag\n};\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The last entry of each LUT must always be ",(0,r.jsx)(n.code,{children:"0xffff"}),"."]}),"\n",(0,r.jsxs)(n.ol,{start:"3",children:["\n",(0,r.jsxs)(n.li,{children:["Implement the ",(0,r.jsx)(n.code,{children:"again index to reg"})," and ",(0,r.jsx)(n.code,{children:"dgain index to reg"})," callback functions, along with the interface to retrieve these callbacks. You can reuse the implementation from the IMX219:"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"typedef uint32_t (*AGainIndexToReg_t)(uint8_t);  // Input: uint8_t index; Output: uint32_t sensor register configuration value\ntypedef uint32_t (*DGainIndexToReg_t)(uint8_t);  // Same as above\n\ntypedef struct {\n        AGainIndexToReg_t again_index_to_reg_callback;\n        DGainIndexToReg_t dgain_index_to_reg_callback;\n} Callbacks;   // Callback structure; no modification needed\n\nuint32_t again_index_to_reg_function(uint8_t isp_index) \n{\n        if (isp_index >= sizeof(imx219_again_lut)/sizeof(uint32_t))\n                isp_index = sizeof(imx219_again_lut)/sizeof(uint32_t) - 1;\n        return imx219_again_lut[isp_index];\n}\n\nuint32_t dgain_index_to_reg_function(uint8_t isp_index) \n{\n        if (isp_index >= sizeof(imx219_dgain_lut)/sizeof(uint32_t))\n                isp_index = sizeof(imx219_dgain_lut)/sizeof(uint32_t) - 1;\n\n        return imx219_dgain_lut[isp_index];\n}\n\nCallbacks cb = {again_index_to_reg_function,\n                dgain_index_to_reg_function,};\n\n// get_index_to_reg_callbacks\nCallbacks* get_index_to_reg_callbacks() {\n        return &cb;\n}\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The generated shared library should be named ",(0,r.jsx)(n.code,{children:"lib<sensor_name>_v4l2.so"}),". At runtime, this ",(0,r.jsx)(n.code,{children:".so"})," file will be automatically matched and loaded via ",(0,r.jsx)(n.code,{children:"dlopen"}),", and the LUT tables will be retrieved through the exported symbols."]}),"\n",(0,r.jsx)(n.h3,{id:"exposure-synchronization-sensor-driver-instructions",children:"Exposure Synchronization Sensor Driver Instructions"}),"\n",(0,r.jsx)(n.p,{children:"The S100 camsys SerDes provides trigger-related interfaces that can be called within the sensor driver to configure LPWM hardware and enable LPWM."}),"\n",(0,r.jsx)(n.p,{children:"Hardware-synchronized exposure currently supports only GMSL sensors. The correct trigger MFP pin must be configured in the sensor's device tree source (DTS)."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"SERDES_OP(priv->dser_dev, trigger_cfg, priv->dser_dev, sen_dev, period, duty);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Call ",(0,r.jsx)(n.code,{children:"trigger_cfg"})," during the sensor's initialization when setting the format to apply LPWM configuration."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"period"})," is in nanoseconds (ns), calculated as ",(0,r.jsx)(n.code,{children:"(1000000 / fps) * 1000"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"duty"})," is also in nanoseconds (ns); if there are no special requirements, it can be set to ",(0,r.jsx)(n.code,{children:"10000"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c",children:"SERDES_OP(priv->dser_dev, trigger_enable, priv->dser_dev, sen_dev, enable);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Call ",(0,r.jsx)(n.code,{children:"trigger_enable"})," when starting or stopping the video stream to turn LPWM output on or off."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>d,x:()=>o});var i=s(96540);const r={},t=i.createContext(r);function d(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:d(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);