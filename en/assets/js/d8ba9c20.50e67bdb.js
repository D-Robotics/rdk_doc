"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[76118],{28453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>o});var i=s(96540);const r={},t=i.createContext(r);function l(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(t.Provider,{value:n},e.children)}},34233:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"Algorithm_Application/C++_Sample/rtsp_yolov5x_display","title":"RTSP Video Streaming and YOLOv5x Inference","description":"This example demonstrates how to combine SP hardware modules (decoder, VIO, display) and BPU on platforms such as RDK S100 to achieve the following pipeline:","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/03_C++_Sample/16_rtsp_yolov5x_display.md","sourceDirName":"04_Algorithm_Application/03_C++_Sample","slug":"/Algorithm_Application/C++_Sample/rtsp_yolov5x_display","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/rtsp_yolov5x_display","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770955133000,"sidebarPosition":16,"frontMatter":{"sidebar_position":16},"sidebar":"tutorialSidebar","previous":{"title":"Video Decoding and YOLOv5x Inference","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/decode_yolov5x_display"},"next":{"title":"4.4.1 ModelZoo Overview","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/model_zoo/model_zoo_intro"}}');var r=s(74848),t=s(28453);const l={sidebar_position:16},o="RTSP Video Streaming and YOLOv5x Inference",d={},c=[{value:"Feature Description",id:"feature-description",level:2},{value:"Model Description",id:"model-description",level:2},{value:"Environment Dependencies",id:"environment-dependencies",level:2},{value:"Directory Structure",id:"directory-structure",level:2},{value:"Build Instructions",id:"build-instructions",level:2},{value:"Parameter Description",id:"parameter-description",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Notes",id:"notes",level:2},{value:"License",id:"license",level:2}];function a(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"rtsp-video-streaming-and-yolov5x-inference",children:"RTSP Video Streaming and YOLOv5x Inference"})}),"\n",(0,r.jsxs)(n.p,{children:["This example demonstrates how to combine SP hardware modules (decoder, VIO, display) and BPU on platforms such as RDK S100 to achieve the following pipeline:",(0,r.jsx)(n.br,{}),"\n","RTSP/H.264 video stream \u2192 Hardware decoding (NV12) \u2192 YOLOv5x inference \u2192 Overlay detection boxes \u2192 Real-time display. The example code is located in the directory ",(0,r.jsx)(n.code,{children:"/app/cdev_demo/bpu/12_rtsp_yolov5x_display_sample/"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"feature-description",children:"Feature Description"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Model Loading"}),(0,r.jsx)(n.br,{}),"\n","Load the BPU model using ",(0,r.jsx)(n.code,{children:"YOLOv5x(model_path)"})," and obtain the class name list via ",(0,r.jsx)(n.code,{children:"load_linewise_labels"})," for subsequent inference."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Preprocessing"}),(0,r.jsx)(n.br,{}),"\n","Retrieve NV12 frames from the SP decoder (",(0,r.jsx)(n.code,{children:"sp_decoder_get_image"}),"), convert them to BGR (",(0,r.jsx)(n.code,{children:"cv::cvtColor"}),"), perform scaling/letterbox processing, and write the result into the YOLOv5x input tensor (",(0,r.jsx)(n.code,{children:"pre_process"}),")."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Model Inference"}),(0,r.jsx)(n.br,{}),"\n","Call ",(0,r.jsx)(n.code,{children:"yolov5x.infer()"})," to execute forward computation on the BPU and generate raw detection results."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Postprocessing"}),(0,r.jsx)(n.br,{}),"\n","Invoke ",(0,r.jsx)(n.code,{children:"yolov5x.post_process"})," to apply confidence thresholding, Non-Maximum Suppression (NMS), and map detection box coordinates back to the display resolution."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"RTSP Streaming and Decoding (SP Decoder / FFmpeg)"}),(0,r.jsx)(n.br,{}),"\n","Initialize the network stack using FFmpeg (",(0,r.jsx)(n.code,{children:"avformat_network_init"}),"), open the RTSP stream (",(0,r.jsx)(n.code,{children:"avformat_open_input"}),"), and pull H.264 video frames via the SP module (",(0,r.jsx)(n.code,{children:"sp_start_decode"}),", ",(0,r.jsx)(n.code,{children:"sp_decoder_get_image"}),")."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Resolution Adaptation and Scaling (VPS)"}),(0,r.jsx)(n.br,{}),"\n","If the display resolution differs from the video stream resolution, use the SP VPS module for scaling (",(0,r.jsx)(n.code,{children:"sp_open_vps"}),") and bind the decoder, VPS, and display modules into a pipeline via ",(0,r.jsx)(n.code,{children:"sp_module_bind"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Screen Display (SP Display)"}),(0,r.jsx)(n.br,{}),"\n","Initialize the display channel via ",(0,r.jsx)(n.code,{children:"sp_start_display"}),"; overlay detection results onto the screen using ",(0,r.jsx)(n.code,{children:"draw_detections_on_disp"}),"; if resolutions match, directly display YUV frames via ",(0,r.jsx)(n.code,{children:"sp_display_set_image"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Signal Handling"}),(0,r.jsx)(n.br,{}),"\n","Register ",(0,r.jsx)(n.code,{children:"signal_handler_func"})," to capture signals like SIGINT, set the global flag ",(0,r.jsx)(n.code,{children:"is_stop"}),", and allow the main loop to exit safely."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"model-description",children:"Model Description"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to the ",(0,r.jsx)(n.a,{href:"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/Ultralytics_YOLOv5x#object-detection-ultralytics-yolov5x",children:"Ultralytics YOLOv5x Object Detection Example section"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"environment-dependencies",children:"Environment Dependencies"}),"\n",(0,r.jsx)(n.p,{children:"Before compiling and running, ensure the following dependencies are installed:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"sudo apt update\nsudo apt install libgflags-dev\n"})}),"\n",(0,r.jsx)(n.h2,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:".\n|-- CMakeLists.txt\n|-- README.md\n|-- inc\n|   `-- ultralytics_yolov5x.hpp       # YOLOv5x wrapper header file\n`-- src\n    |-- main.cc                       # Main program entry: RTSP decoding \u2192 YOLOv5x inference \u2192 Display\n    `-- ultralytics_yolov5x.cc        # YOLOv5x implementation: preprocessing/inference/postprocessing/NMS\n"})}),"\n",(0,r.jsx)(n.h2,{id:"build-instructions",children:"Build Instructions"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Configuration and Compilation","\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mkdir build && cd build\ncmake ..\nmake -j$(nproc)\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"parameter-description",children:"Parameter Description"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Parameter"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Default Value"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"--rtsp_url"})}),(0,r.jsx)(n.td,{children:"RTSP stream URL"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"rtsp://127.0.0.1/assets/1080P_test.h264"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"--transfer_type"})}),(0,r.jsx)(n.td,{children:"RTSP transport protocol (tcp/udp)"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"tcp"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"--model_path"})}),(0,r.jsx)(n.td,{children:"Path to quantized YOLOv5x BPU model (.hbm)"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"--label_file"})}),(0,r.jsx)(n.td,{children:"Class label file (one class name per line)"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/app/res/labels/coco_classes.names"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"--score_thres"})}),(0,r.jsx)(n.td,{children:"Confidence threshold (filters low-score boxes)"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"0.25"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"--nms_thres"})}),(0,r.jsx)(n.td,{children:"NMS IoU threshold"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"0.45"})})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Prepare RTSP Stream"}),(0,r.jsx)(n.br,{}),"\n","Use the pre-installed streaming service to prepare an RTSP stream as the input source. This service converts the ",(0,r.jsx)(n.code,{children:"1080P_test.h264"})," video file into an RTSP stream accessible at ",(0,r.jsx)(n.code,{children:"rtsp://127.0.0.1/assets/1080P_test.h264"}),". Start the streaming service with the following commands:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd /app/res\nsudo chmod +x live555MediaServer\nsudo ./live555MediaServer &\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Run the Model"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ensure you are in the ",(0,r.jsx)(n.code,{children:"build"})," directory."]}),"\n",(0,r.jsxs)(n.li,{children:["Run with default parameters:","\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"./rtsp_yolov5x_display\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Run with custom parameters:","\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"./rtsp_yolov5x_display \\\n    --rtsp_url rtsp://127.0.0.1/assets/1080P_test.h264 \\\n    --transfer_type tcp \\\n    --model_path /opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm \\\n    --label_file /app/res/labels/coco_classes.names \\\n    --score_thres 0.3 \\\n    --nms_thres 0.5\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Terminate Execution"}),(0,r.jsx)(n.br,{}),"\n","Press ",(0,r.jsx)(n.code,{children:"Ctrl+C"})," in the terminal."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"View Results"}),(0,r.jsx)(n.br,{}),"\n","Upon successful execution, the screen will display real-time object detection results."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"This program must run in a desktop environment."}),"\n",(0,r.jsx)(n.li,{children:"For more information about deployment options or model support, please refer to the official documentation or contact platform technical support."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"license",children:"License"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-license",children:"Copyright (C) 2025, XiangshunZhao D-Robotics.\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as\npublished by the Free Software Foundation, either version 3 of the\nLicense, or (at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n"})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(a,{...e})}):a(e)}}}]);