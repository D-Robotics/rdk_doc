"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[16795],{11470:(e,n,t)=>{t.d(n,{A:()=>k});var a=t(96540),o=t(34164),r=t(23104),s=t(56347),i=t(205),l=t(57485),d=t(31682),c=t(70679);function u(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:t}=e;return(0,a.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:t,default:a}})=>({value:e,label:n,attributes:t,default:a}))}(t);return function(e){const n=(0,d.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function _({queryString:e=!1,groupId:n}){const t=(0,s.W6)(),o=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(o),(0,a.useCallback)(e=>{if(!o)return;const n=new URLSearchParams(t.location.search);n.set(o,e),t.replace({...t.location,search:n.toString()})},[o,t])]}function p(e){const{defaultValue:n,queryString:t=!1,groupId:o}=e,r=h(e),[s,l]=(0,a.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:r})),[d,u]=_({queryString:t,groupId:o}),[p,b]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,o]=(0,c.Dv)(n);return[t,(0,a.useCallback)(e=>{n&&o.set(e)},[n,o])]}({groupId:o}),f=(()=>{const e=d??p;return m({value:e,tabValues:r})?e:null})();(0,i.A)(()=>{f&&l(f)},[f]);return{selectedValue:s,selectValue:(0,a.useCallback)(e=>{if(!m({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),b(e)},[u,b,r]),tabValues:r}}var b=t(92303);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var g=t(74848);function x({className:e,block:n,selectedValue:t,selectValue:a,tabValues:s}){const i=[],{blockElementScrollPositionUntilNextRender:l}=(0,r.a_)(),d=e=>{const n=e.currentTarget,o=i.indexOf(n),r=s[o].value;r!==t&&(l(n),a(r))},c=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const t=i.indexOf(e.currentTarget)+1;n=i[t]??i[0];break}case"ArrowLeft":{const t=i.indexOf(e.currentTarget)-1;n=i[t]??i[i.length-1];break}}n?.focus()};return(0,g.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":n},e),children:s.map(({value:e,label:n,attributes:a})=>(0,g.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{i.push(e)},onKeyDown:c,onClick:d,...a,className:(0,o.A)("tabs__item",f.tabItem,a?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function v({lazy:e,children:n,selectedValue:t}){const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=r.find(e=>e.props.value===t);return e?(0,a.cloneElement)(e,{className:(0,o.A)("margin-top--md",e.props.className)}):null}return(0,g.jsx)("div",{className:"margin-top--md",children:r.map((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function y(e){const n=p(e);return(0,g.jsxs)("div",{className:(0,o.A)("tabs-container",f.tabList),children:[(0,g.jsx)(x,{...n,...e}),(0,g.jsx)(v,{...n,...e})]})}function k(e){const n=(0,b.A)();return(0,g.jsx)(y,{...e,children:u(e.children)},String(n))}},19365:(e,n,t)=>{t.d(n,{A:()=>s});t(96540);var a=t(34164);const o={tabItem:"tabItem_Ymn6"};var r=t(74848);function s({children:e,hidden:n,className:t}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,a.A)(o.tabItem,t),hidden:n,children:e})}},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>i});var a=t(96540);const o={},r=a.createContext(o);function s(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),a.createElement(r.Provider,{value:n},e.children)}},92549:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>s,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"Robot_development/boxs/body/mono_face_landmarks_detection","title":"Face 106 Landmarks Detection","description":"Function Introduction","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/05_Robot_development/03_boxs/body/mono_face_landmarks_detection.md","sourceDirName":"05_Robot_development/03_boxs/body","slug":"/Robot_development/boxs/body/mono_face_landmarks_detection","permalink":"/rdk_doc/en/Robot_development/boxs/body/mono_face_landmarks_detection","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1756289213000,"sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Face Age Detection","permalink":"/rdk_doc/en/Robot_development/boxs/body/mono_face_age_detection"},"next":{"title":"Human Detection and Tracking (Ultralytics YOLO Pose)","permalink":"/rdk_doc/en/Robot_development/boxs/body/mono2d_yolo_pose"}}');var o=t(74848),r=t(28453);t(11470),t(19365);const s={sidebar_position:5},i="Face 106 Landmarks Detection",l={},d=[{value:"Function Introduction",id:"function-introduction",level:2},{value:"Supported Platforms",id:"supported-platforms",level:2},{value:"Preparation",id:"preparation",level:2},{value:"RDK Platform",id:"rdk-platform",level:3},{value:"Usage Instructions",id:"usage-instructions",level:2},{value:"Result Analysis",id:"result-analysis",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"face-106-landmarks-detection",children:"Face 106 Landmarks Detection"})}),"\n","\n",(0,o.jsx)(n.h2,{id:"function-introduction",children:"Function Introduction"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.strong,{children:"Face 106 Landmarks Detection Example"})," subscribes to images and smart messages containing face bounding box information, utilizes the BPU for algorithmic inference, and publishes algorithmic messages containing face 106 keypoints information."]}),"\n",(0,o.jsxs)(n.p,{children:["Code Repository: (",(0,o.jsx)(n.a,{href:"https://github.com/D-Robotics/face_landmarks_detection",children:"https://github.com/D-Robotics/face_landmarks_detection"}),")"]}),"\n",(0,o.jsx)(n.h2,{id:"supported-platforms",children:"Supported Platforms"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Platform"}),(0,o.jsx)(n.th,{children:"Operating Mode"}),(0,o.jsx)(n.th,{children:"Example Functionality"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"RDK X3, RDK X3 Module"}),(0,o.jsx)(n.td,{children:"Ubuntu 22.04 (Humble)"}),(0,o.jsx)(n.td,{children:"Starts MIPI/USB camera and displays inference rendering results via the web"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"RDK X5"}),(0,o.jsx)(n.td,{children:"Ubuntu 22.04 (Humble)"}),(0,o.jsx)(n.td,{children:"Starts MIPI/USB camera and displays inference rendering results via the web"})]})]})]}),"\n",(0,o.jsx)(n.h2,{id:"preparation",children:"Preparation"}),"\n",(0,o.jsx)(n.h3,{id:"rdk-platform",children:"RDK Platform"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"The RDK has been flashed with the Ubuntu 22.04 system image."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"The RDK has successfully installed TogetheROS.Bot."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"The RDK has a MIPI or USB camera installed."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Confirm that the PC can access the RDK via the network."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"usage-instructions",children:"Usage Instructions"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.strong,{children:"face_landmarks_detection package"})," subscribes to images published by the sensor package and face bounding box detection results published by the human detection and tracking package. After inference, it publishes algorithmic messages and displays the published images and corresponding algorithmic results on a PC browser through the websocket package."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Using MIPI Camera to Publish Images"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"# Copy the configuration files required for running the example from the tros.b installation path.\ncp -r /opt/tros/${TROS_DISTRO}/lib/mono2d_body_detection/config/ .\n\n# Configure MIPI camera\nexport CAM_TYPE=mipi\n\n# Launch the launch file\nros2 launch face_landmarks_detection body_det_face_landmarks_det.launch.py\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Using USB Camera to Publish Images"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"# Copy the configuration files required for running the example from the tros.b installation path.\ncp -r /opt/tros/${TROS_DISTRO}/lib/mono2d_body_detection/config/ .\n\n# Configure USB camera\nexport CAM_TYPE=usb\n\n# Launch the launch file\nros2 launch face_landmarks_detection body_det_face_landmarks_det.launch.py\n"})}),"\n",(0,o.jsx)(n.h2,{id:"result-analysis",children:"Result Analysis"}),"\n",(0,o.jsx)(n.p,{children:"The following information is displayed in the running terminal:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"[mono2d_body_detection-3] [WARN] [1731988336.541394391] [example]: This is mono2d body det example!\n[face_landmarks_detection-5] [WARN] [1731988336.637554206] [face_landmarks_det_node]: => face_landmarks_det_node params:\n[face_landmarks_detection-5] => feed_type: 0\n[face_landmarks_detection-5] => is_sync_mode: 0\n[face_landmarks_detection-5] => model_file_name: /root/zhikang.zeng/work_humble_ws_x5/tros_ws/install/share/face_landmarks_detection/config/faceLandmark106pts.hbm\n[face_landmarks_detection-5] => is_shared_mem_sub: 1\n[face_landmarks_detection-5] => dump_render_img: 0\n[face_landmarks_detection-5] => ai_msg_pub_topic_name: /hobot_face_landmarks_detection\n[face_landmarks_detection-5] [INFO] [1731988336.638429674] [dnn]: Node init.\n[face_landmarks_detection-5] [INFO] [1731988336.638482188] [face_landmarks_det_node]: => Set node para.\n[face_landmarks_detection-5] [INFO] [1731988336.638589050] [dnn]: Model init.\n[mono2d_body_detection-3] [WARN] [1731988336.641041791] [mono2d_body_det]: Parameter:\n[mono2d_body_detection-3]  is_sync_mode_: 0\n[mono2d_body_detection-3]  model_file_name_: config/multitask_body_head_face_hand_kps_960x544.hbm\n[mono2d_body_detection-3]  is_shared_mem_sub: 1\n[mono2d_body_detection-3]  ai_msg_pub_topic_name: /hobot_mono2d_body_detection\n[mono2d_body_detection-3]  ros_img_topic_name: /image_raw\n[mono2d_body_detection-3]  image_gap: 1\n[face_landmarks_detection-5] [BPU_PLAT]BPU Platform Version(1.3.6)!\n[face_landmarks_detection-5] [HBRT] set log level as 0. version = 3.15.54.0\n[face_landmarks_detection-5] [DNN] Runtime version = 1.23.10_(3.15.54 HBRT)\n[mono2d_body_detection-3] [BPU_PLAT]BPU Platform Version(1.3.6)!\n[mono2d_body_detection-3] [HBRT] set log level as 0. version = 3.15.54.0\n[mono2d_body_detection-3] [DNN] Runtime version = 1.23.10_(3.15.54 HBRT)\n"})}),"\n",(0,o.jsx)(n.p,{children:"The output log shows that the program is running successfully, with an algorithm input and output frame rate of 30fps, and the frame rate is refreshed once per second."}),"\n",(0,o.jsxs)(n.p,{children:["Enter ",(0,o.jsx)(n.a,{href:"http://IP:8000",children:"http://IP:8000"})," in the browser on the PC to view the images and algorithm rendering effects (IP is the IP address of the RDK):"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/03_boxs/function/image/box_adv/face_landmarks_det_render.png",alt:""})})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);