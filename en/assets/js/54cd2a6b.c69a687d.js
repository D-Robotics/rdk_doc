"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[250],{19650:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"Advanced_development/multimedia_development/multimedia_application/sunrise_camera_develop_guide","title":"Sunrise Camera Development Guide","description":"Sunrise Camera System Design","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/07_Advanced_development/03_multimedia_development/02_multimedia_application/11_sunrise_camera_develop_guide.md","sourceDirName":"07_Advanced_development/03_multimedia_development/02_multimedia_application","slug":"/Advanced_development/multimedia_development/multimedia_application/sunrise_camera_develop_guide","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/multimedia_application/sunrise_camera_develop_guide","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1764746491000,"sidebarPosition":11,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"sunrise camera User Guide","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/multimedia_application/sunrise_camera_user_guide"},"next":{"title":"hbmem sample usage instructions","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/multimedia_application/hbmem_sample_guide"}}');var s=t(74848),r=t(28453);const o={},l="Sunrise Camera Development Guide",d={},a=[{value:"Sunrise Camera System Design",id:"sunrise-camera-system-design",level:2},{value:"System Block Diagram",id:"system-block-diagram",level:3},{value:"Microkernel Design",id:"microkernel-design",level:3},{value:"Advantages and Disadvantages of the Architecture",id:"advantages-and-disadvantages-of-the-architecture",level:3},{value:"Sunrise Camera Architecture Overview",id:"sunrise-camera-architecture-overview",level:2},{value:"Module Partitioning",id:"module-partitioning",level:3},{value:"Event Bus Module (communicate)",id:"event-bus-module-communicate",level:3},{value:"Overview",id:"overview",level:4},{value:"Functionality Description",id:"functionality-description",level:4},{value:"Module Code Structure",id:"module-code-structure",level:4},{value:"Interface Description",id:"interface-description",level:4},{value:"Common Library Module (common)",id:"common-library-module-common",level:3},{value:"Overview",id:"overview-1",level:4},{value:"Functionality Description",id:"functionality-description-1",level:4},{value:"Module Code Structure",id:"module-code-structure-1",level:4},{value:"Platform Module",id:"platform-module",level:3},{value:"Overview",id:"overview-2",level:4},{value:"Function Description",id:"function-description",level:4},{value:"Module Code Structure",id:"module-code-structure-2",level:4},{value:"External Interaction Module (Transport)",id:"external-interaction-module-transport",level:3},{value:"Overview",id:"overview-3",level:4},{value:"Media Server Module",id:"media-server-module",level:4},{value:"WebSocket Server Module",id:"websocket-server-module",level:4},{value:"Main Program Entry (main)",id:"main-program-entry-main",level:3},{value:"Overview",id:"overview-4",level:4},{value:"Execution Flow",id:"execution-flow",level:4},{value:"WebServer",id:"webserver",level:3},{value:"Overview",id:"overview-5",level:4},{value:"Function Description",id:"function-description-1",level:4},{value:"Performing Algorithm Inference Using BPU",id:"performing-algorithm-inference-using-bpu",level:2},{value:"Overview",id:"overview-6",level:3},{value:"Adding a New Model",id:"adding-a-new-model",level:3},{value:"Preparing the Algorithm Model",id:"preparing-the-algorithm-model",level:4},{value:"Adding Initialization Code",id:"adding-initialization-code",level:4},{value:"Inference Thread Handler Function",id:"inference-thread-handler-function",level:4},{value:"Post-Processing Thread Function",id:"post-processing-thread-function",level:4},{value:"Post-processing Code",id:"post-processing-code",level:4},{value:"Add Rendering Logic on the Web Page",id:"add-rendering-logic-on-the-web-page",level:4}];function c(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"sunrise-camera-development-guide",children:"Sunrise Camera Development Guide"})}),"\n",(0,s.jsx)(n.h2,{id:"sunrise-camera-system-design",children:"Sunrise Camera System Design"}),"\n",(0,s.jsx)(n.h3,{id:"system-block-diagram",children:"System Block Diagram"}),"\n",(0,s.jsx)(n.p,{children:"Sunrise Camera implements multiple application solutions, such as intelligent cameras and intelligent analytics boxes."}),"\n",(0,s.jsx)(n.p,{children:"The Sunrise Camera source code includes the WebPages layer (user interaction layer), communication module layer, and functional module layer. This document primarily introduces the design of these three modules."}),"\n",(0,s.jsx)(n.p,{children:"The HAL layer modules include multimedia-related module calling interface libraries, BPU module inference libraries, etc."}),"\n",(0,s.jsx)(n.p,{children:"The kernel version includes standard driver libraries as well as the system BSP."}),"\n",(0,s.jsx)(n.p,{children:"The software block diagram is shown below:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/images_to_upload/software_framework-en.png",alt:"software_framwork"})}),"\n",(0,s.jsx)(n.h3,{id:"microkernel-design",children:"Microkernel Design"}),"\n",(0,s.jsx)(n.p,{children:'The microkernel architecture, also known as the "plug-in architecture," refers to a software design where the kernel is relatively small, and most core functionalities and business logic are implemented through plug-ins.'}),"\n",(0,s.jsx)(n.p,{children:"The kernel (core) typically contains only the minimal functionality required for system operation. Plug-ins are mutually independent, and communication between plug-ins should be minimized to avoid interdependencies."}),"\n",(0,s.jsx)(n.h3,{id:"advantages-and-disadvantages-of-the-architecture",children:"Advantages and Disadvantages of the Architecture"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Advantages"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Excellent extensibility: new features can be added simply by developing plug-ins."}),"\n",(0,s.jsx)(n.li,{children:"Functional isolation: plug-ins can be independently loaded and unloaded, facilitating deployment."}),"\n",(0,s.jsx)(n.li,{children:"High customizability to meet diverse development requirements."}),"\n",(0,s.jsx)(n.li,{children:"Supports incremental development, allowing features to be added gradually."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Disadvantages"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Poor scalability: the kernel is usually a single unit, making it difficult to implement in a distributed manner."}),"\n",(0,s.jsx)(n.li,{children:"Higher development complexity due to the need to manage communication between plug-ins and the kernel, as well as plug-in registration mechanisms."}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"sunrise-camera-architecture-overview",children:"Sunrise Camera Architecture Overview"}),"\n",(0,s.jsx)(n.h3,{id:"module-partitioning",children:"Module Partitioning"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Module"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Directory"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Description"})})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Event Bus Module"}),(0,s.jsx)(n.td,{children:"communicate"}),(0,s.jsx)(n.td,{children:"Implements event registration, reception, and distribution across modules."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Common Library Module"}),(0,s.jsx)(n.td,{children:"common"}),(0,s.jsx)(n.td,{children:"Provides common utility functions such as logging, locking, thread operations, queue operations, etc."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Camera Module"}),(0,s.jsx)(n.td,{children:"Platform"}),(0,s.jsx)(n.td,{children:"Contains chip-platform-specific code, encapsulating hardware-dependent components."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"External Interaction Module"}),(0,s.jsx)(n.td,{children:"Transport"}),(0,s.jsx)(n.td,{children:"Handles external device interactions, including rtspserver, websocket, etc."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Main Program Entry"}),(0,s.jsx)(n.td,{children:"Main"}),(0,s.jsx)(n.td,{children:"Contains the main() function entry point."})]})]})]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Top-level Code Structure"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:".\n\u251c\u2500\u2500 common\t\t\t\t\t\t# Common library module code\n\u251c\u2500\u2500 communicate\t\t\t\t\t# Event bus module\n\u251c\u2500\u2500 config\t\t\t\t\t\t# Build configuration directory\n\u251c\u2500\u2500 main\t\t\t\t\t\t# Main entry program\n\u251c\u2500\u2500 Makefile\t\t\t\t\t# Build script\n\u251c\u2500\u2500 makefile.param\t\t\t\t# Build configuration\n\u251c\u2500\u2500 Platform\t\t\t\t\t# Camera module: platform-specific, application scenario, and chip IP-related code\n\u251c\u2500\u2500 start_app.sh\t\t\t\t# Startup script\n\u251c\u2500\u2500 sunrise_camera.service \t\t# Auto-start configuration file\n\u251c\u2500\u2500 third_party\t\t\t\t\t# Third-party dependencies\n\u251c\u2500\u2500 Transport\t\t\t\t\t# Implementation of rtspserver and websocket modules\n\u251c\u2500\u2500 VERSION\t\t\t\t\t\t# Version information\n\u2514\u2500\u2500 WebServer\t\t\t\t\t# Web page program and resource files\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Compilation"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Log in to the device and navigate to the directory: ",(0,s.jsx)(n.code,{children:"/app/multimedia_samples/sunrise_camera"})]}),"\n",(0,s.jsxs)(n.li,{children:["Execute the command: ",(0,s.jsx)(n.code,{children:"make"})]}),"\n",(0,s.jsxs)(n.li,{children:["The generated binary: ",(0,s.jsx)(n.code,{children:"sunrise_camera"})]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sh",children:"root@ubuntu:/app/multimedia_samples/sunrise_camera# ls sunrise_camera/bin/\nlog  sunrise_camera  www\n"})}),"\n",(0,s.jsx)(n.h3,{id:"event-bus-module-communicate",children:"Event Bus Module (communicate)"}),"\n",(0,s.jsx)(n.h4,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"The event bus module serves as the minimal runtime unit. Based on compilation options, it invokes registration interface functions of different modules and handles the reception and dispatching of CMDs (commands) across modules."}),"\n",(0,s.jsx)(n.p,{children:"When modules interact, if a received CMD has been registered and enabled, the event bus forwards it to the appropriate sub-module for processing and returns the result to the requesting module upon completion."}),"\n",(0,s.jsx)(n.p,{children:"If a received CMD is either unregistered or disabled, the CMD invocation fails."}),"\n",(0,s.jsx)(n.h4,{id:"functionality-description",children:"Functionality Description"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Static plug-in control for modules (enabling/disabling at compile time)"}),"\n",(0,s.jsx)(n.li,{children:"CMD command forwarding between modules"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/images_to_upload/event_bus.png",alt:"event_bus"})}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsxs)(n.p,{children:["The camera sub-module defines the command ",(0,s.jsx)(n.code,{children:"SDK_CMD_CAMERA_GET_CHIP_TYPE"}),". After registering this CMD via the ",(0,s.jsx)(n.code,{children:"camera_cmd_register"})," function, when the websocket sub-module receives a web request to query the chip type, it can invoke the camera sub-module's interface using the following code."]}),"\n",(0,s.jsx)(n.p,{children:"The entire process is illustrated below:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/images_to_upload/event_bus_flow.png",alt:"event_bus_flow"})}),"\n",(0,s.jsx)(n.h4,{id:"module-code-structure",children:"Module Code Structure"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:".\n\u251c\u2500\u2500 include\n\u2502   \u251c\u2500\u2500 sdk_common_cmd.h\t\t\t# Defines all CMDs used by sub-modules in the system\n\u2502   \u251c\u2500\u2500 sdk_common_struct.h\t\t    # Defines data structures corresponding to each CMD\n\u2502   \u2514\u2500\u2500 sdk_communicate.h\t\t\t# Declares module interface functions\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 sdk_communicate.c\t\t\t# Implementation of interface functions\n"})}),"\n",(0,s.jsx)(n.h4,{id:"interface-description",children:"Interface Description"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"sdk_globle_prerare"})}),"\n",(0,s.jsxs)(n.p,{children:["All sub-module ",(0,s.jsx)(n.code,{children:"xxx_cmd_register()"})," functions are aggregated into this function. During main program startup, this interface is called to register and enable all required CMDs from sub-modules into the subsystem."]}),"\n",(0,s.jsxs)(n.p,{children:["Each sub-module must implement its own ",(0,s.jsx)(n.code,{children:"xxx_cmd_register()"})," function to register its CMDs. This is a fundamental prerequisite for the system to operate correctly."]}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/images_to_upload/cmd_register.png",alt:"cmd_register"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"sdk_cmd_register"})}),"\n",(0,s.jsx)(n.p,{children:"Interface for CMD registration."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"sdk_cmd_unregister"})}),"\n",(0,s.jsx)(n.p,{children:"Interface for CMD unregistration."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"sdk_cmd_impl"})}),"\n",(0,s.jsx)(n.p,{children:"Sub-modules call this interface to invoke functionalities implemented by other sub-modules."}),"\n",(0,s.jsx)(n.h3,{id:"common-library-module-common",children:"Common Library Module (common)"}),"\n",(0,s.jsx)(n.h4,{id:"overview-1",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This module provides common utility libraries, including but not limited to logging, locking, thread wrappers, and base64 encoding/decoding."}),"\n",(0,s.jsx)(n.p,{children:"It encapsulates commonly used classes and functions in programming to prevent redundant implementations of the same operations across multiple modules."}),"\n",(0,s.jsx)(n.p,{children:"Updates to this module affect all other modules and should therefore be handled with caution."}),"\n",(0,s.jsx)(n.h4,{id:"functionality-description-1",children:"Functionality Description"}),"\n",(0,s.jsx)(n.p,{children:"None"}),"\n",(0,s.jsx)(n.h4,{id:"module-code-structure-1",children:"Module Code Structure"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:".\n\u251c\u2500\u2500 Makefile\t\t\t\t\t# Build script\n\u251c\u2500\u2500 makefile.param\n\u2514\u2500\u2500 utils\n    \u251c\u2500\u2500 include\t\t\t\t    # Header files\n    \u2502   \u251c\u2500\u2500 aes256.h\n    \u2502   \u251c\u2500\u2500 base64.h\n    \u2502   \u251c\u2500\u2500 cJSON_Direct.h\n    \u2502   \u251c\u2500\u2500 cmap.h\n    \u2502   \u251c\u2500\u2500 common_utils.h\n    \u2502   \u251c\u2500\u2500 cqueue.h\n    \u2502   \u251c\u2500\u2500 gen_rand.h\n    \u2502   \u251c\u2500\u2500 lock_utils.h\n    \u2502   \u251c\u2500\u2500 mqueue.h\n    \u2502   \u251c\u2500\u2500 mthread.h\n    \u2502   \u251c\u2500\u2500 nalu_utils.h\n    \u2502   \u251c\u2500\u2500 sha256.h\n    \u2502   \u251c\u2500\u2500 stream_define.h\n    \u2502   \u251c\u2500\u2500 stream_manager.h\n    \u2502   \u2514\u2500\u2500 utils_log.h\n    \u251c\u2500\u2500 Makefile\n    \u2514\u2500\u2500 src                      # Source implementation files\n        \u251c\u2500\u2500 aes256.c\n        \u251c\u2500\u2500 base64.c\n        \u251c\u2500\u2500 cJSON_Direct.c\n        \u251c\u2500\u2500 cmap.c\n        \u251c\u2500\u2500 common_utils.c\n        \u251c\u2500\u2500 cqueue.c\n        \u251c\u2500\u2500 gen_rand.c\n        \u251c\u2500\u2500 lock_utils.c\n        \u251c\u2500\u2500 mqueue.c\n        \u251c\u2500\u2500 mthread.c\n        \u251c\u2500\u2500 nalu_utils.c\n        \u251c\u2500\u2500 sha256.c\n        \u251c\u2500\u2500 stream_manager.c\n        \u2514\u2500\u2500 utils_log.c\n"})}),"\n",(0,s.jsx)(n.h3,{id:"platform-module",children:"Platform Module"}),"\n",(0,s.jsx)(n.h4,{id:"overview-2",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"The module mainly includes: video encoding, ISP control, image control, snapshot capture, video output, algorithm processing, etc."}),"\n",(0,s.jsx)(n.p,{children:"The internal structure of this module is as follows:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"api_vpp"})," serves as the entry point of this module and defines the supported CMD command set;"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"solution_handle"})," handles application configuration reading/writing and assigns values to scene-related interfaces;"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"vpp_camera_impl"})," and ",(0,s.jsx)(n.code,{children:"vpp_box_impl"})," implement functionalities for specific application scenarios;"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"vp_wrap"})," encapsulates the interfaces of the multimedia module;"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"bpu_wrap"})," encapsulates the algorithm inference interfaces and post-processing methods."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/images_to_upload/platform_module.png",alt:"platform_module"})}),"\n",(0,s.jsx)(n.h4,{id:"function-description",children:"Function Description"}),"\n",(0,s.jsxs)(n.p,{children:["To add a new application scenario implementation, you only need to implement the interfaces defined in the ",(0,s.jsx)(n.code,{children:"vpp_ops_t"})," structure."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"typedef struct vpp_ops {\n\tint (*init_param)(void); // Initialize configuration parameters for modules such as VIN, VSE, VENC, BPU, etc.\n\tint (*init)(void); // SDK initialization based on configuration\n\tint (*uninit)(void); // Deinitialization\n\tint (*start)(void); // Start all media-related modules\n\tint (*stop)(void); // Stop\n\t// All CMDs supported by this module are implemented via the following two interfaces\n\tint (*param_set)(SOLUTION_PARAM_E type, char* val, unsigned int length);\n\tint (*param_get)(SOLUTION_PARAM_E type, char* val, unsigned int* length);\n} vpp_ops_t;\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The workflow for launching an application solution (using ",(0,s.jsx)(n.code,{children:"vpp_camera"})," as an example) is as follows:"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/images_to_upload/vpp_camera_flow.png",alt:"vpp_camera_flow"})}),"\n",(0,s.jsx)(n.p,{children:"Initialization and startup procedures for other submodules can also refer to this flowchart."}),"\n",(0,s.jsx)(n.h4,{id:"module-code-structure-2",children:"Module Code Structure"}),"\n",(0,s.jsxs)(n.p,{children:["Code path: ",(0,s.jsx)(n.code,{children:"Platform/S100"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:".\n\u251c\u2500\u2500 api                                   # CMD registration\n\u251c\u2500\u2500 bpu_wrap                              # Encapsulation for BPU algorithm interfaces\n\u251c\u2500\u2500 main                                  # Implementation of actual functional interfaces for CMD registration\n\u251c\u2500\u2500 Makefile                              # Build script\n\u251c\u2500\u2500 makefile.param                        # Build configuration\n\u251c\u2500\u2500 model_zoom                            # Algorithm model repository\n\u251c\u2500\u2500 test_data                             # Stores test video bitstream files and program configuration files\n\u251c\u2500\u2500 vpp_impl                              # Implementation of application scenario functionalities\n\u251c\u2500\u2500 vp_sensors -> ../../../vp_sensors/    # Camera Sensor configuration code, shared with other sample modules\n\u2514\u2500\u2500 vp_wrap                               # Encapsulation of multimedia interfaces\n"})}),"\n",(0,s.jsx)(n.h3,{id:"external-interaction-module-transport",children:"External Interaction Module (Transport)"}),"\n",(0,s.jsx)(n.h4,{id:"overview-3",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This submodule specifically handles interactions with terminals or platforms following a defined transport protocol; it includes communication modules via network, RTSP server, and WebSocket."}),"\n",(0,s.jsx)(n.p,{children:"The interaction module involves the most inter-module communication and must strictly adhere to design conventions. All data requests to other modules must be processed through defined module CMDs."}),"\n",(0,s.jsx)(n.h4,{id:"media-server-module",children:"Media Server Module"}),"\n",(0,s.jsxs)(n.p,{children:["This module encapsulates ZLMediaKit, exposing simple interfaces such as ",(0,s.jsx)(n.code,{children:"init"}),", ",(0,s.jsx)(n.code,{children:"create_media"}),", and ",(0,s.jsx)(n.code,{children:"push_video"}),". Currently, it supports pushing H.264 and H.265 video streams."]}),"\n",(0,s.jsx)(n.p,{children:'For instructions on starting and using this module, please refer to the workflow described in the "Main Program Entry" section.'}),"\n",(0,s.jsx)(n.h4,{id:"websocket-server-module",children:"WebSocket Server Module"}),"\n",(0,s.jsxs)(n.p,{children:["This module handles interactive operations from the web. After a user performs an operation on the web interface, the WebSocket server receives commands and parameters of a specific ",(0,s.jsx)(n.code,{children:"kind"}),". These are processed in the ",(0,s.jsx)(n.code,{children:"handle_user_msg"})," function within ",(0,s.jsx)(n.code,{children:"handle_user_massage.c"}),". To add a new interactive command, implement it within this function."]}),"\n",(0,s.jsx)(n.p,{children:"Currently supported interactive commands include: scene switching, scene parameter retrieval and setting, chip type query, H.264 bitrate configuration, system time synchronization, WebSocket stream pulling and stopping, etc."}),"\n",(0,s.jsx)(n.h3,{id:"main-program-entry-main",children:"Main Program Entry (main)"}),"\n",(0,s.jsx)(n.h4,{id:"overview-4",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"Entry point of the main program and module startup."}),"\n",(0,s.jsx)(n.p,{children:"The current basic submodule startup sequence is as follows. Note that the startup order must follow the dependency relationships among submodules."}),"\n",(0,s.jsx)(n.h4,{id:"execution-flow",children:"Execution Flow"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/images_to_upload/main_flow-en.jpg",alt:"main_flow"})}),"\n",(0,s.jsx)(n.h3,{id:"webserver",children:"WebServer"}),"\n",(0,s.jsx)(n.h4,{id:"overview-5",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This module implements an HTTP-based web service using ZLMediaKit, allowing users to preview video streams and configure application scenarios directly through a web browser."}),"\n",(0,s.jsx)(n.h4,{id:"function-description-1",children:"Function Description"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"WebServer/www"})," directory contains: resource files, web pages, CSS, and JavaScript programs."]}),"\n",(0,s.jsx)(n.h2,{id:"performing-algorithm-inference-using-bpu",children:"Performing Algorithm Inference Using BPU"}),"\n",(0,s.jsx)(n.h3,{id:"overview-6",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This module handles algorithm model loading, data pre-processing, inference, post-processing, and returns results in JSON format."}),"\n",(0,s.jsx)(n.p,{children:"The module's runtime sequence is as follows:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/images_to_upload/bpu_flow-en.jpg",alt:"bpu_flow"})}),"\n",(0,s.jsx)(n.h3,{id:"adding-a-new-model",children:"Adding a New Model"}),"\n",(0,s.jsxs)(n.p,{children:["Currently, ",(0,s.jsx)(n.code,{children:"sunrise_camera"})," supports only a limited number of algorithm models. In practical applications, running additional models for testing is inevitable. This section describes the basic steps for adding a new algorithm model."]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Item"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Source File"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Description"})})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Prepare algorithm model"}),(0,s.jsxs)(n.td,{children:["Place under ",(0,s.jsx)(n.code,{children:"Platform/s100/model_zoom"})," (*.hbm)"]}),(0,s.jsxs)(n.td,{children:["Add fixed-point algorithm models that can run on the development board. System-provided models are stored in ",(0,s.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/"}),"."]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Add model configuration"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"bpu_wrap.c"})}),(0,s.jsxs)(n.td,{children:["Add the new model's name, specify the model file path, and define inference and post-processing function interfaces in ",(0,s.jsx)(n.code,{children:"bpu_models"}),"."]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Inference thread handler"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"bpu_wrap.c"})}),(0,s.jsxs)(n.td,{children:["In the handler, prepare output tensors, call ",(0,s.jsx)(n.strong,{children:"hbDNNInfer"})," for inference, and push results into the output queue. Example: ",(0,s.jsx)(n.strong,{children:"inference_yolov5s"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Post-processing thread"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"bpu_wrap.c"})}),(0,s.jsxs)(n.td,{children:["Retrieve algorithm results from the output queue, apply post-processing, and generate a JSON-formatted result string. If a callback is set, invoke it. Example: ",(0,s.jsx)(n.strong,{children:"post_process_yolov5s"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Post-processing code"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"yolov5_post_process.cpp"})}),(0,s.jsx)(n.td,{children:"Each algorithm model requires corresponding post-processing logic\u2014for example, mapping classification IDs to class names or mapping detection boxes back to original image coordinates."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Add rendering on Web UI"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"WebServer/www/js/DisplayWindowManager.js"})}),(0,s.jsx)(n.td,{children:"Optional"})]})]})]}),"\n",(0,s.jsx)(n.h4,{id:"preparing-the-algorithm-model",children:"Preparing the Algorithm Model"}),"\n",(0,s.jsxs)(n.p,{children:["Algorithm models runnable on the development board come with two possible file extensions: ",(0,s.jsx)(n.code,{children:".bin"})," and ",(0,s.jsx)(n.code,{children:".hbm"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:".bin models"}),": Generated via the algorithm toolchain (PTQ - Post-Training Quantization), using ",(0,s.jsx)(n.code,{children:".bin"})," as the suffix."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:".hbm models"}),": Directly trained using a fixed-point model training framework (QAT - Quantization-Aware Training)."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["For detailed development instructions regarding algorithm models, please refer to the ",(0,s.jsx)(n.em,{children:"Quantization Toolchain Development Guide"}),"."]}),"\n",(0,s.jsx)(n.h4,{id:"adding-initialization-code",children:"Adding Initialization Code"}),"\n",(0,s.jsxs)(n.p,{children:["Define the new algorithm model in the ",(0,s.jsx)(n.code,{children:"bpu_models"})," array within ",(0,s.jsx)(n.code,{children:"bpu_wrap.c"}),", specifying its name, model file path, inference function, and post-processing function:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:'bpu_model_descriptor bpu_models[] = {\n\t{\n\t\t.model_name = "yolov5s",                                   // Algorithm name; displayed on the web client for user selection\n\t\t.model_path = "../model_zoom/yolov5s_672x672_nv12.bin",    // Path to the algorithm model file\n\t\t.inference_func = inference_yolov5s,                       // Inference function\n\t\t.post_proc_func = post_process_yolov5s                     // Post-processing function; if simple, can be merged into the inference function\n\t},\n\t... (omitted) ...\n};\n'})}),"\n",(0,s.jsxs)(n.p,{children:["When an algorithm task starts, it launches the corresponding inference and post-processing threads based on the ",(0,s.jsx)(n.code,{children:"model_name"}),"."]}),"\n",(0,s.jsx)(n.h4,{id:"inference-thread-handler-function",children:"Inference Thread Handler Function"}),"\n",(0,s.jsxs)(n.p,{children:["In the inference thread, prepare output result tensors; dequeue YUV data from the YUV queue; call ",(0,s.jsx)(n.code,{children:"HB_BPU_runModel"})," to perform inference and obtain results; then push the results into the output queue for post-processing."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:'static void *inference_yolov5s(void *ptr)\n{\n\t// Prepare model output node tensors; use 5 rotating output buffers for simplicity.\n\t// In theory, post-processing should be faster than inference.\n\thbDNNTensor output_tensors[5][3];\n\tint32_t cur_ouput_buf_idx = 0;\n\tfor (i = 0; i < 5; i++) {\n\t\tret = prepare_output_tensor(output_tensors[i], dnn_handle);\n\t\tif (ret) {\n\t\t\tSC_LOGE("prepare model output tensor failed");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\twhile (privThread->eState == E_THREAD_RUNNING) {\n\t\t// Get image data for algorithm processing; format is typically NV12 YUV\n\t\tif (mQueueDequeueTimed(&bpu_handle->m_input_queue, 100, (void**)&input_tensor) != E_QUEUE_OK)\n\t\t\tcontinue;\n\n        // Perform model inference\n\t\thbDNNInferCtrlParam infer_ctrl_param;\n\t\tHB_DNN_INITIALIZE_INFER_CTRL_PARAM(&infer_ctrl_param);\n\t\tret = hbDNNInfer(&task_handle,\n\t\t\t\t&output,\n\t\t\t\t&input_tensor->m_dnn_tensor,\n\t\t\t\tdnn_handle,\n\t\t\t\t&infer_ctrl_param);\n\n\t\t// Enqueue data for post-processing\n\t\tYolo5PostProcessInfo_t *post_info;\n\t\tpost_info = (Yolo5PostProcessInfo_t *)malloc(sizeof(Yolo5PostProcessInfo_t));\n\t\t\u2026 \u2026\n\t\tmQueueEnqueue(&bpu_handle->m_output_queue, post_info);\n\t\tcur_ouput_buf_idx++;\n\t\tcur_ouput_buf_idx %= 5;\n\t}\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"post-processing-thread-function",children:"Post-Processing Thread Function"}),"\n",(0,s.jsx)(n.p,{children:"In the post-processing thread, retrieve algorithm results from the output queue, call the post-processing function, and then invoke the algorithm task callback to handle the results (currently, all effective callbacks send results directly to the web for rendering)."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:'\nstatic void *post_process_yolov5s(void *ptr)\n{\n\ttsThread *privThread = (tsThread*)ptr;\n\tYolov5PostProcessInfo_t *post_info;\n\n\tmThreadSetName(privThread, __func__);\n\n\tbpu_handle_t *bpu_handle = (bpu_handle_t *)privThread->pvThreadData;\n\twhile (privThread->eState == E_THREAD_RUNNING) {\n\t\t// Retrieve data from the post-processing data queue\n\t\tif (mQueueDequeueTimed(&bpu_handle->m_output_queue, 100, (void**)&post_info) != E_QUEUE_OK)\n\t\t\tcontinue;\n\n\t\tchar *results = Yolov5PostProcess(post_info); // Perform post-processing, e.g., obtaining detection boxes, filtering out low-confidence results, and scaling detection box dimensions to match the display video resolution\n\n\t\tif (results) {\n\t\t\tif (NULL != bpu_handle->callback) {\n\t\t\t\t// Callback for algorithm task results; in the current application scenario, results are sent to the browser via WebSocket\n\t\t\t\tbpu_handle->callback(results, bpu_handle->m_userdata);\n\t\t\t} else {\n\t\t\t\tSC_LOGI("%s", results);\n\t\t\t}\n\t\t\tfree(results);\n\t\t}\n\t\tif (post_info) {\n\t\t\tfree(post_info);\n\t\t\tpost_info = NULL;\n\t\t}\n\t}\n\tmThreadFinish(privThread);\n\treturn NULL;\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"post-processing-code",children:"Post-processing Code"}),"\n",(0,s.jsx)(n.p,{children:"It is recommended that each algorithm model include a dedicated post-processing method:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"yolov5: yolo5_post_process.cpp"}),"\n",(0,s.jsx)(n.li,{children:"mobilenet_v2: Classification model post-processing is relatively simple\u2014just map the class ID to its corresponding label name."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The post-processing method should accomplish the following tasks:"}),"\n",(0,s.jsx)(n.p,{children:"Analyze the output results: for classification models, match class IDs to their label names; for detection models, map detection boxes from model output coordinates back to the original image coordinates."}),"\n",(0,s.jsx)(n.p,{children:"Format the algorithm results into JSON. For ease of use, perform JSON formatting directly within the function (e.g., for transmission to a web client), so the output can be used immediately."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:'// YOLOv5 output tensor format:\n// Three groups of grids are generated through three downsampling stages; each grid undergoes three predictions, and the final results are output.\nchar* Yolov5PostProcess(Yolov5PostProcessInfo_t *post_info) {\n\thbDNNTensor *tensor = post_info->output_tensor;\n\n\tstd::vector<Detection> dets;\n\tstd::vector<Detection> det_restuls;\n\tuint32_t i = 0;\n\tchar *str_dets;\n\n\t// Filter detection boxes based on confidence scores\n\tfor (i = 0; i < default_yolov5_config.strides.size(); i++) {\n\t\t_postProcess(&tensor[i], post_info, i, dets);\n\t}\n\t// Apply Non-Maximum Suppression (NMS) to merge overlapping boxes, using an IoU threshold (0.65) and a maximum number of output boxes (5000)\n\tyolov5_nms(dets, post_info->nms_threshold, post_info->nms_top_k, det_restuls, false);\n\tstd::stringstream out_string;\n\n\t// Convert algorithm results into JSON format\n\tout_string << "\\"timestamp\\": ";\n\tunsigned long timestamp = post_info->tv.tv_sec * 1000000 + post_info->tv.tv_usec;\n\tout_string << timestamp;\n\tout_string << ",\\"detection_result\\": [";\n\tfor (i = 0; i < det_restuls.size(); i++) {\n\t\tauto det_ret = det_restuls[i];\n\t\tout_string << det_ret;\n\t\tif (i < det_restuls.size() - 1)\n\t\tout_string << ",";\n\t}\n\tout_string << "]" << std::endl;\n\n\tstr_dets = (char *)malloc(out_string.str().length() + 1);\n\tstr_dets[out_string.str().length()] = \'\\0\';\n\tsnprintf(str_dets, out_string.str().length(), "%s", out_string.str().c_str());\n\treturn str_dets;\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"add-rendering-logic-on-the-web-page",children:"Add Rendering Logic on the Web Page"}),"\n",(0,s.jsx)(n.p,{children:"This section is optional. In the current implementation, all algorithm results are rendered on the web page. The data flow is as follows: after post-processing returns results in JSON format, they are sent to the web page via WebSocket. A canvas is implemented on the web page to render the algorithm results."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:'// Generic algorithm result callback function; currently sends results to the web via WebSocket\nint32_t bpu_wrap_general_result_handle(char *result, void *userdata)\n{\n\tint32_t ret = 0;\n\tint32_t pipeline_id = 0;\n\tchar *ws_msg = NULL;\n\n\tif (userdata)\n\t\tpipeline_id = *(int*)userdata;\n\n\t// Add metadata to the JSON-formatted algorithm result\n\t// Allocate memory\n\tws_msg = malloc(strlen(result) + 32);\n\tif (NULL == ws_msg) {\n\t\tSC_LOGE("Failed to allocate memory for ws_msg");\n\t\treturn -1;\n\t}\n\tsprintf(ws_msg, "{\\"kind\\":10, \\"pipeline\\":%d,", pipeline_id + 1);\n\tstrcat(ws_msg, result);\n\tstrcat(ws_msg, "}");\n\n\tret = SDK_Cmd_Impl(SDK_CMD_WEBSOCKET_SEND_MSG, (void*)ws_msg);\n\tfree(ws_msg);\n\treturn ret;\n}\n\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The file ",(0,s.jsx)(n.code,{children:"WebServer/www/js/WebSocketProtocolHandler.js"})," already includes generic handling logic for classification and object detection algorithm results. To render results from a new type of algorithm model, you will need to modify the JavaScript code accordingly."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-js",children:'// Web page WebSocket message handler\nhandleMessage(event) {\n\t{\n\t... ( omitted ) ...\n\ttry {\n            const message = JSON.parse(event.data);\n            if (message && message.kind) {\n                // Parse the message type and invoke the corresponding callback\n                switch (message.kind) {\n\t\t\t\t\t... ( omitted ) ...\n                    case this.REQUEST_TYPES.ALOG_RESULT:\n                        if (this.userCallbacks.onAlogResult) {\n                            this.userCallbacks.onAlogResult(message);\n                        }\n                        break;\n\t\t\t\t\t... ( omitted ) ...\n                    default:\n                        console.warn(`Unknown command type: kind=${message.kind}`);\n                }\n            }\n        } catch (error) {\n            console.error("Failed to parse message:", error);\n        }\n    }\n\t... ( omitted ) ...\n}\n\n'})})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>l});var i=t(96540);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);