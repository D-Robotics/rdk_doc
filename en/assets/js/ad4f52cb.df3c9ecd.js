"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[52295],{28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>d});var s=i(96540);const t={},r=s.createContext(t);function l(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(r.Provider,{value:n},e.children)}},60405:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Algorithm_Application/C++_Sample/ResNet18","title":"Image Classification - ResNet18","description":"This example demonstrates how to deploy the ResNet18 model using C/C++ for image classification inference on RDK S100 devices equipped with a BPU chip. The example code is located in the /app/cdevdemo/bpu/01classificationsample/01resnet18/ directory.","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/03_C++_Sample/02_ResNet18.md","sourceDirName":"04_Algorithm_Application/03_C++_Sample","slug":"/Algorithm_Application/C++_Sample/ResNet18","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/ResNet18","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770955133000,"sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Example Overview","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/Summary"},"next":{"title":"Image Classification - MobileNetV2","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/MobileNetV2"}}');var t=i(74848),r=i(28453);const l={sidebar_position:2},d="Image Classification - ResNet18",o={},c=[{value:"Model Description",id:"model-description",level:2},{value:"Functionality Overview",id:"functionality-overview",level:2},{value:"Environment Dependencies",id:"environment-dependencies",level:2},{value:"Directory Structure",id:"directory-structure",level:2},{value:"Build Instructions",id:"build-instructions",level:2},{value:"Model Download",id:"model-download",level:2},{value:"Parameter Description",id:"parameter-description",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Notes",id:"notes",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"image-classification---resnet18",children:"Image Classification - ResNet18"})}),"\n",(0,t.jsxs)(n.p,{children:["This example demonstrates how to deploy the ",(0,t.jsx)(n.code,{children:"ResNet18"})," model using ",(0,t.jsx)(n.code,{children:"C/C++"})," for image classification inference on RDK S100 devices equipped with a BPU chip. The example code is located in the ",(0,t.jsx)(n.code,{children:"/app/cdev_demo/bpu/01_classification_sample/01_resnet18/"})," directory."]}),"\n",(0,t.jsx)(n.h2,{id:"model-description",children:"Model Description"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Introduction"}),":"]}),"\n",(0,t.jsx)(n.p,{children:'ResNet (Residual Network) is a deep convolutional neural network architecture proposed by Microsoft Research. Its core idea is the introduction of "residual connections," which alleviate the vanishing gradient problem in deep networks through shortcut connections across layers, enabling effective training of networks with dozens or even hundreds of layers. The ResNet18 used in this example is a lightweight variant with an 18-layer structure, widely applied in tasks such as image classification and feature extraction.'}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"HBM Model Name"}),": resnet18_224x224_nv12.hbm"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Input Format"}),": NV12, size 224x224"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": Softmax probability distribution over 1000 classes"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"functionality-overview",children:"Functionality Overview"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Model Loading"})}),"\n",(0,t.jsx)(n.p,{children:"Loads the specified model and parses input/output names and shapes for subsequent inference."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Input Preprocessing"})}),"\n",(0,t.jsx)(n.p,{children:"Resizes the BGR image to 224x224 and converts it to NV12 format (separated Y and UV planes)."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Inference Execution"})}),"\n",(0,t.jsxs)(n.p,{children:["Performs forward inference using the ",(0,t.jsx)(n.code,{children:".infer()"})," method."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Result Post-processing"})}),"\n",(0,t.jsx)(n.p,{children:"Reads the output tensor, parses the top-K classification results (Top-5), and displays class labels along with their probabilities."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"environment-dependencies",children:"Environment Dependencies"}),"\n",(0,t.jsx)(n.p,{children:"Before compiling and running, ensure the following dependencies are installed:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo apt update\nsudo apt install libgflags-dev\n"})}),"\n",(0,t.jsx)(n.h2,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:".\n|-- CMakeLists.txt         # CMake build script\n|-- README.md              # Project documentation\n|-- inc/                   # Header files directory\n|   `-- resnet18.hpp       # Definition of ResNet18 inference class\n`-- src/                   # Source code directory\n    |-- main.cc            # Program entry point, invoking ResNet18 inference pipeline\n    `-- resnet18.cc        # Implementation of ResNet18 inference class\n"})}),"\n",(0,t.jsx)(n.h2,{id:"build-instructions",children:"Build Instructions"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Configuration and Compilation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"mkdir build && cd build\ncmake ..\nmake -j$(nproc)\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"model-download",children:"Model Download"}),"\n",(0,t.jsx)(n.p,{children:"If the model is not found at runtime, download it using the following command:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"wget https://archive.d-robotics.cc/downloads/rdk_model_zoo/rdk_s100/ResNet/resnet18_224x224_nv12.hbm\n"})}),"\n",(0,t.jsx)(n.h2,{id:"parameter-description",children:"Parameter Description"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter"}),(0,t.jsx)(n.th,{children:"Description"}),(0,t.jsx)(n.th,{children:"Default Value"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--model_path"})}),(0,t.jsxs)(n.td,{children:["Path to the model file (",(0,t.jsx)(n.code,{children:".hbm"})," format)"]}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/resnet18_224x224_nv12.hbm"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--test_img"})}),(0,t.jsx)(n.td,{children:"Path to the test image"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/app/res/assets/zebra_cls.jpg"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--label_file"})}),(0,t.jsxs)(n.td,{children:["ImageNet class mapping (dictionary, each line: ",(0,t.jsx)(n.code,{children:"index\\tlabel"}),")"]}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/app/res/labels/imagenet1000_clsidx_to_labels.txt"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--top_k"})}),(0,t.jsx)(n.td,{children:"Number of top-K classification results to output"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"5"})})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Run the Model"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Ensure you are in the ",(0,t.jsx)(n.code,{children:"build"})," directory."]}),"\n",(0,t.jsxs)(n.li,{children:["Run with default parameters:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"./resnet_18\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Run with custom parameters:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"./resnet_18 \\\n--model_path /opt/hobot/model/s100/basic/resnet18_224x224_nv12.hbm \\\n--test_img   /app/res/assets/zebra_cls.jpg \\\n--label_file /app/res/labels/imagenet1000_clsidx_to_labels.txt \\\n--top_k 5\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"View Results"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"Top-5 Predictions:\nzebra: 0.9979\nimpala, Aepyceros melampus: 0.0005\ncheetah, chetah, Acinonyx jubatus: 0.0005\ngazelle: 0.0004\nprairie chicken, prairie grouse, prairie fowl: 0.0002\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"The output displays the top-K classes with the highest probabilities."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"For more information on deployment methods or model support, please refer to the official documentation or contact platform technical support."}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}}}]);