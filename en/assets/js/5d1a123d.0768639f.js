"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[41106],{28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>d});var s=i(96540);const r={},o=s.createContext(r);function t(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(o.Provider,{value:n},e.children)}},63946:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>d,default:()=>a,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Advanced_development/multimedia_development/multimedia_application/sample_pipeline","title":"sample_pipeline Usage Guide","description":"Function Overview","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/07_Advanced_development/03_multimedia_development/02_multimedia_application/09_sample_pipeline.md","sourceDirName":"07_Advanced_development/03_multimedia_development/02_multimedia_application","slug":"/Advanced_development/multimedia_development/multimedia_application/sample_pipeline","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/multimedia_application/sample_pipeline","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1765275210000,"sidebarPosition":9,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"sample_gpu_3d Usage Guide","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/multimedia_application/sample_gpu_3d"},"next":{"title":"sunrise camera User Guide","permalink":"/rdk_doc/en/rdk_s/Advanced_development/multimedia_development/multimedia_application/sunrise_camera_user_guide"}}');var r=i(74848),o=i(28453);const t={},d="sample_pipeline Usage Guide",l={},c=[{value:"Function Overview",id:"function-overview",level:2},{value:"sample_pipeline Architecture Description",id:"sample_pipeline-architecture-description",level:3},{value:"single_pipe_vin_isp_ynr_pym_vpu",id:"single_pipe_vin_isp_ynr_pym_vpu",level:2},{value:"Function Overview",id:"function-overview-1",level:3},{value:"Code Location and Directory Structure",id:"code-location-and-directory-structure",level:3},{value:"Compilation",id:"compilation",level:3},{value:"Execution",id:"execution",level:3},{value:"How to Run the Program",id:"how-to-run-the-program",level:4},{value:"Program Option Descriptions",id:"program-option-descriptions",level:4},{value:"Runtime Behavior",id:"runtime-behavior",level:4},{value:"single_pipe_vin_isp_ynr_pym_gdc",id:"single_pipe_vin_isp_ynr_pym_gdc",level:2},{value:"Function Overview",id:"function-overview-2",level:3},{value:"Code Location and Directory Structure",id:"code-location-and-directory-structure-1",level:3},{value:"Compilation",id:"compilation-1",level:3},{value:"Execution",id:"execution-1",level:3},{value:"How to Run the Program",id:"how-to-run-the-program-1",level:4},{value:"Program Option Descriptions",id:"program-option-descriptions-1",level:4},{value:"Runtime Behavior",id:"runtime-behavior-1",level:4},{value:"single_pipe_vin_isp_ynr_pym_gdc_vpu",id:"single_pipe_vin_isp_ynr_pym_gdc_vpu",level:2},{value:"Function Overview",id:"function-overview-3",level:3},{value:"Code Location and Directory Structure",id:"code-location-and-directory-structure-2",level:3},{value:"Compilation",id:"compilation-2",level:3},{value:"Execution",id:"execution-2",level:3},{value:"How to Run the Program",id:"how-to-run-the-program-2",level:4},{value:"Program Parameter Options Description",id:"program-parameter-options-description",level:4},{value:"Execution Results",id:"execution-results",level:4},{value:"multi_pipe_vin_isp_ynr_pym_gdc_vpu",id:"multi_pipe_vin_isp_ynr_pym_gdc_vpu",level:2},{value:"Function Overview",id:"function-overview-4",level:3},{value:"Code Location and Directory Structure",id:"code-location-and-directory-structure-3",level:3},{value:"Compilation",id:"compilation-3",level:3},{value:"Execution",id:"execution-3",level:3},{value:"How to Run the Program",id:"how-to-run-the-program-3",level:4},{value:"Program Parameter Options Description",id:"program-parameter-options-description-1",level:4},{value:"Execution Results",id:"execution-results-1",level:4},{value:"uvc_capture_sample",id:"uvc_capture_sample",level:2},{value:"Function Overview",id:"function-overview-5",level:3},{value:"Code Location and Directory Structure",id:"code-location-and-directory-structure-4",level:3},{value:"Compilation",id:"compilation-4",level:3},{value:"Execution",id:"execution-4",level:3},{value:"How to Run the Program",id:"how-to-run-the-program-4",level:4},{value:"Program Option Descriptions",id:"program-option-descriptions-2",level:4},{value:"Execution Output",id:"execution-output",level:4}];function p(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"sample_pipeline-usage-guide",children:"sample_pipeline Usage Guide"})}),"\n",(0,r.jsx)(n.h2,{id:"function-overview",children:"Function Overview"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"sample_pipeline"})," is used to implement single or multi-sensor pipeline concatenation, covering common user pipeline scenarios. Users can learn how to build various pipelines by exploring the subdirectories under ",(0,r.jsx)(n.code,{children:"sample_pipeline"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"sample_pipeline-architecture-description",children:"sample_pipeline Architecture Description"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"sample_pipeline"})," contains multiple examples, each residing as a subdirectory under ",(0,r.jsx)(n.code,{children:"app/multimedia_samples/sample_pipeline"}),". Each subdirectory is described below:"]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Directory"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#single_pipe_vin_isp_ynr_pym_vpu",children:"single_pipe_vin_isp_ynr_pym_vpu"})}),(0,r.jsx)(n.td,{children:"Example of a simple single-sensor pipeline concatenated with encoding"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#single_pipe_vin_isp_ynr_pym_gdc",children:"single_pipe_vin_isp_ynr_pym_gdc"})}),(0,r.jsx)(n.td,{children:"Example of a single-sensor pipeline concatenated with GDC transformation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#single_pipe_vin_isp_ynr_pym_gdc_vpu",children:"single_pipe_vin_isp_ynr_pym_gdc_vpu"})}),(0,r.jsx)(n.td,{children:"Example of a single-sensor pipeline concatenated with GDC transformation and encoding"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#multi_pipe_vin_isp_ynr_pym_gdc_vpu",children:"multi_pipe_vin_isp_ynr_pym_gdc_vpu"})}),(0,r.jsx)(n.td,{children:"Example of a multi-sensor pipeline concatenated with encoding"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#uvc_capture_sample",children:"uvc_capture_sample"})}),(0,r.jsx)(n.td,{children:"UVC camera capture example"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"single_pipe_vin_isp_ynr_pym_vpu",children:"single_pipe_vin_isp_ynr_pym_vpu"}),"\n",(0,r.jsx)(n.h3,{id:"function-overview-1",children:"Function Overview"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_vpu"})," example concatenates the ",(0,r.jsx)(n.code,{children:"VIN"}),", ",(0,r.jsx)(n.code,{children:"ISP"}),", ",(0,r.jsx)(n.code,{children:"PYM"}),", and ",(0,r.jsx)(n.code,{children:"CODEC"})," modules, representing one of the most fundamental module concatenation examples. The image from the Camera Sensor passes through VIN and ISP processing before reaching the PYM module. The PYM module is configured with six output channels as follows:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Channel 0 outputs the full-resolution image processed by ISP and YNR. The output data from this channel is then fed into an encoder and saved as an H264 video stream."}),"\n",(0,r.jsx)(n.li,{children:"Channel 1 outputs an NV12-formatted image scaled down by a factor of 2 in both width and height, aligned to 16 pixels."}),"\n",(0,r.jsx)(n.li,{children:"Channel 2 outputs an NV12-formatted image scaled down by a factor of 4 in both width and height, aligned to 16 pixels."}),"\n",(0,r.jsx)(n.li,{children:"Channel 3 outputs an NV12-formatted image scaled down by a factor of 8 in both width and height, aligned to 16 pixels."}),"\n",(0,r.jsx)(n.li,{children:"Channel 4 outputs an NV12-formatted image scaled down by a factor of 16 in both width and height, aligned to 16 pixels."}),"\n",(0,r.jsx)(n.li,{children:"Channel 5 outputs an NV12-formatted image scaled down by a factor of 32 in both width and height, aligned to 16 pixels."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Note: The minimum resolution supported by PYM output is 32. If either the scaled width or height is smaller than 32, the image will not be saved."}),"\n",(0,r.jsx)(n.h3,{id:"code-location-and-directory-structure",children:"Code Location and Directory Structure"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Code location: ",(0,r.jsx)(n.code,{children:"/app/multimedia_samples/sample_pipeline/single_pipe_vin_isp_ynr_pym_vpu"})]}),"\n",(0,r.jsx)(n.li,{children:"Directory structure:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_vpu\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 single_pipe_vin_isp_ynr_pym_vpu.c\n"})}),"\n",(0,r.jsx)(n.h3,{id:"compilation",children:"Compilation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Enter the ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_vpu"})," directory and run ",(0,r.jsx)(n.code,{children:"make"})," to compile."]}),"\n",(0,r.jsxs)(n.li,{children:["The compiled binary is named ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_vpu"})," and located in the source directory."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"execution",children:"Execution"}),"\n",(0,r.jsx)(n.h4,{id:"how-to-run-the-program",children:"How to Run the Program"}),"\n",(0,r.jsxs)(n.p,{children:["Directly executing ",(0,r.jsx)(n.code,{children:"./single_pipe_vin_isp_ynr_pym_vpu"})," displays help information:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"# ./single_pipe_vin_isp_ynr_pym_vpu\nNo sensors specified.\nUsage: single_pipe_vin_isp_ynr_pym_vpu [OPTIONS]\nOptions:\n  -s <sensor_index>      Specify sensor index\n  -l <link_port>         Specify the port for connecting serdes sensors, 0:A 1:B 2:C 3:D\n  -h                     Show this help message\nindex: 0  sensor_name: imx219-30fps             config_file:linear_1920x1080_raw10_30fps_1lane.c\nindex: 1  sensor_name: sc1336_gmsl-30fps        config_file:linear_1280x720_raw10_30fps_2lane.c\nindex: 2  sensor_name: ar0820std-30fps          config_file:linear_3840x2160_30fps_1lane.c\nindex: 3  sensor_name: ar0820std-1080p30        config_file:linear_1920x1080_yuv_30fps_1lane.c\n"})}),"\n",(0,r.jsx)(n.h4,{id:"program-option-descriptions",children:"Program Option Descriptions"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-s"}),": Specifies the Camera Sensor model and configuration."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-l"}),": Specifies the Link Port for Serdes-type sensors (e.g., Port A corresponds to ",(0,r.jsx)(n.code,{children:"-l 0"}),")."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"runtime-behavior",children:"Runtime Behavior"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_vpu"})," program produces the following outputs:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Saves an NV12 image from each PYM output channel to the current working directory every 60 frames."}),"\n",(0,r.jsx)(n.li,{children:"Feeds the output from PYM channel 0 into an encoder and saves the encoded stream to a file."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Example: Using imx219 as the sensor input, execute ",(0,r.jsx)(n.code,{children:"./single_pipe_vin_isp_ynr_pym_vpu -s 0"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Sample log output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"# ./single_pipe_vin_isp_ynr_pym_vpu -s 0\nUsing index:0  sensor_name:imx219-30fps  config_file:linear_1920x1080_raw10_30fps_1lane.c\nmipi mclk is not configed.\nSearching camera sensor on device: /proc/device-tree/soc/vcon@0 i2c bus: 1 mipi rx phy: 0\nmipi rx used phy: 00000000\nmipi mclk is not configed.\nSearching camera sensor on device: /proc/device-tree/soc/vcon@1 i2c bus: 2 mipi rx phy: 1\nmipi rx used phy: 00000000\nINFO: Found sensor_name:imx219-30fps on mipi rx csi 1, i2c addr 0x10, config_file:linear_1920x1080_raw10_30fps_1lane.c\n        [0] use [isp + ynr].\n                vin [hw:1]\n                isp [hw:1] [slot_id:0] [mode:1]\n                ynr [hw:1] [slot_id:0] [mode:1]\n                pym [hw:1] [slot_id:0] [mode:1]\n                vin ->online-> isp ->online-> ynr ->online-> pym\n\nINFO: ISP channel info:\n        input info: [mipi_rx: 1] [is_online: 1]\n        isp channel info: [hw_id: 1] [slot_id: 0] [mode:1]\n\npym config:\n        ichn input width = 1920, height = 1080\n        ochn[0] ratio= 1, width = 1920, height = 1080 wstride=1920 vstride=1080 out[1920*1080]\n        ochn[1] ratio= 2, width = 960, height = 540 wstride=960 vstride=540 out[960*540]\n        ochn[2] ratio= 4, width = 480, height = 270 wstride=480 vstride=270 out[480*270]\n        ochn[3] ratio= 8, width = 240, height = 134 wstride=240 vstride=134 out[240*134]\n        ochn[4] ratio= 16, width = 120, height = 66 wstride=128 vstride=66 out[120*66]\n        ochn[5] ratio= 32, width = 60, height = 32 wstride=64 vstride=32 out[60*32]\n\nEncode idx: 0, init successful\n####################### pym chn 0 #######################\n=== Frame Info ===\nFrame ID: 1\nTimestamps: 1960130089350\ntv: 1746703610.867799\ntrig_tv: 1746703610.867799\nFrame Done: 8\nBuffer Index: 0\n\n=== Graphic Buffer ===\nFile Descriptors: 26 -1 -1\nPlane Count: 2\nFormat: 8\nWidth: 1920\nHeight: 1080\nStride: 1920\nVertical Stride: 1080\nIs Contiguous: 1\nShare IDs: 181 0 0\nFlags: 67108881\nSizes: 2073600 1036800 0\nVirtual Addresses: 0xffff849f0000 0xffff84bea400 (nil)\nPhysical Addresses: 17296588800 17298662400 0\nOffsets: 0 0 0\n####################### pym chn 1 #######################\n=== Frame Info ===\nFrame ID: 1\nTimestamps: 1960130089350\ntv: 1746703610.867799\ntrig_tv: 1746703610.867799\nFrame Done: 8\nBuffer Index: 0\n\n=== Graphic Buffer ===\nFile Descriptors: 27 -1 -1\nPlane Count: 2\nFormat: 8\nWidth: 960\nHeight: 540\nStride: 960\nVertical Stride: 540\nIs Contiguous: 1\nShare IDs: 182 0 0\nFlags: 67108881\nSizes: 518400 259200 0\nVirtual Addresses: 0xffff84930000 0xffff849ae900 (nil)\nPhysical Addresses: 17299734528 17300252928 0\nOffsets: 0 0 0\n####################### pym chn 2 #######################\n=== Frame Info ===\nFrame ID: 1\nTimestamps: 1960130089350\ntv: 1746703610.867799\ntrig_tv: 1746703610.867799\nFrame Done: 8\nBuffer Index: 0\n\n=== Graphic Buffer ===\nFile Descriptors: 28 -1 -1\nPlane Count: 2\nFormat: 8\nWidth: 480\nHeight: 270\nStride: 480\nVertical Stride: 270\nIs Contiguous: 1\nShare IDs: 183 0 0\nFlags: 67108881\nSizes: 129600 64800 0\nVirtual Addresses: 0xffff84900000 0xffff8491fa40 (nil)\nPhysical Addresses: 17300520960 17300650560 0\nOffsets: 0 0 0\n####################### pym chn 3 #######################\n=== Frame Info ===\nFrame ID: 1\nTimestamps: 1960130089350\ntv: 1746703610.867799\ntrig_tv: 1746703610.867799\nFrame Done: 8\nBuffer Index: 0\n\n=== Graphic Buffer ===\nFile Descriptors: 29 -1 -1\nPlane Count: 2\nFormat: 8\nWidth: 240\nHeight: 134\nStride: 240\nVertical Stride: 134\nIs Contiguous: 1\nShare IDs: 184 0 0\nFlags: 67108881\n```Sizes: 32160 16080 0  \nVirtual Addresses: 0xffff848f0000 0xffff848f7da0 (nil)  \nPhysical Addresses: 17300717568 17300749728 0  \nOffsets: 0 0 0  \n####################### pym chn 4 #######################  \n=== Frame Info ===  \nFrame ID: 1  \nTimestamps: 1960130089350  \ntv: 1746703610.867799  \ntrig_tv: 1746703610.867799  \nFrame Done: 8  \nBuffer Index: 0  \n\n=== Graphic Buffer ===  \nFile Descriptors: 30 -1 -1  \nPlane Count: 2  \nFormat: 8  \nWidth: 120  \nHeight: 66  \nStride: 128  \nVertical Stride: 66  \nIs Contiguous: 1  \nShare IDs: 185 0 0  \nFlags: 67108881  \nSizes: 8448 4224 0  \nVirtual Addresses: 0xffff848e0000 0xffff848e2100 (nil)  \nPhysical Addresses: 17300783104 17300791552 0  \nOffsets: 0 0 0  \n####################### pym chn 5 #######################  \n=== Frame Info ===  \nFrame ID: 1  \nTimestamps: 1960130089350  \ntv: 1746703610.867799  \ntrig_tv: 1746703610.867799  \nFrame Done: 8  \nBuffer Index: 0  \n\n=== Graphic Buffer ===  \nFile Descriptors: 31 -1 -1  \nPlane Count: 2  \nFormat: 8  \nWidth: 60  \nHeight: 32  \nStride: 64  \nVertical Stride: 32  \nIs Contiguous: 1  \nShare IDs: 186 0 0  \nFlags: 67108881  \nSizes: 2048 1024 0  \nVirtual Addresses: 0xffff848d0000 0xffff848d0800 (nil)  \nPhysical Addresses: 17300848640 17300850688 0  \nOffsets: 0 0 0  \n...  \n"})}),"\n",(0,r.jsx)(n.p,{children:"The following files will be saved at runtime:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"single_pipe_vin_isp_ynr_pym_vpu.h264  \npym_output_nv12_chn0_1920x1080_stride_1920_count_0.yuv  \npym_output_nv12_chn1_960x540_stride_960_count_0.yuv  \npym_output_nv12_chn2_480x270_stride_480_count_0.yuv  \npym_output_nv12_chn3_240x134_stride_240_count_0.yuv  \npym_output_nv12_chn4_120x66_stride_128_count_0.yuv  \npym_output_nv12_chn5_60x32_stride_64_count_0.yuv  \n... ...  \n"})}),"\n",(0,r.jsx)(n.h2,{id:"single_pipe_vin_isp_ynr_pym_gdc",children:"single_pipe_vin_isp_ynr_pym_gdc"}),"\n",(0,r.jsx)(n.h3,{id:"function-overview-2",children:"Function Overview"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc"})," sample demonstrates a basic pipeline that chains together the ",(0,r.jsx)(n.code,{children:"VIN"}),", ",(0,r.jsx)(n.code,{children:"ISP"}),", ",(0,r.jsx)(n.code,{children:"PYM"}),", and ",(0,r.jsx)(n.code,{children:"GDC"})," modules. The image from the camera sensor passes through the VIN, ISP, and PYM modules before reaching the GDC module, which applies geometric distortion correction based on a GDC bin file to generate YUV images."]}),"\n",(0,r.jsx)(n.h3,{id:"code-location-and-directory-structure-1",children:"Code Location and Directory Structure"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Code location: ",(0,r.jsx)(n.code,{children:"/app/multimedia_samples/sample_pipeline/single_pipe_vin_isp_ynr_pym_gdc"})]}),"\n",(0,r.jsx)(n.li,{children:"Directory structure:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc  \n\u251c\u2500\u2500 Makefile  \n\u2514\u2500\u2500 single_pipe_vin_isp_ynr_pym_gdc.c  \n"})}),"\n",(0,r.jsx)(n.h3,{id:"compilation-1",children:"Compilation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Enter the ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc"})," directory and run ",(0,r.jsx)(n.code,{children:"make"})," to compile."]}),"\n",(0,r.jsxs)(n.li,{children:["The output binary will be ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc"})," in the source directory."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"execution-1",children:"Execution"}),"\n",(0,r.jsx)(n.h4,{id:"how-to-run-the-program-1",children:"How to Run the Program"}),"\n",(0,r.jsxs)(n.p,{children:["Running the program directly (",(0,r.jsx)(n.code,{children:"./single_pipe_vin_isp_ynr_pym_gdc"}),") displays help information:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"# ./single_pipe_vin_isp_ynr_pym_gdc  \nNo sensors specified.  \nUsage: single_pipe_vin_isp_pym_vpu [OPTIONS]  \nOptions:  \n  -s <sensor_index>      Specify sensor index  \n  -l <link_port>         Specify the port for connecting serdes sensors, 0:A 1:B 2:C 3:D  \n  -f <gdc_bin_file>      Specify sensor gdc_bin_file path  \n  -h                     Show this help message  \nindex: 0  sensor_name: imx219-30fps             config_file:linear_1920x1080_raw10_30fps_1lane.c  \nindex: 1  sensor_name: sc1336_gmsl-30fps        config_file:linear_1280x720_raw10_30fps_2lane.c  \nindex: 2  sensor_name: ar0820std-30fps          config_file:linear_3840x2160_30fps_1lane.c  \nindex: 3  sensor_name: ar0820std-1080p30        config_file:linear_1920x1080_yuv_30fps_1lane.c  \nindex: 4  sensor_name: ovx3cstd-30fps           config_file:linear_1920x1280_yuv_30fps_1lane.c  \n"})}),"\n",(0,r.jsx)(n.h4,{id:"program-option-descriptions-1",children:"Program Option Descriptions"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-s"}),": Specifies the camera sensor model and configuration."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-l"}),": Specifies the link port for SerDes-type sensors (e.g., Port A corresponds to ",(0,r.jsx)(n.code,{children:"-l 0"}),")."]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{title:"Note",type:"caution",children:(0,r.jsx)(n.p,{children:"The link port value must match the physical port on the deserializer to which the SerDes sensor is connected. Ensure the sensor is connected to the specified port."})}),"\n",(0,r.jsx)(n.h4,{id:"runtime-behavior-1",children:"Runtime Behavior"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc"})," program outputs the following:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Saves one NV12 image from each GDC output channel to the current working directory every 30 frames."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Example: Using imx219 as the sensor input, run:",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.code,{children:"./single_pipe_vin_isp_ynr_pym_gdc -s 0 -f ../../vp_sensors/gdc_bin/imx219_gdc.bin"})]}),"\n",(0,r.jsx)(n.p,{children:"Sample log output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"# ./single_pipe_vin_isp_ynr_pym_gdc -s 0 -f ../../vp_sensors/gdc_bin/imx219_gdc.bin  \nUsing index:0  sensor_name:imx219-30fps  config_file:linear_1920x1080_raw10_30fps_1lane.c  \nmipi mclk is not configed.  \nSearching camera sensor on device: /proc/device-tree/soc/vcon@0 i2c bus: 1 mipi rx phy: 0  \nmipi rx used phy: 00000000  \nmipi mclk is not configed.  \nSearching camera sensor on device: /proc/device-tree/soc/vcon@1 i2c bus: 2 mipi rx phy: 1  \nmipi rx used phy: 00000000  \nINFO: Found sensor_name:imx219-30fps on mipi rx csi 1, i2c addr 0x10, config_file:linear_1920x1080_raw10_30fps_1lane.c  \n        [0] use [isp + ynr].  \n                vin [hw:1]  \n                isp [hw:1] [slot_id:0] [mode:1]  \n                ynr [hw:1] [slot_id:0] [mode:1]  \n                pym [hw:1] [slot_id:0] [mode:1]  \n                vin ->online-> isp ->online-> ynr ->online-> pym  \n\nINFO: ISP channel info:  \n        input info: [mipi_rx: 1] [is_online: 1]  \n        isp channel info: [hw_id: 1] [slot_id: 0] [mode:1]  \n\npym config:  \n        ichn input width = 1920, height = 1080  \n        ochn[0] ratio= 1, width = 1920, height = 1080 wstride=1920 vstride=1080 out[1920*1080]  \n        ochn[1] ratio= 2, width = 960, height = 540 wstride=960 vstride=540 out[960*540]  \n        ochn[2] ratio= 4, width = 480, height = 270 wstride=480 vstride=270 out[480*270]  \n        ochn[3] ratio= 8, width = 240, height = 134 wstride=240 vstride=134 out[240*134]  \n        ochn[4] ratio= 16, width = 120, height = 66 wstride=128 vstride=66 out[120*66]  \n        ochn[5] ratio= 32, width = 60, height = 32 wstride=64 vstride=32 out[60*32]  \n\ngdc(296805) dump yuv 1920x1080(stride:1920), buffer size: 2073600 + 1036800 frame id: 1, timestamp: 21677343453900  \ngdc(296805) dump yuv 1920x1080(stride:1920), buffer size: 2073600 + 1036800 frame id: 31, timestamp: 21678330776125  \ngdc(296805) dump yuv 1920x1080(stride:1920), buffer size: 2073600 + 1036800 frame id: 61, timestamp: 21679318103925  \ngdc(296805) dump yuv 1920x1080(stride:1920), buffer size: 2073600 + 1036800 frame id: 91, timestamp: 21680305428000  \ngdc(296805) dump yuv 1920x1080(stride:1920), buffer size: 2073600 + 1036800 frame id: 121, timestamp: 21681292757750  \n"})}),"\n",(0,r.jsx)(n.p,{children:"The following files will be saved at runtime:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"gdc_handle_296805_chn0_1920x1080_stride_1920_frameid_121_ts_21681292757750.yuv  \ngdc_handle_296805_chn0_1920x1080_stride_1920_frameid_1_ts_21677343453900.yuv  \ngdc_handle_296805_chn0_1920x1080_stride_1920_frameid_31_ts_21678330776125.yuv  \ngdc_handle_296805_chn0_1920x1080_stride_1920_frameid_61_ts_21679318103925.yuv  \ngdc_handle_296805_chn0_1920x1080_stride_1920_frameid_91_ts_21680305428000.yuv  \n... ...  \n"})}),"\n",(0,r.jsx)(n.h2,{id:"single_pipe_vin_isp_ynr_pym_gdc_vpu",children:"single_pipe_vin_isp_ynr_pym_gdc_vpu"}),"\n",(0,r.jsx)(n.h3,{id:"function-overview-3",children:"Function Overview"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc_vpu"})," sample demonstrates a basic pipeline chaining the ",(0,r.jsx)(n.code,{children:"VIN"}),", ",(0,r.jsx)(n.code,{children:"ISP"}),", ",(0,r.jsx)(n.code,{children:"YNR"}),", ",(0,r.jsx)(n.code,{children:"PYM"}),", ",(0,r.jsx)(n.code,{children:"GDC"}),", and ",(0,r.jsx)(n.code,{children:"CODEC"})," modules. The camera sensor image flows through VIN, ISP, YNR, and PYM modules, then reaches the GDC module. GDC applies geometric distortion correction using a GDC bin file to produce YUV images, which are then passed to the encoder and saved as an H.264 video bitstream."]}),"\n",(0,r.jsx)(n.h3,{id:"code-location-and-directory-structure-2",children:"Code Location and Directory Structure"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Code location: ",(0,r.jsx)(n.code,{children:"/app/multimedia_samples/sample_pipeline/single_pipe_vin_isp_ynr_pym_gdc_vpu"})]}),"\n",(0,r.jsx)(n.li,{children:"Directory structure:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc_vpu  \n\u251c\u2500\u2500 Makefile  \n\u2514\u2500\u2500 single_pipe_vin_isp_ynr_pym_gdc_vpu.c  \n"})}),"\n",(0,r.jsx)(n.h3,{id:"compilation-2",children:"Compilation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Enter the ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc_vpu"})," directory and run ",(0,r.jsx)(n.code,{children:"make"})," to compile."]}),"\n",(0,r.jsxs)(n.li,{children:["The output binary will be ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc_vpu"})," in the source directory."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"execution-2",children:"Execution"}),"\n",(0,r.jsx)(n.h4,{id:"how-to-run-the-program-2",children:"How to Run the Program"}),"\n",(0,r.jsxs)(n.p,{children:["Running the program directly (",(0,r.jsx)(n.code,{children:"./single_pipe_vin_isp_ynr_pym_gdc_vpu"}),") displays help information:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"# ./single_pipe_vin_isp_ynr_pym_gdc_vpu  \nNo sensors specified.  \n```Usage: single_pipe_vin_isp_pym_vpu [OPTIONS]  \nOptions:  \n  -s <sensor_index>      Specify sensor index  \n  -l <link_port>         Specify the port for connecting serdes sensors, 0:A 1:B 2:C 3:D  \n  -f <gdc_bin_file>      Specify sensor gdc_bin_file path  \n  -h                     Show this help message  \nindex: 0  sensor_name: imx219-30fps             config_file:linear_1920x1080_raw10_30fps_1lane.c  \nindex: 1  sensor_name: sc1336_gmsl-30fps        config_file:linear_1280x720_raw10_30fps_2lane.c  \nindex: 2  sensor_name: ar0820std-30fps          config_file:linear_3840x2160_30fps_1lane.c  \nindex: 3  sensor_name: ar0820std-1080p30        config_file:linear_1920x1080_yuv_30fps_1lane.c  \nindex: 4  sensor_name: ovx3cstd-30fps           config_file:linear_1920x1280_yuv_30fps_1lane.c  \n\n"})}),"\n",(0,r.jsx)(n.h4,{id:"program-parameter-options-description",children:"Program Parameter Options Description"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-s"}),": Specify the Camera Sensor model and configuration."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-l"}),": Specify the Link Port for Serdes-type sensors. For example, if connected to Port A, specify as 0: ",(0,r.jsx)(n.code,{children:"-l 0"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{title:"Note",type:"caution",children:(0,r.jsx)(n.p,{children:"The value for the link setting depends on the port to which the Serdes sensor is connected on the deserializer. Please ensure the Serdes sensor is connected to the specified port."})}),"\n",(0,r.jsx)(n.h4,{id:"execution-results",children:"Execution Results"}),"\n",(0,r.jsxs)(n.p,{children:["The output of ",(0,r.jsx)(n.code,{children:"single_pipe_vin_isp_ynr_pym_gdc_vpu"})," is as follows:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Saves one NV12 image from each GDC output channel to the current working directory every 30 frames."}),"\n",(0,r.jsx)(n.li,{children:"Sends the GDC channel output images to the encoder for encoding and saves the encoded data to files."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Example: Using imx219 as the sensor input, execute:",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.code,{children:"./single_pipe_vin_isp_ynr_pym_gdc_vpu -s 0 -f ../../vp_sensors/gdc_bin/imx219_gdc.bin"})]}),"\n",(0,r.jsx)(n.p,{children:"Sample log output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# ./single_pipe_vin_isp_ynr_pym_gdc_vpu -s 0 -f ../../vp_sensors/gdc_bin/imx219_gdc.bin  \nUsing index:0  sensor_name:imx219-30fps  config_file:linear_1920x1080_raw10_30fps_1lane.c  \nmipi mclk is not configed.  \nSearching camera sensor on device: /proc/device-tree/soc/vcon@0 i2c bus: 1 mipi rx phy: 0  \nmipi rx used phy: 00000000  \nmipi mclk is not configed.  \nSearching camera sensor on device: /proc/device-tree/soc/vcon@1 i2c bus: 2 mipi rx phy: 1  \nmipi rx used phy: 00000000  \nINFO: Found sensor_name:imx219-30fps on mipi rx csi 1, i2c addr 0x10, config_file:linear_1920x1080_raw10_30fps_1lane.c  \n        [0] use [isp + ynr].  \n                vin [hw:1]  \n                isp [hw:1] [slot_id:0] [mode:1]  \n                ynr [hw:1] [slot_id:0] [mode:1]  \n                pym [hw:1] [slot_id:0] [mode:1]  \n                vin ->online-> isp ->online-> ynr ->online-> pym  \n\nINFO: ISP channel info:  \n        input info: [mipi_rx: 1] [is_online: 1]  \n        isp channel info: [hw_id: 1] [slot_id: 0] [mode:1]  \n\npym config:  \n        ichn input width = 1920, height = 1080  \n        ochn[0] ratio= 1, width = 1920, height = 1080 wstride=1920 vstride=1080 out[1920*1080]  \n        ochn[1] ratio= 2, width = 960, height = 540 wstride=960 vstride=540 out[960*540]  \n        ochn[2] ratio= 4, width = 480, height = 270 wstride=480 vstride=270 out[480*270]  \n        ochn[3] ratio= 8, width = 240, height = 134 wstride=240 vstride=134 out[240*134]  \n        ochn[4] ratio= 16, width = 120, height = 66 wstride=128 vstride=66 out[120*66]  \n        ochn[5] ratio= 32, width = 60, height = 32 wstride=64 vstride=32 out[60*32]  \n\nEncode idx: 0, init successful  \ngdc(296805) dump yuv 1920x1080(stride:1920), buffer size: 2073600 + 1036800 frame id: 1, timestamp: 21970340530375  \ngdc(296805) dump yuv 1920x1080(stride:1920), buffer size: 2073600 + 1036800 frame id: 31, timestamp: 21971327856500  \ngdc(296805) dump yuv 1920x1080(stride:1920), buffer size: 2073600 + 1036800 frame id: 61, timestamp: 21972315184900  \ngdc(296805) dump yuv 1920x1080(stride:1920), buffer size: 2073600 + 1036800 frame id: 91, timestamp: 21973302504675  \n"})}),"\n",(0,r.jsx)(n.p,{children:"The following files will be saved during execution:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"single_pipe_vin_isp_ynr_pym_gdc_vpu.h264  \ngdc_handle_296805_chn0_1920x1080_stride_1920_frameid_1_ts_21970340530375.yuv  \ngdc_handle_296805_chn0_1920x1080_stride_1920_frameid_31_ts_21971327856500.yuv  \ngdc_handle_296805_chn0_1920x1080_stride_1920_frameid_61_ts_21972315184900.yuv  \ngdc_handle_296805_chn0_1920x1080_stride_1920_frameid_91_ts_21973302504675.yuv  \n... ...  \n"})}),"\n",(0,r.jsx)(n.h2,{id:"multi_pipe_vin_isp_ynr_pym_gdc_vpu",children:"multi_pipe_vin_isp_ynr_pym_gdc_vpu"}),"\n",(0,r.jsx)(n.h3,{id:"function-overview-4",children:"Function Overview"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"multi_pipe_vin_isp_ynr_pym_gdc_vpu"})," supports simultaneous input from multiple sensors and processes video streams through multiple processing modules such as VIN, ISP, PYM, GDC, and CODEC."]}),"\n",(0,r.jsx)(n.p,{children:"Notes:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["The ",(0,r.jsx)(n.code,{children:"GDC"})," module requires a bin file as input. This sample program searches for bin files in the directory ",(0,r.jsx)(n.code,{children:"/app/multimedia_samples/vp_sensors/gdc_bin"}),". The ",(0,r.jsx)(n.code,{children:"GDC"})," module runs only if a suitable bin file is found."]}),"\n",(0,r.jsxs)(n.li,{children:["The ",(0,r.jsx)(n.code,{children:"CODEC"})," module requires a minimum input resolution of 256 (width) \xd7 128 (height). If the output resolution of the selected PYM channel is smaller than this minimum, the program will exit immediately."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"code-location-and-directory-structure-3",children:"Code Location and Directory Structure"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Code location: ",(0,r.jsx)(n.code,{children:"/app/multimedia_samples/sample_pipeline/multi_pipe_vin_isp_ynr_pym_gdc_vpu"})]}),"\n",(0,r.jsx)(n.li,{children:"Directory structure:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"multi_pipe_vin_isp_ynr_pym_gdc_vpu  \n\u251c\u2500\u2500 Makefile  \n\u2514\u2500\u2500 multi_pipe_vin_isp_ynr_pym_gdc_vpu.c  \n"})}),"\n",(0,r.jsx)(n.h3,{id:"compilation-3",children:"Compilation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Enter the ",(0,r.jsx)(n.code,{children:"multi_pipe_vin_isp_ynr_pym_gdc_vpu"})," directory and run ",(0,r.jsx)(n.code,{children:"make"})," to compile."]}),"\n",(0,r.jsxs)(n.li,{children:["The output binary is ",(0,r.jsx)(n.code,{children:"multi_pipe_vin_isp_ynr_pym_gdc_vpu"}),", located in the source directory."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"execution-3",children:"Execution"}),"\n",(0,r.jsx)(n.h4,{id:"how-to-run-the-program-3",children:"How to Run the Program"}),"\n",(0,r.jsxs)(n.p,{children:["Execute ",(0,r.jsx)(n.code,{children:"./multi_pipe_vin_isp_ynr_pym_gdc_vpu"})," directly to display help information:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"# ./multi_pipe_vin_isp_ynr_pym_gdc_vpu  \nUsage: multi_pipe_vin_isp_ynr_pym_gdc_vpu [Options]  \nOptions:  \n-c, --config=\"sensor=id link=port channel=pym_chn type=TYPE output=FILE, 'channel' and 'type' and 'output' is not mandatory\"  \n                Configure parameters for each video pipeline, can be repeated up to 6 times  \n                sensor   --  Sensor index, can have multiple parameters, reference sensor list.  \n                link     --  Specify the port for connecting serdes sensors, 0:A 1:B 2:C 3:D, can be set to [0-3].  \n                channel  --  Pym channel index bind to encode, default 0, can be set to [0-5].  \n                type     --  Encode type, default is h264, can be set to [h264, h265].  \n                output   --  Save codec stream data to file, default is 'pipeline[xx]_[width]x[height]_[xxx]fps.[type]'.  \n-v, --verbose   Enable verbose mode  \n-h, --help      Show help message  \nSupport sensor list:  \nindex: 0  sensor_name: imx219-30fps             config_file:linear_1920x1080_raw10_30fps_1lane.c  \nindex: 1  sensor_name: sc1336_gmsl-30fps        config_file:linear_1280x720_raw10_30fps_2lane.c  \nindex: 2  sensor_name: ar0820std-30fps          config_file:linear_3840x2160_30fps_1lane.c  \nindex: 3  sensor_name: ar0820std-1080p30        config_file:linear_1920x1080_yuv_30fps_1lane.c  \n"})}),"\n",(0,r.jsx)(n.h4,{id:"program-parameter-options-description-1",children:"Program Parameter Options Description"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:'-c, --config="sensor=id channel=vse_chn type=TYPE output=FILE"'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Configures parameters for each video pipeline. This option can be repeated multiple times (up to 6)."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sensor"})," is mandatory; ",(0,r.jsx)(n.code,{children:"channel"}),", ",(0,r.jsx)(n.code,{children:"type"}),", and ",(0,r.jsx)(n.code,{children:"output"})," are optional. If not specified, the program uses default values."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sensor"}),": Sensor index (mandatory). Multiple parameters are allowed; refer to the sensor list."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"link"}),": Link Port for Serdes-type sensors (ignored for MIPI-type sensors). For example, if connected to Port A, specify as 0: ",(0,r.jsx)(n.code,{children:"-l 0"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"channel"}),": VSE channel index (optional, default: 0, range: [0\u20135])."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"type"}),": Encoding type (optional, default: h264, options: [h264, h265])."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"output"}),": Filename for saving encoded stream data (optional, default: ",(0,r.jsx)(n.code,{children:"pipeline[xx]_[width]x[height]_[xxx]fps.[type]"}),")."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"-v, --verbose"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Enables verbose mode."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"-h, --help"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Displays help information."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Notes:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Serdes-type sensors must specify a Link Port."}),"\n",(0,r.jsxs)(n.li,{children:["To adjust the number of video pipelines, simply add or remove ",(0,r.jsx)(n.code,{children:"-c"})," parameter sets."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"execution-results-1",children:"Execution Results"}),"\n",(0,r.jsxs)(n.p,{children:["The output of ",(0,r.jsx)(n.code,{children:"multi_pipe_vin_isp_ynr_pym_gdc_vpu"}),": Each video processing pipeline encodes the processed video stream into H.264/H.265 format and saves it to a file."]}),"\n",(0,r.jsx)(n.p,{children:"Example:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Use imx219 (MIPI-type) and sc1336 (Serdes-type) as sensor inputs."}),"\n",(0,r.jsxs)(n.li,{children:["Execute the command:",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.code,{children:'./multi_pipe_vin_isp_ynr_pym_gdc_vpu -c "sensor=0" -c "sensor=1 link=0"'})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Sample log output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:'#./multi_pipe_vin_isp_ynr_pym_gdc_vpu -c "sensor=0"  -c"sensor=1 link=0"  \nUsing index:0  sensor_name:imx219-30fps  config_file:linear_1920x1080_raw10_30fps_1lane.c  \nsensor_type:0  \nmipi mclk is not configed.  \nSearching camera sensor on device: /proc/device-tree/soc/vcon@0 i2c bus: 1 mipi rx phy: 0  \nmipi rx used phy: 00000000  \nmipi mclk is not configed.  \nSearching camera sensor on device: /proc/device-tree/soc/vcon@1 i2c bus: 2 mipi rx phy: 1  \nmipi rx used phy: 00000000  \nINFO: Found sensor_name:imx219-30fps on mipi rx csi 1, i2c addr 0x10, config_file:linear_1920x1080_raw10_30fps_1lane.c  \nMIPI host: 0x2  \n  Host 1: Used  \nUsing index:1  sensor_name:sc1336_gmsl-30fps  config_file:linear_1280x720_raw10_30fps_2lane.c  \nsensor_type:1  \nMIPI host: 0x2  \n  Host 1: Used  \nPipeline index 0:  \n        Sensor index: 0  \n        Sensor name: imx219-30fps  \n        Active mipi host: 1  \n        PYM Channel: 0  \n        Encode type: h264  \nPipeline index 1:  \n        Sensor index: 0  \n        Sensor name: sc1336_gmsl-30fps  \n        Active mipi host: 4  \n        PYM Channel: 0  \n        Encode type: h264  \nVerbose: 0  \n\nPipeline Connect Param:  \n        [0] use [isp + ynr].  \n                isp [hw:1] [slot_id:4] [mode:1]  \n                ynr [hw:1] [slot_id:4] [mode:1]  \n                pym [hw:1] [slot_id:4] [mode:1]  \n        [1] use [isp + ynr].  \n                isp [hw:1] [slot_id:5] [mode:1]  \n                ynr [hw:1] [slot_id:5] [mode:1]  \n                pym [hw:1] [slot_id:5] [mode:1]  \n\nINFO: ISP channel info:  \n        input info: [mipi_rx: 1] [is_online: 1]\n        isp channel info: [hw_id: 1] [slot_id: 4] [mode:1]\n\npym config:\n        ichn input width = 1920, height = 1080\n        ochn[0] ratio= 1, width = 1920, height = 1080 wstride=1920 vstride=1080 out[1920*1080]\n        ochn[1] ratio= 2, width = 960, height = 540 wstride=960 vstride=536 out[960*536]\n        ochn[2] ratio= 4, width = 480, height = 270 wstride=480 vstride=264 out[480*264]\n        ochn[3] ratio= 8, width = 240, height = 134 wstride=240 vstride=128 out[240*128]\n        ochn[4] ratio= 16, width = 120, height = 66 wstride=128 vstride=64 out[120*64]\n        ochn[5] ratio= 32, width = 60, height = 32 wstride=64 vstride=32 out[56*32]\n\n        [0] use [gdc].\n[0] encoder input resolution is 1920*1080, output file is pipeline0_1920x1080_30fps.h264.\nCreate Encode idx: 0, init successful\nvc_index:0\n\nINFO: ISP channel info:\n        input info: [mipi_rx: 4] [is_online: 1]\n        isp channel info: [hw_id: 1] [slot_id: 5] [mode:1]\n\npym config:\n        ichn input width = 1280, height = 720\n        ochn[0] ratio= 1, width = 1280, height = 720 wstride=1280 vstride=720 out[1280*720]\n        ochn[1] ratio= 2, width = 640, height = 360 wstride=640 vstride=360 out[640*360]\n        ochn[2] ratio= 4, width = 320, height = 180 wstride=320 vstride=176 out[320*176]\n        ochn[3] ratio= 8, width = 160, height = 90 wstride=160 vstride=88 out[160*88]\n        ochn[4] ratio= 16, width = 80, height = 44 wstride=80 vstride=40 out[80*40]\n[Warning] ochn[5] ratio= 32, height = 22 < PYM_MIN_HEIGHT(32), so not enable.\n\n        [1] not use [gdc].\n[1] encoder input resolution is 1280*720, output file is pipeline1_1280x720_30fps.h264.\nCreate Encode idx: 1, init successful\nAll deserial link info:\n        [link_port:0] sc1336_gmsl:0@256\n        [link_port:1] sc1336_gmsl:0@256\n        [link_port:2] sc1336_gmsl:0@256\n        [link_port:3] sc1336_gmsl:0@256\n'})}),"\n",(0,r.jsx)(n.p,{children:"The following files will be saved during execution:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"pipeline0_1920x1080_30fps.h264\npipeline1_1280x720_30fps.h264\n"})}),"\n",(0,r.jsx)(n.h2,{id:"uvc_capture_sample",children:"uvc_capture_sample"}),"\n",(0,r.jsx)(n.h3,{id:"function-overview-5",children:"Function Overview"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"uvc_capture_sample"})," is a program for testing the UVC camera video capture pipeline. It captures images from a UVC camera and saves the output images, and supports displaying ISP-related information."]}),"\n",(0,r.jsx)(n.h3,{id:"code-location-and-directory-structure-4",children:"Code Location and Directory Structure"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Code location: ",(0,r.jsx)(n.code,{children:"/app/multimedia_samples/sample_pipeline/uvc_capture_sample"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Directory structure"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"uvc_capture_sample\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 common_utils.c\n\u251c\u2500\u2500 common_utils.h\n\u251c\u2500\u2500 uvc_capture_sample.c\n\u251c\u2500\u2500 uvc_capture_sample.h\n\u251c\u2500\u2500 v4l2_common_utils.c\n\u2514\u2500\u2500 v4l2_common_utils.h\n"})}),"\n",(0,r.jsx)(n.h3,{id:"compilation-4",children:"Compilation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Enter the ",(0,r.jsx)(n.code,{children:"uvc_capture_sample"})," directory and run ",(0,r.jsx)(n.code,{children:"make"})," to compile."]}),"\n",(0,r.jsxs)(n.li,{children:["The output binary is ",(0,r.jsx)(n.code,{children:"uvc_capture_sample"}),", located in the source directory."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"execution-4",children:"Execution"}),"\n",(0,r.jsx)(n.h4,{id:"how-to-run-the-program-4",children:"How to Run the Program"}),"\n",(0,r.jsxs)(n.p,{children:["Run the program directly with ",(0,r.jsx)(n.code,{children:"./uvc_capture_sample -h"})," to display help information."]}),"\n",(0,r.jsx)(n.h4,{id:"program-option-descriptions-2",children:"Program Option Descriptions"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Options:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-i, --video_id <id>"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Specifies the video device node, e.g., video0, video1."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-d, --dump_file"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Whether to save image files. Enabling this option saves captured images to files."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-F, --format"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Sets the image format; choose a format supported by the UVC camera, such as YUYV or NV12."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-l, --loop_cnt <num>"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Sets the number of capture loops (i.e., how many frames to capture)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-H, --height <px>"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Sets the image height (in pixels)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-W, --width <px>"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Sets the image width (in pixels)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-E, --show_isp_info"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Displays ISP exposure and white balance information."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-h, --help"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Displays help information."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Examples:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Configure a UVC camera video pipeline using video0, specify YUYV format, and save 5 captured frames."}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"./uvc_capture_sample -i 0  -l 5 -W 1920 -H 1080 -F YUYV  -d\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Configure a UVC camera video pipeline using video0, specify YUYV format, save 5 captured frames, and print current exposure and white balance information."}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"./uvc_capture_sample -i 0  -l 5 -W 1920 -H 1080 -F YUYV  -d -E\n"})}),"\n",(0,r.jsx)(n.h4,{id:"execution-output",children:"Execution Output"}),"\n",(0,r.jsx)(n.p,{children:"Run the following command:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"./uvc_capture_sample -i 0  -l 5 -W 1920 -H 1080 -F YUYV  -d\n"})}),"\n",(0,r.jsx)(n.p,{children:"Example log output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"ptc[0].video_id = 0\nptc[0].loop_cnt = 5\nptc[0].pic_width = 1920\nptc[0].pic_height = 1080\nptc[0].pic_format = 6\nptc[0].dump_mask = 1\nDEBUG: index = 0, max_num = 24\npipe_num:0\nTestContext[0] create pthread success\nloop_cnt: 5\nopen device: /dev/video0 (fd=3)\n     driver: uvcvideo\n       card: FHD Camera Microphone: FHD Came\n    version: 6.1.83\n   all caps: 84a00001\ndevice caps: 04200001\n 0: Motion-JPEG 0x47504a4d 0x1\n...\nfiledump(./yuv_dump/isp_5_s0_c0_b1_f0_005838.yuv, size(4147200) is successed\nloop cnt use up\npipe(0)Test thread 281473524101408---join done.\n------ Test case uvc_capture_sample done  ------\n"})})]})}function a(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}}}]);