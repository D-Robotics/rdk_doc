"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[31097],{28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>l});var t=i(96540);const s={},r=t.createContext(s);function o(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:n},e.children)}},36319:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>m,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"Algorithm_Application/Python_Sample/Summary","title":"Example Overview","description":"This project contains multiple AI example programs written in Python, designed for the RDK S100 platform, covering common AI tasks such as image classification, object detection, instance segmentation, pose estimation, OCR, and speech recognition. The examples perform inference using quantized models in .hbm format, enabling developers to quickly validate model performance and accelerate application development.","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/02_Python_Sample/01_Summary.md","sourceDirName":"04_Algorithm_Application/02_Python_Sample","slug":"/Algorithm_Application/Python_Sample/Summary","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/Summary","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1765441999000,"sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"4.2\u53c2\u8003\u793a\u4f8b\uff08Python\uff09","permalink":"/rdk_doc/en/rdk_s/03_Python_Sample"},"next":{"title":"Image Classification - ResNet18","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/ResNet18"}}');var s=i(74848),r=i(28453);const o={sidebar_position:1},l="Example Overview",a={},c=[{value:"Overview",id:"overview",level:2},{value:"Environment Requirements",id:"environment-requirements",level:3},{value:"Python Environment",id:"python-environment",level:4},{value:"Dependencies",id:"dependencies",level:4},{value:"Other Components",id:"other-components",level:4},{value:"Directory Structure",id:"directory-structure",level:3},{value:"Quick Start",id:"quick-start",level:3},{value:"Common Utilities",id:"common-utilities",level:3},{value:"Notes",id:"notes",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"example-overview",children:"Example Overview"})}),"\n",(0,s.jsxs)(n.p,{children:["This project contains multiple AI example programs written in Python, designed for the RDK S100 platform, covering common AI tasks such as image classification, object detection, instance segmentation, pose estimation, OCR, and speech recognition. The examples perform inference using quantized models in ",(0,s.jsx)(n.code,{children:".hbm"})," format, enabling developers to quickly validate model performance and accelerate application development."]}),"\n",(0,s.jsxs)(n.p,{children:["The on-device code for this project is located at: ",(0,s.jsx)(n.code,{children:"/app/pydev_demo/"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.h3,{id:"environment-requirements",children:"Environment Requirements"}),"\n",(0,s.jsx)(n.p,{children:"This project is written in Python and relies on several third-party libraries. Please ensure your environment meets the following requirements:"}),"\n",(0,s.jsx)(n.h4,{id:"python-environment",children:"Python Environment"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Python version: Python 3.10.x is recommended (currently tested and verified on Python 3.10.12)"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"dependencies",children:"Dependencies"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Dependency list"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Library Name"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Recommended Version"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"numpy"}),(0,s.jsx)(n.td,{children:"Scientific computing library for tensor and matrix operations"}),(0,s.jsx)(n.td,{children:">=1.26.4"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"opencv-python"}),(0,s.jsx)(n.td,{children:"Image processing and visualization (cv2)"}),(0,s.jsx)(n.td,{children:">=4.11.0.86"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"scipy"}),(0,s.jsx)(n.td,{children:"Mathematical functions library (e.g., softmax)"}),(0,s.jsx)(n.td,{children:">=1.15.3"})]})]})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Installing dependencies"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Install dependencies\npip install -r requirements.txt\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Note:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"The above dependency list and installation file only include the basic libraries required to run the models. Some example programs require additional third-party libraries. Please refer to the corresponding example's README.md or the relevant section of this document for details."})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"other-components",children:"Other Components"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["hbm_runtime: Used to load and run ",(0,s.jsx)(n.code,{children:".hbm"})," models. This is pre-installed by default on the system. For manual installation instructions, refer to section ",(0,s.jsx)(n.a,{href:"/rdk_doc/en/rdk_s/Algorithm_Application/python-api#4.1-python-interface",children:"4.1 Python Interface"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Hobot VIO: Used to access camera image streams (e.g., hobot_vio, such as libsrcampy)."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:".\n\u251c\u2500\u2500 01_classification_sample/        # Image classification example\n\u251c\u2500\u2500 02_detection_sample/             # Object detection example\n\u251c\u2500\u2500 03_instance_segmentation_sample/ # Instance segmentation example\n\u251c\u2500\u2500 04_pose_sample/                  # Pose estimation example\n\u251c\u2500\u2500 05_open_instance_seg_sample/     # Open-vocabulary instance segmentation example\n\u251c\u2500\u2500 06_lane_detection_sample/        # Lane detection example\n\u251c\u2500\u2500 07_speech_sample/                # Speech recognition example\n\u251c\u2500\u2500 08_OCR_sample/                   # OCR text recognition example\n\u251c\u2500\u2500 09_usb_camera_sample/            # USB camera + object detection example\n\u251c\u2500\u2500 10_mipi_camera_sample/           # MIPI camera + object detection example\n\u251c\u2500\u2500 11_web_display_camera_sample/    # Camera + Web + object detection example\n\u251c\u2500\u2500 utils/                           # Common preprocessing and postprocessing utility modules\n\u251c\u2500\u2500 requirements.txt                 # Python environment dependencies\n\u2514\u2500\u2500 README.md                        # Top-level usage documentation (this file)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"quick-start",children:"Quick Start"}),"\n",(0,s.jsx)(n.p,{children:"Taking the ResNet18 image classification example as an illustration:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Enter the sample directory","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cd 01_classification_sample/01_resnet18\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Run the model","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 resnet18.py \\\n--model-path /opt/hobot/model/s100/basic/resnet18_224x224_nv12.hbm \\\n--test-img /app/res/assets/zebra_cls.jpg\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["View results","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"Top-5 Predictions:\nzebra: 0.9979\nimpala, Aepyceros melampus: 0.0005\ncheetah, chetah, Acinonyx jubatus: 0.0005\ngazelle: 0.0004\nprairie chicken, prairie grouse, prairie fowl: 0.0002\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"common-utilities",children:"Common Utilities"}),"\n",(0,s.jsxs)(n.p,{children:["The project uses a unified set of utility modules to simplify example development, located under ",(0,s.jsx)(n.code,{children:"utils/"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"preprocess_utils.py: Image preprocessing functions, such as resize and color format conversion."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"postprocess_utils.py: Model postprocessing logic, such as NMS and bounding box transformations."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"draw_utils.py: Functions for drawing detection boxes, keypoints, segmentation masks, etc."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"common_utils.py: Utilities for printing model information, defining colors, etc."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"notes",children:"Notes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["All example programs use models in ",(0,s.jsx)(n.code,{children:".hbm"})," format and must be used with the platform's ",(0,s.jsx)(n.code,{children:"hbm_runtime"})," Python inference interface."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Note: Each subdirectory includes a ",(0,s.jsx)(n.code,{children:"README.md"})," file that provides detailed instructions regarding required environment setup, command-line arguments, and execution methods for the corresponding model."]}),"\n"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);