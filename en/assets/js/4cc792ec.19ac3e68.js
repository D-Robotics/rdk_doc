"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[45943],{11470:(e,n,s)=>{s.d(n,{A:()=>y});var o=s(96540),r=s(34164),t=s(23104),a=s(56347),i=s(205),l=s(57485),c=s(31682),d=s(70679);function h(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function u(e){const{values:n,children:s}=e;return(0,o.useMemo)(()=>{const e=n??function(e){return h(e).map(({props:{value:e,label:n,attributes:s,default:o}})=>({value:e,label:n,attributes:s,default:o}))}(s);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,s])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function p({queryString:e=!1,groupId:n}){const s=(0,a.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(r),(0,o.useCallback)(e=>{if(!r)return;const n=new URLSearchParams(s.location.search);n.set(r,e),s.replace({...s.location,search:n.toString()})},[r,s])]}function b(e){const{defaultValue:n,queryString:s=!1,groupId:r}=e,t=u(e),[a,l]=(0,o.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const s=n.find(e=>e.default)??n[0];if(!s)throw new Error("Unexpected error: 0 tabValues");return s.value}({defaultValue:n,tabValues:t})),[c,h]=p({queryString:s,groupId:r}),[b,x]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[s,r]=(0,d.Dv)(n);return[s,(0,o.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:r}),g=(()=>{const e=c??b;return m({value:e,tabValues:t})?e:null})();(0,i.A)(()=>{g&&l(g)},[g]);return{selectedValue:a,selectValue:(0,o.useCallback)(e=>{if(!m({value:e,tabValues:t}))throw new Error(`Can't select invalid tab value=${e}`);l(e),h(e),x(e)},[h,x,t]),tabValues:t}}var x=s(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var _=s(74848);function j({className:e,block:n,selectedValue:s,selectValue:o,tabValues:a}){const i=[],{blockElementScrollPositionUntilNextRender:l}=(0,t.a_)(),c=e=>{const n=e.currentTarget,r=i.indexOf(n),t=a[r].value;t!==s&&(l(n),o(t))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const s=i.indexOf(e.currentTarget)+1;n=i[s]??i[0];break}case"ArrowLeft":{const s=i.indexOf(e.currentTarget)-1;n=i[s]??i[i.length-1];break}}n?.focus()};return(0,_.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},e),children:a.map(({value:e,label:n,attributes:o})=>(0,_.jsx)("li",{role:"tab",tabIndex:s===e?0:-1,"aria-selected":s===e,ref:e=>{i.push(e)},onKeyDown:d,onClick:c,...o,className:(0,r.A)("tabs__item",g.tabItem,o?.className,{"tabs__item--active":s===e}),children:n??e},e))})}function f({lazy:e,children:n,selectedValue:s}){const t=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=t.find(e=>e.props.value===s);return e?(0,o.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,_.jsx)("div",{className:"margin-top--md",children:t.map((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==s}))})}function v(e){const n=b(e);return(0,_.jsxs)("div",{className:(0,r.A)("tabs-container",g.tabList),children:[(0,_.jsx)(j,{...n,...e}),(0,_.jsx)(f,{...n,...e})]})}function y(e){const n=(0,x.A)();return(0,_.jsx)(v,{...e,children:h(e.children)},String(n))}},14088:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>m,frontMatter:()=>l,metadata:()=>o,toc:()=>h});const o=JSON.parse('{"id":"Robot_development/quick_demo/demo_sensor","title":"5.2.1 Image Capture","description":"USB camera","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/05_Robot_development/02_quick_demo/demo_sensor.md","sourceDirName":"05_Robot_development/02_quick_demo","slug":"/Robot_development/quick_demo/demo_sensor","permalink":"/rdk_doc/en/Robot_development/quick_demo/demo_sensor","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1750509720000,"sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"5.1.6 Version Release Notes","permalink":"/rdk_doc/en/Robot_development/quick_start/changelog"},"next":{"title":"5.2.2 Display","permalink":"/rdk_doc/en/Robot_development/quick_demo/demo_render"}}');var r=s(74848),t=s(28453),a=s(11470),i=s(19365);const l={sidebar_position:1},c="5.2.1 Image Capture",d={},h=[{value:"USB camera",id:"usb-camera",level:2},{value:"Introduction",id:"introduction",level:3},{value:"Supported Platforms",id:"supported-platforms",level:3},{value:"Preparation",id:"preparation",level:3},{value:"RDK",id:"rdk",level:4},{value:"How to Use (default usb_pixel_format is mjpeg)",id:"how-to-use-default-usb_pixel_format-is-mjpeg",level:3},{value:"Usage Method 2 (usb_pixel_format is yuyv2rgb)",id:"usage-method-2-usb_pixel_format-is-yuyv2rgb",level:3},{value:"Notes",id:"notes",level:3},{value:"MIPI camera",id:"mipi-camera",level:2},{value:"Introduction",id:"introduction-1",level:3},{value:"Supported Platforms",id:"supported-platforms-1",level:3},{value:"Preparation",id:"preparation-1",level:3},{value:"RDK",id:"rdk-1",level:4},{value:"Usage",id:"usage",level:3},{value:"RDK Platform",id:"rdk-platform",level:4},{value:"Caution",id:"caution",level:3},{value:"RealSense Image Capture",id:"realsense-image-capture",level:2},{value:"Feature Overview",id:"feature-overview",level:3},{value:"Supported Platforms",id:"supported-platforms-2",level:3},{value:"Preparation",id:"preparation-2",level:3},{value:"RDK Platform",id:"rdk-platform-1",level:4},{value:"Usage Instructions",id:"usage-instructions",level:3},{value:"1. Log in to the RDK via Serial Port or SSH and Verify the ROS Version",id:"1-log-in-to-the-rdk-via-serial-port-or-ssh-and-verify-the-ros-version",level:4},{value:"2. Install RealSense SDK 2.0 and RealSense ROS2 Wrapper",id:"2-install-realsense-sdk-20-and-realsense-ros2-wrapper",level:4},{value:"3. Start the RealSense Camera",id:"3-start-the-realsense-camera",level:4},{value:"4. Depth and RGB Alignment",id:"4-depth-and-rgb-alignment",level:4},{value:"5. Displaying Images and Point Clouds",id:"5-displaying-images-and-point-clouds",level:4},{value:"Dual MIPI camera",id:"dual-mipi-camera",level:2},{value:"Introduction",id:"introduction-2",level:3},{value:"Supported Platforms",id:"supported-platforms-3",level:3},{value:"Preparation",id:"preparation-3",level:3},{value:"RDK",id:"rdk-2",level:4},{value:"Usage",id:"usage-1",level:3},{value:"RDK Platform",id:"rdk-platform-2",level:4},{value:"Caution",id:"caution-1",level:3},{value:"RGBD camera",id:"rgbd-camera",level:2},{value:"Introduction",id:"introduction-3",level:3},{value:"Supported Platforms",id:"supported-platforms-4",level:3},{value:"Preparations",id:"preparations",level:3},{value:"RDK Platform",id:"rdk-platform-3",level:4},{value:"Usage",id:"usage-2",level:3},{value:"RDK",id:"rdk-3",level:4},{value:"Instructions",id:"instructions",level:3},{value:"Orbbec camera",id:"orbbec-camera",level:2},{value:"Introduction",id:"introduction-4",level:3},{value:"Supported Platforms",id:"supported-platforms-5",level:3},{value:"Preparations",id:"preparations-1",level:3},{value:"RDK Platform",id:"rdk-platform-4",level:4},{value:"Usage",id:"usage-3",level:3},{value:"1. Log in to the RDK via serial port or SSH and confirm the ROS version.",id:"1-log-in-to-the-rdk-via-serial-port-or-ssh-and-confirm-the-ros-version",level:4},{value:"2. Download the Orbbec ROS2 wrapper source code for compilation.",id:"2-download-the-orbbec-ros2-wrapper-source-code-for-compilation",level:4},{value:"3. Start the Orbbec camera.",id:"3-start-the-orbbec-camera",level:4},{value:"4. Depth and RGB Alignment",id:"4-depth-and-rgb-alignment-1",level:4},{value:"5. Displaying Images and Point Clouds",id:"5-displaying-images-and-point-clouds-1",level:4},{value:"ZED camera",id:"zed-camera",level:2},{value:"Introduction",id:"introduction-5",level:3},{value:"Supported Platforms",id:"supported-platforms-6",level:3},{value:"Preparation",id:"preparation-4",level:3},{value:"RDK Platform",id:"rdk-platform-5",level:4},{value:"Usage",id:"usage-4",level:3}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"521-image-capture",children:"5.2.1 Image Capture"})}),"\n","\n",(0,r.jsx)(n.h2,{id:"usb-camera",children:"USB camera"}),"\n",(0,r.jsx)(n.h3,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:"In order to achieve environmental perception capability, robot products usually carry cameras to obtain image information. USB cameras are easy to obtain, easy to use, and have good versatility. TogetheROS.Bot supports USB cameras and supports ROS2 standard image messages."}),"\n",(0,r.jsxs)(n.p,{children:["Code repository:  (",(0,r.jsx)(n.a,{href:"https://github.com/D-Robotics/hobot_usb_cam.git",children:"https://github.com/D-Robotics/hobot_usb_cam.git"}),")"]}),"\n",(0,r.jsx)(n.h3,{id:"supported-platforms",children:"Supported Platforms"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"Operating Mode"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X3, RDK X3 Module"}),(0,r.jsx)(n.td,{children:"Ubuntu 20.04 (Foxy), Ubuntu 22.04 (Humble)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X5, RDK S100"}),(0,r.jsx)(n.td,{children:"Ubuntu 22.04 (Humble)"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"preparation",children:"Preparation"}),"\n",(0,r.jsx)(n.h4,{id:"rdk",children:"RDK"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Confirm that the USB camera is working properly and connect it to the USB slot of the RDK."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"RDK has burned the  Ubuntu 20.04/22.04 system image provided by D-Robotics."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"RDK has successfully installed tros.b."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Confirm that the PC can access the RDK via the network."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"how-to-use-default-usb_pixel_format-is-mjpeg",children:"How to Use (default usb_pixel_format is mjpeg)"}),"\n",(0,r.jsx)(n.p,{children:"Taking RDK as an example:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Log in to the RDK via SSH and confirm the device name of the USB camera. Here, let's take ",(0,r.jsx)(n.code,{children:"/dev/video8"})," as an example."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Start the USB camera using the following command:"}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Start the launch file\nros2 launch hobot_usb_cam hobot_usb_cam.launch.py usb_video_device:=/dev/video8\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"If the program outputs the following information, it means the node has been successfully launched."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"[INFO] [launch]: All log files can be found below /root/.ros/log/2024-01-18-19-44-39-419588-ubuntu-3951\n[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [hobot_usb_cam-1]: process started with pid [3953]\n[hobot_usb_cam-1] [WARN] [1705578280.808870437] [hobot_usb_cam]: framerate: 30\n[hobot_usb_cam-1] [WARN] [1705578280.809851560] [hobot_usb_cam]: pixel_format_name: mjpeg\n[hobot_usb_cam-1] [WARN] [1705578280.936383062] [hobot_usb_cam]: Camera calibration file: [/opt/tros/lib/hobot_usb_cam/config/usb_camera_calibration.yaml] does not exist!\n[hobot_usb_cam-1] If you need calibration msg, please make sure the calibration file path is correct and the calibration file exists!\n[hobot_usb_cam-1] [WARN] [1705578280.936697507] [hobot_usb_cam]: This devices supproted formats:\n[hobot_usb_cam-1] [WARN] [1705578280.936858791] [hobot_usb_cam]:        Motion-JPEG: 640 x 480 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.936912830] [hobot_usb_cam]:        Motion-JPEG: 1920 x 1080 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.936960328] [hobot_usb_cam]:        Motion-JPEG: 320 x 240 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937007285] [hobot_usb_cam]:        Motion-JPEG: 800 x 600 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937053241] [hobot_usb_cam]:        Motion-JPEG: 1280 x 720 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937098906] [hobot_usb_cam]:        Motion-JPEG: 1024 x 576 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937144528] [hobot_usb_cam]:        YUYV 4:2:2: 640 x 480 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937190068] [hobot_usb_cam]:        YUYV 4:2:2: 1920 x 1080 (5 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937235858] [hobot_usb_cam]:        YUYV 4:2:2: 320 x 240 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937282064] [hobot_usb_cam]:        YUYV 4:2:2: 800 x 600 (20 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937328020] [hobot_usb_cam]:        YUYV 4:2:2: 1280 x 720 (10 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937373518] [hobot_usb_cam]:        YUYV 4:2:2: 1024 x 576 (15 Hz)\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Open another terminal to view the USB camera image on the web page:"}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch websocket websocket.launch.py websocket_image_topic:=/image websocket_only_show_image:=true\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Open a web browser (Chrome/Firefox/Edge) on your PC and enter  ",(0,r.jsx)(n.code,{children:"http://IP:8000"})," (where IP is the RDK IP address). Click on the upper left corner to view the real-time image from the USB camera.\n",(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/usb_cam_pic.png",alt:"image-usb-camera"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"usage-method-2-usb_pixel_format-is-yuyv2rgb",children:"Usage Method 2 (usb_pixel_format is yuyv2rgb)"}),"\n",(0,r.jsx)(n.p,{children:"Here is an example using the RDK platform:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["SSH into the RDK and confirm the USB camera device name, for example ",(0,r.jsx)(n.code,{children:"/dev/video8"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Start the USB camera using the following command:"}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch hobot_usb_cam hobot_usb_cam.launch.py usb_video_device:=/dev/video8 usb_pixel_format:=yuyv2rgb usb_image_width:=640 usb_image_height:=480\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"If the following information is outputted by the program, it indicates that the node has been successfully launched"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"[INFO] [launch]: All log files can be found below /root/.ros/log/2024-01-18-19-44-39-419588-ubuntu-3951\n[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [hobot_usb_cam-1]: process started with pid [3953]\n[hobot_usb_cam-1] [WARN] [1705578280.808870437] [hobot_usb_cam]: framerate: 30\n[hobot_usb_cam-1] [WARN] [1705578280.809851560] [hobot_usb_cam]: pixel_format_name: yuyv2rgb\n[hobot_usb_cam-1] [WARN] [1705578280.936383062] [hobot_usb_cam]: Camera calibration file: [/opt/tros/lib/hobot_usb_cam/config/usb_camera_calibration.yaml] does not exist!\n[hobot_usb_cam-1] If you need calibration msg, please make sure the calibration file path is correct and the calibration file exists!\n[hobot_usb_cam-1] [WARN] [1705578280.936697507] [hobot_usb_cam]: This devices supproted formats:\n[hobot_usb_cam-1] [WARN] [1705578280.936858791] [hobot_usb_cam]:        Motion-JPEG: 640 x 480 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.936912830] [hobot_usb_cam]:        Motion-JPEG: 1920 x 1080 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.936960328] [hobot_usb_cam]:        Motion-JPEG: 320 x 240 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937007285] [hobot_usb_cam]:        Motion-JPEG: 800 x 600 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937053241] [hobot_usb_cam]:        Motion-JPEG: 1280 x 720 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.9379806] [hobot_usb_cam]:        Motion-JPEG: 1024 x 576 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937144528] [hobot_usb_cam]:        YUYV 4:2:2: 640 x 480 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937190068] [hobot_usb_cam]:        YUYV 4:2:2: 1920 x 1080 (5 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937235858] [hobot_usb_cam]:        YUYV 4:2:2: 320 x 240 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937282064] [hobot_usb_cam]:        YUYV 4:2:2: 800 x 600 (20 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937328020] [hobot_usb_cam]:        YUYV 4:2:2: 1280 x 720 (10 Hz)\n[hobot_usb_cam-1] [WARN] [1705578280.937373518] [hobot_usb_cam]:        YUYV 4:2:2: 1024 x 576 (15 Hz)\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Encode to mjpeg with hobot codec"}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Start the launch file\nros2 launch hobot_codec hobot_codec_encode.launch.py codec_in_mode:=ros codec_in_format:=rgb8 codec_out_mode:=ros codec_sub_topic:=/image codec_pub_topic:=/image_mjpeg\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"View the USB camera image on the web side, open a new terminal:"}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch websocket websocket.launch.py websocket_image_topic:=/image_mjpeg websocket_only_show_image:=true\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Open a browser on your PC (chrome/firefox/edge) and enter  ",(0,r.jsx)(n.code,{children:"http://IP:8000"})," (IP is the RDK IP address), click on the top left to display the web side to view the real-time image from the USB camera\n",(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/usb_cam_pic.png",alt:"image-usb-camera"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"notes",children:"Notes"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"USB cameras need to be calibrated and the camera calibration file path needs to be set in order to publish camera parameters. However, this does not affect other functionalities."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"To set the camera calibration file path, follow the steps below:"}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Start with launch command\nros2 launch hobot_usb_cam hobot_usb_cam.launch.py usb_camera_calibration_file_path:=\uff08actual calibration file absolute path\uff09\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Changes to the pixel_format configuration:"}),"\n",(0,r.jsx)(n.p,{children:'hobot_usb_cam supports the following configurations:\n"mjpeg", "mjpeg-compressed", "mjpeg2rgb", "rgb8", "yuyv", "yuyv2rgb", "uyvy", "uyvy2rgb", "m4202rgb", "mono8", "mono16", "y102mono8"'}),"\n",(0,r.jsx)(n.p,{children:"Start usb camera with the default parameters of the first type to query the formats supported by the device hardware, as shown in the log below:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"[hobot_usb_cam-1] [WARN] [1705548544.174669672] [hobot_usb_cam]: This devices supproted formats:\n[hobot_usb_cam-1] [WARN] [1705548544.174844917] [hobot_usb_cam]:        Motion-JPEG: 640 x 480 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.174903166] [hobot_usb_cam]:        Motion-JPEG: 1920 x 1080 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.174950581] [hobot_usb_cam]:        Motion-JPEG: 320 x 240 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.174996788] [hobot_usb_cam]:        Motion-JPEG: 800 x 600 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.175043412] [hobot_usb_cam]:        Motion-JPEG: 1280 x 720 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.175089161] [hobot_usb_cam]:        Motion-JPEG: 1024 x 576 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.175135035] [hobot_usb_cam]:        YUYV 4:2:2: 640 x 480 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.175180325] [hobot_usb_cam]:        YUYV 4:2:2: 1920 x 1080 (5 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.175226449] [hobot_usb_cam]:        YUYV 4:2:2: 320 x 240 (30 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.175272365] [hobot_usb_cam]:        YUYV 4:2:2: 800 x 600 (20 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.175318697] [hobot_usb_cam]:        YUYV 4:2:2: 1280 x 720 (10 Hz)\n[hobot_usb_cam-1] [WARN] [1705548544.175365195] [hobot_usb_cam]:        YUYV 4:2:2: 1024 x 576 (15 Hz)\n"})}),"\n",(0,r.jsx)(n.p,{children:"a. Query the image formats supported by the usb camera, as shown in the log above. The log shows support for mjpeg and YUYV."}),"\n",(0,r.jsx)(n.p,{children:'b. Only "mjpeg", "mjpeg-compressed", "mjpeg2rgb", "yuyv", and "yuyv2rgb" can be set; otherwise, the hobot_usb_cam program will exit.'}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"mipi-camera",children:"MIPI camera"}),"\n",(0,r.jsx)(n.h3,{id:"introduction-1",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:"To achieve environmental perception capabilities, robots often carry cameras, ToF, and other types of sensors. In order to reduce the cost of sensor adaptation and usage for users, TogetheROS.Bot wraps multiple commonly used sensors into the hobot_sensor module and abstracts them into ROS standard image messages. When the configured sensor parameters do not match the connected camera, the program will automatically adapt to the correct sensor type. The currently supported MIPI sensor types are as follows:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Name"}),(0,r.jsx)(n.th,{children:"Representational Image"}),(0,r.jsx)(n.th,{children:"Parameters"}),(0,r.jsx)(n.th,{children:"Reference Link"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"F37"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/F37.jpg",alt:"F37"})}),(0,r.jsx)(n.td,{children:"200W Pixel"}),(0,r.jsx)(n.td,{children:"RDK X3, RDK X3 Module"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"GC4663"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/GC4663.jpg",alt:"GC4663"})}),(0,r.jsx)(n.td,{children:"400W Pixel"}),(0,r.jsx)(n.td,{children:"RDK X3, RDK X3 Module"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"IMX219"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/IMX219.jpg",alt:"IMX219"})}),(0,r.jsx)(n.td,{children:"800W Pixel"}),(0,r.jsx)(n.td,{children:"RDK X3, RDK X3 Module, RDK Ultra, RDK X5"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"IMX477"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/IMX477.jpg",alt:"IMX477"})}),(0,r.jsx)(n.td,{children:"200W Pixel"}),(0,r.jsx)(n.td,{children:"RDK X3, RDK X3 Module"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"OV5647"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/OV5647.jpg",alt:"OV5647"})}),(0,r.jsx)(n.td,{children:"200W Pixel"}),(0,r.jsx)(n.td,{children:"RDK X3, RDK X3 Module, RDK X5"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:["Code repository:  (",(0,r.jsx)(n.a,{href:"https://github.com/D-Robotics/hobot_mipi_cam.git",children:"https://github.com/D-Robotics/hobot_mipi_cam.git"}),")"]}),"\n",(0,r.jsx)(n.h3,{id:"supported-platforms-1",children:"Supported Platforms"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"System"}),(0,r.jsx)(n.th,{children:"Function"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X3, RDK X3 Module, RDK X5"}),(0,r.jsx)(n.td,{children:"Ubuntu 20.04 (Foxy), Ubuntu 22.04 (Humble)"}),(0,r.jsx)(n.td,{children:"Start MIPI camera and display images through Web"})]})})]}),"\n",(0,r.jsx)(n.h3,{id:"preparation-1",children:"Preparation"}),"\n",(0,r.jsx)(n.h4,{id:"rdk-1",children:"RDK"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Confirm that the camera is correctly connected to RDK. For example, the connection between the F37 camera and RDK X3 is shown in the following figure:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/08_FAQ/image/hardware_and_system/image-X3-PI-Camera.png",alt:"image-X3-PI-Camera"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"RDK is flashed with the  Ubuntu 20.04/22.04 system image provided by D-Robotics"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"RDK has successfully installed tros.b"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Confirm that the PC can access RDK through the network"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"usage",children:"Usage"}),"\n",(0,r.jsx)(n.h4,{id:"rdk-platform",children:"RDK Platform"}),"\n",(0,r.jsx)(n.p,{children:"Take the F37 as an example to introduce the method of acquiring and previewing images:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["SSH into RDK and determine the camera model, take ",(0,r.jsx)(n.code,{children:"F37"})," as an example, and determine the path to read the camera calibration file, take ",(0,r.jsx)(n.code,{children:"/opt/tros/lib/mipi_cam/config/F37_calibration.yaml"})," as an example."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Start the ",(0,r.jsx)(n.code,{children:"hobot_sensor"})," node with the following command:"]}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Start the launch file\nros2 launch mipi_cam mipi_cam.launch.py mipi_video_device:=F37 mipi_camera_calibration_file_path:=/opt/tros/${TROS_DISTRO}/lib/mipi_cam/config/F37_calibration.yaml\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"If the following information is outputted, it means that the node has been successfully started:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"[INFO] [launch]: All log files can be found below /root/.ros/log/2022-06-11-15-16-13-641715-ubuntu-8852\n[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [mipi_cam-1]: process started with pid [8854]\n...\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"To view the F37 camera image on the web, as raw data needs to be encoded into JPEG images, two terminals need to be launched separately: one for subscribing to MIPI data and encoding it into JPEG, and one for publishing with a webservice."}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Start encoding\nros2 launch hobot_codec hobot_codec_encode.launch.py\n\n# Launch another terminal\n# Start websocket\nros2 launch websocket websocket.launch.py websocket_image_topic:=/image_jpeg websocket_only_show_image:=true\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Open a web browser on the PC (Chrome/Firefox/Edge) and enter  ",(0,r.jsx)(n.code,{children:"http://IP:8000"})," (IP address of the RDK) to see the real-time display of the F37 camera's output.\n",(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/hobot_codec/web-f37-codec.png",alt:"web-f37-codec"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"To query the camera's intrinsic parameters on the PC (the specific data may vary depending on the calibrated camera file), use the following command and view the results:"}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"root@ubuntu:~# source /opt/ros/foxy/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"root@ubuntu:~# source /opt/ros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:" root@ubuntu:~# ros2 topic echo /camera_info\n     header:\n stamp:\n     sec: 1662013622\n     nanosec: 672922214\n frame_id: default_cam\n height: 1080\n width: 1920\n distortion_model: plumb_bob\n d:\n - 0.169978\n - -0.697303\n - -0.002944\n - -0.004961\n - 0.0\n k:\n - 1726.597634\n - 0.0\n - 904.979671\n - 0.0\n - 1737.359551\n - 529.123375\n - 0.0\n - 0.0\n - 1.0\n r:\n - 1.0\n - 0.0- 0.0\n- 0.0\n- 1.0\n- 0.0\n- 0.0\n- 0.0\n- 1.0\np:\n- 1685.497559\n- 0.0\n- 881.6396\n- 0.0\n- 0.0\n- 1756.460205\n- 526.781147\n- 0.0\n- 0.0\n- 0.0\n- 1.0\n- 0.0\nbinning_x: 0\nbinning_y: 0\nroi:\nx_offset: 0\ny_offset: 0\nheight: 0\nwidth: 0\ndo_rectify: false\n\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"caution",children:"Caution"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["mipi_cam provides the calibration files for two types of cameras, F37 and GC4663. By default, it reads the calibration file for F37, ",(0,r.jsx)(n.code,{children:"F37_calibration.yaml"}),". If you want to use GC4663, please change the path to the camera calibration file accordingly, as below:"]}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Start the launch file\nros2 launch mipi_cam mipi_cam.launch.py mipi_video_device:=GC4663 mipi_camera_calibration_file_path:=/opt/tros/${TROS_DISTRO}/lib/mipi_cam/config/GC4663_calibration.yaml\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Caution when plugging/unplugging the camera:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"NEVER plug or unplug the camera module without powering off the development board first. Otherwise, it may result in damaging the camera module."})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"If you encounter any issues with the startup of the hobot_sensor node, you can troubleshoot the problems by following these steps:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Check the hardware connections."}),"\n",(0,r.jsx)(n.li,{children:"Make sure you have set up the tros.b environment."}),"\n",(0,r.jsx)(n.li,{children:"Verify the parameters are correct, for more details refer to the Hobot_Sensors README.md file."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"realsense-image-capture",children:"RealSense Image Capture"}),"\n",(0,r.jsx)(n.h3,{id:"feature-overview",children:"Feature Overview"}),"\n",(0,r.jsx)(n.p,{children:'Stereo cameras are commonly used sensors in robotics, often serving as the "eyes" of the robot. They have diverse applications, including navigation and obstacle avoidance, object recognition, 3D reconstruction, and human-robot interaction. The RDK platform supports popular stereo camera models such as RealSense and Orbbec.'}),"\n",(0,r.jsx)(n.p,{children:"Currently, the usage of RealSense and Orbbec stereo cameras on ROS follows the architecture shown below. It requires platform-specific SDK library files. These SDKs provide APIs for camera initialization and configuration. On top of these SDKs, ROS wrappers are implemented, enabling the integration of stereo cameras into ROS."}),"\n",(0,r.jsx)(n.p,{children:"The general installation process for stereo camera ROS packages involves:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Installing the camera's SDK library files."}),"\n",(0,r.jsx)(n.li,{children:"Installing the ROS wrapper for the camera."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/stereo-camera-ros-arch.png",alt:"Stereo Camera ROS Architecture"})}),"\n",(0,r.jsx)(n.p,{children:"This section explains how to use a RealSense camera on the RDK platform."}),"\n",(0,r.jsx)(n.h3,{id:"supported-platforms-2",children:"Supported Platforms"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"Operating System"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X3, RDK X3 Module"}),(0,r.jsx)(n.td,{children:"Ubuntu 20.04 (Foxy), Ubuntu 22.04 (Humble)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X5"}),(0,r.jsx)(n.td,{children:"Ubuntu 22.04 (Humble)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK Ultra"}),(0,r.jsx)(n.td,{children:"Ubuntu 20.04 (Foxy)"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"preparation-2",children:"Preparation"}),"\n",(0,r.jsx)(n.h4,{id:"rdk-platform-1",children:"RDK Platform"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Ensure your RealSense camera is functioning properly and connect it to the RDK's USB port using the provided USB cable."}),"\n",(0,r.jsx)(n.li,{children:"Verify that the RDK is flashed with the Ubuntu 20.04/Ubuntu 22.04 system image."}),"\n",(0,r.jsx)(n.li,{children:"Confirm that tros.b is successfully installed on the RDK."}),"\n",(0,r.jsx)(n.li,{children:"Ensure that your PC can access the RDK over the network."}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"usage-instructions",children:"Usage Instructions"}),"\n",(0,r.jsxs)(n.p,{children:["To use the RealSense series cameras on the RDK platform, install RealSense SDK 2.0 and the RealSense ROS wrapper using the ",(0,r.jsx)(n.code,{children:"apt"})," command."]}),"\n",(0,r.jsx)(n.p,{children:"Below are the GitHub repositories for RealSense SDK 2.0 and the RealSense ROS wrapper. This guide references these repositories, which also contain more detailed instructions for advanced use cases:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["RealSense SDK 2.0: ",(0,r.jsx)(n.a,{href:"https://github.com/IntelRealSense/librealsense",children:"GitHub Repository"})]}),"\n",(0,r.jsxs)(n.li,{children:["RealSense ROS wrapper: ",(0,r.jsx)(n.a,{href:"https://github.com/IntelRealSense/realsense-ros/tree/ros2-development",children:"GitHub Repository"})]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"1-log-in-to-the-rdk-via-serial-port-or-ssh-and-verify-the-ros-version",children:"1. Log in to the RDK via Serial Port or SSH and Verify the ROS Version"}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n# Print the ROS version environment variable\necho $ROS_DISTRO\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n# Print the ROS version environment variable\necho $ROS_DISTRO\n"})})})]}),"\n",(0,r.jsx)(n.h4,{id:"2-install-realsense-sdk-20-and-realsense-ros2-wrapper",children:"2. Install RealSense SDK 2.0 and RealSense ROS2 Wrapper"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Install RealSense SDK 2.0\nsudo apt-get install ros-$ROS_DISTRO-librealsense2* -y \n# Install RealSense ROS2 wrapper\nsudo apt-get install ros-$ROS_DISTRO-realsense2-* -y\n"})}),"\n",(0,r.jsx)(n.h4,{id:"3-start-the-realsense-camera",children:"3. Start the RealSense Camera"}),"\n",(0,r.jsx)(n.p,{children:"After installation, you can start the RealSense camera using the following ROS command:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"ros2 launch realsense2_camera rs_launch.py\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/realsense-start-up-log.png",alt:"realsense-start-up-log"})}),"\n",(0,r.jsxs)(n.p,{children:["You can use the ",(0,r.jsx)(n.code,{children:"ros2 topic list"})," command to view the topics published by the RealSense camera. When started with default parameters, the RealSense camera will only enable the depth and RGB data streams."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/realsense-basic-topic.png",alt:"realsense-basic-topic"})}),"\n",(0,r.jsx)(n.p,{children:"The RealSense ROS wrapper provides numerous configurable parameters. For example:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Setting ",(0,r.jsx)(n.code,{children:"enable_infra1:=true"})," enables the camera's left IR data stream."]}),"\n",(0,r.jsxs)(n.li,{children:["Setting ",(0,r.jsx)(n.code,{children:"pointcloud.enable:=true"})," enables the point cloud data stream."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"ros2 launch realsense2_camera rs_launch.py enable_infra1:=true pointcloud.enable:=true\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/realsense-ir-pointcloud-topic.png",alt:"realsense-ir-pointcloud-topic"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/realsense-image.png",alt:"realsense-image"})}),"\n",(0,r.jsxs)(n.p,{children:["Additionally, RealSense provides several services that can be viewed using the ",(0,r.jsx)(n.code,{children:"ros2 service list"})," command. For example, you can use these services to query the camera's serial number, firmware version, and other information."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"ros2 service call /camera/device_info realsense2_camera_msgs/srv/DeviceInfo\n"})}),"\n",(0,r.jsxs)(n.p,{children:["For more details on topics and service configurations, refer to the RealSense ROS wrapper's ",(0,r.jsx)(n.a,{href:"https://github.com/IntelRealSense/realsense-ros/tree/ros2-development",children:"GitHub repository"}),"."]}),"\n",(0,r.jsx)(n.h4,{id:"4-depth-and-rgb-alignment",children:"4. Depth and RGB Alignment"}),"\n",(0,r.jsx)(n.p,{children:"In practical applications, it's often necessary to align the depth map with the color image. RealSense provides corresponding launch methods to achieve this."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"ros2 launch realsense2_camera rs_launch.py enable_rgbd:=true enable_sync:=true align_depth.enable:=true enable_color:=true enable_depth:=true \n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/realsense-d2c-topic.png",alt:"realsense-d2c-topic"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/realsense-image-align.png",alt:"realsense-image-align"})}),"\n",(0,r.jsx)(n.h4,{id:"5-displaying-images-and-point-clouds",children:"5. Displaying Images and Point Clouds"}),"\n",(0,r.jsxs)(n.p,{children:["There are multiple ways to display images and point clouds from the RealSense camera. Refer to ",(0,r.jsx)(n.a,{href:"/rdk_doc/en/Robot_development/quick_demo/demo_render",children:"2.2 Data Visualization"})," for details."]}),"\n",(0,r.jsxs)(n.p,{children:["For example, you can use ",(0,r.jsx)(n.code,{children:"rviz2"})," on a PC to display the data. Ensure that the PC can access the RDK over the network. Note that since data is transmitted over the network, this method may cause significant load and result in lag or stuttering."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/realsense-rviz2.png",alt:"realsense-rviz2"})}),"\n",(0,r.jsxs)(n.p,{children:["It is recommended to directly read data on the RDK to verify if the output stream is functioning correctly. You can use ",(0,r.jsx)(n.code,{children:"ros2 topic echo topic_name"})," to print the data or write code to subscribe to the relevant topics."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/realsense-topic-echo.png",alt:"realsense-topic-echo"})}),"\n",(0,r.jsx)(n.h2,{id:"dual-mipi-camera",children:"Dual MIPI camera"}),"\n",(0,r.jsx)(n.h3,{id:"introduction-2",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:"To achieve environmental perception capabilities, robots often carry stereo cameras, ToF, and other types of sensors. In order to reduce the cost of sensor adaptation and usage for users, TogetheROS.Bot wraps multiple commonly used sensors into the hobot_sensor module and abstracts them into ROS standard image messages. When the configured sensor parameters do not match the connected camera, the program will automatically adapt to the correct sensor type. The currently supported MIPI sensor types are as follows:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Model"}),(0,r.jsx)(n.th,{children:"Specifications"}),(0,r.jsx)(n.th,{children:"Supported Platforms"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Camera"}),(0,r.jsx)(n.td,{children:"SC230ai"}),(0,r.jsx)(n.td,{children:"200W"}),(0,r.jsx)(n.td,{children:"RDK X5"})]})})]}),"\n",(0,r.jsxs)(n.p,{children:["Code repository:  (",(0,r.jsx)(n.a,{href:"https://github.com/D-Robotics/hobot_mipi_cam.git",children:"https://github.com/D-Robotics/hobot_mipi_cam.git"}),")"]}),"\n",(0,r.jsx)(n.h3,{id:"supported-platforms-3",children:"Supported Platforms"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"System"}),(0,r.jsx)(n.th,{children:"Function"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X5"}),(0,r.jsx)(n.td,{children:"Ubuntu 22.04 (Humble)"}),(0,r.jsx)(n.td,{children:"Start MIPI camera and display images through Web"})]})})]}),"\n",(0,r.jsx)(n.h3,{id:"preparation-3",children:"Preparation"}),"\n",(0,r.jsx)(n.h4,{id:"rdk-2",children:"RDK"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Confirm that the camera is correctly connected to RDK. For example, the connection between the dual camera and RDK X5 is shown in the following figure:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/image-X5-PI-DualCamera.jpg",alt:"image-X5-PI-DualCamera"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"RDK is flashed with the  Ubuntu 22.04 system image provided by D-Robotics"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"RDK has successfully installed tros.b"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Confirm that the PC can access RDK through the network"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"usage-1",children:"Usage"}),"\n",(0,r.jsx)(n.h4,{id:"rdk-platform-2",children:"RDK Platform"}),"\n",(0,r.jsx)(n.p,{children:"Take the SC230ai as an example to introduce the method of acquiring and previewing images:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["SSH into RDK and determine the camera model, take ",(0,r.jsx)(n.code,{children:"SC230ai"})," as an example."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Start the ",(0,r.jsx)(n.code,{children:"hobot_sensor"})," node with the following command:"]}),"\n",(0,r.jsx)(a.A,{groupId:"tros-distro",children:(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Start the launch file\nros2 launch mipi_cam mipi_cam_dual_channel.launch.py\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"If the following information is outputted, it means that the node has been successfully started:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"[INFO] [launch]: All log files can be found below /root/.ros/log/2024-09-18-19-15-26-160110-ubuntu-3931\n[INFO] [launch]: Default logging verbosity is set to INFO\nconfig_file_path is  /opt/tros/humble/lib/mipi_cam/config/\nHobot shm pkg enables zero-copy with fastrtps profiles file: /opt/tros/humble/lib/hobot_shm/config/shm_fastdds.xml\nHobot shm pkg sets RMW_FASTRTPS_USE_QOS_FROM_XML: 1\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\n[INFO] [mipi_cam-1]: process started with pid [3932]\n[mipi_cam-1] [WARN] [1726658126.449994704] [mipi_node]: frame_ts_type value: sensor\n[mipi_cam-1] [ERROR] [1726658126.455022356] [mipi_factory]: This is't support device type(), start defaule capture.\n[mipi_cam-1]\n[mipi_cam-1] [WARN] [1726658126.456074125] [mipi_cam]: this board support mipi:\n[mipi_cam-1] [WARN] [1726658126.456274529] [mipi_cam]: host 0\n[mipi_cam-1] [WARN] [1726658126.456333567] [mipi_cam]: host 2\n[mipi_cam-1] [WARN] [1726658128.722451045] [mipi_cam]: [init]->cap default init success.\n[mipi_cam-1]\n...\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"To view the dual camera image on the web, as raw data needs to be encoded into JPEG images, need to be coded Jpeg image node,  and one for publishing with a webservice node."}),"\n",(0,r.jsx)(a.A,{groupId:"tros-distro",children:(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Start the launch file\nros2 launch mipi_cam mipi_cam_dual_channel_websocket.launch.py\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Open a web browser on the PC (Chrome/Firefox/Edge) and enter  ",(0,r.jsx)(n.code,{children:"http://IP:8000"})," (IP address of the RDK) to see the real-time display of the dual camera's output.\n",(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/web-dualcamera-codec.jpg",alt:"web-dualcamera-codec"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"caution-1",children:"Caution"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Caution when plugging/unplugging the camera:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"NEVER plug or unplug the camera module without powering off the development board first. Otherwise, it may result in damaging the camera module."})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"If you encounter any issues with the startup of the hobot_sensor node, you can troubleshoot the problems by following these steps:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Check the hardware connections."}),"\n",(0,r.jsx)(n.li,{children:"Make sure you have set up the tros.b environment."}),"\n",(0,r.jsx)(n.li,{children:"Verify the parameters are correct, for more details refer to the Hobot_Sensors README.md file."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"rgbd-camera",children:"RGBD camera"}),"\n",(0,r.jsx)(n.h3,{id:"introduction-3",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:"In order to achieve environmental perception capability, robot products usually carry cameras, ToF and other types of sensors. To reduce the cost of sensor adaptation and usage for users, TogetheROS.Bot encapsulates and abstracts multiple commonly used sensors into the hobot_sensor module, which supports ROS standard image messages, custom image message output, and camera calibration data publishing. Currently supported types of RGBD sensors are as follows:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Model"}),(0,r.jsx)(n.th,{children:"Specification"}),(0,r.jsx)(n.th,{children:"Supported Platforms"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Camera"}),(0,r.jsx)(n.td,{children:"CP3AM"}),(0,r.jsx)(n.td,{children:"200W"}),(0,r.jsx)(n.td,{children:"RDK X3"})]})})]}),"\n",(0,r.jsxs)(n.p,{children:["Code Repository:  (",(0,r.jsx)(n.a,{href:"https://github.com/D-Robotics/hobot_rgbd_cam.git",children:"https://github.com/D-Robotics/hobot_rgbd_cam.git"}),")"]}),"\n",(0,r.jsx)(n.h3,{id:"supported-platforms-4",children:"Supported Platforms"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"System"}),(0,r.jsx)(n.th,{children:"Function"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X3"}),(0,r.jsx)(n.td,{children:"Ubuntu 20.04 (Foxy), Ubuntu 22.04 (Humble)"}),(0,r.jsx)(n.td,{children:"Start RGBD camera and preview RGB and depth images on PC using rviz2"})]})})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Note: Only supports RDK X3, RDK X3 Module is not supported yet."})}),"\n",(0,r.jsx)(n.h3,{id:"preparations",children:"Preparations"}),"\n",(0,r.jsx)(n.h4,{id:"rdk-platform-3",children:"RDK Platform"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Make sure the camera is correctly connected to the RDK. The connection for RGBD module to RDK X3 is shown as below:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/hobot_rgbd.png",alt:"hobot_rgbd"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Note: The RGBD module needs an additional adapter board to connect to RDK X3"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"RDK has been flashed with the  Ubuntu 20.04/22.04 system image provided by D-Robotics."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"RDK has successfully installed tros.b."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Make sure the PC can access the RDK through the network."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Install ros2 foxy version and rviz2 on the PC, using the following command:"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"  sudo apt install ros-foxy-rviz-common ros-foxy-rviz-default-plugins ros-foxy-rviz2\n"})}),"\n",(0,r.jsx)(n.h3,{id:"usage-2",children:"Usage"}),"\n",(0,r.jsx)(n.h4,{id:"rdk-3",children:"RDK"}),"\n",(0,r.jsx)(n.p,{children:"Taking CP3AM as an example, the method of acquiring and previewing camera data is introduced below:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"SSH into the RDK and start the hobot_sensor node with the following command:"}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"cp -r /opt/tros/lib/rgbd_sensor/parameter .\n# Launch the node\nros2 launch rgbd_sensor rgbd_sensor.launch.py\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"If the program outputs the following information, it indicates that the node has been successfully launched:"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:'[WARN] [1654573498.706920307] [example]: [wuwl]->This is rgbd!\nsh: 1: echo: echo: I/O error\npipeId[1], mipiIdx[1], vin_vps_mode[3]\n[ERROR]["LOG"][irs2381c_utility.c:192] 2381 enter sensor_init_setting\n[ERROR]["LOG"][irs2381c_utility.c:200] start write 2381c reg\ncamera read reg: 0xa001 val:0x7\n...\n[ERROR]["LOG"][irs2381c_utility.c:207] end write 2381c reg\nHB_MIPI_InitSensor end\nHB_MIPI_SetDevAttr end\npstHbVideoDev->vin_fd = 29\nsensorID: 634-2362-2676-68d0 \nfind local calib_file\n\nfind local calib_file\n\nSDK Version: V4.4.35 build 20220525 09:27:53.\nread file(./calib-0634-2362-2676-68d0.bin), ok, file_len=132096, read_len=132096.......\nmodule config file(user custom) is: ./parameter/T00P11A-17.ini.\nparse calib data, data len:132096...\nsunny_degzip2 decode_len=155575.\ncalib data with crc.\nparse calib data, ok.\nmax roi (firstly): (0, 224, 0, 128).\ncur roi (firstly): (0, 224, 0, 128).\nHB_MIPI_InitSensor end\nHB_MIPI_SetDevAttr end\npstHbVideoDev->vin_fd = 55\nvencChnAttr.stRcAttr.enRcMode=11\nmmzAlloc paddr = 0x1a6e6000, vaddr = 0x917e1000\ncamera read reg: 0x9400 val:0x1\n...\n\n[wuwl-StartCamera]->camT=3, ret=0.\ncamera read reg: 0x3e val:0x40\n[ERROR]["vio_devop"][utils/dev_ioctl.c:121] [499334.399304]dev_node_dqbuf_ispoll[121]: failed to ioctl: dq (14 - Bad address)\n[ERROR]["vio_devop"][utils/dev_ioctl.c:189] [499334.399355]entity_node_dqbuf_ispoll[189]: dev type(9) dq failed\n\n[ERROR]["vio_core"][commom_grp/binding_main.c:1034] [499334.399371]comm_dq_no_data[1034]: G1 MIPI_SIF_MODULE module chn0 dq failed! maybe framedrop error_detail -14\n```[wuwl-StartCamera]->camT=1, ret=0.\n[INFO] [1654573500.226606117] [rclcpp]: [childStart]-> ret=0 !\n\n[INFO] [1654573500.226831567] [rclcpp]: [StartStream]->pthread create sucess\n\n[INFO] [1654573500.226963854] [rclcpp]: <========>[doCapStreamLoop]->Start.\n\n[WARN] [1654573500.226998103] [rgbd_node]: [RgbdNode]->mipinode init sucess.\n\n[WARN] [1654573500.227352507] [example]: [wuwl]->rgbd init!\n[WARN] [1654573500.228502174] [example]: [wuwl]->rgbd add_node!\n\n[INFO] [1662723985.860666547] [rgbd_node]: publish camera info.\n[INFO] [1662723985.866077156] [rgbd_node]: [pub_ori_pcl]->pub pcl w:h=24192:1,nIdx-24192:sz=24192.\n[INFO] [1662723985.876428980] [rgbd_node]: [timer_ros_pub]->pub dep w:h=224:129,sz=982464, infra w:h=224:108, sz=24192.\n\n[INFO] [1662723985.946767230] [rgbd_node]: publish camera info.\n[INFO] [1662723985.951415418] [rgbd_node]: [pub_ori_pcl]->pub pcl w:h=24192:1,nIdx-24192:sz=24192.\n[INFO] [1662723985.960161280] [rgbd_node]: [timer_ros_pub]->pub dep w:h=224:129,sz=982464, infra w:h=224:108, sz=24192.\n...\n\n'})}),"\n",(0,r.jsxs)(n.ol,{start:"3",children:["\n",(0,r.jsx)(n.li,{children:"Query the current topic on the PC, and the command are as follows:"}),"\n"]}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"source /opt/ros/foxy/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"source /opt/ros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 topic list\n"})}),"\n",(0,r.jsx)(n.p,{children:"The result are as follows:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"/rgbd_CP3AM/depth/image_rect_raw\n\n/rgbd_CP3AM/depth/color/points\n\n/rgbd_CP3AM/color/camera_info\n\n/rgbd_CP3AM/aligned_depth_to_color/color/points\n\n/rgbd_CP3AM/infra/image_rect_raw\n\n/rgbd_CP3AM/color/image_rect_raw\n\n/parameter_events\n\n/rosout\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"4",children:["\n",(0,r.jsx)(n.li,{children:"Subscribe to topics and preview camera data on a PC."}),"\n"]}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"source /opt/ros/foxy/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"source /opt/ros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 run rviz2 rviz2\n"})}),"\n",(0,r.jsx)(n.p,{children:'Click the "add" button in the rviz2 interface to add topics published by rgbd_sensor (refer to the rgbd_CP3AM related topics indicated in section 3). To subscribe to point cloud data, modify the "Fixed Frame" option in the Global Options of rviz2 configuration to "depth". Then you can view real-time point cloud information. In the point topic configuration, select "points" as the point type.'}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/hobot_rgbd_sensor.png",alt:"hobot_rgbd_sensor"})}),"\n",(0,r.jsxs)(n.ol,{start:"5",children:["\n",(0,r.jsx)(n.li,{children:"Query camera intrinsics on a PC."}),"\n"]}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"source /opt/ros/foxy/setup.bash\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"source /opt/ros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /rgbd_CP3AM/color/camera_info\n"})}),"\n",(0,r.jsx)(n.p,{children:"The output result is as follows:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:" header:\n stamp:\n     sec: 119811\n     nanosec: 831645108\n frame_id: color\n height: 1080\n width: 1920\n distortion_model: plumb_bob\n d:\n - -0.32267\n - 0.083221\n - 0.000164\n - -0.002134\n - 0.0\n k:\n - 1066.158339\n - 0.0\n - 981.393777\n - 0.0\n - 1068.659998\n - 545.569587\n - 0.0\n - 0.0\n - 1.0\n r:\n - 1.0\n - 0.0\n - 0.0```\n- 0.0\n- 1.0\n- 0.0\n- 0.0\n- 0.0\n- 1.0\np:\n- 741.315308\n- 0.0\n- 968.865379\n- 0.0\n- 0.0\n- 969.43042\n- 546.524343\n- 0.0\n- 0.0\n- 0.0\n- 1.0\n- 0.0\nbinning_x: 0\nbinning_y: 0\nroi:\nx_offset: 0\ny_offset: 0\nheight: 0\nwidth: 0\ndo_rectify: false\n"})}),"\n",(0,r.jsx)(n.h3,{id:"instructions",children:"Instructions"}),"\n",(0,r.jsx)(n.p,{children:"If there is an abnormality in the startup of the hobot_sensor node, you can troubleshoot the problem using the following steps:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Check hardware connections."}),"\n",(0,r.jsx)(n.li,{children:"Check if the tros.b environment is set."}),"\n",(0,r.jsx)(n.li,{children:"Check if the parameters are correct. For specific details, please refer to the Hobot_Sensors README.md file."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"orbbec-camera",children:"Orbbec camera"}),"\n",(0,r.jsx)(n.h3,{id:"introduction-4",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:'Stereo cameras are commonly used sensors in robot development, often serving as the "eyes" of robots. Applications of stereo cameras in robots cover various aspects, such as navigation and obstacle avoidance, target recognition, 3D reconstruction, and human-robot interaction. The RDK platform supports popular stereo cameras on the market, including the RealSense, Orbbec, ZED, and other series.'}),"\n",(0,r.jsx)(n.p,{children:"Currently, the use of RealSense and Orbbec stereo cameras on ROS follows the architecture described below. Firstly, SDK library files compiled for different hardware platforms are required. The camera SDK provides APIs for camera startup and settings. Based on this, ROS wrapping is performed to enable ROS to call the camera."}),"\n",(0,r.jsx)(n.p,{children:"Therefore, the general installation process for the stereo camera ROS package is: first install the camera's SDK library files, then install the camera's ROS wrapper package."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/stereo-camera-ros-arch.png",alt:"stereo-camera-ros-arch"})}),"\n",(0,r.jsx)(n.p,{children:"This section introduces the usage of Orbbec cameras on the RDK platform."}),"\n",(0,r.jsx)(n.h3,{id:"supported-platforms-5",children:"Supported Platforms"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"Operating Mode"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X3, RDK X3 Module"}),(0,r.jsx)(n.td,{children:"Ubuntu 20.04 (Foxy), Ubuntu 22.04 (Humble)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X5"}),(0,r.jsx)(n.td,{children:"Ubuntu 22.04 (Humble)"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"preparations-1",children:"Preparations"}),"\n",(0,r.jsx)(n.h4,{id:"rdk-platform-4",children:"RDK Platform"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Ensure that the Orbbec camera is functioning properly and connect the USB cable to the ",(0,r.jsx)("font",{color:"red",children:(0,r.jsx)("b",{children:"USB3.0"})})," slot of the RDK (currently, USB2.0 may have issues with startup)."]}),"\n",(0,r.jsx)(n.li,{children:"The RDK has Ubuntu 20.04/Ubuntu 22.04 system images burned onto it."}),"\n",(0,r.jsx)(n.li,{children:"The RDK has successfully installed tros.b."}),"\n",(0,r.jsx)(n.li,{children:"Confirm that the PC can access the RDK via the network."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"usage-3",children:"Usage"}),"\n",(0,r.jsx)(n.p,{children:"Currently, Orbbec cameras do not support direct installation of SDK library files and ROS wrapper packages using apt commands. Instead, source code must be downloaded and compiled before they can be run on the RDK platform."}),"\n",(0,r.jsx)(n.p,{children:"Here are the GitHub repositories for the Orbbec SDK and Orbbec ROS2 wrapper. This tutorial is also based on these repositories, and users can refer to the more detailed tutorials in these repositories."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Orbbec SDK: ",(0,r.jsx)(n.a,{href:"https://github.com/orbbec/OrbbecSDK",children:"https://github.com/orbbec/OrbbecSDK"})]}),"\n",(0,r.jsxs)(n.li,{children:["Orbbec ROS2 wrapper: ",(0,r.jsx)(n.a,{href:"https://github.com/orbbec/OrbbecSDK_ROS2",children:"https://github.com/orbbec/OrbbecSDK_ROS2"})]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"1-log-in-to-the-rdk-via-serial-port-or-ssh-and-confirm-the-ros-version",children:"1. Log in to the RDK via serial port or SSH and confirm the ROS version."}),"\n",(0,r.jsxs)(a.A,{groupId:"tros-distro",children:[(0,r.jsx)(i.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n# Print the ROS version environment variable\necho $ROS_DISTRO\n"})})}),(0,r.jsx)(i.A,{value:"humble",label:"Humble",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n# Print the ROS version environment variable\necho $ROS_DISTRO\n"})})})]}),"\n",(0,r.jsx)(n.h4,{id:"2-download-the-orbbec-ros2-wrapper-source-code-for-compilation",children:"2. Download the Orbbec ROS2 wrapper source code for compilation."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# First, create a ros workspace\nmkdir -p tros_ws/src\ncd tros_ws/src\n\n# Download the Orbbec ROS2 wrapper source code to the tros_ws/src directory\ngit clone https://github.com/orbbec/OrbbecSDK_ROS2.git\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Note that the OrbbecSDK_ROS2 repository already contains the SDK library files for the Orbbec camera, located in the ",(0,r.jsx)(n.code,{children:"OrbbecSDK_ROS2/orbbec_camera/SDK"})," directory. The ",(0,r.jsx)(n.code,{children:"arm64"})," version is required for compilation on the RDK platform."]}),"\n",(0,r.jsx)(n.p,{children:"After downloading the source code, the next step is to compile it. However, compiling this program requires at least 4GB of memory, and the RDK platform may encounter memory insufficiency issues, leading to compilation failures."}),"\n",(0,r.jsx)(n.p,{children:"There are two solutions:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Set up swap space to serve as temporary memory."}),"\n",(0,r.jsx)(n.li,{children:"Use cross-compilation, compiling on a PC and running on the RDK."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["The advantage of Solution 1 is simplicity and direct compilation on the RDK platform, but the disadvantage is slower compilation speed due to limited RDK platform performance. For example, compilation on the RDK X3 platform takes about 30 minutes. The advantage of Solution 2 is faster compilation speed, but the disadvantage is the complexity of setting up the cross-compilation environment. This tutorial introduces the implementation of Solution 1, and Solution 2 can be referenced in the tutorial: ",(0,r.jsx)(n.a,{href:"https://developer.d-robotics.cc/forumDetail/112555549341653662",children:"Cross-compilation Environment Deployment"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Below is how to set up swap space:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Create a 4GB swap file in the /swapfile directory\nsudo dd if=/dev/zero of=/swapfile bs=1M count=4096\n# For security reasons, set the permissions of the swap file to allow only the root user to read and write\nsudo chmod 600 /swapfile\n# Use the mkswap command to format the file as swap space\nsudo mkswap /swapfile\n# Use the swapon command to enable the swap file\nsudo swapon /swapfile\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/swapfile.png",alt:"swapfile"})}),"\n",(0,r.jsxs)(n.p,{children:["After setting up the swap space, you can use ",(0,r.jsx)(n.code,{children:"swapon --show"}),", ",(0,r.jsx)(n.code,{children:"free -h"}),", or ",(0,r.jsx)(n.code,{children:"htop"})," commands to check the current swap usage. For example, using the ",(0,r.jsx)(n.code,{children:"htop"})," command:"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/htop-swap.png",alt:"htop-swap"})}),"\n",(0,r.jsxs)(n.p,{children:["This setting is only temporary and will be lost after a power cycle. If you want the swap space to be used after a system reboot, you can either re-execute ",(0,r.jsx)(n.code,{children:"sudo swapon /swapfile"})," or add it to the ",(0,r.jsx)(n.code,{children:"/etc/fstab"})," file."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Open /etc/fstab using vim\nsudo vim /etc/fstab\n# Add the following line, save and exit\n/swapfile none swap sw 0 0\n# Execute sync to flush the cache and ensure all data is correctly written to disk\nsync\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/etc-fstab.png",alt:"etc-fstab"})}),"\n",(0,r.jsx)(n.p,{children:"To delete the swap space, you can execute the following commands."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Use the swapoff command to disable the swap file\nsudo swapoff /swapfile\n# Delete the swap file\nsudo rm -rf /swapfile\n# If the swap file entry was added in /etc/fstab, remove it\nsudo vim /etc/fstab\n# Delete the following line\n/swapfile none swap sw 0 0\n"})}),"\n",(0,r.jsx)(n.p,{children:"After setting up the swap space, you can proceed with the compilation."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Return to the ros workspace\ncd tros_ws\n# Execute colcon to build, which may take a while, please be patient\ncolcon build\n"})}),"\n",(0,r.jsx)(n.p,{children:"Compilation results on the RDK X3 platform:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/orbbec-ros-colcon-build.png",alt:"orbbec-ros-colcon-build"})}),"\n",(0,r.jsx)(n.h4,{id:"3-start-the-orbbec-camera",children:"3. Start the Orbbec camera."}),"\n",(0,r.jsx)(n.p,{children:"After compilation, the Orbbec camera can be started through ROS commands. OrbbecSDK_ROS2 has launch files for all Orbbec cameras, including the Astra series, Dabai series, and Gemini series. Simply use the corresponding launch file to start. This tutorial takes the Gemini2 camera as an example."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"cd tros_ws\nsource ./install/setup.bash\nros2 launch orbbec_camera gemini2.launch.py\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/orbbec-start-up-log.png",alt:"orbbec-start-up-log"})}),"\n",(0,r.jsxs)(n.p,{children:["You can use ",(0,r.jsx)(n.code,{children:"ros2 topic list"})," to view the topics published by Gemini2. With default parameters, starting the Gemini2 camera will enable the camera's depth data stream, RGB data stream, IR data stream, and point cloud data stream."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/orbbec-topic-list.png",alt:"orbbec-topic-echo"})}),"\n",(0,r.jsxs)(n.p,{children:["The Orbbec ROS2 wrapper offers numerous configurable parameters. For instance, setting ",(0,r.jsx)(n.code,{children:"enable_point_cloud:=false"})," and ",(0,r.jsx)(n.code,{children:"enable_colored_point_cloud:=false"})," will disable the camera's point cloud data streams."]}),"\n",(0,r.jsxs)(n.p,{children:["Moreover, the Orbbec camera activates several services, which can be viewed using ",(0,r.jsx)(n.code,{children:"ros2 service list"}),". These services allow for querying the camera's SDK version, adjusting or querying exposure time and gain, enabling or disabling the laser, among other functionalities. For example:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Query SDK Version\nros2 service call /camera/get_sdk_version orbbec_camera_msgs/srv/GetString '{}'\n# Disable Color Camera Auto Exposure\nros2 service call /camera/set_color_auto_exposure std_srvs/srv/SetBool '{data: false}'\n# Enable Laser\nros2 service call /camera/set_laser_enable std_srvs/srv/SetBool '{data: true}'\n"})}),"\n",(0,r.jsx)(n.p,{children:"For more detailed settings regarding topics and services, please refer to the Orbbec ROS2 wrapper's GitHub repository."}),"\n",(0,r.jsx)(n.h4,{id:"4-depth-and-rgb-alignment-1",children:"4. Depth and RGB Alignment"}),"\n",(0,r.jsx)(n.p,{children:"In practical applications, it is often necessary to align the depth map of a stereo camera with its color image. Orbbec provides a corresponding launch configuration for this purpose."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"cd tros_ws\nsource ./install/setup.bash\nros2 launch orbbec_camera gemini2.launch.py depth_registration:=true\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/orbbec-image-align.png",alt:"orbbec-image-align"})}),"\n",(0,r.jsx)(n.h4,{id:"5-displaying-images-and-point-clouds-1",children:"5. Displaying Images and Point Clouds"}),"\n",(0,r.jsxs)(n.p,{children:["There are multiple methods to display Orbbec's images and point clouds. For reference, see ",(0,r.jsx)(n.a,{href:"/rdk_doc/en/Robot_development/quick_demo/demo_render",children:"2.2 Data Visualization"}),". For instance, you can use ",(0,r.jsx)(n.code,{children:"rviz2"})," on a PC to display the data, but note that this requires the PC to access the RDK via the network, which can be demanding and may lead to lag."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/orbbec-rviz2.png",alt:"orbbec-rviz2"})}),"\n",(0,r.jsxs)(n.p,{children:["It is recommended to read the data directly on the RDK to verify the data flow. You can use ",(0,r.jsx)(n.code,{children:"ros2 topic echo topic_name"})," to print data or write code to subscribe to the corresponding topics."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/orbbec-topic-echo.png",alt:"orbbec-topic-echo.png"})}),"\n",(0,r.jsx)(n.h2,{id:"zed-camera",children:"ZED camera"}),"\n",(0,r.jsx)(n.h3,{id:"introduction-5",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:'Stereo cameras are commonly used sensors in robot development, often serving as the "eyes" of robots. Their applications in robotics span various aspects, including navigation and obstacle avoidance, object recognition, 3D reconstruction, and human-robot interaction. The RDK platform supports popular stereo cameras on the market, such as RealSense, Orbbec, and ZED series cameras.'}),"\n",(0,r.jsxs)(n.p,{children:["Code Repository: ",(0,r.jsx)(n.a,{href:"https://github.com/D-Robotics/hobot_zed_cam",children:"https://github.com/D-Robotics/hobot_zed_cam"})]}),"\n",(0,r.jsx)(n.p,{children:"This section introduces how to use the ZED camera on the RDK platform."}),"\n",(0,r.jsx)(n.h3,{id:"supported-platforms-6",children:"Supported Platforms"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"Operating System"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RDK X5"}),(0,r.jsx)(n.td,{children:"Ubuntu 22.04 (Humble)"})]})})]}),"\n",(0,r.jsx)(n.h3,{id:"preparation-4",children:"Preparation"}),"\n",(0,r.jsx)(n.h4,{id:"rdk-platform-5",children:"RDK Platform"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Ensure that the ZED camera is functioning properly and connect it to the RDK via a USB cable."}),"\n",(0,r.jsx)(n.li,{children:"The RDK should have Ubuntu 22.04 system image flashed onto it."}),"\n",(0,r.jsxs)(n.li,{children:["The RDK should have ",(0,r.jsx)(n.code,{children:"tros.b"})," installed successfully."]}),"\n",(0,r.jsx)(n.li,{children:"Ensure that the PC can access the RDK via the network."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"usage-4",children:"Usage"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Log in to the RDK via SSH and start the ZED camera using the following commands:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n\n# Launch the ZED camera to publish stereo image data\nros2 launch hobot_zed_cam pub_stereo_imgs.launch.py need_rectify:=true\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsx)(n.li,{children:"If the program outputs information similar to the following, it indicates that the node has been successfully launched:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"[anypub_stereo_imgs-1] [INFO] [0946684888.710715101] [pub_stereo_imgs_nv12_node]: => connected to camera sn: 38085162[/dev/video0]\n[anypub_stereo_imgs-1] [INFO] [0946684888.779280740] [pub_stereo_imgs_nv12_node]: => calibration file found. Loading...\n[anypub_stereo_imgs-1] [INFO] [0946684888.831008271] [pub_stereo_imgs_nv12_node]: => camera Matrix L:\n[anypub_stereo_imgs-1] [514.5878861678406, 0, 665.3764572143555, 0;\n[anypub_stereo_imgs-1]  0, 514.5878861678406, 320.3872646755642, 0;\n[anypub_stereo_imgs-1]  0, 0, 1, 0]\n[anypub_stereo_imgs-1] [INFO] [0946684888.831235937] [pub_stereo_imgs_nv12_node]: => camera Matrix R:\n[anypub_stereo_imgs-1] [514.5878861678406, 0, 665.3764572143555, 61695.48427422668;\n[anypub_stereo_imgs-1]  0, 514.5878861678406, 320.3872646755642, 0;\n[anypub_stereo_imgs-1]  0, 0, 1, 0]\n[anypub_stereo_imgs-1] [INFO] [0946684888.831287187] [pub_stereo_imgs_nv12_node]: => rectified fx: 514.587886, fy: 514.587886, cx: 665.376457, cy: 320.387265, base_line: 0.119893\n[anypub_stereo_imgs-1] [INFO] [0946684888.831357562] [pub_stereo_imgs_nv12_node]: => camera_fx:=514.587886 camera_fy:=514.587886 camera_cx:=665.376457 camera_cy:=320.387265 base_line:=0.119893\n[anypub_stereo_imgs-1] [INFO] [0946684888.851400416] [pub_stereo_imgs_nv12_node]: => raw img size: [1280, 720]\n[anypub_stereo_imgs-1] [INFO] [0946684888.883419384] [pub_stereo_imgs_nv12_node]: => rectify img size: [1280, 640]\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"3",children:["\n",(0,r.jsxs)(n.li,{children:["Open a web browser on the PC (",(0,r.jsx)(n.code,{children:"Chrome/Firefox/Edge"}),"), enter ",(0,r.jsx)(n.code,{children:"IP:8000"})," (where IP is the IP address of the RDK), and click on the web display in the top left corner to view the real-time ZED camera feed."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/02_quick_demo/image/demo_sensor/zed_cam_pic.png",alt:"ZED Camera Real-Time Feed"})})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(u,{...e})}):u(e)}},19365:(e,n,s)=>{s.d(n,{A:()=>a});s(96540);var o=s(34164);const r={tabItem:"tabItem_Ymn6"};var t=s(74848);function a({children:e,hidden:n,className:s}){return(0,t.jsx)("div",{role:"tabpanel",className:(0,o.A)(r.tabItem,s),hidden:n,children:e})}},28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>i});var o=s(96540);const r={},t=o.createContext(r);function a(e){const n=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);