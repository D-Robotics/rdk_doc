"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[63023],{16222:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"Advanced_development/linux_development/driver_development_s100/driver_hbmem/s100_hbmem_FAQ","title":"FAQ","description":"FAQ001: Memory Concepts","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/07_Advanced_development/02_linux_development/04_driver_development_s100/15_driver_hbmem/05_s100_hbmem_FAQ.md","sourceDirName":"07_Advanced_development/02_linux_development/04_driver_development_s100/15_driver_hbmem","slug":"/Advanced_development/linux_development/driver_development_s100/driver_hbmem/s100_hbmem_FAQ","permalink":"/rdk_doc/en/rdk_s/Advanced_development/linux_development/driver_development_s100/driver_hbmem/s100_hbmem_FAQ","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1764751642000,"sidebarPosition":5,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Debug Information","permalink":"/rdk_doc/en/rdk_s/Advanced_development/linux_development/driver_development_s100/driver_hbmem/s100_hbmem_debug"},"next":{"title":"\u4ee5\u592a\u7f51\u4f7f\u7528\u5f00\u53d1\u6307\u5357","permalink":"/rdk_doc/en/rdk_s/16_driver_ethernet"}}');var i=s(74848),t=s(28453);const a={},o="FAQ",l={},c=[{value:"FAQ001: Memory Concepts",id:"faq001-memory-concepts",level:2},{value:"FAQ002: Structure Descriptions",id:"faq002-structure-descriptions",level:2},{value:"FAQ003: Operational Notes",id:"faq003-operational-notes",level:2},{value:"FAQ004: Function Interfaces",id:"faq004-function-interfaces",level:2},{value:"FAQ005: Memory Allocation",id:"faq005-memory-allocation",level:2},{value:"FAQ006: Memory Sharing",id:"faq006-memory-sharing",level:2},{value:"FAQ007: Memory Queue Management",id:"faq007-memory-queue-management",level:2},{value:"FAQ008: Memory Pools",id:"faq008-memory-pools",level:2},{value:"FAQ009: Software Performance",id:"faq009-software-performance",level:2},{value:"FAQ010: Memory Leaks",id:"faq010-memory-leaks",level:2},{value:"FAQ011: Software Debugging",id:"faq011-software-debugging",level:2},{value:"FAQ012: Module Usage",id:"faq012-module-usage",level:2}];function d(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"faq",children:"FAQ"})}),"\n",(0,i.jsx)(n.h2,{id:"faq001-memory-concepts",children:"FAQ001: Memory Concepts"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: What are the purposes of the other two types of reserved ION memory (cma_reserved and carveout)?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Both types of memory are essentially carveout. The reason they are distinguished is that one carveout is primarily used for BPU and codec memory allocation in the system, while modules in VIO allocate memory from the other carveout."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Is Hbmem required because certain IPs need physically contiguous memory?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq002-structure-descriptions",children:"FAQ002: Structure Descriptions"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: What is the semantic difference between com_buf and graph_buf?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: com_buf represents a single, contiguous buffer with a simpler structure. In contrast, graph_buf is more complex and consists of multiple planes."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Does com_buf have width and height attributes, or only a size?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: It only has a size. Width and height attributes must be retrieved from individual modules; however, graph_buf does include width and height attributes."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Are com_buf and graph_buf structurally just different encapsulations, with graph_buf carrying richer semantics, but fundamentally equivalent?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Does offset only exist if we explicitly set it? Is this offset the base address when allocating memory?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes, it must be set manually. For example, if you obtain a buffer and want to pass an offset address to another process, you can set the offset here. This offset is then passed along with the buffer and transparently transmitted to the other process. Newly allocated buffers always have an offset of zero. The offset is used during inter-process transmission to carry transparent information indicating an offset within the buffer."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Why was graph_buf introduced in addition to com_buf? What's the difference?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: When allocating com_buf, you can only specify size and standard allocation attributes. In contrast, graph_buf allows specifying width, height, format, stride, contiguity, and other standard allocation attributes during allocation. Compared to com_buf, graph_buf carries richer buffer metadata, making it easier for users to directly allocate buffers in RGB/YUV/RAW formats."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq003-operational-notes",children:"FAQ003: Operational Notes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: Does each process need to call module_open? Is this an extra step for users? Can it be opened repeatedly? Is there internal protection?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes, each process must call module_open, as different engineers typically develop each process, necessitating this operation per process. Within a single process, multiple opens are not recommended and unnecessary; each open must have a corresponding close. Normally, if allocated memory isn't freed explicitly, it will be freed during module_close. However, missing the corresponding close operation will prevent memory from being freed. That said, when a process terminates, all ION-allocated memory will be released automatically."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Can the file descriptor (fd) limit be increased using Linux ulimit?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes, ulimit can be used to raise the fd limit. In some scenarios, the issue isn't actually insufficient fds but rather fd leaks caused by incorrect API usage."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq004-function-interfaces",children:"FAQ004: Function Interfaces"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: Are these interface functions merely wrappers at the driver level?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: They are more than just wrappers. Buffers allocated via Hbmem are universally usable across modules, and all relevant information can be retrieved via virtual addresses. For instance, after obtaining a buffer from VIO, you can convert it to a com_buf and pass it to another module like BPU."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Can buffer information be obtained via the get_buffer_info interface?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes. Additionally, you can use hb_mem_get_com_buffer_info_with_vaddr to retrieve com_buf information using a virtual address."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Is invalid a blocking interface? Could calling invalid from two processes cause a deadlock? What happens after a timeout?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: It is a blocking interface; deadlocks cannot occur as the function handles this internally; there is no timeout\u2014the function only returns after the operation completes."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq005-memory-allocation",children:"FAQ005: Memory Allocation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: Is memory allocated via the interface physically contiguous?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: First, it depends on which heap is selected\u2014memory allocated from CMA or carveout heaps is physically contiguous. Second, you can choose the heap via parameters."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Are the provided APIs equivalent to generic interfaces but with added inter-process sharing capability? If inter-process sharing isn't needed, can malloc be used instead?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: If you use standard malloc, the allocated memory will not be physically contiguous."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Does the allocated buffer support automatic format conversion? Does the S100X support hardware-based format conversion?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Automatic format conversion is not supported. For hardware-based format conversion, consider using CIM and Pyramid."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: How do I specify which heap to use for memory allocation?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A: Include one of the following flags in the allocation flags:","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"HB_MEM_USAGE_PRIV_HEAP_DMA;\nHB_MEM_USAGE_PRIV_HEAP_RESERVED;\nHB_MEM_USAGE_PRIV_HEAP_2_RESERVED;\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Assuming the allocated memory is accessed only by CPUs in processes A and B, should cacheable memory be allocated for performance? If cacheable, does process B need to perform invalidate when only reading?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: If used exclusively between CPUs, cacheable memory is recommended. Enabling cacheable significantly accelerates memory access\u2014by over 1000x as expected. For CPU-only read/write access, no invalidate or flush operations are needed; cache coherency is guaranteed by the CPU's MESI protocol."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: If the memory is intended for an IP (e.g., GDC/codec) and won't be accessed by process B's CPU, can we directly pass the physical address, or must we still use a buffer?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Directly using a physical address without allocating via ION cannot guarantee exclusive usage during the address's lifetime\u2014it might be allocated by another user. Thus, when hardware or software uses the buffer, its lifetime must be properly managed."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Why is the virtual address converted to uint8_t when allocating YUV memory?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Storing the virtual address in a uint8_t* pointer primarily addresses compatibility\u2014some systems are 32-bit while others are 64-bit."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: What is the purpose of the offset field in com_buf and graphic_buf?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: The offset field indicates the data's offset relative to the buffer's virtual or physical address. Combined with the address, it allows direct access to the desired data."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:['Q: What does the warning "No need to invalidate for uncached buffer" mean during invalid/flush operations?',"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: This warning indicates that invalidate/flush operations are unnecessary for uncached memory. You can check the memory's cacheability via its flags."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Are there memory allocation requirements for using hbmem_dmacpy\u2014e.g., must memory be allocated via hb_mem_alloc_com_buf or hbmem_alloc?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Memory allocated from Hbmem can be used directly via its virtual address. For non-Hbmem memory, use memcopy for copying."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: How can I check memory attributes?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: If you have a common buffer or graphic buffer structure, check its flags. If you only have a virtual address, use hb_mem_get_buf_info to retrieve the corresponding flags."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: If one heap fails to allocate, the system automatically tries another heap\u2014why does allocation failure still occur?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Fallback to another heap doesn't combine heaps; it attempts allocation in the other heap's space, which is still limited by that heap's total size. Each heap is managed independently, so allocatable size is constrained by each heap's available space."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq006-memory-sharing",children:"FAQ006: Memory Sharing"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: What information is transferred between processes during inter-process memory sharing?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: A complete com_buf or graph_buf structure is transferred."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: When passing com_buf from one process to another, must it be converted via an import interface before use?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Does import have a corresponding release operation that decrements the reference count?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes. Every import must be paired with a free operation. Continuous imports without frees will cause fd counts to exceed 1024."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Do different hardware components have distinct memory management APIs? Can their memories be converted and accessed mutually?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: In multi-process memory sharing, how can process A know if process B has released the imported buffer? Can hb_mem_get_share_info be used?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes. Use hb_mem_wait_share_status to wait until the client count returns to its pre-import value. Before importing, use hb_mem_get_share_info to check the current client count."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Why are both in_buf and out_buf needed during memory sharing import?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: During sharing, a new dma_buf must be created for the buffer with a new fd. Additionally, the shared memory might not occupy the entire buffer. Import also increments the buffer's underlying reference count."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Why does dma copy use memcopy instead of dmacopy for memory smaller than PAGE_SIZE?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Previously, dma copy had size restrictions, so memcopy was used for copies under 4K. Now, dma copy supports any size down to 1 byte."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Why must an imported buffer be released when no longer needed?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Import increments the buffer's reference count, while hb_mem_free_buf decrements it."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: How can a thread or process verify the validity of a received com_buf?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A: Users may need to check buffer validity\u2014if invalid, they should allocate a new one.",(0,i.jsx)(n.br,{}),"\n","For synchronized threads within the same process, use hb_mem_get_com_buf/hb_mem_get_graph_buf to retrieve buffer info from libhbmem and verify it matches the allocated buffer.",(0,i.jsx)(n.br,{}),"\n","For cross-process sharing, since libhbmem info is process-isolated, buffer validity cannot be confirmed via libhbmem interfaces."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: How to share only part of a buffer between processes?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A: If process A allocates an 8K buffer but wants to share only the last 4K with process B, it should set the physical address to PA+4KB and size to 4K when passing the buffer. After import, process B will get a virtual address starting at the mmap base plus a 4KB offset.",(0,i.jsx)(n.br,{}),"\n","Note: Setting offset won't achieve this\u2014after import, the virtual address will always be the mmap base address."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: If the buffer type (common/graphic) is unknown, how to get its ID? Must import always be called for inter-process sharing? What if the type is uncertain?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A: Use hb_mem_get_buf_type_and_buf_with_vaddr to get the buffer type and structure from the virtual address, then extract the share ID.",(0,i.jsx)(n.br,{}),"\n","Inter-process sharing always requires import\u2014otherwise, buffer safety during its lifetime isn't guaranteed, and virtual addresses from other processes are unusable without import (which generates a new virtual address)."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: With multiple addresses of uncertain allocation origin (common/graphic buffer or separate allocations), how should they be handled?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Use hb_mem_get_buf_type_and_buf_with_vaddr to determine the buffer type and structure from the virtual address, then import. The same buffer supports multiple imports."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: In special scenarios where process A allocates memory, stops using it, and transfers management to process B\u2014can B perform the actual release?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes. Once process A confirms process B has imported the buffer, A can release it. Then, when B releases the buffer, the memory is freed immediately\u2014effectively transferring buffer lifetime control to B."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq007-memory-queue-management",children:"FAQ007: Memory Queue Management"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: Earlier it was mentioned that memory queues are single-process, yet shared memory can be used for inter-process communication\u2014what exactly does memory queue management mean?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Memory sharing and memory queue management are separate features. Memory sharing allows an IP to pass a buffer directly to another process, which can then use import to access it. Memory queue management handles buffers within a single process\u2014for example, a server can create a buffer queue, add buffers to it, and clients can dequeue them, similar to a message queue. The queue isn't restricted to buffer info\u2014it can hold other data too."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq008-memory-pools",children:"FAQ008: Memory Pools"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: How to understand pre-allocating a large memory block for use, then managing it with a custom memory management queue?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Memory pool allocation first requests a large block from a heap. Subsequent allocations happen within this block without kernel involvement, making them much faster than direct API calls. Free operations return memory to the pool, which can be destroyed after use. For managing multiple allocated buffers, you can either implement your own queue or use our provided management queue."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: When using memory pools, must we pre-estimate total memory needs and reserve it at the application layer?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Can memory pools be used for inter-process operations?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Not recommended\u2014it's essentially a single buffer."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Are there size requirements for pool allocation?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: No specific requirements\u2014allocate as needed as long as space is available. Allocations are page-size aligned."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq009-software-performance",children:"FAQ009: Software Performance"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: How is Hbmem stability ensured?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Hbmem is based on ION. We conduct extensive testing\u2014including exception cases, long-term stability, and stress tests\u2014on both ION and Hbmem interfaces. Additionally, we validate allocation functionality in real-world scenarios like VIO, BPU, and codec."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: How are un-released allocations handled?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: First, if a process exits without releasing memory, the system automatically recovers it. Second, for running processes with leaks, you can check sys nodes to monitor the user's memory allocation status."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq010-memory-leaks",children:"FAQ010: Memory Leaks"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: Won't process termination cause memory leaks?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Normally, all memory is reclaimed upon process termination with no leaks. However, if process A allocates memory and shares it with process B (incrementing the usage count), terminating A won't free the memory\u2014it remains with B and is released only when B terminates."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq011-software-debugging",children:"FAQ011: Software Debugging"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: Are there diagnostic tools for these interfaces?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"A: Yes, use sys nodes for diagnostics:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"# Corresponds to HB_MEM_USAGE_PRIV_HEAP_DMA\ncat /sys/kernel/debug/ion/heaps/ion_cma\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"# Corresponds to HB_MEM_USAGE_PRIV_HEAP_RESERVED\ncat /sys/kernel/debug/ion/heaps/carveout\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"# Corresponds to HB_MEM_USAGE_PRIV_HEAP_2_RESERVED\ncat /sys/kernel/debug/ion/heaps/cma_reserved\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"# For all heap info\ncat /sys/kernel/debug/ion/heaps/all_heap_info\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:'cat /sys/kernel/debug/ion/clients/"client name"\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"faq012-module-usage",children:"FAQ012: Module Usage"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Q: Do modules like camera and pyramid output com_buf?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes\u2014all current system modules use com_buf with contiguous memory."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Q: Is the hbmem_alloc interface in hbmem.h discouraged?","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A: Yes\u2014it's the legacy interface kept for compatibility. If you have existing Hbmem-based code, you can use it; otherwise, use the new interfaces."}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>o});var r=s(96540);const i={},t=r.createContext(i);function a(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);