"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[23621],{1269:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>d,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"Algorithm_Application/C++_Sample/usb_camera","title":"USB Camera YOLOv5x Inference","description":"A real-time inference example of Ultralytics YOLOv5x based on the BPU, supporting reading frames from a USB camera, performing object detection, and visualizing detection results in full-screen mode. The sample code is located in the /app/cdevdemo/bpu/09usbcamerasample/ directory.","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/03_C++_Sample/13_usb_camera.md","sourceDirName":"04_Algorithm_Application/03_C++_Sample","slug":"/Algorithm_Application/C++_Sample/usb_camera","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/usb_camera","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1769771781000,"sidebarPosition":13,"frontMatter":{"sidebar_position":13},"sidebar":"tutorialSidebar","previous":{"title":"Text Detection and Recognition - PaddleOCR","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/PaddleOCR"},"next":{"title":"MIPI Camera YOLOv5x Inference","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/mipi_camera_yolov5x"}}');var s=i(74848),t=i(28453);const d={sidebar_position:13},l="USB Camera YOLOv5x Inference",o={},c=[{value:"Feature Description",id:"feature-description",level:2},{value:"Model Description",id:"model-description",level:2},{value:"Environment Dependencies",id:"environment-dependencies",level:2},{value:"Directory Structure",id:"directory-structure",level:2},{value:"Build the Project",id:"build-the-project",level:2},{value:"Parameter Description",id:"parameter-description",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Notes",id:"notes",level:2},{value:"License",id:"license",level:2}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"usb-camera-yolov5x-inference",children:"USB Camera YOLOv5x Inference"})}),"\n",(0,s.jsxs)(n.p,{children:["A real-time inference example of Ultralytics YOLOv5x based on the BPU, supporting reading frames from a USB camera, performing object detection, and visualizing detection results in full-screen mode. The sample code is located in the ",(0,s.jsx)(n.code,{children:"/app/cdev_demo/bpu/09_usb_camera_sample/"})," directory."]}),"\n",(0,s.jsx)(n.h2,{id:"feature-description",children:"Feature Description"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Model Loading"})}),"\n",(0,s.jsxs)(n.p,{children:["Load the specified ",(0,s.jsx)(n.code,{children:".hbm"})," model file and extract model-related metadata."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Camera Capture"})}),"\n",(0,s.jsxs)(n.p,{children:["Automatically scan devices under ",(0,s.jsx)(n.code,{children:"/dev/video*"}),", open the first available USB camera, and configure it to use MJPEG encoding, 1080p resolution, and 30 FPS."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Image Preprocessing"})}),"\n",(0,s.jsx)(n.p,{children:"Resize the BGR image to the model's input resolution (using letterbox mode or standard scaling) and convert it to NV12 format."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Inference Execution"})}),"\n",(0,s.jsxs)(n.p,{children:["Submit the input tensor via the ",(0,s.jsx)(n.code,{children:"infer()"})," method and perform forward computation on the BPU."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Post-processing"})}),"\n",(0,s.jsx)(n.p,{children:"Includes decoding quantized outputs, filtering candidate boxes (based on a score threshold), applying NMS for deduplication, and mapping bounding box coordinates back to the original image dimensions."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Visualization"})}),"\n",(0,s.jsx)(n.p,{children:"Draw detection boxes along with their class labels and confidence scores onto the image, and display the result in a full-screen window with support for real-time processing and exit control."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"model-description",children:"Model Description"}),"\n",(0,s.jsxs)(n.p,{children:["Refer to the ",(0,s.jsx)(n.a,{href:"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/Ultralytics_YOLOv5x#object-detection-ultralytics-yolov5x",children:"Ultralytics YOLOv5x Object Detection Example section"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"environment-dependencies",children:"Environment Dependencies"}),"\n",(0,s.jsx)(n.p,{children:"Before compiling and running, ensure the following dependencies are installed:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt update\nsudo apt install libgflags-dev\n"})}),"\n",(0,s.jsx)(n.h2,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:".\n|-- CMakeLists.txt                 # CMake build script: target/dependency/include/link configuration\n|-- README.md                      # Usage instructions (current file)\n|-- inc\n|   `-- ultralytics_yolov5x.hpp    # YOLOv5x inference wrapper header: interfaces for loading/preprocessing/inference/postprocessing\n`-- src\n    |-- main.cc                    # Program entry point: camera detection \u2192 frame capture \u2192 inference \u2192 drawing \u2192 display (full-screen window)\n    `-- ultralytics_yolov5x.cc     # Inference implementation: letterbox, NV12 tensor writing, decoding, NMS, and box coordinate restoration\n"})}),"\n",(0,s.jsx)(n.h2,{id:"build-the-project",children:"Build the Project"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Configuration and Compilation","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mkdir build && cd build\ncmake ..\nmake -j$(nproc)\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"parameter-description",children:"Parameter Description"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Parameter"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Default Value"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--video_device"})}),(0,s.jsxs)(n.td,{children:["Specify video device (e.g., ",(0,s.jsx)(n.code,{children:"/dev/video0"}),"; leave empty for auto-detection)"]}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:'""'})," (empty: automatically detect the first openable device under ",(0,s.jsx)(n.code,{children:"/dev/video*"}),")"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--model_path"})}),(0,s.jsxs)(n.td,{children:["Path to the BPU quantized model (",(0,s.jsx)(n.code,{children:".hbm"}),")"]}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--label_file"})}),(0,s.jsx)(n.td,{children:"Class label file (one class name per line)"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/app/res/labels/coco_classes.names"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--score_thres"})}),(0,s.jsx)(n.td,{children:"Confidence score threshold"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"0.25"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--nms_thres"})}),(0,s.jsx)(n.td,{children:"IoU threshold for NMS"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"0.45"})})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,s.jsx)(n.p,{children:"Note: This program must run in a desktop environment."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Run the model"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Ensure you are in the ",(0,s.jsx)(n.code,{children:"build"})," directory."]}),"\n",(0,s.jsxs)(n.li,{children:["Run with default parameters:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"./usb_camera\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Run with custom parameters:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"./usb_camera \\\n    --video_device /dev/video0 \\\n    --model_path /opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm \\\n    --label_file /app/res/labels/coco_classes.names \\\n    --score_thres 0.25 \\\n    --nms_thres 0.45\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Exit the program"})}),"\n",(0,s.jsxs)(n.p,{children:["Place your mouse cursor inside the display window and press the ",(0,s.jsx)(n.code,{children:"q"})," key to exit."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"View Results"})}),"\n",(0,s.jsx)(n.p,{children:"Upon successful execution, the screen will display real-time object detection results."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"This program must run in a desktop environment."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"For more information about deployment options or model support, please refer to the official documentation or contact platform technical support."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"license",children:"License"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-license",children:"Copyright (C) 2025, XiangshunZhao D-Robotics.\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as\npublished by the Free Software Foundation, either version 3 of the\nLicense, or (at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n"})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>d,x:()=>l});var r=i(96540);const s={},t=r.createContext(s);function d(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);