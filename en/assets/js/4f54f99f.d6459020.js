"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[52184],{28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>l});var s=i(96540);const t={},r=s.createContext(t);function o(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(r.Provider,{value:n},e.children)}},81390:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"Algorithm_Application/Python_Sample/Ultralytics_YOLOv5x","title":"Object Detection - Ultralytics YOLOv5x","description":"This example demonstrates how to perform object detection on images using a quantized Ultralytics YOLOv5x model on the BPU. It supports preprocessing, postprocessing, NMS (Non-Maximum Suppression), drawing bounding boxes, and saving results. The example code is located in the /app/pydevdemo/02detectionsample/01ultralytics_yolov5x/ directory.","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/02_Python_Sample/04_Ultralytics_YOLOv5x.md","sourceDirName":"04_Algorithm_Application/02_Python_Sample","slug":"/Algorithm_Application/Python_Sample/Ultralytics_YOLOv5x","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/Ultralytics_YOLOv5x","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770955066000,"sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Image Classification - MobileNetV2","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/MobileNetV2"},"next":{"title":"Object Detection - Ultralytics YOLO11","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/Ultralytics_YOLO11"}}');var t=i(74848),r=i(28453);const o={sidebar_position:4},l="Object Detection - Ultralytics YOLOv5x",c={},d=[{value:"Model Description",id:"model-description",level:2},{value:"Functionality Description",id:"functionality-description",level:2},{value:"Environment Dependencies",id:"environment-dependencies",level:2},{value:"Directory Structure",id:"directory-structure",level:2},{value:"Parameter Description",id:"parameter-description",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Notes",id:"notes",level:2},{value:"License",id:"license",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"object-detection---ultralytics-yolov5x",children:"Object Detection - Ultralytics YOLOv5x"})}),"\n",(0,t.jsxs)(n.p,{children:["This example demonstrates how to perform object detection on images using a quantized Ultralytics YOLOv5x model on the BPU. It supports preprocessing, postprocessing, NMS (Non-Maximum Suppression), drawing bounding boxes, and saving results. The example code is located in the ",(0,t.jsx)(n.code,{children:"/app/pydev_demo/02_detection_sample/01_ultralytics_yolov5x/"})," directory."]}),"\n",(0,t.jsx)(n.h2,{id:"model-description",children:"Model Description"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Overview"}),":"]}),"\n",(0,t.jsx)(n.p,{children:'Ultralytics YOLOv5x is a high-performance object detection model. The name "YOLO" stands for "You Only Look Once," enabling simultaneous object localization and classification in a single forward pass. YOLOv5x is the largest variant in the YOLOv5 series, featuring more network parameters and delivering high detection accuracy, making it suitable for scenarios demanding high precision. The model divides the input image into a grid and predicts multiple anchor boxes per grid cell, each with associated class probabilities and bounding box coordinates. This model has been quantized into the HBM format optimized for BPU chips, accepting NV12 input images of size 672\xd7672.'}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"HBM Model Name"}),": ",(0,t.jsx)(n.code,{children:"yolov5x_672x672_nv12.hbm"})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Input Format"}),": NV12, size 672x672 (separate Y and UV planes)"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": N bounding boxes, each represented as a triplet (class index, confidence score, bounding box coordinates)"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"functionality-description",children:"Functionality Description"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Model Loading"})}),"\n",(0,t.jsxs)(n.p,{children:["Load the quantized Ultralytics YOLOv5x model via ",(0,t.jsx)(n.code,{children:"hbm_runtime"}),", parsing model name, input/output names, shapes, and quantization parameters to prepare for inference."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Input Preprocessing"})}),"\n",(0,t.jsx)(n.p,{children:"Resize the input image to 672x672, convert it to NV12 format (with separate Y and UV planes), and organize the input as a nested dictionary to match the inference interface."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Inference Execution"})}),"\n",(0,t.jsxs)(n.p,{children:["Run inference using the ",(0,t.jsx)(n.code,{children:".run()"})," method, supporting configuration of inference priority and BPU core binding (e.g., core0/core1)."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Result Postprocessing"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Dequantize the output tensors;"}),"\n",(0,t.jsx)(n.li,{children:"Decode YOLO outputs to obtain predicted bounding boxes, confidence scores, and class indices;"}),"\n",(0,t.jsx)(n.li,{children:"Apply initial filtering based on a confidence score threshold;"}),"\n",(0,t.jsx)(n.li,{children:"Perform NMS (Non-Maximum Suppression) to remove redundant boxes;"}),"\n",(0,t.jsx)(n.li,{children:"Map predicted bounding box coordinates back to the original image dimensions;"}),"\n",(0,t.jsx)(n.li,{children:"Overlay detection boxes and save the resulting image."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"environment-dependencies",children:"Environment Dependencies"}),"\n",(0,t.jsxs)(n.p,{children:["This example has no special environment requirements\u2014just ensure the dependencies from ",(0,t.jsx)(n.code,{children:"pydev"})," are installed:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install -r ../../requirements.txt\n"})}),"\n",(0,t.jsx)(n.h2,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:".\n\u251c\u2500\u2500 ultralytics_yolov5x.py      # Main inference script\n\u2514\u2500\u2500 README.md                   # Usage instructions\n"})}),"\n",(0,t.jsx)(n.h2,{id:"parameter-description",children:"Parameter Description"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter"}),(0,t.jsx)(n.th,{children:"Description"}),(0,t.jsx)(n.th,{children:"Default Value"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--model-path"})}),(0,t.jsx)(n.td,{children:"Path to the model file (.hbm format)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--test-img"})}),(0,t.jsx)(n.td,{children:"Path to the test image"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/app/res/assets/kite.jpg"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--label-file"})}),(0,t.jsx)(n.td,{children:"Path to the class label file (one class per line)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/app/res/labels/coco_classes.names"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--img-save-path"})}),(0,t.jsx)(n.td,{children:"Path to save the detection result image"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"result.jpg"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--priority"})}),(0,t.jsx)(n.td,{children:"Model scheduling priority (0\u2013255)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"0"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--bpu-cores"})}),(0,t.jsxs)(n.td,{children:["List of BPU core IDs to use (e.g., ",(0,t.jsx)(n.code,{children:"--bpu-cores 0 1"}),")"]}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"[0]"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--nms-thres"})}),(0,t.jsx)(n.td,{children:"Non-Maximum Suppression (NMS) threshold"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"0.45"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--score-thres"})}),(0,t.jsx)(n.td,{children:"Confidence score threshold"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"0.25"})})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Run the model"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["With default parameters:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python ultralytics_yolov5x.py\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["With custom parameters:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python ultralytics_yolov5x.py \\\n    --model-path /opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm \\\n    --test-img /app/res/assets/kite.jpg \\\n    --label-file /app/res/labels/coco_classes.names \\\n    --img-save-path result.jpg \\\n    --priority 0 \\\n    --bpu-cores 0 \\\n    --nms-thres 0.45 \\\n    --score-thres 0.25\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"View Results"})}),"\n",(0,t.jsxs)(n.p,{children:["Upon successful execution, bounding boxes will be drawn on the input image and saved to the path specified by ",(0,t.jsx)(n.code,{children:"--img-save-path"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"[Saved] Result saved to: result.jpg\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["If the specified model path does not exist, try checking in ",(0,t.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"license",children:"License"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-license",children:"Copyright (C) 2025, XiangshunZhao D-Robotics.\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as\npublished by the Free Software Foundation, either version 3 of the\nLicense, or (at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}}}]);