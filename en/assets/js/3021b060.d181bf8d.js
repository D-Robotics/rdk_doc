"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[3481],{6775:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>m,frontMatter:()=>d,metadata:()=>t,toc:()=>u});const t=JSON.parse('{"id":"Robot_development/boxs/body/reid","title":"Human Instance Tracking Reid","description":"Introduction","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/05_Robot_development/03_boxs/body/reid.md","sourceDirName":"05_Robot_development/03_boxs/body","slug":"/Robot_development/boxs/body/reid","permalink":"/rdk_doc/en/Robot_development/boxs/body/reid","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1756548429000,"sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Human Detection and Tracking (Ultralytics YOLO Pose)","permalink":"/rdk_doc/en/Robot_development/boxs/body/mono2d_yolo_pose"},"next":{"title":"Road Structuring","permalink":"/rdk_doc/en/Robot_development/boxs/driver/parking_perception"}}');var i=o(74848),r=o(28453),s=o(11470),a=o(19365);const d={sidebar_position:7},l="Human Instance Tracking Reid",c={},u=[{value:"Introduction",id:"introduction",level:2},{value:"Supported Platforms",id:"supported-platforms",level:2},{value:"Preparation",id:"preparation",level:2},{value:"RDK",id:"rdk",level:3},{value:"Usage",id:"usage",level:2},{value:"RDK",id:"rdk-1",level:3},{value:"Result Analysis",id:"result-analysis",level:2}];function _(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"human-instance-tracking-reid",children:"Human Instance Tracking Reid"})}),"\n","\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsxs)(n.p,{children:["The reid package is a usage example based on ",(0,i.jsx)(n.a,{href:"https://github.com/KaiyangZhou/deep-person-reid.git",children:"Reid"})," quantification deployment. The image data comes from local image feedback and subscribed image msg. Reid relies on the input of the person's detection box. By extracting the person's feature which size is 1 x 512, we calculate the cosine distance with other's features in dataset get the similarity. Fianlly, we get the instance track id."]}),"\n",(0,i.jsxs)(n.p,{children:["Code repository:  (",(0,i.jsx)(n.a,{href:"https://github.com/D-Robotics/reid.git",children:"https://github.com/D-Robotics/reid.git"}),")"]}),"\n",(0,i.jsx)(n.p,{children:"Application scenario: body tracking, body instance detection."}),"\n",(0,i.jsx)(n.h2,{id:"supported-platforms",children:"Supported Platforms"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Platform"}),(0,i.jsx)(n.th,{children:"System"}),(0,i.jsx)(n.th,{children:"Function"})]})}),(0,i.jsx)(n.tbody,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"RDK X5"}),(0,i.jsx)(n.td,{children:"Ubuntu 22.04 (Humble)"}),(0,i.jsx)(n.td,{children:"Start MIPI/USB camera/local image offline, inference rendering results displayed/saved locally on the Web"})]})})]}),"\n",(0,i.jsx)(n.h2,{id:"preparation",children:"Preparation"}),"\n",(0,i.jsx)(n.h3,{id:"rdk",children:"RDK"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The RDK has burned the Ubuntu 22.04 system image provided by D-Robotics."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The RDK has successfully installed TogetheROS.Bot."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,i.jsx)(n.p,{children:'The package publishes algorithm messages that include detection and track id information, and users can subscribe to the message "/perception/detection/reid" for application development.'}),"\n",(0,i.jsx)(n.h3,{id:"rdk-1",children:"RDK"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Publishing images from MIPI camera"})}),"\n",(0,i.jsx)(s.A,{groupId:"tros-distro",children:(0,i.jsx)(a.A,{value:"humble",label:"Humble",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n\n# Copy the configuration file required for running the example from the installation path of tros.b.\ncp -r /opt/tros/${TROS_DISTRO}/lib/reid/config/ .\n\n# Configuring MIPI camera\nexport CAM_TYPE=mipi\n\n# Start the launch file\nros2 launch reid reid.launch.py \n"})})})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Publishing images from USB camera"})}),"\n",(0,i.jsx)(s.A,{groupId:"tros-distro",children:(0,i.jsx)(a.A,{value:"humble",label:"Humble",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n\n# Copy the configuration file required for running the example from the installation path of tros.b.\ncp -r /opt/tros/${TROS_DISTRO}/lib/reid/config/ .\n\n# Configuring USB camera\nexport CAM_TYPE=usb\n\n# Start the launch file\nros2 launch reid reid.launch.py \n"})})})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Using a single image offline"})}),"\n",(0,i.jsx)(s.A,{groupId:"tros-distro",children:(0,i.jsx)(a.A,{value:"humble",label:"Humble",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n\n# Copy the configuration file required for running the example from the installation path of tros.b.\ncp -r /opt/tros/${TROS_DISTRO}/lib/reid/config/ .\n\n# Configure the local playback image.\nexport CAM_TYPE=fb\n\n# Start the launch file\nros2 launch reid reid.launch.py \n"})})})}),"\n",(0,i.jsx)(n.h2,{id:"result-analysis",children:"Result Analysis"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Using a image publish tool to publish images"})}),"\n",(0,i.jsx)(n.p,{children:"After the package is initialized, the following information will be displayed in the terminal:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"[INFO] [launch]: All log files can be found below /root/.ros/log/2025-07-28-12-05-31-492990-ubuntu-24131\n[INFO] [launch]: Default logging verbosity is set to INFO\ncamera_type is  fb\nusing feedback\nHobot shm pkg enables zero-copy with fastrtps profiles file: /opt/tros/humble/lib/hobot_shm/config/shm_fastdds.xml\nHobot shm pkg sets RMW_FASTRTPS_USE_QOS_FROM_XML: 1\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nwebserver has launch\ncamera_type is  fb\nusing feedback\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nwebserver has launch\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nenv of RMW_FASTRTPS_USE_QOS_FROM_XML is  1 , ignore env setting\nwebserver has launch\n[INFO] [hobot_image_pub-1]: process started with pid [24147]\n[INFO] [hobot_codec_republish-2]: process started with pid [24149]\n[INFO] [mono2d_body_detection-3]: process started with pid [24151]\n[INFO] [websocket-4]: process started with pid [24153]\n[INFO] [reid-5]: process started with pid [24155]\n[hobot_codec_republish-2] [WARN] [1753675532.073298709] [hobot_codec_decoder]: Parameters:\n[hobot_codec_republish-2] sub_topic: /image\n[hobot_codec_republish-2] pub_topic: /hbmem_img\n[hobot_codec_republish-2] channel: 1\n[hobot_codec_republish-2] in_mode: ros\n[hobot_codec_republish-2] out_mode: shared_mem\n[hobot_codec_republish-2] in_format: jpeg\n[hobot_codec_republish-2] out_format: nv12\n[hobot_codec_republish-2] enc_qp: 10\n[hobot_codec_republish-2] jpg_quality: 60\n[hobot_codec_republish-2] input_framerate: 30\n[hobot_codec_republish-2] output_framerate: -1\n[hobot_codec_republish-2] dump_output: 0\n[hobot_codec_republish-2] [WARN] [1753675532.084413614] [HobotCodecImpl]: platform x5\n[mono2d_body_detection-3] [WARN] [1753675532.729885121] [mono2d_body_det]: Parameter:\n[mono2d_body_detection-3]  is_sync_mode_: 0\n[mono2d_body_detection-3]  model_file_name_: config/multitask_body_head_face_hand_kps_960x544.hbm\n[mono2d_body_detection-3]  is_shared_mem_sub: 1\n[mono2d_body_detection-3]  ai_msg_pub_topic_name: /hobot_mono2d_body_detection\n[mono2d_body_detection-3]  ros_img_topic_name: /image_raw\n[mono2d_body_detection-3]  image_gap: 1\n[mono2d_body_detection-3] [BPU_PLAT]BPU Platform Version(1.3.6)!\n[mono2d_body_detection-3] [HBRT] set log level as 0. version = 3.15.55.0\n[mono2d_body_detection-3] [DNN] Runtime version = 1.24.5_(3.15.55 HBRT)\n[websocket-4] [WARN] [1753675532.786307105] [websocket]:\n[websocket-4] Parameter:\n[websocket-4]  image_topic: /image\n[websocket-4]  image_type: mjpeg\n[websocket-4]  only_show_image: 0\n[websocket-4]  smart_topic: /perception/detection/reid\n[websocket-4]  output_fps: 0\n[reid-5] [WARN] [1753675532.797354134] [reid_node]: Parameter:\n[reid-5]  feed_type(0:local, 1:sub): 1\n[reid-5]  db_file: reid.db\n[reid-5]  model_file_name: config/reid.bin\n[reid-5]  dump_render_img: 0\n[reid-5]  is_sync_mode: 1\n[reid-5]  is_shared_mem_sub: 1\n[reid-5]  threshold: 0.7\n[reid-5]  ai_msg_pub_topic_name: /perception/detection/reid\n[reid-5]  ai_msg_sub_topic_name: /hobot_mono2d_body_detection\n[reid-5]  ros_img_topic_name: /image_raw\n[reid-5]  sharedmem_img_topic_name: /hbmem_img\n[reid-5] [BPU_PLAT]BPU Platform Version(1.3.6)!\n[reid-5] [HBRT] set log level as 0. version = 3.15.55.0\n[reid-5] [DNN] Runtime version = 1.24.5_(3.15.55 HBRT)\n[hobot_image_pub-1] [WARN] [1753675532.819144234] [image_pub_node]: parameter:\n[hobot_image_pub-1] image_source: config/person_body.jpg\n[hobot_image_pub-1] source_image_w: 960\n[hobot_image_pub-1] source_image_h: 544\n[hobot_image_pub-1] output_image_w: 1920\n[hobot_image_pub-1] output_image_h: 1080\n[hobot_image_pub-1] fps: 10\n[hobot_image_pub-1] is_shared_mem: 0\n[hobot_image_pub-1] is_loop: 1\n[hobot_image_pub-1] is_compressed_img_pub: 1\n[hobot_image_pub-1] image_format: jpg\n[hobot_image_pub-1] pub_encoding: nv12pub_name_mode: 0\n[hobot_image_pub-1] msg_pub_topic_name: /image\n[mono2d_body_detection-3] [WARN] [1753675532.965378414] [mono2d_body_det]: Enabling zero-copy\n[mono2d_body_detection-3] [WARN] [1753675532.965547956] [mono2d_body_det]: Create hbmem_subscription with topic_name: /hbmem_img\n[mono2d_body_detection-3] (MOTMethod.cpp:39): MOTMethod::Init config/iou2_euclid_method_param.json\n[mono2d_body_detection-3]\n[mono2d_body_detection-3] (IOU2.cpp:34): IOU2 Mot::Init config/iou2_euclid_method_param.json\n[mono2d_body_detection-3]\n[mono2d_body_detection-3] (MOTMethod.cpp:39): MOTMethod::Init config/iou2_method_param.json\n[mono2d_body_detection-3]\n[mono2d_body_detection-3] (IOU2.cpp:34): IOU2 Mot::Init config/iou2_method_param.json\n[mono2d_body_detection-3]\n[mono2d_body_detection-3] (MOTMethod.cpp:39): MOTMethod::Init config/iou2_method_param.json\n[mono2d_body_detection-3]\n[mono2d_body_detection-3] (IOU2.cpp:34): IOU2 Mot::Init config/iou2_method_param.json\n[mono2d_body_detection-3]\n[mono2d_body_detection-3] (MOTMethod.cpp:39): MOTMethod::Init config/iou2_method_param.json\n[mono2d_body_detection-3]\n[mono2d_body_detection-3] (IOU2.cpp:34): IOU2 Mot::Init config/iou2_method_param.json\n[mono2d_body_detection-3]\n[reid-5] [A][DNN][packed_model.cpp:247][Model](2025-07-28,12:05:32.926.316) [HorizonRT] The model builder version = 1.24.4\n[reid-5] [WARN] [1753675533.102411862] [reid_node]: Create hbmem_subscription with topic_name: /hbmem_img\n[mono2d_body_detection-3] [WARN] [1753675533.132823359] [mono2d_body_det]: Loaned messages are only safe with const ref subscription callbacks. If you are using any other kind of subscriptions, set the ROS_DISABLE_LOANED_MESSAGES environment variable to 1 (the default).\n[mono2d_body_detection-3] [WARN] [1753675533.133154735] [mono2d_body_det]: SharedMemImgProcess Recved img encoding: nv12, h: 1088, w: 1920, step: 1920, index: 0, stamp: 1753675533_58950288, data size: 3133440, comm delay [74.1792]ms\n[reid-5] [WARN] [1753675533.132964485] [reid_node]: Loaned messages are only safe with const ref subscription callbacks. If you are using any other kind of subscriptions, set the ROS_DISABLE_LOANED_MESSAGES environment variable to 1 (the default).\n[mono2d_body_detection-3] [W][DNN]bpu_model_info.cpp:491][Version](2025-07-28,12:05:32.951.571) Model: multitask_body_head_face_hand_kps_960x544. Inconsistency between the hbrt library version 3.15.55.0 and the model build version 3.15.47.0 detected, in order to ensure correct model results, it is recommended to use compilation tools and the BPU SDK from the same OpenExplorer package.\n[reid-5] [WARN] [1753675533.492897025] [reid_fet_manage]:\n[reid-5] [WARN] [1753675533.503463345] [reid_fet_manage]: Query failed, storage: 1.\n[reid-5] [WARN] [1753675533.504189180] [reid_fet_manage]:\n[reid-5] id: 0, item similarity: 0.490674\n[reid-5] id: 1, item similarity: 0.490674\n[reid-5] [WARN] [1753675533.519353762] [reid_fet_manage]: Query failed, storage: 2.\n[reid-5] [WARN] [1753675533.520454765] [reid_fet_manage]:\n[reid-5] id: 0, item similarity: 0.428227\n[reid-5] id: 1, item similarity: 0.428227\n[reid-5] id: 2, item similarity: 0.424104\n[reid-5] [WARN] [1753675533.534144760] [reid_fet_manage]: Query failed, storage: 3.\n[reid-5] [WARN] [1753675533.535162346] [reid_fet_manage]:\n[reid-5] id: 0, item similarity: 0.410272\n[reid-5] id: 1, item similarity: 0.410272\n[reid-5] id: 2, item similarity: 0.519591\n[reid-5] id: 3, item similarity: 0.432213\n[reid-5] [WARN] [1753675533.547124461] [reid_fet_manage]: Query failed, storage: 4.\n[reid-5] [WARN] [1753675533.548487965] [reid_fet_manage]:\n[reid-5] id: 0, item similarity: 0.480041\n[reid-5] id: 1, item similarity: 0.480041\n[reid-5] id: 2, item similarity: 0.369116\n[reid-5] id: 3, item similarity: 0.475912\n[reid-5] id: 4, item similarity: 0.568766\n[reid-5] [WARN] [1753675533.565484010] [reid_fet_manage]: Query failed, storage: 5.\n[mono2d_body_detection-3] [WARN] [1753675534.191426925] [mono2d_body_det]: input fps: 11.68, out fps: 11.71, infer time ms: 85, post process time ms: 2\n[reid-5] [WARN] [1753675534.696986895] [reid_node]: input fps: 4.00, out fps: 4.15, infer time ms: 240, post process time ms: 0\n[mono2d_body_detection-3] [WARN] [1753675536.166313555] [mono2d_body_det]: SharedMemImgProcess Recved img encoding: nv12, h: 1088, w: 1920, step: 1920, index: 31, stamp: 1753675536_158953660, data size: 3133440, comm delay [7.3511]ms\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Using single image offline"})}),"\n",(0,i.jsxs)(n.p,{children:["The result will be rendered on web. On the PC-side browser, you can view the image and algorithm rendering effect by entering ",(0,i.jsx)(n.a,{href:"http://IP:8000",children:"http://IP:8000"})," (IP is the IP address of the RDK), and open the settings in the upper right corner of the interface."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/03_boxs/function/image/box_adv/render_reid.png",alt:""})})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(_,{...e})}):_(e)}},11470:(e,n,o)=>{o.d(n,{A:()=>R});var t=o(96540),i=o(34164),r=o(23104),s=o(56347),a=o(205),d=o(57485),l=o(31682),c=o(70679);function u(e){return t.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function _(e){const{values:n,children:o}=e;return(0,t.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:o,default:t}})=>({value:e,label:n,attributes:o,default:t}))}(o);return function(e){const n=(0,l.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,o])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function h({queryString:e=!1,groupId:n}){const o=(0,s.W6)(),i=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,d.aZ)(i),(0,t.useCallback)(e=>{if(!i)return;const n=new URLSearchParams(o.location.search);n.set(i,e),o.replace({...o.location,search:n.toString()})},[i,o])]}function p(e){const{defaultValue:n,queryString:o=!1,groupId:i}=e,r=_(e),[s,d]=(0,t.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const o=n.find(e=>e.default)??n[0];if(!o)throw new Error("Unexpected error: 0 tabValues");return o.value}({defaultValue:n,tabValues:r})),[l,u]=h({queryString:o,groupId:i}),[p,b]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[o,i]=(0,c.Dv)(n);return[o,(0,t.useCallback)(e=>{n&&i.set(e)},[n,i])]}({groupId:i}),g=(()=>{const e=l??p;return m({value:e,tabValues:r})?e:null})();(0,a.A)(()=>{g&&d(g)},[g]);return{selectedValue:s,selectValue:(0,t.useCallback)(e=>{if(!m({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);d(e),u(e),b(e)},[u,b,r]),tabValues:r}}var b=o(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var f=o(74848);function y({className:e,block:n,selectedValue:o,selectValue:t,tabValues:s}){const a=[],{blockElementScrollPositionUntilNextRender:d}=(0,r.a_)(),l=e=>{const n=e.currentTarget,i=a.indexOf(n),r=s[i].value;r!==o&&(d(n),t(r))},c=e=>{let n=null;switch(e.key){case"Enter":l(e);break;case"ArrowRight":{const o=a.indexOf(e.currentTarget)+1;n=a[o]??a[0];break}case"ArrowLeft":{const o=a.indexOf(e.currentTarget)-1;n=a[o]??a[a.length-1];break}}n?.focus()};return(0,f.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":n},e),children:s.map(({value:e,label:n,attributes:t})=>(0,f.jsx)("li",{role:"tab",tabIndex:o===e?0:-1,"aria-selected":o===e,ref:e=>{a.push(e)},onKeyDown:c,onClick:l,...t,className:(0,i.A)("tabs__item",g.tabItem,t?.className,{"tabs__item--active":o===e}),children:n??e},e))})}function v({lazy:e,children:n,selectedValue:o}){const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=r.find(e=>e.props.value===o);return e?(0,t.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,f.jsx)("div",{className:"margin-top--md",children:r.map((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==o}))})}function x(e){const n=p(e);return(0,f.jsxs)("div",{className:(0,i.A)("tabs-container",g.tabList),children:[(0,f.jsx)(y,{...n,...e}),(0,f.jsx)(v,{...n,...e})]})}function R(e){const n=(0,b.A)();return(0,f.jsx)(x,{...e,children:u(e.children)},String(n))}},19365:(e,n,o)=>{o.d(n,{A:()=>s});o(96540);var t=o(34164);const i={tabItem:"tabItem_Ymn6"};var r=o(74848);function s({children:e,hidden:n,className:o}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,t.A)(i.tabItem,o),hidden:n,children:e})}},28453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>a});var t=o(96540);const i={},r=t.createContext(i);function s(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);