"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[93927],{28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>l});var s=i(96540);const d={},r=s.createContext(d);function o(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(d):e.components||d:o(e.components),s.createElement(r.Provider,{value:n},e.children)}},77884:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>t,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"Basic_Application/multi_media/cdev_demo","title":"3.4.2 Reference Examples (C++)","description":"This section introduces multiple functional examples for multimedia library development, including camera image capture, video encoding/decoding, video display, algorithm inference, and other features.","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/03_Basic_Application/04_multi_media/cdev_demo.md","sourceDirName":"03_Basic_Application/04_multi_media","slug":"/Basic_Application/multi_media/cdev_demo","permalink":"/rdk_doc/en/rdk_s/Basic_Application/multi_media/cdev_demo","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1764174115000,"sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"3.4.1 Reference Examples (Python)","permalink":"/rdk_doc/en/rdk_s/Basic_Application/multi_media/pydev_vio_demo"},"next":{"title":"Camera Object","permalink":"/rdk_doc/en/rdk_s/Basic_Application/multi_media/multi_media_api/pydev/object_camera"}}');var d=i(74848),r=i(28453);const o={sidebar_position:2},l="3.4.2 Reference Examples (C++)",t={},a=[{value:"Camera Image Capture and Display",id:"camera-image-capture-and-display",level:2},{value:"Local Saving of Camera Images",id:"local-saving-of-camera-images",level:2},{value:"Camera Image Capture and Encoding",id:"camera-image-capture-and-encoding",level:2},{value:"Video File Decoding and Display",id:"video-file-decoding-and-display",level:2},{value:"RTSP Stream Pulling and Decoding",id:"rtsp-stream-pulling-and-decoding",level:2},{value:"VPS Scaling Example",id:"vps-scaling-example",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,d.jsxs)(d.Fragment,{children:[(0,d.jsx)(n.header,{children:(0,d.jsx)(n.h1,{id:"342-reference-examples-c",children:"3.4.2 Reference Examples (C++)"})}),"\n",(0,d.jsx)(n.p,{children:"This section introduces multiple functional examples for multimedia library development, including camera image capture, video encoding/decoding, video display, algorithm inference, and other features."}),"\n",(0,d.jsx)(n.h2,{id:"camera-image-capture-and-display",children:"Camera Image Capture and Display"}),"\n",(0,d.jsxs)(n.p,{children:["The ",(0,d.jsx)(n.code,{children:"vio2display"})," example implements image capture from a ",(0,d.jsx)(n.code,{children:"MIPI"})," camera and outputs the video via an ",(0,d.jsx)(n.code,{children:"HDMI"})," interface, allowing users to preview the live feed on a monitor."]}),"\n",(0,d.jsx)(n.p,{children:"Example flow diagram:"}),"\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/04_multi_media/image/cdev_demo/s100/image-vio_to_display.png",alt:"image-vio_to_display"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"Environment Setup:"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["With the development board powered off, connect the ",(0,d.jsx)(n.code,{children:"MIPI"})," camera to the board. Currently, this sample only supports MIPI sensors: IMX219, SC230AI."]}),"\n",(0,d.jsx)(n.li,{children:"Connect the development board to a monitor using an HDMI cable."}),"\n",(0,d.jsx)(n.li,{children:"Power on the development board and log in via the command line."}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Execution Method:"}),"\nThe example code is provided in source form and must be compiled using the ",(0,d.jsx)(n.code,{children:"make"})," command before running. Follow these steps:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:~$ cd /app/cdev_demo/vio2display\nsunrise@ubuntu:/app/cdev_demo/vio2display$ make\nsunrise@ubuntu:/app/cdev_demo/vio2display$ ./vio2display -w 1920 -h 1080\n"})}),"\n",(0,d.jsx)(n.p,{children:"Parameter descriptions:"}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-w"}),": Sensor output width"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-h"}),": Sensor output height"]}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Expected Result:"}),"\nAfter successful execution, the development board outputs the real-time video captured by the ",(0,d.jsx)(n.code,{children:"MIPI"})," camera to the connected monitor. Sample log output:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:/app/cdev_demo/vio2display$ ./vio2display -w 1920 -h 1080\n[UCP]: log level = 3\n[UCP]: UCP version = 3.7.3\n[VP]: log level = 3\n[DNN]: log level = 3\n[HPL]: log level = 3\n[UCPT]: log level = 6\ndisp_w=1920, disp_h=1080\n2025/06/16 10:12:21.574 !INFO [CamInitParam][0295]set camera fps: -1,width: 1920,height: 1080\nmipi mclk is not configed.\nSearching camera sensor on device: /proc/device-tree/soc/vcon@0 i2c bus: 1 mipi rx phy: 0\nWARN: Sensor Name: ar0820std-30fps, Expected Chip ID: 0xCB34, Actual Chip ID Read: 0x00\n[0] INFO: Found sensor name:imx219-30fps on mipi rx csi 0, i2c addr 0x10, config_file:linear_1920x1080_raw10_30fps_1lane.c\n2025/06/16 10:12:21.575 !INFO [CamInitPymParam][0258]Setting PYM channel:0: crop_x:0, crop_y:0, input_width:1920, input_height:1080, dst_w:1920, dst_h:1080\nsp_open_camera success!\n2025/06/16 10:12:21.727 !INFO [OpenDisplay][0111]Wayland is available, using Wayland for rendering.\nUsing default socket path: /run/user/1000/wayland-0\nPress 'q' to Exit !\n"})}),"\n"]}),"\n"]}),"\n",(0,d.jsx)(n.h2,{id:"local-saving-of-camera-images",children:"Local Saving of Camera Images"}),"\n",(0,d.jsxs)(n.p,{children:["The ",(0,d.jsx)(n.code,{children:"vio_capture"})," example captures images from a MIPI camera and saves them locally in both RAW and YUV formats. The example flow diagram is as follows:"]}),"\n",(0,d.jsx)(n.p,{children:"Example flow diagram:"}),"\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/04_multi_media/image/cdev_demo/s100/image-vio_capture.png",alt:"image-vio_capture.png"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"Environment Setup:"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["With the development board powered off, connect the ",(0,d.jsx)(n.code,{children:"MIPI"})," camera to the board. Currently, this sample only supports MIPI sensors: IMX219, SC230AI."]}),"\n",(0,d.jsx)(n.li,{children:"Power on the development board and log in via the command line."}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Execution Method:"}),"\nThe example code is provided in source form and must be compiled using the ",(0,d.jsx)(n.code,{children:"make"})," command before running. Follow these steps:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:~$ cd /app/cdev_demo/vio_capture/\nsunrise@ubuntu:/app/cdev_demo/vio_capture$ make\nsunrise@ubuntu:/app/cdev_demo/vio_capture$ ./capture -b 10 -c 10 -w 1920 -h 1080\n"})}),"\n",(0,d.jsx)(n.p,{children:"Parameter descriptions:"}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-b"}),": Bit depth of the RAW image. For example, IMX219 supports RAW10 format, so the bit depth is 10. Refer to the ",(0,d.jsx)(n.a,{href:"http://sysgbj2.hobot.cc/rdk_doc/rdk_s/Advanced_development/hardware_development/accessory",children:"Accessory List"})," for supported sensor formats."]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-c"}),": Number of images to save. The interval between capturing each image is typically 1/fps."]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-w"}),": Width of the saved images"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-h"}),": Height of the saved images"]}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Expected Result:"}),"\nAfter successful execution, the specified number of image files are saved in the current directory. RAW format files are named ",(0,d.jsx)(n.code,{children:"raw_*.raw"}),", and YUV format files are named ",(0,d.jsx)(n.code,{children:"yuv_*.yuv"}),". Sample log output:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:/app/cdev_demo/vio_capture$ ./capture -b 10 -c 10 -w 1920 -h 1080\n[UCP]: log level = 3\n[UCP]: UCP version = 3.7.3\n[VP]: log level = 3\n[DNN]: log level = 3\n[HPL]: log level = 3\n[UCPT]: log level = 6\n2025/06/04 22:24:22.139 !INFO [CamInitParam][0296]set camera fps: -1,width: 1920,height: 1080\n\nmipi mclk is not configed.\nSearching camera sensor on device: /proc/device-tree/soc/vcon@0 i2c bus: 1 mipi rx phy: 0\nWARN: Sensor Name: ar0820std-30fps, Expected Chip ID: 0xCB34, Actual Chip ID Read: 0x00\n[0] INFO: Found sensor name:imx219-30fps on mipi rx csi 0, i2c addr 0x10, config_file:linear_1920x1080_raw10_30fps_1lane.c\n2025/06/04 22:24:22.140 !INFO [CamInitPymParam][0259]Setting PYM channel:0: crop_x:0, crop_y:0, input_width:1920, input_height:1080, dst_w:1920, dst_h:1080\ncapture time :0\ntemp_ptr.data_size[0]:2592000\n... omitted ...\ncapture time :9\ntemp_ptr.data_size[0]:2592000\n"})}),"\n"]}),"\n"]}),"\n",(0,d.jsx)(n.h2,{id:"camera-image-capture-and-encoding",children:"Camera Image Capture and Encoding"}),"\n",(0,d.jsxs)(n.p,{children:["The ",(0,d.jsx)(n.code,{children:"vio2encoder"})," example captures images from a ",(0,d.jsx)(n.code,{children:"MIPI"})," camera, encodes them, and saves the encoded video locally."]}),"\n",(0,d.jsx)(n.p,{children:"Example flow diagram:"}),"\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/04_multi_media/image/cdev_demo/s100/image-vio_to_encode.png",alt:"image-vio_to_encoder"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"Environment Setup:"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["With the development board powered off, connect the ",(0,d.jsx)(n.code,{children:"MIPI"})," camera to the board. Currently, this sample only supports MIPI sensors: IMX219, SC230AI."]}),"\n",(0,d.jsx)(n.li,{children:"Power on the development board and log in via the command line."}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Execution Method:"})," Run the program using the following commands. The example code is provided in source form and must be compiled using the ",(0,d.jsx)(n.code,{children:"make"})," command before running. Follow these steps:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:~$ cd /app/cdev_demo/vio2encoder\nsunrise@ubuntu:/app/cdev_demo/vio2encoder$ make\nsunrise@ubuntu:/app/cdev_demo/vio2encoder$ ./vio2encoder -w 1920 -h 1080 --iwidth 1920 --iheight 1080 -o stream.h264\n"})}),"\n",(0,d.jsx)(n.p,{children:"Parameter descriptions:"}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-w"}),": Encoded video width"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-h"}),": Encoded video height"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"--iwidth"}),": Sensor output width"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"--iheight"}),": Sensor output height"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-o"}),": Output path for the encoded video"]}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Expected Result:"}),"\nAfter successful execution, a video file named ",(0,d.jsx)(n.code,{children:"stream.h264"})," is generated in the current directory. Sample log output:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:/app/cdev_demo/vio2encoder$  ./vio2encoder -w 1920 -h 1080 --iwidth 1920 --iheight 1080 -o stream.h264\n[UCP]: log level = 3\n[UCP]: UCP version = 3.7.3\n[VP]: log level = 3\n[DNN]: log level = 3\n[HPL]: log level = 3\n[UCPT]: log level = 6\n2025/06/16 11:04:37.628 !INFO [CamInitParam][0295]set camera fps: -1,width: 1920,height: 1080\n\nmipi mclk is not configed.\nSearching camera sensor on device: /proc/device-tree/soc/vcon@0 i2c bus: 1 mipi rx phy: 0\nWARN: Sensor Name: ar0820std-30fps, Expected Chip ID: 0xCB34, Actual Chip ID Read: 0x00\n[0] INFO: Found sensor name:imx219-30fps on mipi rx csi 0, i2c addr 0x10, config_file:linear_1920x1080_raw10_30fps_1lane.c\n2025/06/16 11:04:37.629 !INFO [CamInitPymParam][0258]Setting PYM channel:0: crop_x:0, crop_y:0, input_width:1920, input_height:1080, dst_w:1920, dst_h:1080\nsp_open_camera success!\n2025/06/16 11:04:37.770 !INFO [vp_encode_config_param][0408]codec type is h264: frame size:3110912  frame rate: 30\nsp_start_encode success!\nsp_module_bind(vio -> encoder) success!\n^C\nrecv:2,Stoping...\n"})}),"\n"]}),"\n"]}),"\n",(0,d.jsx)(n.h2,{id:"video-file-decoding-and-display",children:"Video File Decoding and Display"}),"\n",(0,d.jsxs)(n.p,{children:["The ",(0,d.jsx)(n.code,{children:"decoder2display"})," example decodes a video file and outputs it via the ",(0,d.jsx)(n.code,{children:"HDMI"})," interface, allowing users to preview the video on a monitor."]}),"\n",(0,d.jsx)(n.p,{children:"Example flow diagram:"}),"\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/04_multi_media/image/cdev_demo/s100/image-decoder_to_display.png",alt:"image-decoder_to_display"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"Environment Setup:"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsx)(n.li,{children:"Connect the development board to a monitor using an HDMI cable."}),"\n",(0,d.jsx)(n.li,{children:"Power on the development board and log in via the command line."}),"\n",(0,d.jsxs)(n.li,{children:["Prepare an encoded video file ",(0,d.jsx)(n.code,{children:"stream.h264"})," as input."]}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Execution Method:"}),"\nThe example code is provided in source form and must be compiled using the ",(0,d.jsx)(n.code,{children:"make"})," command before running. Follow these steps:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:~$ cd /app/cdev_demo/decode2display\nsunrise@ubuntu:/app/cdev_demo/decode2display$ make\nsunrise@ubuntu:/app/cdev_demo/decode2display$ ./decoder2display -w 1920 -h 1080 -i /app/res/assets/1080P_test.h264\n"})}),"\n",(0,d.jsx)(n.p,{children:"Parameter descriptions:"}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-h"}),": Height of the video file"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-w"}),": Width of the video file"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-i"}),": Path to the video file"]}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Expected Result:"})," After the program runs correctly, the video will be output through the development board's ",(0,d.jsx)(n.code,{children:"HDMI"})," interface, and users can preview the video on a monitor. The runtime log is as follows:"]}),"\n"]}),"\n"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:/app/cdev_demo/decode2display$ ./decoder2display -w 1920 -h 1080 -i /app/res/assets/1080P_test.h264\n[UCP]: log level = 3\n[UCP]: UCP version = 3.7.3\n[VP]: log level = 3\n[DNN]: log level = 3\n[HPL]: log level = 3\n[UCPT]: log level = 6\ndisp_w=1920, disp_h=1080\nsp_start_decode success!\n2025/06/16 10:48:49.220 !WARN [sp_start_display][0049]Warning: Using vot_chn values 0-3 is deprecated. Defaulting to HDMI mode.\n2025/06/16 10:48:49.221 !WARN [sp_start_display][0050]Please use the new method: pass 10 for DisplayPort (DP) or 11 for HDMI.\n2025/06/16 10:48:49.221 !INFO [OpenDisplay][0111]Wayland is available, using Wayland for rendering.\n\nUsing default socket path: /run/user/1000/wayland-0\nsp_start_display success!\n"})}),"\n",(0,d.jsx)(n.h2,{id:"rtsp-stream-pulling-and-decoding",children:"RTSP Stream Pulling and Decoding"}),"\n",(0,d.jsxs)(n.p,{children:["This example, ",(0,d.jsx)(n.code,{children:"rtsp2display"}),", implements the functionality of pulling an ",(0,d.jsx)(n.code,{children:"rtsp"})," stream, decoding it, and outputting the video via ",(0,d.jsx)(n.code,{children:"HDMI"}),", allowing users to preview the on a monitor."]}),"\n",(0,d.jsx)(n.p,{children:"Example workflow diagram:"}),"\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/04_multi_media/image/cdev_demo/s100/image-rtsp_to_display.png",alt:"rtsp2display"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"Environment Setup:"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsx)(n.p,{children:"Connect the development board to a monitor using an HDMI cable."}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsx)(n.p,{children:"Power on the development board and log in via command line."}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:["Prepare an ",(0,d.jsx)(n.code,{children:"rtsp"})," stream as the input source using the pre-installed streaming service. This service converts the ",(0,d.jsx)(n.code,{children:"1080P_test.h264"})," video file into an RTSP stream with the URL ",(0,d.jsx)(n.code,{children:"rtsp://127.0.0.1/assets/1080P_test.h264"}),". Users can start the streaming service with the following commands:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-text",children:"cd /app/res\nsunrise@ubuntu:/app/res# sudo chmod +x live555MediaServer\nsunrise@ubuntu:/app/res# sudo ./live555MediaServer &\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"How to Run:"}),"\nThe example code is provided in source form and must be compiled using the ",(0,d.jsx)(n.code,{children:"make"})," command before execution. Steps are as follows:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:~$ cd /app/cdev_demo/rtsp2display\nsunrise@ubuntu:/app/cdev_demo/rtsp2display$ make # Some warning messages may appear; they can be ignored.\nsunrise@ubuntu:/app/cdev_demo/rtsp2display$ ./rtsp2display -i rtsp://127.0.0.1/assets/1080P_test.h264 -t tcp\n"})}),"\n",(0,d.jsx)(n.p,{children:"Parameter configuration:"}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-i"}),": Stream URL"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-t"}),": Transport type, options are ",(0,d.jsx)(n.code,{children:"tcp"})," / ",(0,d.jsx)(n.code,{children:"udp"})]}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Expected Result:"}),"\nAfter the program runs correctly, the video will be output through the development board's ",(0,d.jsx)(n.code,{children:"HDMI"})," interface, and users can preview the video on a monitor. The runtime log is as follows:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{children:"sunrise@ubuntu:/app/cdev_demo/rtsp2display$ ./rtsp2display -i rtsp://127.0.0.1/assets/1080P_test.h264 -t tcp\n[UCP]: log level = 3\n[UCP]: UCP version = 3.7.3\n[VP]: log level = 3\n[DNN]: log level = 3\n[HPL]: log level = 3\n[UCPT]: log level = 6\navformat_open_input ok!\navformat_find_stream_info ok!\nInput #0, rtsp, from 'rtsp://127.0.0.1/assets/1080P_test.h264':\n  Metadata:\n    title           : H.264 Video, streamed by the LIVE555 Media Server\n    comment         : 1080P_test.h264\n  Duration: N/A, start: 0.040000, bitrate: N/A\n  Stream #0:0: Video: h264 (High), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], 25 fps, 25 tbr, 90k tbn, 50 tbc\nav_dump_format ok!\nrtsp_w:1920,rtsp_h:1080\ndisplay_w:1920,dispaly_h:1080\n2025/06/16 10:57:21.724 !WARN [sp_start_display][0049]Warning: Using vot_chn values 0-3 is deprecated. Defaulting to HDMI mode.\n2025/06/16 10:57:21.724 !WARN [sp_start_display][0050]Please use the new method: pass 10 for DisplayPort (DP) or 11 for HDMI.\n2025/06/16 10:57:21.724 !INFO [OpenDisplay][0111]Wayland is available, using Wayland for rendering.\n\nUsing default socket path: /run/user/1000/wayland-0\n2025/06/16 10:57:21.793 !INFO [CamInitPymParam][0258]Setting PYM channel:0: crop_x:0, crop_y:0, input_width:1920, input_height:1080, dst_w:1920, dst_h:1080\nsp_open_vps success!\nCould not read frame ---(error 'End of file')\n"})}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"Notes:"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsx)(n.li,{children:"When using UDP for stream transmission, screen corruption may occur due to packet loss; switching to TCP transmission can resolve this issue."}),"\n",(0,d.jsxs)(n.li,{children:['If the above command results in a "Connection refused" error, the ',(0,d.jsx)(n.code,{children:"127.0.0.1"})," part may need to include the actual port number printed when ",(0,d.jsx)(n.code,{children:"live555MediaServer"})," starts. For example:","\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-shell",children:"# final output of live555MediaServer\n...\n(We use port 8000 for optional RTSP-over-HTTP tunneling, or for HTTP live streaming (for indexed Transport Stream files only).)\n...\n\n# rtsp2display actual command\nsunrise@ubuntu:/app/cdev_demo/rtsp2display$ ./rtsp2display -i rtsp://127.0.0.1:8000/assets/1080P_test.h264 -t tcp\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,d.jsx)(n.h2,{id:"vps-scaling-example",children:"VPS Scaling Example"}),"\n",(0,d.jsxs)(n.p,{children:["This example implements video scaling based on the Video Processing Subsystem (",(0,d.jsx)(n.code,{children:"VPS"}),") module, capable of scaling down a single frame extracted from a video file or scaling a specified image."]}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"Environment Setup:"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsx)(n.li,{children:"Power on the development board and log in via command line."}),"\n",(0,d.jsx)(n.li,{children:"Prepare an image (NV12) or video file (H264) as input."}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"How to Run:"}),"\nThe example code is provided in source form and must be compiled using the ",(0,d.jsx)(n.code,{children:"make"})," command before execution. Steps are as follows:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-bash",children:"sunrise@ubuntu:~$ cd /app/cdev_demo/vps\nsunrise@ubuntu:/app/cdev_demo/vps$ make\nsunrise@ubuntu:/app/cdev_demo/vps$ ./vps -m 1 -i input_1080p.h264 -o output1.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\nsunrise@ubuntu:/app/cdev_demo/vps$ ./vps -m 2 -i input_1080p.yuv -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\n"})}),"\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"Parameter Configuration:"})}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-i"}),": Path to the input file"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"--iheight"}),": Input height"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"--iwidth"}),": Input width"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-m"}),": Input mode: ",(0,d.jsx)(n.code,{children:"1"})," for video stream; ",(0,d.jsx)(n.code,{children:"2"})," for NV12 image"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"-o"}),": Output path"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"--oheight"}),": Output height"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"--owidth"}),": Output width"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"--skip"}),": (Optional) For video stream input, skip the specified number of initial frames."]}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Expected Result:"}),"\nAfter the program runs correctly, the processed image file ",(0,d.jsx)(n.code,{children:"output.yuv"})," will be saved in the current directory. The runtime log is as follows:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-shell",children:"sunrise@ubuntu:/app/cdev_demo/vps$ ./vps -m 1 -i input_1080p.h264 -o output1.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\n[UCP]: log level = 3\n[UCP]: UCP version = 3.7.3\n[VP]: log level = 3\n[DNN]: log level = 3\n[HPL]: log level = 3\n[UCPT]: log level = 6\n2025/06/16 10:33:02.709 !INFO [CamInitPymParam][0258]Setting PYM channel:0: crop_x:0, crop_y:0, input_width:1920, input_height:1080, dst_w:1280, dst_h:720\nsunrise@ubuntu:/app/cdev_demo/vps$ ./vps -m 2 -i input_1080p.yuv -o output.yuv --iheight 1080 --iwidth 1920 --oheight 720 --owidth 1280\n[UCP]: log level = 3\n[UCP]: UCP version = 3.7.3\n[VP]: log level = 3\n[DNN]: log level = 3\n[HPL]: log level = 3\n[UCPT]: log level = 6\n2025/06/16 10:33:29.134 !INFO [CamInitPymParam][0258]Setting PYM channel:0: crop_x:0, crop_y:0, input_width:1920, input_height:1080, dst_w:1280, dst_h:720\n... omitted ...\n"})}),"\n"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,d.jsx)(n,{...e,children:(0,d.jsx)(c,{...e})}):c(e)}}}]);