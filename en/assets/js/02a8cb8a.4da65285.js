"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[80948],{28453:(t,e,n)=>{n.d(e,{R:()=>i,x:()=>o});var d=n(96540);const r={},s=d.createContext(r);function i(t){const e=d.useContext(s);return d.useMemo(function(){return"function"==typeof t?t(e):{...e,...t}},[e,t])}function o(t){let e;return e=t.disableParentContext?"function"==typeof t.components?t.components(r):t.components||r:i(t.components),d.createElement(s.Provider,{value:e},t.children)}},41485:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>a,frontMatter:()=>i,metadata:()=>d,toc:()=>c});const d=JSON.parse('{"id":"Advanced_development/toolchain_development/expert/note","title":"Appendix","description":"Eager Mode","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/07_Advanced_development/04_toolchain_development/expert/note.md","sourceDirName":"07_Advanced_development/04_toolchain_development/expert","slug":"/Advanced_development/toolchain_development/expert/note","permalink":"/rdk_doc/en/Advanced_development/toolchain_development/expert/note","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1756296606000,"sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"API Manual","permalink":"/rdk_doc/en/Advanced_development/toolchain_development/expert/api_reference"},"next":{"title":"8. \u5e38\u89c1\u95ee\u9898","permalink":"/rdk_doc/en/FAQ"}}');var r=n(74848),s=n(28453);const i={sidebar_position:6},o="Appendix",l={},c=[{value:"Eager Mode",id:"eager-mode",level:2},{value:"Difference with fx mode",id:"difference-with-fx-mode",level:3},{value:"Usage Flow",id:"usage-flow",level:3},{value:"Build Float Model",id:"build-float-model",level:4},{value:"Float Model Pretraining",id:"float-model-pretrain",level:4},{value:"Set BPU architecture",id:"set-bpu",level:4},{value:"Operator fusion",id:"op-fuse",level:4},{value:"Convert floating-point model to quantized model",id:"float-to-quantized",level:4},{value:"Quantization Tnjkraining",id:"quantization-tnjkraining",level:4},{value:"Convert Quantized Model to Fixed-point Model",id:"convert-quantized-model-to-fixed-point-model",level:4},{value:"Check and Compile the Fixed-point Prediction Model",id:"check-and-compile-the-fixed-point-prediction-model",level:4},{value:"Supported General Operators",id:"supported-general-operators",level:2},{value:"Overall Explanation",id:"overall-explanation",level:3},{value:"torch function class",id:"torch-function-class",level:3},{value:"torch.nn.functional function class",id:"torchnnfunctional-function-class",level:3},{value:"torch.nn Module Class",id:"torchnn-module-class",level:3},{value:"torch.Tensor method Class",id:"torchtensor-method-class",level:3},{value:"torchvision Operations",id:"torchvision-operations",level:3}];function h(t){const e={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...t.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"appendix",children:"Appendix"})}),"\n",(0,r.jsx)(e.h2,{id:"eager-mode",children:"Eager Mode"}),"\n",(0,r.jsxs)(e.p,{children:["Similar to PyTorch official recommendation, we suggest users to use fx quantization mode as the first choice. horizon_plugin_pytorch currently supports quantization with eager mode.\nThe overall process of eager mode follows the quantization interface and concept from PyTorch officially, therefore, it is recommended to first read the relevant part about eager mode in ",(0,r.jsx)(e.a,{href:"https://pytorch.org/docs/stable/quantization.html#quantization",children:(0,r.jsx)(e.strong,{children:"PyTorch official documentation"})}),"."]}),"\n",(0,r.jsx)(e.h3,{id:"difference-with-fx-mode",children:"Difference with fx mode"}),"\n",(0,r.jsx)(e.p,{children:"When using eager mode in horizon_plugin_pytorch, the main differences compared with fx mode are:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Eager mode only supports module-based operators. You need to manually replace the functional operators in the floating-point model with Module-based operators in PyTorch or proprietary operators defined in horizon_plugin_pytorch, including but not limited to:"}),"\n"]}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Floating-point operators"}),(0,r.jsx)(e.th,{children:"Replaced operators"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.functional.relu"}),(0,r.jsx)(e.td,{children:"torch.nn.ReLU()"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsxs)(e.td,{children:["a + b ",(0,r.jsx)("br",{})," torch.add"]}),(0,r.jsx)(e.td,{children:"horizon.nn.quantized.FloatFunctional().add"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Tensor.exp"}),(0,r.jsx)(e.td,{children:"horizon.nn.Exp()"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.functional.interpolate"}),(0,r.jsx)(e.td,{children:"horizon.nn.Interpolate()"})]})]})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["You need to manually define the operators to be fused and explicitly call the fusion function, and specify to use ",(0,r.jsx)(e.code,{children:"fuser_func"})," provided in horizon_plugin_pytorch. The example is shown below:"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"import torch\nfrom torch import nn\nimport horizon_plugin_pytorch as horizon\n\n\nclass ConvBNReLU(nn.Sequential):\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(ConvBNReLU, self).__init__(\n            nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=out_channels,\n            kernel_size=kernel_size\n            ),\n            nn.BatchNorm2d(num_features=out_channels),\n            nn.ReLU()\n        )\n\n    # Specify the operators that can be fused\n    def fuse_model(self):\n        torch.quantization.fuse_modules(\n            self,\n            ['0', '1', '2'],\n            inplace=True,\n    # Specify the fuse function provided by horizon_plugin_pytorch in the horizon_plugin_pytorch package\n    fuser_func=horizon.quantization.fuse_known_modules,\n    )\n\n    float_model = ConvBNReLU(1, 1, 1)\n    # Need to explicitly call the fuse function\n    float_model.fuse_model()\n\n    print(float_model)\n    # ConvBNReLU(\n    #   (0): ConvReLU2d(\n    #     (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n    #     (1): ReLU()\n    #   )\n    #   (1): Identity()\n    #   (2): Identity()\n    # )\n"})}),"\n",(0,r.jsx)(e.h3,{id:"usage-flow",children:"Usage Flow"}),"\n",(0,r.jsx)(e.p,{children:"The overall flow of quantization-aware training in Eager mode is shown in the following figure:"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/07_Advanced_development/04_toolchain_development/expert/qat.svg",alt:"qat"})}),"\n",(0,r.jsx)(e.h4,{id:"build-float-model",children:"Build Float Model"}),"\n",(0,r.jsx)(e.p,{children:"When building a float model in Eager mode, there are a few things to note:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Insert quantization and dequantization nodes in the network. Generally, a quantization node should be inserted at the beginning of the float model, and a dequantization node should be inserted at the end. When the float model is converted to a QAT model for quantization-aware training, the inserted quantization node will quantize the input;"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Replace some float-type function-form operators with operators inherited from Module in PyTorch or some proprietary operators provided by the Plugin;"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Define the fusion function for float operators to fuse eligible operators."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"import torch\nimport torch.optim as optim\nimport horizon_plugin_pytorch as horizon\nimport os\nfrom torch import nn\nfrom torchvision import datasets, transforms\nfrom torch.quantization import DeQuantStub\nfrom horizon_plugin_pytorch.quantization import QuantStub\n\nclass ConvBNReLU(nn.Sequential):\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(ConvBNReLU, self).__init__(\n            nn.Conv2d(\n            in_channels=in_channels,\n            in_channels = in_channels,\n            out_channels = out_channels,\n            kernel_size = kernel_size\n            ),\n            nn.BatchNorm2d(num_features=out_channels),\n            nn.ReLU()\n        )\n\n    # Specify the floating point operators that can be fused\n    def fuse_model(self):\n        torch.quantization.fuse_modules(\n            self,\n            ['0', '1', '2'],\n            inplace=True,\n            fuser_func=horizon.quantization.fuse_known_modules,\n        )\n\nclass ClassiFier(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ClassiFier, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, 1)\n\n    def forward(self, data):\n        return self.conv(data)\n\n# Build the floating point model\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv0 = ConvBNReLU(1, 10, 5)\n        self.max_pool = nn.MaxPool2d(kernel_size=2)\n        self.conv1 = ConvBNReLU(10, 20, 5)\n        self.avg_pool = nn.AvgPool2d(kernel_size=8)\n        self.classifier = ClassiFier(20, 10)\n        # To adapt to the BPU, when getting input from the camera, the scale of the QuantStub must be set to 1/128 explicitly.\n        self.quant = QuantStub(scale=1/128)\n        self.dequant = DeQuantStub()\n\n    def forward(self, x):\n        # Insert quantization node to quantize the input\n        x = self.quant(x)\n        x = self.conv0(x)\n        x = self.max_pool(x)\n        x = self.conv1(x)\n        x = self.avg_pool(x)\n        x = self.classifier(x)\n        # Insert dequantization node to dequantize the output\n        x = self.dequant(x)\n        return x\n\n    # Define the fusion function```python\ndef fuse_model(self):\n    from horizon_plugin_pytorch import quantization\n\n    for m in self.modules():\n        if type(m) == ConvBNReLU:\n            m.fuse_model()\n"})}),"\n",(0,r.jsx)(e.h4,{id:"float-model-pretrain",children:"Float Model Pretraining"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'train_batch_size = 16\ntest_batch_size = 16\nepoch_num = 1\nneval_batches = 1\nmodel_file = \'model.pt\'\n\nclass AverageMeter(object):\n    """Computes and stores the average and current value"""\n\n    def __init__(self, name, fmt=":f"):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = "{name} {val" + self.fmt + "} ({avg" + self.fmt + "})"\n        return fmtstr.format(**self.__dict__)\n\ncriterion = nn.CrossEntropyLoss()\n\ndef accuracy(output, target, topk=(1,)):\n    """Computes the accuracy over the k top predictions for the specified\n    values of k\n    """\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n\ndef get_train_data_loader():\n    train_loader = torch.utils.data.DataLoader(\n        datasets.MNIST(\n            \'mnist_data\',\n            train=True,\n            download=True,\n            transform=transforms.Compose(\n                [transforms.ToTensor(),\n                 transforms.Normalize((0.5,), (0.5,))]\n            )\n        ),\n        batch_size=train_batch_size,\n        shuffle=True,\n    )\n    return train_loader\n\ndef get_test_data_loader():\n    train_loader = torch.utils.data.DataLoader(\n        datasets.MNIST(\n            \'mnist_data\',\n            train=False,\n            download=True,\n            transform=transforms.Compose(\n                [transforms.ToTensor(),\n                 transforms.Normalize((0.5,), (0.5,))]\n            )\n        ),\n        batch_size=test_batch_size,\n        shuffle=True,\n    )\n    return train_loader\n\ndata_loader = get_train_data_loader()\ntest_loader = get_test_data_loader()\n\ndef train(model, device, optimizer, epoch):\n    global min_loss\n    model.train()\n    for batch_idx, (data, target) in enumerate(data_loader):\n        data = data.to(device)\n        target = target.to(device)\n        output = model(data)\n        output = output.view(-1, 10)\n        loss = criterion(output, target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if batch_idx %  100 == 0:\n            print (\'Train Epoch: {} batch {} \\t Loss: {:.6f}\'.\n                format(epoch, batch_idx, loss.item()))\n\ndef evaluate(model, device, neval_batches):\n    model.eval()\n    top1 = AverageMeter("Acc@1", ":6.2f")\n    top5 = AverageMeter("Acc@5", ":6.2f")\n    tested_batches = 0\n    with torch.no_grad():\n        for batch_idx, (data, target) in enumerate(test_loader):\n            tested_batches += 1\n            data = data.to(device)\n            target = target.to(device)\n            output = model(data)\n            output = output.view(-1, 10)\n            loss = criterion(output, target)\n            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n            top1.update(acc1[0], data.size(0))\n            top5.update(acc5[0], data.size(0))\n            if tested_batches >= neval_batches:\n                return top1, top5\n\n    return top1, top5\n\n\ndef train_float_model(device):\n    model = Net().to(device)\n    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.1)\n    for nepoch in range(epoch_num):\n        train(model, device, optimizer, nepoch)\n        top1, top5 = evaluate(model, device, neval_batches)\n        print(\n            "float training Epoch %d :float evaluation accuracy on %d images, \\\n            %2.2f" % (nepoch, neval_batches * test_batch_size, top1.avg)\n        )\n    torch.save(model.state_dict(), model_file)\n\ntrain_float_model(torch.device(\'cuda\'))\n'})}),"\n",(0,r.jsx)(e.p,{children:"If you want to perform quantization-aware training on an existing floating-point model, you can first load the float model and then proceed with the steps for(fusion operators) and quantization training. If you're directly quantizing after float training without any intermediate step, there's no need to explicitly load the model. You can proceed directly."}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"def load_model():\n    model = Net()\n    state_dict = torch.load(model_file)\n    model.load_state_dict(state_dict)\n    model.to('cpu')\n    return model\n\n# Load the float model for quantization-aware training\nqat_model = load_model()\n"})}),"\n",(0,r.jsx)(e.h4,{id:"set-bpu",children:"Set BPU architecture"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Set march to BERNOULLI2 for **RDK X3** and BAYES for **RDK Ultra**.\nhorizon.march.set_march(horizon.march.March.BAYES)\n"})}),"\n",(0,r.jsx)(e.h4,{id:"op-fuse",children:"Operator fusion"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"qat_model.fuse_model()\n"})}),"\n",(0,r.jsx)(e.h4,{id:"float-to-quantized",children:"Convert floating-point model to quantized model"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'def load_and_prepare_qat_model(device):\n    # Load pre-trained floating-point model\n    global qat_model\n    qat_model = qat_model.to(device)\n    top1, top5 = evaluate(qat_model, device, neval_batches)\n    print(\n        "float evaluation accuracy on %d images, \\\n        %2.2f" % (neval_batches * test_batch_size, top1.avg)\n    )\n    # Set the quantization parameters for quantizing the weights and outputs of operators\n    qat_model.qconfig = horizon.quantization.get_default_qat_qconfig()\n    # Turn off quantization for the output layer to improve accuracy\n    qat_model.classifier.qconfig = \\\n        horizon.quantization.get_default_qat_out_qconfig()\n    # Convert the floating-point model to quantized model\n    horizon.quantization.prepare_qat(qat_model, inplace=True)\n    print(\n        "After preparation for QAT, note fake-quantization modules \\n",\n        qat_model.conv0,\n    )\n    qat_model = qat_model.to(device)\n    load_and_prepare_qat_model(torch.device(\'cuda\'))\n'})}),"\n",(0,r.jsx)(e.h4,{id:"quantization-tnjkraining",children:"Quantization Tnjkraining"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"def quantization_training(device):\n    # Quantization training for the quantized model\n    optimizer = optim.SGD(qat_model.parameters(), lr=0.0001)\n    for nepoch in range(1):\n        train(qat_model, device, optimizer, nepoch)\n        # Evaluate the quantized model for one epoch\n        top1, top5 = evaluate(qat_model, device, neval_batches)\n        print(\n            \"QAT Epoch %d :float evaluation accuracy on %d images, %2.2f\"\n            % (nepoch, neval_batches * test_batch_size, top1.avg)\n        )\n\nquantization_training(torch.device('cuda'))\n"})}),"\n",(0,r.jsx)(e.h4,{id:"convert-quantized-model-to-fixed-point-model",children:"Convert Quantized Model to Fixed-point Model"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"quantized_model = horizon.quantization.convert(\n    qat_model.eval(), inplace=False\n)\n"})}),"\n",(0,r.jsx)(e.h4,{id:"check-and-compile-the-fixed-point-prediction-model",children:"Check and Compile the Fixed-point Prediction Model"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'def compile_quantized_model(device):\n    example_input = torch.ones(size=(neval_batches, 1, 28, 28), device=device)\n    traced_model = torch.jit.trace(quantized_model, example_input)\n    top1, top5 = evaluate(traced_model, device, neval_batches)\n    print(\n        "Traced : int evaluation accuracy on %d images, %2.2f"\n        % (neval_batches * test_batch_size, top1.avg)\n    )\n\n    # Check if the model can be compiled using hbdk. hbdk is a tool for compiling fixed-point models.\n    horizon.quantization.check_model(quantized_model, example_input, advice=1)\n    hbdk_dir = "hbdk_model"\n    if not os.path.exists(hbdk_dir):\n        os.mkdir(hbdk_dir)\n\n    # Compile the model, and the model.hbm in the hbdk_model directory is the compiled on-board model.\n    horizon.quantization.compile_model(traced_model, [example_input], opt=2, hbm=hbdk_dir + "/model.hbm"\n)\n# Static performance analysis of the model\nhorizon.quantization.perf_model(\n    traced_model,\n    [example_input],\n    opt=2,\n    input_source=["pyramid"],\n    layer_details=True,\n    out_dir=hbdk_dir,\n)\nhorizon.quantization.visualize_model(\n    traced_model,\n    [example_input],\n    save_path=hbdk_dir + "/model.svg",\n    show=False,\n)\n\ncompile_quantized_model(torch.device(\'cuda\'))\n'})}),"\n",(0,r.jsx)(e.h2,{id:"supported-general-operators",children:"Supported General Operators"}),"\n",(0,r.jsx)(e.h3,{id:"overall-explanation",children:"Overall Explanation"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Unless otherwise specified, the inputs and outputs of Bernoulli2 architecture-constrained operators are all 4-dimensional."}),"\n",(0,r.jsx)(e.li,{children:"In eager mode, some operators need to be manually replaced, while fx mode does not need to replace operators manually."}),"\n",(0,r.jsxs)(e.li,{children:["By default, the supported operators do not perform operator fusion. For operators that can be fused (such as (conv, bn), relu), refer to the ",(0,r.jsx)(e.a,{href:"/rdk_doc/en/Advanced_development/toolchain_development/expert/advanced_content#op_fusion",children:(0,r.jsx)(e.strong,{children:"Operator Fusion"})})," section."]}),"\n",(0,r.jsx)(e.li,{children:"In the inference phase, transparent operators (such as Identity, Dropout) will be optimized out during deployment."}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"torch-function-class",children:"torch function class"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Operator"}),(0,r.jsx)(e.th,{children:"Eager mode equivalent operator"}),(0,r.jsx)(e.th,{children:"Bernoulli2"}),(0,r.jsx)(e.th,{children:"Input"}),(0,r.jsx)(e.th,{children:"Output"}),(0,r.jsx)(e.th,{children:"Bayes"}),(0,r.jsx)(e.th,{children:"Output"}),(0,r.jsx)(e.th,{children:"Other constraints"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Input"}),(0,r.jsx)(e.td,{children:"Output"}),(0,r.jsx)(e.td,{children:"Other constraints"}),(0,r.jsx)(e.td,{children:"Input"}),(0,r.jsx)(e.td,{children:"Output"}),(0,r.jsx)(e.td,{children:"Other constraints"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.abs"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.acos"}),(0,r.jsx)(e.td,{children:"horizon.nn.Acos"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Implementation using a lookup table, with accuracy risks"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.acosh"}),(0,r.jsx)(e.td,{children:"horizon.nn.Acosh"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.add"}),(0,r.jsx)(e.td,{children:"torch.nn.quantized.FloatFunctional or horizon.nn.quantized.FloatFunctional"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsxs)(e.td,{children:["in_channel",(0,r.jsx)(e.code,{children:"<="}),"2048, not supported for operands as constants"]}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Supports broadcasting except for N dimensions, only one input can be broadcasted, call add_scalar if one of the operands is a scalar"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.argmax"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.argmin"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.asin"}),(0,r.jsx)(e.td,{children:"horizon.nn.Asin"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.asinh"}),(0,r.jsx)(e.td,{children:"horizon.nn.Asinh"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.atan"}),(0,r.jsx)(e.td,{children:"horizon.nn.Atan"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.atanh"}),(0,r.jsx)(e.td,{children:"horizon.nn.Atanh"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.cat"}),(0,r.jsx)(e.td,{children:"torch.nn.quantized.FloatFunctional or horizon.nn.quantized.FloatFunctional"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsxs)(e.td,{children:["input shape: [N, C, H, W], N",(0,r.jsx)(e.code,{children:"<="}),"4096, HWC",(0,r.jsx)(e.code,{children:"<="}),"65536, 2",(0,r.jsx)(e.code,{children:"<="}),"input number",(0,r.jsx)(e.code,{children:"<="}),"1024"]})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.ceil"}),(0,r.jsx)(e.td,{children:"horizon.nn.Ceil"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"Do not exceed the level of 1e6 for int8 input and the level of 1e8 for int16 input."})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.clamp"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"Supports min and max inputs as Tensor/Constant Tensor/Scalar/None. For Constant Tensor, the input data range should be consistent with input to avoid precision issues."}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.clip"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.clamp"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.cos"}),(0,r.jsx)(e.td,{children:"horizon.nn.Cos"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.cosh"}),(0,r.jsx)(e.td,{children:"horizon.nn.Cosh"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.div"}),(0,r.jsx)(e.td,{children:"horizon.nn.Div"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint16"}),(0,r.jsx)(e.td,{children:"qint16"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.eq"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qbool"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.erf"}),(0,r.jsx)(e.td,{children:"horizon.nn.Erf"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.exp"}),(0,r.jsx)(e.td,{children:"horizon.nn.Exp"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Uses table lookup, has precision risk"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.floor"}),(0,r.jsx)(e.td,{children:"horizon.nn.Floor"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"Int8 inputs should not exceed 1e6 in magnitude, int16 inputs should not exceed 1e8."}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.gather"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.ge"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.greater"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.greater_equal"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.gt"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.le"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.less"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.less_equal"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.log"}),(0,r.jsx)(e.td,{children:"horizon.nn.HardLog"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.lt"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.matmul"}),(0,r.jsx)(e.td,{children:"horizon.nn.quantized.FloatFunctional"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8, qint32"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"Input shape: [N, C, H, W], input size < 1 GB, N <= 4096, C, H, W <= 8192."})}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.max"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"Only for model output. Output format differs from torch: Compiler supports a Tensor with max_value in one channel and max_value_index in another."}),(0,r.jsx)(e.td,{children:"qint8, qint16 output; int32 index"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"Index can only be used as model output. Input shape: [N, C, H, W], 1 <= N <= 4096, 1 <= H, W, C <= 65535. Supports min and max inputs as Tensor/Constant Tensor/Scalar/None. Consistency in input data range with min and max is required for precision."})}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.maximum"}),(0,r.jsx)(e.td,{children:"horizon.nn.quantized.FloatFunctional"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsxs)(e.td,{children:["input: qint8, qint16",(0,r.jsx)("br",{})," other: qint8, qint16"]}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"-"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.mean"}),(0,r.jsx)(e.td,{children:"horizon.nn.quantized.FloatFunctional"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Supports channel-wise mean only. QAT has training parameters, don't use standalone in inference."}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Supports mean in CHW. QAT has quantization parameters."})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.min"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.minimum"}),(0,r.jsx)(e.td,{children:"horizon.nn.quantized.FloatFunctional"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.maximum"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.mul"}),(0,r.jsx)(e.td,{children:"torch.nn.quantized.FloatFunctional or horizon.nn.quantized.FloatFunctional"}),(0,r.jsx)(e.td,{children:"Refer to torch.add"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.add"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.pow"}),(0,r.jsx)(e.td,{children:"horizon.nn.Pow"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.reciprocal"}),(0,r.jsx)(e.td,{children:"horizon.nn.Reciprocal"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.selu"}),(0,r.jsx)(e.td,{children:"horizon.nn.Selu"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.sin"}),(0,r.jsx)(e.td,{children:"horizon.nn.Sin"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.sinh"}),(0,r.jsx)(e.td,{children:"horizon.nn.Sinh"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.split"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"-"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.sqrt"}),(0,r.jsx)(e.td,{children:"horizon.nn.Sqrt"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.sub"}),(0,r.jsx)(e.td,{children:"horizon.nn.quantized.FloatFunctional"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"in_channel <= 2048"})}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Supports broadcasting except N dimensions. Only one input can broadcast."})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.sum"}),(0,r.jsx)(e.td,{children:"horizon.nn.quantized.FloatFunctional"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8, qint32"}),(0,r.jsx)(e.td,{children:"Supports batch and channel-wise sum."}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Supports sum in HWC only."})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.tan"}),(0,r.jsx)(e.td,{children:"horizon.nn.Tan"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.topk"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"-"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]})]})]}),"\n",(0,r.jsx)(e.h3,{id:"torchnnfunctional-function-class",children:"torch.nn.functional function class"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Operator"}),(0,r.jsx)(e.th,{children:"Eager Mode Replacement Operator"}),(0,r.jsx)(e.th,{children:"Bernoulli2"}),(0,r.jsx)(e.th,{}),(0,r.jsx)(e.th,{}),(0,r.jsx)(e.th,{children:"Bayes"}),(0,r.jsx)(e.th,{}),(0,r.jsx)(e.th,{})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"input"}),(0,r.jsx)(e.td,{children:"output"}),(0,r.jsx)(e.td,{children:"other limits"}),(0,r.jsx)(e.td,{children:"input"}),(0,r.jsx)(e.td,{children:"output"}),(0,r.jsx)(e.td,{children:"other limits"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.functional.grid_sample"}),(0,r.jsx)(e.td,{children:"N/A"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsxs)(e.td,{children:["Input: qint8 ",(0,r.jsx)("br",{})," Grid: qint8, qint16"]}),(0,r.jsx)(e.td,{children:"Output: qint8"}),(0,r.jsxs)(e.td,{children:["Input shape: [N, C, H, W], 1\u2264H, W\u22641024 and H",(0,r.jsx)(e.em,{children:"W\u2264720"}),"1024. Supports bilinear and nearest interpolation with padding modes only zeros and border."]})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.functional.interpolate"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Supports nearest and bilinear interpolation. 1/256 \u2264 scale \u2264 256"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Supports nearest and bilinear interpolation. Input shape: [N, C, H, W], 1\u2264C, H, W\u22648192. align_corners supports False and None. Requires recompute_scale_factors to be True when scale=[]."}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.functional.pad"}),(0,r.jsx)(e.td,{children:"N/A"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"N/A"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"Reflect mode not supported."})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.functional.relu"}),(0,r.jsx)(e.td,{children:"torch.nn.ReLU"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"Fused Conv2d+BN+ReLU operations will be automatically applied."})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.functional.relu6(fused)"}),(0,r.jsx)(e.td,{children:"torch.nn.ReLU6"}),(0,r.jsx)(e.td,{children:"N/A"}),(0,r.jsx)(e.td,{children:"N/A"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"N/A"})]})]})]}),"\n",(0,r.jsx)(e.h3,{id:"torchnn-module-class",children:"torch.nn Module Class"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Operator"}),(0,r.jsx)(e.th,{children:"Eager Mode Replacement"}),(0,r.jsx)(e.th,{children:"Bernoulli2"}),(0,r.jsx)(e.th,{children:"Input"}),(0,r.jsx)(e.th,{children:"Output"}),(0,r.jsx)(e.th,{children:"Other Constraints"}),(0,r.jsx)(e.th,{children:"Input (Bayes)"}),(0,r.jsx)(e.th,{children:"Output (Bayes)"}),(0,r.jsx)(e.th,{children:"Other Constraints (Bayes)"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.AdaptiveAvgPool2d"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"Converted with AvgPool2d, accuracy issue"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.AvgPool2d"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"1<=kernel<=7, 1<=stride<=185"})}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsxs)(e.td,{children:[(0,r.jsx)(e.code,{children:"1<=kernel, stride, padding<=256"}),";"]}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.BatchNorm2d"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"BN2d absorbed in QAT, not present in prediction models. Limited by compiler, uses BpuConvolution for standalone usage"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"BN2d absorbed in QAT, not shown in model. See Conv2d constraints for standalone use"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.BatchNorm3d"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"BN3d absorbed in QAT, not present in prediction models. Limited by compiler, uses BpuConvolution for standalone usage"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"BN3d absorbed in QAT, not shown in model. See Conv2d constraints for standalone use"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.ChannelShuffle"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:"shuffle_index values must be unique"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.ConstantPad2d"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.Conv2d"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8, qint32"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"input: qint8, qint16; weight: qint8; bias: qint32"}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"out_channel<=8192, max out_channel for model output: 16384. Input channel<=8192, kernel<32, dilation<=16, stride=1 when dilation!=1. Supports sumin, sumin conv only supports stride (1, 1) or (2, 2). Weight shape: [N, C, H, W], N, C<=8192, H, W<=31. For model output, C<=16384, weight_size < 65535. Padding<=256. qint16 input overflow limits apply."})}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.Conv3d"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"input: qint8, weight: qint8, bias: qint32"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"input: [N, C, D, H, W] int8, N<=128; H, W, D, C<=65536; weight: [C_o, C_i, D, H, W] int8, N, C<=65536, D, H<=9, W<=8191; bias: int32; output: [N, C, D, H, W] int8, int16, int32; stride: [D, H, W], D, H, W=1 or 2, same for all; padding: [D, H, W], D<=kernel_d/2, H<=kernel_h/2, W<=kernel_w/2 (kernel_w is the W dimension of weight); group, dilation unsupported"})}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.ConvTranspose2d"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"2<=kernel<=14, channel<=2048. Padding H*W=[0, (kernel_h-1)/2] * [0, (kernel_w-1)/2]. 2<=stride<=4, dilation=(1, 1)"})}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"Input shape: [N, C, H, W], 1<=N<=128, 1<=channel<=2048; Weight shape: [N, C, H, W], 1<=N, C<=2048, 2<=H, W<=14, weight_size<=65535; kernel>=stride, 1<=stride<=14, 1<=out_channel<=2048, in_channel<=2048, pad<=kernel/stride, 0<=out_pad<=1; Bias int32 type. Supports sumin, sumin input int8 type; 0<=output_padding<=1; Supports group, requires weight_n and input channel divisible by group; dilation=1"})}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.Dropout"}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.Dropout2d"}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.ELU"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.GELU"}),(0,r.jsx)(e.td,{children:"Refer to torch.exp"}),(0,r.jsx)(e.td,{children:"Refer to torch.exp"}),(0,r.jsx)(e.td,{children:"Refer to torch.exp"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.GLU"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.HardSigmoid"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.Identity"}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.LayerNorm"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsxs)(e.td,{children:["Lower-level implementation uses multiple lookups, higher risk of precision loss. Use rsqrt_kwargs to control internal rsqrt lookup parameters. ",(0,r.jsx)(e.code,{children:"H * W <= 16384"}),", normalized_shape ",(0,r.jsx)(e.code,{children:"H * W < 16384"})]}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.LeakyReLU"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.Linear"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"input: qint8; weight: qint8; bias: qint32"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"in_features <= 8192, out_features <= 8192."})}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.LSTMCell"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Input is 2-dimensional"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.MaxPool2d"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"1<=kernel<=64, 1<=stride<=256, padding>=0"})}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"Input_shape: [N, C, H, W], 1<=H, W, C<=8192; 1<=kernel, stride<=256; 0<=padding<=255;"})}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.MultiheadAttention"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Unsupported: add_bias_kv, add_zero_attn, qkv embed_dim inconsistencies. Supports int8/int16 inputs, potential precision risks from table lookups and masking"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.PixelShuffle"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.PixelUnshuffle"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.PReLU"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.ReLU"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.ReLU6"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.ReplicationPad2d"}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{children:"Refer to torch.nn.ZeroPad2d"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.Sigmoid"}),(0,r.jsx)(e.td,{children:"Refer to torch.exp"}),(0,r.jsx)(e.td,{children:"Refer to torch.exp"}),(0,r.jsx)(e.td,{children:"Refer to torch.exp"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.SiLU"}),(0,r.jsx)(e.td,{children:"Refer to torch.exp"}),(0,r.jsx)(e.td,{children:"Refer to torch.exp"}),(0,r.jsx)(e.td,{children:"Refer to torch.exp"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.Softmax"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Multiple lookups and summations involved, high precision risk"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.Softplus"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{children:"Refer to torch.acos"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.nn.SyncBatchNorm"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"Uses torch.nn.Conv2d composition"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]})]})]}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Operator"}),(0,r.jsx)(e.th,{children:"Eager Mode Replacement Operator"}),(0,r.jsx)(e.th,{children:"Bernoulli2"}),(0,r.jsx)(e.th,{}),(0,r.jsx)(e.th,{children:"Constraints"}),(0,r.jsx)(e.th,{children:"Bayes"}),(0,r.jsx)(e.th,{}),(0,r.jsx)(e.th,{})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.quantization.DeQuantStub"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"float32"}),(0,r.jsx)(e.td,{children:"Common Use: Segmented network models, dequantizing data from BPU to CPU for CPU processing convenience."}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"float32"}),(0,r.jsx)(e.td,{children:"Same as above"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.quantization.QuantStub"}),(0,r.jsx)(e.td,{children:"horizon.quantization.QuantStub"}),(0,r.jsx)(e.td,{children:"float32"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Common Use: Model inputs, or before data is quantized from CPU to BPU in segmented models. Scale parameter setup: Set based on input data, aiming for high precision quantization of float data to int8. For example, if input float range is (-1, 1), use scale = 1 / 128. Pre-trained float models: In pre-trained models, use a special conv layer to handle scale settings, as the model may not follow this method. Requires uniform input distribution for QuantStub."}),(0,r.jsx)(e.td,{children:"float32"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Same as above with additional note about pre-trained models."})]})]})]}),"\n",(0,r.jsx)(e.h3,{id:"torchtensor-method-class",children:"torch.Tensor method Class"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Operator"}),(0,r.jsx)(e.th,{children:"Eager Mode Replacement"}),(0,r.jsx)(e.th,{children:"Bernoulli2"}),(0,r.jsx)(e.th,{}),(0,r.jsx)(e.th,{}),(0,r.jsx)(e.th,{children:"Bayes"}),(0,r.jsx)(e.th,{}),(0,r.jsx)(e.th,{})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsxs)(e.td,{children:["torch.Tensor.",(0,r.jsx)(e.strong,{children:"getitem"})]}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Same as input"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.transpose"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32"}),(0,r.jsx)(e.td,{children:"Tensor.dtype"}),(0,r.jsx)(e.td,{children:"Not supported for N-dimensional transposes"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.argmax"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.argmin"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.clamp"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Tensor.dtype"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"dim <= 10, 1 <= each_dim_size < 65536"})})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.clip"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.Tensor.clip"}),(0,r.jsx)(e.td,{children:"Refer to torch.Tensor.clip"}),(0,r.jsx)(e.td,{children:"Refer to torch.Tensor.clip"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.eq"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.expand"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Tensor.dtype"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.ge"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.greater"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.greater_equal"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.gt"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.le"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.less"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.less_equal"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"}),(0,r.jsx)(e.td,{children:"Refer to torch.eq"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.max"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.min"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Refer to torch.max"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.repeat"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Tensor.dtype"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.reshape"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Tensor.dtype"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.tile"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Tensor.dtype"}),(0,r.jsx)(e.td,{})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torch.Tensor.abs"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"Not supported"}),(0,r.jsx)(e.td,{children:"qint8, qint16"}),(0,r.jsx)(e.td,{children:"Tensor.dtype"}),(0,r.jsx)(e.td,{})]})]})]}),"\n",(0,r.jsx)(e.h3,{id:"torchvision-operations",children:"torchvision Operations"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Operator"}),(0,r.jsx)(e.th,{children:"Eager Mode Replacement"}),(0,r.jsx)(e.th,{children:"Bernoulli2"}),(0,r.jsx)(e.th,{children:"Notes"}),(0,r.jsx)(e.th,{children:"Input"}),(0,r.jsx)(e.th,{children:"Bayesian"}),(0,r.jsx)(e.th,{children:"Output"}),(0,r.jsx)(e.th,{children:"Additional Constraints"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torchvision.models.detection.rpn.AnchorGenerator"}),(0,r.jsx)(e.td,{children:"horizon.nn.AnchorGenerator"}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32, float32"}),(0,r.jsx)(e.td,{children:"Supports Tensor.shape determinable offline"}),(0,r.jsx)(e.td,{children:"qint8, qint16, qint32, float32"}),(0,r.jsx)(e.td,{children:"float32"}),(0,r.jsx)(e.td,{children:"float32"}),(0,r.jsx)(e.td,{children:"Input: int8/int16/int32/float32, Output: float32"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torchvision.ops.MultiScaleRoIAlign"}),(0,r.jsx)(e.td,{children:"horizon.nn.MultiScaleRoIAlign"}),(0,r.jsx)(e.td,{children:"Refer to torchvision.ops.RoIAlign"}),(0,r.jsx)(e.td,{children:"Refer to torchvision.ops.RoIAlign"}),(0,r.jsx)(e.td,{children:"Refer to torchvision.ops.RoIAlign"}),(0,r.jsx)(e.td,{children:"Refer to torchvision.ops.RoIAlign"}),(0,r.jsx)(e.td,{children:"Refer to torchvision.ops.RoIAlign"}),(0,r.jsx)(e.td,{children:"Refer to torchvision.ops.RoIAlign"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"torchvision.ops.RoIAlign"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:"qint8"}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"1 <= feature number <= 5; Bboxes only support List[Tensor] format with shape [1, box_num, 4], where the last dimension represents [left, top, right, bottom]."})})]})]})]})]})}function a(t={}){const{wrapper:e}={...(0,s.R)(),...t.components};return e?(0,r.jsx)(e,{...t,children:(0,r.jsx)(h,{...t})}):h(t)}}}]);