"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[58664,72038],{11470:(e,t,n)=>{n.d(t,{A:()=>y});var o=n(96540),r=n(34164),a=n(23104),i=n(56347),d=n(205),s=n(57485),l=n(31682),c=n(70679);function u(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:t,children:n}=e;return(0,o.useMemo)(()=>{const e=t??function(e){return u(e).map(({props:{value:e,label:t,attributes:n,default:o}})=>({value:e,label:t,attributes:n,default:o}))}(n);return function(e){const t=(0,l.XI)(e,(e,t)=>e.value===t.value);if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,n])}function m({value:e,tabValues:t}){return t.some(t=>t.value===e)}function p({queryString:e=!1,groupId:t}){const n=(0,i.W6)(),r=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,s.aZ)(r),(0,o.useCallback)(e=>{if(!r)return;const t=new URLSearchParams(n.location.search);t.set(r,e),n.replace({...n.location,search:t.toString()})},[r,n])]}function b(e){const{defaultValue:t,queryString:n=!1,groupId:r}=e,a=h(e),[i,s]=(0,o.useState)(()=>function({defaultValue:e,tabValues:t}){if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=t.find(e=>e.default)??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:a})),[l,u]=p({queryString:n,groupId:r}),[b,f]=function({groupId:e}){const t=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,r]=(0,c.Dv)(t);return[n,(0,o.useCallback)(e=>{t&&r.set(e)},[t,r])]}({groupId:r}),g=(()=>{const e=l??b;return m({value:e,tabValues:a})?e:null})();(0,d.A)(()=>{g&&s(g)},[g]);return{selectedValue:i,selectValue:(0,o.useCallback)(e=>{if(!m({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);s(e),u(e),f(e)},[u,f,a]),tabValues:a}}var f=n(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var _=n(74848);function v({className:e,block:t,selectedValue:n,selectValue:o,tabValues:i}){const d=[],{blockElementScrollPositionUntilNextRender:s}=(0,a.a_)(),l=e=>{const t=e.currentTarget,r=d.indexOf(t),a=i[r].value;a!==n&&(s(t),o(a))},c=e=>{let t=null;switch(e.key){case"Enter":l(e);break;case"ArrowRight":{const n=d.indexOf(e.currentTarget)+1;t=d[n]??d[0];break}case"ArrowLeft":{const n=d.indexOf(e.currentTarget)-1;t=d[n]??d[d.length-1];break}}t?.focus()};return(0,_.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},e),children:i.map(({value:e,label:t,attributes:o})=>(0,_.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{d.push(e)},onKeyDown:c,onClick:l,...o,className:(0,r.A)("tabs__item",g.tabItem,o?.className,{"tabs__item--active":n===e}),children:t??e},e))})}function x({lazy:e,children:t,selectedValue:n}){const a=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const e=a.find(e=>e.props.value===n);return e?(0,o.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,_.jsx)("div",{className:"margin-top--md",children:a.map((e,t)=>(0,o.cloneElement)(e,{key:t,hidden:e.props.value!==n}))})}function j(e){const t=b(e);return(0,_.jsxs)("div",{className:(0,r.A)("tabs-container",g.tabList),children:[(0,_.jsx)(v,{...t,...e}),(0,_.jsx)(x,{...t,...e})]})}function y(e){const t=(0,f.A)();return(0,_.jsx)(j,{...e,children:u(e.children)},String(t))}},19365:(e,t,n)=>{n.d(t,{A:()=>i});n(96540);var o=n(34164);const r={tabItem:"tabItem_Ymn6"};var a=n(74848);function i({children:e,hidden:t,className:n}){return(0,a.jsx)("div",{role:"tabpanel",className:(0,o.A)(r.tabItem,n),hidden:t,children:e})}},28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>d});var o=n(96540);const r={},a=o.createContext(r);function i(e){const t=o.useContext(a);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(a.Provider,{value:t},e.children)}},80610:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>l,default:()=>m,frontMatter:()=>s,metadata:()=>o,toc:()=>u});const o=JSON.parse('{"id":"Robot_development/boxs/spatial/mono3d_indoor_detection","title":"Monocular 3D Indoor Detection","description":"Introduction","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/05_Robot_development/03_boxs/spatial/mono3d_indoor_detection.md","sourceDirName":"05_Robot_development/03_boxs/spatial","slug":"/Robot_development/boxs/spatial/mono3d_indoor_detection","permalink":"/rdk_doc/en/Robot_development/boxs/spatial/mono3d_indoor_detection","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1766730309000,"sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Monocular Elevation Network","permalink":"/rdk_doc/en/Robot_development/boxs/spatial/elevation_net"},"next":{"title":"Visual Inertial Odometry Algorithm","permalink":"/rdk_doc/en/Robot_development/boxs/spatial/hobot_vio"}}');var r=n(74848),a=n(28453),i=n(11470),d=n(19365);const s={sidebar_position:2},l="Monocular 3D Indoor Detection",c={},u=[{value:"Introduction",id:"introduction",level:2},{value:"Supported Platforms",id:"supported-platforms",level:2},{value:"Preparation",id:"preparation",level:2},{value:"RDK",id:"rdk",level:3},{value:"Usage",id:"usage",level:2},{value:"RDK",id:"rdk-1",level:3},{value:"Result Analysis",id:"result-analysis",level:2}];function h(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"monocular-3d-indoor-detection",children:"Monocular 3D Indoor Detection"})}),"\n","\n",(0,r.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(t.p,{children:"The mono3d_indoor_detection package is an example of indoor object 3D detection algorithm based on the hobot_dnn package. It uses the 3D detection model and indoor data on the D-Robotics's RDK to perform model inference using BPU and obtain the inference results."}),"\n",(0,r.jsx)(t.p,{children:"Compared to 2D object detection, which can only recognize the object category and bounding box, 3D object detection can identify the precise position and orientation of the object. For example, in navigation the rich information provided by 3D object detection algorithms can help the planning and control robot achieve better effects."}),"\n",(0,r.jsx)(t.p,{children:"The supported indoor object detection categories of the algorithm include: charging docks, trash cans, and slippers."}),"\n",(0,r.jsx)(t.p,{children:"The detection results for each category include:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"Length, width, height: The length, width, and height of the three-dimensional object (i.e. hexahedron), measured in meters."}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"Orientation: The orientation of the object relative to the camera, measured in radians. The range is from -\u03c0 to \u03c0, representing the angle between the camera coordinate system x-axis and the object's forward direction in the camera coordinate system."}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"Depth information: The distance from the camera to the object, measured in meters."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["Code repository:  (",(0,r.jsx)(t.a,{href:"https://github.com/D-Robotics/mono3d_indoor_detection",children:"https://github.com/D-Robotics/mono3d_indoor_detection"}),")"]}),"\n",(0,r.jsx)(t.p,{children:"Applications: The monocular 3D indoor detection algorithm can directly identify the exact position and orientation of objects in images, enabling object posture recognition. It is mainly used in autonomous driving, smart home, and other fields."}),"\n",(0,r.jsx)(t.h2,{id:"supported-platforms",children:"Supported Platforms"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Platform"}),(0,r.jsx)(t.th,{children:"System"}),(0,r.jsx)(t.th,{children:"Function"})]})}),(0,r.jsx)(t.tbody,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"RDK X3, RDK X3 Module, RDK X5"}),(0,r.jsx)(t.td,{children:"Ubuntu 20.04 (Foxy), Ubuntu 22.04 (Humble)"}),(0,r.jsx)(t.td,{children:"\xb7 Start MIPI/USB camera/local data and save the inference rendering result locally"})]})})]}),"\n",(0,r.jsx)(t.h2,{id:"preparation",children:"Preparation"}),"\n",(0,r.jsx)(t.h3,{id:"rdk",children:"RDK"}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"RDK has been flashed with the  Ubuntu 20.04/22.04 system system image provided by D-Robotics."}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"TogetheROS.Bot has been successfully installed on the RDK."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"usage",children:"Usage"}),"\n",(0,r.jsx)(t.p,{children:"Because the 3D detection model is related to camera parameters, different cameras need to adjust the parameters accordingly."}),"\n",(0,r.jsx)(t.p,{children:"The mono3d_indoor_detection algorithm package uses local image input for inference. After the inference, it can detect object categories and 3D positioning information, and publish the algorithm message for 3D information. Users can subscribe to the 3D detection result message for application development."}),"\n",(0,r.jsx)(t.h3,{id:"rdk-1",children:"RDK"}),"\n",(0,r.jsxs)(i.A,{groupId:"tros-distro",children:[(0,r.jsx)(d.A,{value:"foxy",label:"Foxy",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,r.jsx)(d.A,{value:"humble",label:"Humble",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"# Copy the configuration file required for running the example from the installation path of tros.b.\ncp -r /opt/tros/${TROS_DISTRO}/lib/mono3d_indoor_detection/config/ .\n\n# Start the launch file\nros2 launch mono3d_indoor_detection mono3d_indoor_detection.launch.py \n"})}),"\n",(0,r.jsx)(t.h2,{id:"result-analysis",children:"Result Analysis"}),"\n",(0,r.jsx)(t.p,{children:"After processing one frame of image data, the mono3d_indoor_detection package outputs the following information:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"[mono3d_indoor_detection-1] [INFO] [1662612553.868256257] [mono3d_detection]: target type: trash_can\n[mono3d_indoor_detection-1] [INFO] [1662612553.868303755] [mono3d_detection]: target type: width, value: 0.236816\n[mono3d_indoor_detection-1] [INFO] [1662612553.868358420] [mono3d_detection]: target type: height, value: 0.305664\n[mono3d_indoor_detection-1] [INFO] [1662612553.868404002] [mono3d_detection]: target type: length, value: 0.224182\n[mono3d_indoor_detection-1] [INFO] [1662612553.868448000] [mono3d_detection]: target type: rotation, value: -1.571989\n[mono3d_indoor_detection-1] [INFO] [1662612553.868487790] [mono3d_detection]: target type: x, value: -0.191978\n[mono3d_indoor_detection-1] [INFO] [1662612553.868530705] [mono3d_detection]: target type: y, value: -0.143963\n[mono3d_indoor_detection-1] [INFO] [1662612553.868570870] [mono3d_detection]: target type: z, value: 0.714024\n[mono3d_indoor_detection-1] [INFO] [1662612553.868611119] [mono3d_detection]: target type: depth, value: 0.714024\n[mono3d_indoor_detection-1] [INFO] [1662612553.868651409] [mono3d_detection]: target type: score, value: 0.973215\n[mono3d_indoor_detection-1] [INFO] [1662612553.868760238] [mono3d_detection]: target type: trash_can\n[mono3d_indoor_detection-1] [INFO] [1662612553.868799486] [mono3d_detection]: target type: width, value: 0.253052\n[mono3d_indoor_detection-1] [INFO] [1662612553.868842610] [mono3d_detection]: target type: height, value: 0.282349\n[mono3d_indoor_detection-1] [INFO] [1662612553.868885191] [mono3d_detection]: target type: length, value: 0.257935\n[mono3d_indoor_detection-1] [INFO] [1662612553.868929273] [mono3d_detection]: target type: rotation, value: -1.542728\n[mono3d_indoor_detection-1] [INFO] [1662612553.868968855] [mono3d_detection]: target type: x, value: 0.552460\n[mono3d_indoor_detection-1] [INFO] [1662612553.869010645] [mono3d_detection]: target type: y, value: -0.164073\n[mono3d_indoor_detection-1] [INFO] [1662612553.869050018] [mono3d_detection]: target type: z, value: 1.088358\n[mono3d_indoor_detection-1] [INFO] [1662612553.869088767] [mono3d_detection]: target type: depth, value: 1.088358\n[mono3d_indoor_detection-1] [INFO] [1662612553.869126765] [mono3d_detection]: target type: score, value: 0.875521\n"})}),"\n",(0,r.jsx)(t.p,{children:"The log displays the processing result of a frame. The result shows that the target type in the subscribed algorithm message is trash_can, and it also provides the 3D coordinates, distance, and rotation angle information of the trash_can."}),"\n",(0,r.jsx)(t.p,{children:"The rendered result of a local image (which can be replaced by modifying the feed_image field in mono3d_indoor_detection.launch.py) is saved as an image in the result directory of the program. The corresponding inference result and rendering information of the image are as follows:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/03_boxs/function/image/box_adv/indoor_render.jpeg",alt:""})})]})}function m(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}}}]);