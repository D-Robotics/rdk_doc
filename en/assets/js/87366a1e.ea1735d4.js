"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[80310],{23132:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"Algorithm_Application/C++_Sample/Ultralytics_YOLOv5x","title":"Object Detection - Ultralytics YOLOv5x","description":"This example demonstrates how to perform image object detection on the BPU using a quantized Ultralytics YOLOv5x model. It supports preprocessing, postprocessing, NMS (Non-Maximum Suppression), drawing of final bounding boxes, and saving results. The example code is located in the directory /app/cdevdemo/bpu/02detectionsample/01ultralytics_yolov5x/.","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/03_C++_Sample/04_Ultralytics_YOLOv5x.md","sourceDirName":"04_Algorithm_Application/03_C++_Sample","slug":"/Algorithm_Application/C++_Sample/Ultralytics_YOLOv5x","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/Ultralytics_YOLOv5x","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770723091000,"sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Image Classification - MobileNetV2","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/MobileNetV2"},"next":{"title":"Object Detection - Ultralytics YOLO11","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/C++_Sample/Ultralytics_YOLO11"}}');var s=i(74848),r=i(28453);const l={sidebar_position:4},o="Object Detection - Ultralytics YOLOv5x",c={},d=[{value:"Model Description",id:"model-description",level:2},{value:"Functionality Description",id:"functionality-description",level:2},{value:"Environment Dependencies",id:"environment-dependencies",level:2},{value:"Directory Structure",id:"directory-structure",level:2},{value:"Building the Project",id:"building-the-project",level:2},{value:"Parameter Description",id:"parameter-description",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Notes",id:"notes",level:2},{value:"License",id:"license",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"object-detection---ultralytics-yolov5x",children:"Object Detection - Ultralytics YOLOv5x"})}),"\n",(0,s.jsxs)(n.p,{children:["This example demonstrates how to perform image object detection on the BPU using a quantized Ultralytics YOLOv5x model. It supports preprocessing, postprocessing, NMS (Non-Maximum Suppression), drawing of final bounding boxes, and saving results. The example code is located in the directory ",(0,s.jsx)(n.code,{children:"/app/cdev_demo/bpu/02_detection_sample/01_ultralytics_yolov5x/"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"model-description",children:"Model Description"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Overview:"}),"\n",(0,s.jsx)(n.p,{children:'Ultralytics YOLOv5x is a high-performance object detection model. The name "YOLO" stands for "You Only Look Once," enabling simultaneous object localization and classification in a single forward pass. Among the YOLOv5 variants, YOLOv5x is the largest, featuring more network parameters and delivering high detection accuracy, making it suitable for scenarios demanding high precision. The Ultralytics YOLOv5x model divides the input image into multiple grids, with each grid predicting multiple anchors\' class probabilities and bounding boxes. This model has been quantized into the HBM format compatible with the BPU chip and accepts NV12 input images of size 672\xd7672.'}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"HBM Model Name: yolov5x_672x672_nv12.hbm"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Input Format: NV12, size 672x672 (separate Y and UV planes)"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Output: N bounding boxes, each represented as a triplet (class index, confidence score, bounding box coordinates)"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"functionality-description",children:"Functionality Description"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Model Loading"}),"\n",(0,s.jsx)(n.p,{children:"Load the quantized Ultralytics YOLOv5x model, parse relevant model information, and prepare configurations for subsequent inference."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Input Preprocessing"}),"\n",(0,s.jsx)(n.p,{children:"Resize the input image to 672x672, convert it to NV12 format (separate Y and UV planes), and organize the input as a nested dictionary to match the inference interface."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Inference Execution"}),"\n",(0,s.jsxs)(n.p,{children:["Run the inference process using the ",(0,s.jsx)(n.code,{children:".infer()"})," method."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Result Postprocessing"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Dequantize the output tensors;"}),"\n",(0,s.jsx)(n.li,{children:"Decode YOLO outputs to obtain predicted bounding boxes, confidence scores, and class indices;"}),"\n",(0,s.jsx)(n.li,{children:"Apply an initial filter based on a confidence score threshold;"}),"\n",(0,s.jsx)(n.li,{children:"Perform NMS (Non-Maximum Suppression) to remove redundant boxes;"}),"\n",(0,s.jsx)(n.li,{children:"Map predicted bounding box coordinates back to the original image dimensions;"}),"\n",(0,s.jsx)(n.li,{children:"Overlay detection boxes and save the resulting image."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"environment-dependencies",children:"Environment Dependencies"}),"\n",(0,s.jsx)(n.p,{children:"Ensure the following dependencies are installed on your system:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt update\nsudo apt install libgflags-dev\n"})}),"\n",(0,s.jsx)(n.h2,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:".\n\u251c\u2500\u2500 CMakeLists.txt                 # Build configuration file\n\u251c\u2500\u2500 README.md                      # Usage instructions\n\u251c\u2500\u2500 inc\n\u2502   \u2514\u2500\u2500 ultralytics_yolov5x.hpp     # Class definition for YOLOv5x model wrapper\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 main.cc                     # Inference entry point (argument parsing and execution)\n    \u2514\u2500\u2500 ultralytics_yolov5x.cc      # Implementation of YOLOv5x inference logic\n"})}),"\n",(0,s.jsx)(n.h2,{id:"building-the-project",children:"Building the Project"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Configuration and Compilation","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mkdir build && cd build\ncmake ..\nmake -j$(nproc)\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"parameter-description",children:"Parameter Description"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Parameter"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Default Value"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--model-path"})}),(0,s.jsx)(n.td,{children:"Path to the model file (.hbm format)"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--test-img"})}),(0,s.jsx)(n.td,{children:"Path to the test image"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/app/res/assets/kite.jpg"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--label-file"})}),(0,s.jsx)(n.td,{children:"Path to the class label file"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/app/res/labels/coco_classes.names"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--score-thres"})}),(0,s.jsx)(n.td,{children:"Confidence score threshold (filters low-score boxes)"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"0.25"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--nms-thres"})}),(0,s.jsx)(n.td,{children:"IoU threshold for NMS (Non-Maximum Suppression)"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"0.45"})})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Running the Model"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Using default parameters:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"./ultralytics_yolov5x\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Running with custom parameters:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"./ultralytics_yolov5x \\\n    --model-path /opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm \\\n    --test-img /app/res/assets/kite.jpg \\\n    --label-file /app/res/labels/coco_classes.names \\\n    --score-thres 0.25 \\\n    --nms-thres 0.45\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Viewing Results"}),"\n",(0,s.jsxs)(n.p,{children:["Upon successful execution, detection bounding boxes will be drawn on the original image and saved as ",(0,s.jsx)(n.code,{children:"build/result.jpg"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"[Saved] Result saved to: result.jpg\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["The output result is saved as ",(0,s.jsx)(n.code,{children:"result.jpg"}),", which users can inspect directly."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"For more information about deployment options or model support, please refer to the official documentation or contact platform technical support."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"license",children:"License"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-license",children:"Copyright (C) 2025, XiangshunZhao D-Robotics.\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as\npublished by the Free Software Foundation, either version 3 of the\nLicense, or (at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var t=i(96540);const s={},r=t.createContext(s);function l(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);