"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[9349],{28453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(96540);const o={},s=t.createContext(o);function r(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(s.Provider,{value:n},e.children)}},51297:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>r,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"Basic_Application/pydev_demo_sample/segment_sample","title":"3.3.2 Segment Model Example Introduction","description":"Example Overview","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/03_Basic_Application/03_pydev_demo_sample/04_segment_sample.md","sourceDirName":"03_Basic_Application/03_pydev_demo_sample","slug":"/Basic_Application/pydev_demo_sample/segment_sample","permalink":"/rdk_doc/en/Basic_Application/pydev_demo_sample/segment_sample","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1764747404000,"sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"3.3.1 Basic Image Classification Example Introduction","permalink":"/rdk_doc/en/Basic_Application/pydev_demo_sample/basic_sample"},"next":{"title":"3.3.3 YOLOv3 Model Example Introduction","permalink":"/rdk_doc/en/Basic_Application/pydev_demo_sample/yolov3_sample"}}');var o=i(74848),s=i(28453);const r={sidebar_position:2},a="3.3.2 Segment Model Example Introduction",l={},d=[{value:"Example Overview",id:"example-overview",level:2},{value:"Effect Demonstration",id:"effect-demonstration",level:2},{value:"Hardware Preparation",id:"hardware-preparation",level:2},{value:"Hardware Connection",id:"hardware-connection",level:3},{value:"Quick Start",id:"quick-start",level:2},{value:"Code and Board Location",id:"code-and-board-location",level:3},{value:"Compilation and Execution",id:"compilation-and-execution",level:3},{value:"Execution Effect",id:"execution-effect",level:3},{value:"Detailed Introduction",id:"detailed-introduction",level:2},{value:"Example Program Parameter Options Description",id:"example-program-parameter-options-description",level:3},{value:"Software Architecture Description",id:"software-architecture-description",level:3},{value:"API Process Description",id:"api-process-description",level:3},{value:"FAQ",id:"faq",level:3}];function c(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"332-segment-model-example-introduction",children:"3.3.2 Segment Model Example Introduction"})}),"\n",(0,o.jsx)(n.h2,{id:"example-overview",children:"Example Overview"}),"\n",(0,o.jsxs)(n.p,{children:["The image segmentation example is a ",(0,o.jsx)(n.strong,{children:"Python interface"})," development code example located in ",(0,o.jsx)(n.code,{children:"/app/pydev_demo/04_segment_sample/"}),", demonstrating how to use the MobileNet-UNet model for semantic segmentation tasks. This example shows how to perform pixel-level classification on input images, segment different objects in the image, and visually display the segmentation results."]}),"\n",(0,o.jsx)(n.h2,{id:"effect-demonstration",children:"Effect Demonstration"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/03_pydev_demo_sample/image/pydev_04_runing.png",alt:"output-img"})}),"\n",(0,o.jsx)(n.h2,{id:"hardware-preparation",children:"Hardware Preparation"}),"\n",(0,o.jsx)(n.h3,{id:"hardware-connection",children:"Hardware Connection"}),"\n",(0,o.jsxs)(n.p,{children:["This example only requires the RDK development board itself, without additional peripheral connections. Ensure the development board is properly powered and the system is booted.\n",(0,o.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/03_pydev_demo_sample/image/pydev_04_hw_connect.png",alt:"connect-img"})]}),"\n",(0,o.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,o.jsx)(n.h3,{id:"code-and-board-location",children:"Code and Board Location"}),"\n",(0,o.jsxs)(n.p,{children:["Navigate to ",(0,o.jsx)(n.code,{children:"/app/pydev_demo/04_segment_sample/"})," location, where you can see the image segmentation example contains the following files:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"root@ubuntu:/app/pydev_demo/04_segment_sample# tree \n.\n\u251c\u2500\u2500 segmentation.png\n\u2514\u2500\u2500 test_mobilenet_unet.py\n"})}),"\n",(0,o.jsx)(n.h3,{id:"compilation-and-execution",children:"Compilation and Execution"}),"\n",(0,o.jsx)(n.p,{children:"The Python example does not require compilation and can be run directly:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"python3 test_mobilenet_unet.py\n"})}),"\n",(0,o.jsx)(n.h3,{id:"execution-effect",children:"Execution Effect"}),"\n",(0,o.jsx)(n.p,{children:"After running, the program will load the pre-trained MobileNet-UNet model, perform segmentation processing on the segmentation.png image, and generate the segmentation result image segment_result.png."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"root@ubuntu:/app/pydev_demo/04_segment_sample# ./test_mobilenet_unet.py \nMatplotlib is building the font cache; this may take a moment.\n[BPU_PLAT]BPU Platform Version(1.3.6)!\n[HBRT] set log level as 0. version = 3.15.55.0\n[DNN] Runtime version = 1.24.5_(3.15.55 HBRT)\n[A][DNN][packed_model.cpp:247][Model](2025-09-10,10:07:36.611.352) [HorizonRT] The model builder version = 1.23.8\n[W][DNN]bpu_model_info.cpp:491][Version](2025-09-10,10:07:36.671.453) Model: unet_mobilenet_1024x2048_nv12. Inconsistency between the hbrt library version 3.15.55.0 and the model build version 3.15.54.0 detected, in order to ensure correct model results, it is recommended to use compilation tools and the BPU SDK from the same OpenExplorer package.\n========== Model load successfully. ==========\n========== Model forward finished. ==========\n========== Postprocess successfully. ==========\n========== Waiting for drawing image  ..........\nSaving predicted image with name segment_result.png \n========== Dump result image segment_result.png successfully. ==========\nroot@ubuntu:/app/pydev_demo/04_segment_sample# \n"})}),"\n",(0,o.jsx)(n.h2,{id:"detailed-introduction",children:"Detailed Introduction"}),"\n",(0,o.jsx)(n.h3,{id:"example-program-parameter-options-description",children:"Example Program Parameter Options Description"}),"\n",(0,o.jsx)(n.p,{children:"The image segmentation example does not require command line parameters and can be run directly. The program will automatically load the segmentation.png image in the same directory for segmentation processing."}),"\n",(0,o.jsx)(n.h3,{id:"software-architecture-description",children:"Software Architecture Description"}),"\n",(0,o.jsx)(n.p,{children:"The software architecture of the image segmentation example includes the following core components:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Model Loading: Using the pyeasy_dnn module to load the pre-trained MobileNet-UNet model."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Image Preprocessing: Converting the input image to the NV12 format and specified dimensions required by the model."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Model Inference: Calling the model for forward computation to generate segmentation masks."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Post-processing: Performing argmax operation on the model output to obtain the category of each pixel."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Result Visualization: Using a color palette to visualize the segmentation results and overlay them on the original image."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Result Saving: Saving the visualized results as an image file."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)("center",{children:(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/03_pydev_demo_sample/image/pydev_04_segment_sample_software_arch.png",alt:"software_arch"})})}),"\n",(0,o.jsx)(n.h3,{id:"api-process-description",children:"API Process Description"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Model Loading: models = pyeasy_dnn.load('../models/mobilenet_unet_1024x2048_nv12.bin')"}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Image Preprocessing: Adjusting image dimensions and converting to NV12 format"}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Model Inference: outputs = models[0].forward(nv12_data)"}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Post-processing: pred_result = np.argmax(model_output[0], axis=-1)"}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Result Visualization: Using a palette to convert segmentation masks into color images"}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Result Saving: Overlaying segmentation results on the original image and saving"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)("center",{children:(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:"http://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/03_Basic_Application/03_pydev_demo_sample/image/pydev_04_segment_sample_api_flow.png",alt:"API_Flow"})})}),"\n",(0,o.jsx)(n.h3,{id:"faq",children:"FAQ"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," What should I do if I encounter \"ModuleNotFoundError: No module named 'matplotlib'\" error when running the example?",(0,o.jsx)(n.br,{}),"\n",(0,o.jsx)(n.strong,{children:"A:"})," Please ensure the matplotlib library is installed. You can use the command pip3 install matplotlib to install it."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," How to change the test image?",(0,o.jsx)(n.br,{}),"\n",(0,o.jsx)(n.strong,{children:"A:"})," Place the new image file in the example directory and modify img_file = cv2.imread('your_image_path') in the code."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," What should I do if the segmentation results are inaccurate?",(0,o.jsx)(n.br,{}),"\n",(0,o.jsx)(n.strong,{children:"A:"})," The MobileNet-UNet model is trained for urban street scene scenarios and may not perform well for other scenarios. You can try using segmentation models more suitable for specific scenarios."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," How to modify the output image resolution?",(0,o.jsx)(n.br,{}),"\n",(0,o.jsx)(n.strong,{children:"A:"})," The model input resolution is fixed at 1024x2048, and the output image resolution will be automatically adjusted to the original image resolution."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," Can real-time video stream processing be achieved?",(0,o.jsx)(n.br,{}),"\n",(0,o.jsx)(n.strong,{children:"A:"})," The current example is designed for single images, but the code can be modified to achieve real-time segmentation processing of video streams."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," How to obtain other pre-trained segmentation models?",(0,o.jsx)(n.br,{}),"\n",(0,o.jsx)(n.strong,{children:"A:"})," You can refer to the ",(0,o.jsx)(n.a,{href:"https://github.com/D-Robotics/rdk_model_zoo",children:"model_zoo repository"})," or ",(0,o.jsx)(n.a,{href:"https://github.com/D-Robotics/hobot_model",children:"Toolchain's basic model repository "})]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);