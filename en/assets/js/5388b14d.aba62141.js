"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[38752],{28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>a});var o=n(96540);const s={},r=o.createContext(s);function i(e){const t=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(r.Provider,{value:t},e.children)}},91461:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"Robot_development/boxs/function/hobot_bev","title":"BEV Perception Algorithm","description":"Function Introduction","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/05_Robot_development/03_boxs/function/hobot_bev.md","sourceDirName":"05_Robot_development/03_boxs/function","slug":"/Robot_development/boxs/function/hobot_bev","permalink":"/rdk_doc/en/Robot_development/boxs/function/hobot_bev","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1751967457000,"sidebarPosition":10,"frontMatter":{"sidebar_position":10},"sidebar":"tutorialSidebar","previous":{"title":"LiDAR Object Detection Algorithm","permalink":"/rdk_doc/en/Robot_development/boxs/function/hobot_centerpoint"},"next":{"title":"Visual Inertial Odometry Algorithm","permalink":"/rdk_doc/en/Robot_development/boxs/function/hobot_vio"}}');var s=n(74848),r=n(28453);const i={sidebar_position:10},a="BEV Perception Algorithm",l={},d=[{value:"Function Introduction",id:"function-introduction",level:2},{value:"Supported Platforms",id:"supported-platforms",level:2},{value:"Preparation Work",id:"preparation-work",level:2},{value:"Usage Instructions",id:"usage-instructions",level:2},{value:"Using Local Dataset for Injection",id:"using-local-dataset-for-injection",level:3},{value:"Result Analysis",id:"result-analysis",level:2}];function c(e){const t={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"bev-perception-algorithm",children:"BEV Perception Algorithm"})}),"\n",(0,s.jsx)(t.h2,{id:"function-introduction",children:"Function Introduction"}),"\n",(0,s.jsxs)(t.p,{children:["The BEV perception algorithm is a multi-task model trained on the ",(0,s.jsx)(t.a,{href:"https://www.nuscenes.org/nuscenes",children:"nuscenes"})," dataset using ",(0,s.jsx)(t.a,{href:"https://developer.d-robotics.cc/api/v1/fileData/horizon_j5_open_explorer_cn_doc/hat/source/examples/bev.html",children:"OpenExplorer"}),"."]}),"\n",(0,s.jsx)(t.p,{children:"The algorithm takes 6 sets of image data as input: front view, left-front, right-front, rear view, left-rear, and right-rear images. The model outputs the 3D detection boxes for 10 categories of objects, including obstacles, various types of vehicles, traffic signs, and semantic segmentation for lane lines, sidewalks, and road edges."}),"\n",(0,s.jsx)(t.p,{children:"This example uses local image data as input, performs algorithm inference using the BPU, and publishes the rendered images of the perception results. The results are displayed on the PC browser."}),"\n",(0,s.jsxs)(t.p,{children:["Code Repository: ",(0,s.jsx)(t.a,{href:"https://github.com/D-Robotics/hobot_bev.git",children:"https://github.com/D-Robotics/hobot_bev.git"})]}),"\n",(0,s.jsx)(t.h2,{id:"supported-platforms",children:"Supported Platforms"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Platform"}),(0,s.jsx)(t.th,{children:"Run Method"}),(0,s.jsx)(t.th,{children:"Example Functionality"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"RDK Ultra"}),(0,s.jsx)(t.td,{children:"Ubuntu 20.04 (Foxy)"}),(0,s.jsx)(t.td,{children:"Use local data injection and display inference results via web"})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"preparation-work",children:"Preparation Work"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The RDK has the Ubuntu 20.04 system image flashed."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The RDK has TogetheROS.Bot installed successfully."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"Ensure that the PC can access the RDK through the network."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"usage-instructions",children:"Usage Instructions"}),"\n",(0,s.jsx)(t.h3,{id:"using-local-dataset-for-injection",children:"Using Local Dataset for Injection"}),"\n",(0,s.jsx)(t.p,{children:"Use the local dataset for injection, perform inference, and publish the rendered images of the algorithm's results. These images will be displayed on the PC browser via a WebSocket package."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)(t.strong,{children:"Prepare the Local Dataset for Injection"})})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-shell",children:"# Download the dataset\nwget http://archive.d-robotics.cc/TogetheROS/data/hobot_bev_data.tar.gz\n\n# Extract the dataset\nmkdir -p hobot_bev_data\ntar -zxvf hobot_bev_data.tar.gz -C hobot_bev_data\n\n# After extraction, the dataset will be located at hobot_bev_data/data\n\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)(t.strong,{children:"Using Dataset for Injection"})})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-shell",children:"# \u914d\u7f6etros.b\u73af\u5883\n# Configure the tros.b environment\nsource /opt/tros/setup.bash\n\n# Start the websocket service\nros2 launch websocket websocket_service.launch.py\n\n# Start the run script and specify the dataset path\nros2 launch hobot_bev hobot_bev.launch.py image_pre_path:=hobot_bev_data/data\n\n"})}),"\n",(0,s.jsx)(t.h2,{id:"result-analysis",children:"Result Analysis"}),"\n",(0,s.jsx)(t.p,{children:"The following information will be output in the terminal:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-text",children:"[INFO] [launch]: All log files can be found below /root/.ros/log/2023-07-05-17-47-07-232907-hobot-2627970\n[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [hobot_bev-1]: process started with pid [2627972]\n[INFO] [websocket-2]: process started with pid [2627974]\n[hobot_bev-1] [WARN] [1688579227.907268364] [bev_node]:\n[hobot_bev-1]  image_pre_path: hobot_bev_data/data\n[hobot_bev-1] [BPU_PLAT]BPU Platform Version(1.3.3)!\n[hobot_bev-1] [HBRT] set log level as 0. version = 3.14.25.0\n[hobot_bev-1] [DNN] Runtime version = 1.12.3_(3.14.25 HBRT)\n[hobot_bev-1] [WARN] [1688579228.714778531] [dnn]: Run default SetOutputParser.\n[hobot_bev-1] [WARN] [1688579228.714925489] [dnn]: Set output parser with default dnn node parser, you will get all output tensors and should parse output_tensors in PostProcess.\n[hobot_bev-1] [WARN] [1688579228.886846489] [bev_node]: loop 0/1002\n[hobot_bev-1] [WARN] [1688579229.474568573] [bev_node]: loop 1/1002\n[hobot_bev-1] [WARN] [1688579230.058551781] [bev_node]: loop 2/1002\n[hobot_bev-1] [WARN] [1688579230.691667198] [bev_node]: loop 3/1002\n[hobot_bev-1] [WARN] [1688579231.324658782] [bev_node]: loop 4/1002\n[hobot_bev-1] [WARN] [1688579231.365145532] [bev_node]: input fps: 2.47, out fps: 2.52, infer time ms: 12, post process time ms: 659\n[hobot_bev-1] [WARN] [1688579231.915645741] [bev_node]: loop 5/1002\n[hobot_bev-1] [WARN] [1688579231.996993824] [bev_node]: input fps: 2.47, out fps: 2.52, infer time ms: 12, post process time ms: 658\n"})}),"\n",(0,s.jsxs)(t.p,{children:["To view the images and algorithm rendering results, open a web browser on the PC and enter the following URL (replace ",(0,s.jsx)(t.code,{children:"IP"})," with the RDK's IP address):",(0,s.jsx)(t.a,{href:"http://IP:8000",children:"http://IP:8000"})]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/03_boxs/function/image/box_adv/render_bev.jpeg",alt:""})})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);