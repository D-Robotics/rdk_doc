"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[72056],{28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>d});var s=i(96540);const t={},r=s.createContext(t);function l(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(r.Provider,{value:n},e.children)}},35048:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Algorithm_Application/Python_Sample/ResNet18","title":"Image Classification - ResNet18","description":"This example demonstrates how to deploy the ResNet18 model for image classification inference using the Python API of hbmruntime. It is applicable to RDK S100 devices equipped with a BPU chip. The example code is located in the /app/pydevdemo/01classificationsample/01_resnet18/ directory.","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/02_Python_Sample/02_ResNet18.md","sourceDirName":"04_Algorithm_Application/02_Python_Sample","slug":"/Algorithm_Application/Python_Sample/ResNet18","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/ResNet18","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1764645625000,"sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Example Overview","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/Summary"},"next":{"title":"Image Classification - MobileNetV2","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/MobileNetV2"}}');var t=i(74848),r=i(28453);const l={sidebar_position:2},d="Image Classification - ResNet18",o={},c=[{value:"Model Description",id:"model-description",level:2},{value:"Functionality Description",id:"functionality-description",level:2},{value:"Environment Dependencies",id:"environment-dependencies",level:2},{value:"Directory Structure",id:"directory-structure",level:2},{value:"Parameter Description",id:"parameter-description",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Notes",id:"notes",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"image-classification---resnet18",children:"Image Classification - ResNet18"})}),"\n",(0,t.jsxs)(n.p,{children:["This example demonstrates how to deploy the ",(0,t.jsx)(n.code,{children:"ResNet18"})," model for image classification inference using the Python API of ",(0,t.jsx)(n.code,{children:"hbm_runtime"}),". It is applicable to RDK S100 devices equipped with a BPU chip. The example code is located in the ",(0,t.jsx)(n.code,{children:"/app/pydev_demo/01_classification_sample/01_resnet18/"})," directory."]}),"\n",(0,t.jsx)(n.h2,{id:"model-description",children:"Model Description"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Introduction"}),":"]}),"\n",(0,t.jsx)(n.p,{children:'ResNet (Residual Network) is a deep convolutional neural network architecture proposed by Microsoft Research. Its core idea is to introduce "residual connections," which alleviate the vanishing gradient problem in deep networks through shortcut connections across layers, enabling effective training of networks with dozens or even hundreds of layers. The ResNet18 used in this example is a lightweight variant with 18 layers, widely applied in tasks such as image classification and feature extraction.'}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"HBM Model Name"}),": ",(0,t.jsx)(n.code,{children:"resnet18_224x224_nv12.hbm"})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Input Format"}),": NV12, size 224x224"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": Softmax probability distribution over 1000 classes"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Model Download URL"})," (automatically downloaded by the program):"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"https://archive.d-robotics.cc/downloads/rdk_model_zoo/rdk_s100/ResNet/resnet18_224x224_nv12.hbm\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"functionality-description",children:"Functionality Description"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Model Loading"})}),"\n",(0,t.jsxs)(n.p,{children:["Use ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," to load the specified model and parse input/output names and shapes for subsequent inference."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Input Preprocessing"})}),"\n",(0,t.jsx)(n.p,{children:"Resize the BGR image to 224x224 and convert it to NV12 format (separated Y and UV planes)."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Inference Execution"})}),"\n",(0,t.jsxs)(n.p,{children:["Perform forward inference using the ",(0,t.jsx)(n.code,{children:".run()"})," method, supporting optional scheduling parameters (priority, core binding)."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Result Post-processing"})}),"\n",(0,t.jsx)(n.p,{children:"Read the output tensor, parse the top-K classification results (Top-5), and display class labels along with their probabilities."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"environment-dependencies",children:"Environment Dependencies"}),"\n",(0,t.jsx)(n.p,{children:"This example has no special environment requirements; simply ensure that the dependencies listed in pydev are installed."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install -r ../../requirements.txt\n"})}),"\n",(0,t.jsx)(n.h2,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:".\n\u251c\u2500\u2500 resnet18.py                 # Main program: uses `hbm_runtime` to run ResNet18 classification\n\u2514\u2500\u2500 README.md                   # Usage instructions\n"})}),"\n",(0,t.jsx)(n.h2,{id:"parameter-description",children:"Parameter Description"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter"}),(0,t.jsx)(n.th,{children:"Description"}),(0,t.jsx)(n.th,{children:"Default Value"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--model-path"})}),(0,t.jsx)(n.td,{children:"Path to the model file (.hbm format)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/resnet18_224x224_nv12.hbm"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--test-img"})}),(0,t.jsx)(n.td,{children:"Path to the test image"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/app/res/assets/zebra_cls.jpg"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--label-file"})}),(0,t.jsx)(n.td,{children:"Path to the class label mapping file"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/app/res/labels/imagenet1000_clsidx_to_labels.txt"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--priority"})}),(0,t.jsx)(n.td,{children:"Model priority (0\u2013255; higher value means higher priority)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"0"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--bpu-cores"})}),(0,t.jsxs)(n.td,{children:["List of BPU core IDs to use for inference (e.g., ",(0,t.jsx)(n.code,{children:"--bpu-cores 0 1"}),")"]}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"[0]"})})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Run the Model"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Using default parameters:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python resnet18.py\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Running with custom parameters:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python resnet18.py \\\n--model-path /opt/hobot/model/s100/basic/resnet18_224x224_nv12.hbm \\\n--test-img /app/res/assets/zebra_cls.jpg \\\n--label-file /app/res/labels/imagenet1000_clsidx_to_labels.txt\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"View Results"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"Top-5 Predictions:\nzebra: 0.9979\nimpala, Aepyceros melampus: 0.0005\ncheetah, chetah, Acinonyx jubatus: 0.0005\ngazelle: 0.0004\nprairie chicken, prairie grouse, prairie fowl: 0.0002\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"If the specified model path does not exist, the program will attempt to download the model automatically."}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}}}]);