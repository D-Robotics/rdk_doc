"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[62262],{28453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>d});var s=i(96540);const t={},l=s.createContext(t);function r(e){const n=s.useContext(l);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),s.createElement(l.Provider,{value:n},e.children)}},89590:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>d,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"Algorithm_Application/python-api","title":"Python API Reference Manual","description":"Overview","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/01_Python_API.md","sourceDirName":"04_Algorithm_Application","slug":"/Algorithm_Application/python-api","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/python-api","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770014688000,"sidebarPosition":1,"frontMatter":{"sidebar_position":1,"id":"python-api","title":"Python API Reference Manual","sidebar_label":"4.1 Python API"},"sidebar":"tutorialSidebar","previous":{"title":"4. \u7b97\u6cd5\u5e94\u7528\u5f00\u53d1","permalink":"/rdk_doc/en/rdk_s/Basic_Development"},"next":{"title":"4.2\u53c2\u8003\u793a\u4f8b\uff08Python\uff09","permalink":"/rdk_doc/en/rdk_s/03_Python_Sample"}}');var t=i(74848),l=i(28453);const r={sidebar_position:1,id:"python-api",title:"Python API Reference Manual",sidebar_label:"4.1 Python API"},d=void 0,a={},o=[{value:"Overview",id:"overview",level:2},{value:"Applicable Scenarios",id:"applicable-scenarios",level:3},{value:"Key Features",id:"key-features",level:3},{value:"Installation",id:"installation",level:2},{value:"System Dependencies",id:"system-dependencies",level:3},{value:"Building the Wheel Package",id:"building-the-wheel-package",level:3},{value:"Building During DEB Installation",id:"building-during-deb-installation",level:4},{value:"Building During System Software Compilation",id:"building-during-system-software-compilation",level:4},{value:"Building On-Device",id:"building-on-device",level:4},{value:"Installation Methods",id:"installation-methods",level:3},{value:"Using a Wheel Package",id:"using-a-wheel-package",level:4},{value:"Using a .deb Package",id:"using-a-deb-package",level:4},{value:"Uninstallation Instructions",id:"uninstallation-instructions",level:3},{value:"Quick Start",id:"quick-start",level:2},{value:"Environment Setup",id:"environment-setup",level:3},{value:"Examples",id:"examples",level:3},{value:"Single-Model, Single-Input Inference",id:"single-model-single-input-inference",level:4},{value:"Single-Model, Multi-Input Inference",id:"single-model-multi-input-inference",level:4},{value:"Common Issues",id:"common-issues",level:3},{value:"Module/Class/Function Reference (API Reference)",id:"moduleclassfunction-reference-api-reference",level:2},{value:"Enumerations",id:"enumerations",level:3},{value:"hbDNNDataType",id:"hbdnndatatype",level:4},{value:"Tensor data type enumeration:",id:"tensor-data-type-enumeration",level:5},{value:"Example",id:"example",level:5},{value:"hbDNNQuantiType",id:"hbdnnquantitype",level:4},{value:"Tensor quantization type enumeration:",id:"tensor-quantization-type-enumeration",level:5},{value:"Example",id:"example-1",level:5},{value:"Class Reference",id:"class-reference",level:3},{value:"HB_HBMRuntime",id:"hb_hbmruntime",level:4},{value:"Constructor",id:"constructor",level:5},{value:"Attributes",id:"attributes",level:5},{value:"Inference Execution Functions",id:"inference-execution-functions",level:5},{value:"Configuration Functions",id:"configuration-functions",level:5},{value:"QuantParams Class",id:"quantparams-class",level:4},{value:"Attributes",id:"attributes-1",level:5},{value:"Example:",id:"example-2",level:5},{value:"SchedParam Class",id:"schedparam-class",level:4},{value:"Attributes",id:"attributes-2",level:5},{value:"Example:",id:"example-3",level:5}];function c(e){const n={a:"a",br:"br",code:"code",h2:"h2",h3:"h3",h4:"h4",h5:"h5",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"hbm_runtime"})," is a Python binding interface based on pybind11, designed to access and operate the C++ libraries ",(0,t.jsx)(n.code,{children:"libhbucp"}),"/",(0,t.jsx)(n.code,{children:"libdnn"}),", providing high-performance neural network model loading and inference capabilities."]}),"\n",(0,t.jsx)(n.p,{children:"This interface encapsulates low-level model runtime details, enabling Python users to conveniently load single or multiple neural network models, manage input/output metadata, and flexibly execute inference operations. The interface supports multiple input data formats and ensures input data is stored contiguously through intelligent conversion, thereby enhancing runtime efficiency."}),"\n",(0,t.jsx)(n.h3,{id:"applicable-scenarios",children:"Applicable Scenarios"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Rapid integration and invocation of ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," runtime functionality within a Python environment."]}),"\n",(0,t.jsx)(n.li,{children:"Applications requiring high inference efficiency and flexibility, such as robotic vision and intelligent edge computing."}),"\n",(0,t.jsx)(n.li,{children:"Scenarios requiring simultaneous loading and management of multiple models, with dynamic configuration of inference priorities and hardware resource allocation."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"key-features",children:"Key Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Multi-model support"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Supports loading either a single model or a group of multiple models. Each model can independently retrieve input/output metadata and perform inference."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Flexible input formats"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Supports single input (",(0,t.jsx)(n.code,{children:"numpy.ndarray"}),");"]}),"\n",(0,t.jsxs)(n.li,{children:["Supports input dictionaries mapped by model name (",(0,t.jsx)(n.code,{children:"Dict[str, np.ndarray]"}),");"]}),"\n",(0,t.jsxs)(n.li,{children:["Supports multi-model, multi-input structures (",(0,t.jsx)(n.code,{children:"Dict[str, Dict[str, np.ndarray]]"}),"). All inputs are automatically checked for C-contiguous memory layout and copied if necessary to ensure efficient and correct low-level access."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Specifiable inference priority"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Allows explicit specification of scheduling priority for model tasks via the ",(0,t.jsx)(n.code,{children:"priority: Dict[str, int]"})," parameter, enabling the scheduler to reasonably allocate inference tasks under limited hardware resources."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Specifiable BPU cores for inference"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Supports explicitly assigning BPU compute cores for model inference via ",(0,t.jsx)(n.code,{children:"bpu_cores: Dict[str, List[int]]"}),", enabling strategies such as heterogeneous core binding."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Parallel multi-model inference"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["For multi-model input scenarios, the underlying system automatically employs a multi-threaded mechanism to execute each model\u2019s inference task in parallel (",(0,t.jsx)(n.code,{children:"multi-threaded launch"}),"). This achieves higher throughput on multi-core BPU systems (note: single-core BPU execution remains sequential)."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Metadata access interface"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Number, names, and data types (",(0,t.jsx)(n.code,{children:"hbDNNDataType"})," enum) of inputs/outputs;"]}),"\n",(0,t.jsx)(n.li,{children:"Tensor shapes, memory strides, and quantization parameters (including scale, zero point, and quantization type) for inputs/outputs;"}),"\n",(0,t.jsx)(n.li,{children:"Model description information, HBM file metadata, etc."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Fully bound type system"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Supports quantization parameter structure ",(0,t.jsx)(n.code,{children:"QuantParams"}),", data type enum ",(0,t.jsx)(n.code,{children:"hbDNNDataType"}),", model scheduling parameter object ",(0,t.jsx)(n.code,{children:"SchedParam"}),", and quantization type enum ",(0,t.jsx)(n.code,{children:"hbDNNQuantiType"}),", providing type-safe attribute access."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," module is a high-performance Python interface for C++-based inference runtime, relying on pybind11 and Horizon Robotics\u2019 underlying inference libraries (e.g., ",(0,t.jsx)(n.code,{children:"libdnn"}),", ",(0,t.jsx)(n.code,{children:"libhbucp"}),"). It supports installation via system DEB packages (",(0,t.jsx)(n.code,{children:".deb"}),") and is compatible with Python 3.10 and above."]}),"\n",(0,t.jsx)(n.h3,{id:"system-dependencies",children:"System Dependencies"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Dependency"}),(0,t.jsx)(n.th,{children:"Minimum Version"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Python"}),(0,t.jsx)(n.td,{children:"\u2265 3.10"}),(0,t.jsx)(n.td,{children:"Python 3.10 is recommended"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"pip"}),(0,t.jsx)(n.td,{children:"\u2265 22.0"}),(0,t.jsx)(n.td,{children:"Required for installing wheel packages"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"pybind11"}),(0,t.jsx)(n.td,{children:"Any"}),(0,t.jsx)(n.td,{children:"Used during build; not required when installing package"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"scikit-build-core"}),(0,t.jsx)(n.td,{children:"\u2265 0.7"}),(0,t.jsx)(n.td,{children:"Used when building wheel packages (source builds only)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Horizon Base Libraries"}),(0,t.jsx)(n.td,{children:"Platform-dependent"}),(0,t.jsxs)(n.td,{children:["e.g., ",(0,t.jsx)(n.code,{children:"libdnn.so"}),", ",(0,t.jsx)(n.code,{children:"libucp.so"}),", typically provided by BSP"]})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"building-the-wheel-package",children:"Building the Wheel Package"}),"\n",(0,t.jsx)(n.p,{children:"There are three methods to build the wheel package, as described below."}),"\n",(0,t.jsx)(n.h4,{id:"building-during-deb-installation",children:"Building During DEB Installation"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," wheel is automatically built during installation of the ",(0,t.jsx)(n.code,{children:"hobot-dnn"})," package. After installing the ",(0,t.jsx)(n.code,{children:".deb"})," package, the ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," ",(0,t.jsx)(n.code,{children:".whl"})," file will be generated."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Install from repository\nsudo apt-get install hobot-dnn\n\n# Install from local .deb package (note: package name may vary by build timestamp)\ndpkg -i hobot-dnn_4.0.4-20250909195426_arm64.deb\n\n# After installation, the wheel package can be found in /tmp on the device\nls /tmp\n\n# Note: wheel filename varies by version; xxx represents the version number\n# hbm_runtime-x.x.x-cp310-cp310-manylinux_2_34_aarch64.whl\n"})}),"\n",(0,t.jsx)(n.h4,{id:"building-during-system-software-compilation",children:"Building During System Software Compilation"}),"\n",(0,t.jsxs)(n.p,{children:["When compiling the system software image, the ",(0,t.jsx)(n.code,{children:"hobot-dnn"})," ",(0,t.jsx)(n.code,{children:".deb"})," package is installed, which triggers the build of the ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," wheel package. The resulting ",(0,t.jsx)(n.code,{children:".whl"})," file is saved to ",(0,t.jsx)(n.code,{children:"out/product/deb_packages"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo ./pack_image.sh\n\nls out/product/deb_packages\n\n# Note: wheel filename varies by version; xxx represents the version number\n# hbm_runtime-x.x.x-cp310-cp310-manylinux_2_34_aarch64.whl\n"})}),"\n",(0,t.jsx)(n.h4,{id:"building-on-device",children:"Building On-Device"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Navigate to the hbm_runtime source directory\ncd /usr/hobot/lib/hbm_runtime\n\n# Run the build script\n./build.sh\n\n# View the built wheel package\nls dist/\n\n# Note: wheel filename varies by version; xxx represents the version number\n# hbm_runtime-x.x.x-cp310-cp310-manylinux_2_34_aarch64.whl\n"})}),"\n",(0,t.jsx)(n.h3,{id:"installation-methods",children:"Installation Methods"}),"\n",(0,t.jsx)(n.h4,{id:"using-a-wheel-package",children:"Using a Wheel Package"}),"\n",(0,t.jsx)(n.p,{children:"Choose one of the following two methods:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Install from local wheel file"}),(0,t.jsx)(n.br,{}),"\n","Locate the ",(0,t.jsx)(n.code,{children:".whl"}),' file built in the "Building the Wheel Package" section.']}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Example: install local .whl file using pip (note: filename varies by version)\npip install hbm_runtime-x.x.x-cp310-cp310-manylinux_2_34_aarch64.whl\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Install from pypi"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install hbm_runtime\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"using-a-deb-package",children:"Using a .deb Package"}),"\n",(0,t.jsx)(n.p,{children:"Choose one of the following two methods:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Install from local .deb package"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Example: install .deb package (note: package name may vary by build timestamp)\nsudo dpkg -i hobot-dnn_4.0.2-20250714201215_arm64.deb\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Install via apt repository"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo apt-get install hobot-dnn\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Common Issues"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["If files are not updated after ",(0,t.jsx)(n.code,{children:".deb"})," installation, check whether other dependencies (e.g., an older version of ",(0,t.jsx)(n.code,{children:"hobot-spdev"}),") are preventing overwrites."]}),"\n",(0,t.jsxs)(n.li,{children:["Use ",(0,t.jsx)(n.code,{children:"dpkg -L hobot-dnn"})," to verify whether files were deployed successfully."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"uninstallation-instructions",children:"Uninstallation Instructions"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Uninstall pip-installed package:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip uninstall hbmruntime\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Uninstall .deb-installed package:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo apt remove hobot-dnn\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,t.jsxs)(n.p,{children:["This section demonstrates how to use ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," for model loading and inference. With just a few lines of code, you can run a model and obtain output results."]}),"\n",(0,t.jsx)(n.h3,{id:"environment-setup",children:"Environment Setup"}),"\n",(0,t.jsxs)(n.p,{children:["Ensure that ",(0,t.jsx)(n.code,{children:"HBMRuntime"})," is properly installed (see ",(0,t.jsx)(n.a,{href:"#installation",children:"Installation"}),") and that you have an ",(0,t.jsx)(n.code,{children:".hbm"})," model file ready."]}),"\n",(0,t.jsx)(n.h3,{id:"examples",children:"Examples"}),"\n",(0,t.jsx)(n.h4,{id:"single-model-single-input-inference",children:"Single-Model, Single-Input Inference"}),"\n",(0,t.jsx)(n.p,{children:"Applicable when the model has only one input tensor."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom hbm_runtime import HB_HBMRuntime\n\n# Load model\nmodel = HB_HBMRuntime("/opt/hobot/model/s100/basic/lanenet256x512.hbm")\n\n# Get model name and input name\nmodel_name = model.model_names[0]\ninput_name = model.input_names[model_name][0]  # assuming the model has only one input\n\n# Get the corresponding input shape\ninput_shape = model.input_shapes[model_name][input_name]\n\n# Construct numpy input\ninput_tensor = np.ones(input_shape, dtype=np.float32)\n\n# Run inference\noutputs = model.run(input_tensor)\n\n# Retrieve output results\noutput_array = outputs[model_name]\nprint("Output:", output_array)\n'})}),"\n",(0,t.jsx)(n.h4,{id:"single-model-multi-input-inference",children:"Single-Model, Multi-Input Inference"}),"\n",(0,t.jsx)(n.p,{children:"Applicable when the model has multiple input tensors."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom hbm_runtime import HB_HBMRuntime\n\nhb_dtype_map = {\n    "U8": np.uint8,\n    "S8": np.int8,\n    "F32": np.float32,\n    "F16": np.float16,\n    "U16": np.uint16,\n    "S16": np.int16,\n    "S32": np.int32,\n    "U32": np.uint32,\n    "BOOL8": np.bool_,\n}\n\n# Load model\nmodel = HB_HBMRuntime("/opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm")\n\n# Get model name (assuming only one model is loaded)\nmodel_name = model.model_names[0]\n\n# Prepare input names, shapes, and data types\ninput_names = model.input_names[model_name]\ninput_shapes = model.input_shapes[model_name]\ninput_dtypes = model.input_dtypes[model_name]\n\n# Construct input dictionary\n\ninput_tensors = {}\nfor name in input_names:\n    shape = input_shapes[name]\n    np_dtype = hb_dtype_map.get(input_dtypes[name].name, np.float32)  # fallback\n    input_tensors[name] = np.ones(shape, dtype=np_dtype)\n\n# Optional: Specify inference priority and BPU device\npriority = {model_name: 5}\nbpu_cores = {model_name: [0]}\n\nmodel.set_scheduling_params(\n    priority=priority,\n    bpu_cores=bpu_cores\n)\n\n# Perform inference, optionally specifying priority and BPU cores\nresults = model.run(input_tensors)\n\n# Output results\nfor output_name, output_data in results[model_name].items():\n    print(f"Output: {output_name}, shape={output_data.shape}")\n\n'})}),"\n",(0,t.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Issue"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"How to obtain model names?"}),(0,t.jsxs)(n.td,{children:["Use ",(0,t.jsx)(n.code,{children:"model.model_names"})," to view the list of loaded model names."]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"How to confirm input dimensions/types?"}),(0,t.jsxs)(n.td,{children:["Use ",(0,t.jsx)(n.code,{children:"model.input_shapes"})," and ",(0,t.jsx)(n.code,{children:"model.input_dtypes"}),"."]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"How to confirm BPU core allocation?"}),(0,t.jsxs)(n.td,{children:["Specify BPU cores using the ",(0,t.jsx)(n.code,{children:"bpu_cores"})," parameter (e.g., [0, 1, 2, 3]); actual availability depends on hardware support."]})]})]})]}),"\n",(0,t.jsxs)(n.p,{children:["For more advanced usage (e.g., multi-input models, reading quantization parameters), please refer to the ",(0,t.jsx)(n.a,{href:"#module-class-function-reference-api-reference",children:"API Reference"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"moduleclassfunction-reference-api-reference",children:"Module/Class/Function Reference (API Reference)"}),"\n",(0,t.jsxs)(n.p,{children:["The Python module ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," is a PyBind11-wrapped interface for Horizon's HBM model inference, implemented on top of the underlying ",(0,t.jsx)(n.code,{children:"libdnn"})," and ",(0,t.jsx)(n.code,{children:"libhbucp"})," libraries. It provides unified APIs for model loading, querying input/output information, performing inference, and supports multi-model loading, multi-input inference, specifying inference models, BPU cores, and inference task priorities."]}),"\n",(0,t.jsx)(n.h3,{id:"enumerations",children:"Enumerations"}),"\n",(0,t.jsx)(n.h4,{id:"hbdnndatatype",children:"hbDNNDataType"}),"\n",(0,t.jsx)(n.h5,{id:"tensor-data-type-enumeration",children:"Tensor data type enumeration:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"S4: 4-bit signed"}),"\n",(0,t.jsx)(n.li,{children:"U4: 4-bit unsigned"}),"\n",(0,t.jsx)(n.li,{children:"S8: 8-bit signed"}),"\n",(0,t.jsx)(n.li,{children:"U8: 8-bit unsigned"}),"\n",(0,t.jsx)(n.li,{children:"F16: 16-bit float"}),"\n",(0,t.jsx)(n.li,{children:"S16: 16-bit signed"}),"\n",(0,t.jsx)(n.li,{children:"U16: 16-bit unsigned"}),"\n",(0,t.jsx)(n.li,{children:"F32: 32-bit float"}),"\n",(0,t.jsx)(n.li,{children:"S32: 32-bit signed"}),"\n",(0,t.jsx)(n.li,{children:"U32: 32-bit unsigned"}),"\n",(0,t.jsx)(n.li,{children:"F64: 64-bit float"}),"\n",(0,t.jsx)(n.li,{children:"S64: 64-bit signed"}),"\n",(0,t.jsx)(n.li,{children:"U64: 64-bit unsigned"}),"\n",(0,t.jsx)(n.li,{children:"BOOL8: 8-bit bool type"}),"\n",(0,t.jsx)(n.li,{children:"MAX: Maximum value (reserved field)"}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"example",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from hbm_runtime import hbDNNDataType\nprint(hbDNNDataType.F32)  # Output: hbDNNDataType.F32\n"})}),"\n",(0,t.jsx)(n.h4,{id:"hbdnnquantitype",children:"hbDNNQuantiType"}),"\n",(0,t.jsx)(n.h5,{id:"tensor-quantization-type-enumeration",children:"Tensor quantization type enumeration:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"NONE: Non-quantized type"}),"\n",(0,t.jsx)(n.li,{children:"SCALE: Linear scale quantization (scale + zero_point)"}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"example-1",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from hbm_runtime import hbDNNQuantiType\nprint(hbDNNQuantiType.SCALE)  # Output: hbDNNQuantiType.SCALE\n"})}),"\n",(0,t.jsx)(n.h3,{id:"class-reference",children:"Class Reference"}),"\n",(0,t.jsx)(n.h4,{id:"hb_hbmruntime",children:"HB_HBMRuntime"}),"\n",(0,t.jsx)(n.p,{children:"Model runtime class that loads one or multiple HBM model files and provides inference execution interfaces."}),"\n",(0,t.jsx)(n.h5,{id:"constructor",children:"Constructor"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Function signature"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"HB_HBMRuntime(model_file: str)\nHB_HBMRuntime(model_files: List[str])\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Parameters"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"model_file"}),(0,t.jsx)(n.td,{children:"str"}),(0,t.jsx)(n.td,{children:"Path to the HBM model file"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"model_files"}),(0,t.jsx)(n.td,{children:"List[str]"}),(0,t.jsx)(n.td,{children:"Paths to multiple HBM model files (for multi-model loading)"})]})]})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Return value"}),"\n",(0,t.jsx)(n.p,{children:"Class instance"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from hbm_runtime import HB_HBMRuntime\n\nmodel = HB_HBMRuntime("model.hbm")\n# Or load multiple models:\nmodel = HB_HBMRuntime(["model1.hbm", "model2.hbm"])\n'})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"attributes",children:"Attributes"}),"\n",(0,t.jsx)(n.p,{children:"All attributes listed below are read-only."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"version: str"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Retrieves the library version number."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"str: Version number string."}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'print("Version:", HB_HBMRuntime.version)\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"model_names: List[str]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"List of loaded model names."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"List[str]: List of model names."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.model_names)\n# Output: ['model_1', 'model_2']\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"model_count: int"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Number of loaded models."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"int: Number of loaded models."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.model_count)\n# Output: 2\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"model_descs: Dict[str, str]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Description information for each model (embedded notes from the model)."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Dict[str, str]: Keys are model names; values are overall model descriptions, typically provided by the compiler."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Print descriptions for all models\nprint(model.model_descs)\n# Output: {'yolov5x_672x672_nv12': 'Image classification model based on ResNet-18.'}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"hbm_descs: Dict[str, str]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Annotation or metadata information from each HBM file."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'Dict[str, str]: Keys are HBM filenames (e.g., "resnet18"); values are annotation or metadata strings from the HBM file.'}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Print description information for all model files\nprint(model.hbm_descs)\n# Output: {'/opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm': 'xxx'}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"input_counts: Dict[str, int]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Number of input tensors for each model."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Dict[str, int]: Keys are model names; values are the number of input tensors for the corresponding model."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Print description information for all model files\nprint(model.input_counts)\n# Output: {'yolov5x_672x672_nv12': 2}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"input_names: Dict[str, List[str]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"List of input tensor names for each model."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Keys are model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner List[str]: List of input tensor names for the model."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.input_names)\n# Output: {'yolov5x_672x672_nv12': ['data_y', 'data_uv']}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"input_descs: Dict[str, Dict[str, str]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Description for each input tensor."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, str]: Keys are input tensor names; values are their descriptions."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Print description information for all model files\nprint(model.input_descs)\n# Output: {'yolov5x_672x672_nv12': {'data_uv': 'xxx', 'data_y': 'xxx'}}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"input_shapes: Dict[str, Dict[str, List[int]]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Shape of each input tensor."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, List[int]]: Keys are input names; values are tensor dimensions (shapes)."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"model.input_shapes\n# Output: {'yolov5x_672x672_nv12': {'data_uv': [1, 336, 336, 2], 'data_y': [1, 672, 672, 1]}}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"input_dtypes: Dict[str, Dict[str, hbDNNDataType]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Description:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Data type of each input tensor."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, hbDNNDataType]: Keys are input tensor names; values are data types (e.g., F32, U8)."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"Example:"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:" print(model.input_dtypes)\n # Output: {'yolov5x_672x672_nv12': {'data_uv': <hbDNNDataType.U8: 3>, 'data_y': <hbDNNDataType.U8: 3>}}\n \n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"input_quants: Dict[str, Dict[str, QuantParams]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Provides quantization parameter information for all input tensors of each model. Used to support pre-processing computations for quantized models or to understand the quantization scheme of tensors."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'Outer Dict[str, ...]: Keys are model names (e.g., "resnet50").'}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, QuantParams]: Keys are input tensor names; values are QuantParams instances."}),"\n",(0,t.jsxs)(n.li,{children:["QuantParams class attributes:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"scale: np.ndarray \u2014 Quantization scale factor, typically a floating-point array."}),"\n",(0,t.jsx)(n.li,{children:"zero_point: np.ndarray \u2014 Zero point used for symmetric/asymmetric quantization offset."}),"\n",(0,t.jsx)(n.li,{children:"quant_type: hbDNNQuantiType \u2014 Enumeration value indicating quantization type (e.g., SCALE, NONE)."}),"\n",(0,t.jsx)(n.li,{children:"axis: int \u2014 Indicates the axis along which quantization is applied, in the case of per-channel quantization."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'quanti_info = model.input_quants\nfor model, inputs in quanti_info.items():\n    print(f"{model}:")\n    for name, info in inputs.items():\n        print(f"  {name}:")\n        print(f"    quant_type: {info.quant_type.name}")\n        print(f"    quantize_axis: {info.axis}")\n        print(f"    scale_data: {info.scale.tolist()}")\n        print(f"    zero_point_data: {info.zero_point.tolist()}")\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"input_strides: Dict[str, Dict[str, List[int]]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Stride information for each input tensor."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, List[int]]: Keys are input names; values are stride information for the corresponding input tensors."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.input_strides)\n# Output: {'yolov5x_672x672_nv12': {'data_uv': [-1, -1, 2, 1], 'data_y': [-1, -1, 1, 1]}}\n"})}),"\n","Note: For detailed explanation of strides, refer to the description in the libdnn library within the ",(0,t.jsx)(n.a,{href:"http://j6.doc.oe.hobot.cc/3.0.31/guide/ucp/runtime/bpu_sdk_api/data_structure/hbDNNTensorProperties.html",children:"OE documentation"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"output_counts: Dict[str, int]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Number of output tensors for each model."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Dict[str, int]: Keys are model names; values are the number of output tensors for the corresponding model."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.output_counts)\n# Output: {'yolov5x_672x672_nv12': 3}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"output_names: Dict[str, List[str]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"List of output tensor names for each model."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Keys are model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner List[str]: List of output tensor names for the corresponding model."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.output_names)\n# Output: {'yolov5x_672x672_nv12': ['output', '1310', '1312']}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"output_descs: Dict[str, Dict[str, str]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Descriptions for each output tensor."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, str]: Keys are output tensor names; values are their corresponding descriptions."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.output_descs)\n# Output: {'yolov5x_672x672_nv12': {'1310': 'xxx', '1312': 'xxx', 'output': 'xxx'}}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"output_shapes: Dict[str, Dict[str, List[int]]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Shape of each output tensor."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, List[int]]: Keys are output names; values are the dimensions (shape) of the corresponding output tensors."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.output_shapes)\n# Output: {'yolov5x_672x672_nv12': {'1310': [1, 42, 42, 255], '1312': [1, 21, 21, 255], 'output': [1, 84, 84, 255]}}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"output_dtypes: Dict[str, Dict[str, hbDNNDataType]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Data type of each output tensor."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, hbDNNDataType]: Keys are output tensor names; values are data types (e.g., F32, U8)."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.output_dtypes)\n# Output: {'yolov5x_672x672_nv12': {'1310': <hbDNNDataType.S32: 8>, '1312': <hbDNNDataType.S32: 8>, 'output': <hbDNNDataType.S32: 8>}}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"output_quants: Dict[str, Dict[str, QuantParams]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Provides quantization parameter information for all output tensors of each model. Used to support post-processing computations for quantized models (e.g., converting int8 data back to float32) or to understand the quantization scheme (e.g., scale-based)."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'Outer Dict[str, ...]: Keys are model names (e.g., "resnet50").'}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, QuantParams]: Keys are output tensor names; values are QuantParams instances."}),"\n",(0,t.jsxs)(n.li,{children:["QuantParams class attributes:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"scale: np.ndarray \u2014 Quantization scale factor, typically a floating-point array."}),"\n",(0,t.jsx)(n.li,{children:"zero_point: np.ndarray \u2014 Zero point used for symmetric/asymmetric quantization offset."}),"\n",(0,t.jsx)(n.li,{children:"quant_type: hbDNNQuantiType \u2014 Enumeration value indicating quantization type (e.g., SCALE, NONE)."}),"\n",(0,t.jsx)(n.li,{children:"axis: int \u2014 Indicates the axis along which quantization is applied, in the case of per-channel quantization."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'output_quanti = model.output_quants\nfor model, outputs in output_quanti.items():\n    print(f"{model}:")\n    for name, info in outputs.items():\n        print(f"  {name}:")\n        print(f"    quant_type: {info.quant_type.name}")\n        print(f"    quantize_axis: {info.axis}")\n        print(f"    scale_data: {info.scale}")\n        print(f"    zero_point_data: {info.zero_point}")\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"output_strides: Dict[str, Dict[str, List[int]]]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Stride information for each output tensor."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner Dict[str, List[int]]: Keys are output names; values are stride information for the corresponding output tensors."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model.output_strides)\n# Output: {'yolov5x_672x672_nv12': {'1310': [1806336, 43008, 1024, 4], '1312': [451584, 21504, 1024, 4], 'output': [7225344, 86016, 1024, 4]}}\n"})}),"\n","Note: For detailed explanation of strides, refer to the description in the libdnn library within the ",(0,t.jsx)(n.a,{href:"http://j6.doc.oe.hobot.cc/3.0.31/guide/ucp/runtime/bpu_sdk_api/data_structure/hbDNNTensorProperties.html",children:"OE documentation"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"sched_params: Dict[str, SchedParam]"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Functionality:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["sched_params provides scheduling parameters for all currently loaded models, including:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Priority (",(0,t.jsx)(n.code,{children:"priority"}),")"]}),"\n",(0,t.jsxs)(n.li,{children:["Custom ID (",(0,t.jsx)(n.code,{children:"customId"}),")"]}),"\n",(0,t.jsxs)(n.li,{children:["Assigned BPU cores (",(0,t.jsx)(n.code,{children:"bpu_cores"}),")"]}),"\n",(0,t.jsxs)(n.li,{children:["Device ID (",(0,t.jsx)(n.code,{children:"deviceId"}),")\nThese scheduling parameters influence how models execute on hardware, especially critical in multi-model deployments or multi-core devices."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Structure:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Outer Dict[str, ...]: Model names."}),"\n",(0,t.jsxs)(n.li,{children:["Inner SchedParam: Instance of the SchedParam class containing scheduling parameters ",(0,t.jsx)(n.code,{children:"priority"}),", ",(0,t.jsx)(n.code,{children:"customId"}),", ",(0,t.jsx)(n.code,{children:"bpu_cores"}),", and ",(0,t.jsx)(n.code,{children:"deviceId"})," for the model:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'{\n    "model_name": SchedParam(\n        priority: int,\n        customId: int,\n        bpu_cores: List[int],\n        deviceId: int\n    )\n}\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'params = model.sched_params\nfor name, sched in params.items():\n    print(f"Model: {name}")\n    print(f"  priority: {sched.priority}")\n    print(f"  customId: {sched.customId}")\n    print(f"  bpu_cores: {sched.bpu_cores}")\n    print(f"  deviceId: {sched.deviceId}")\n# Output:\n# Model: yolo12s_detect_nashe_640x640_nv12\n#   priority: 10\n#   customId: 0\n#   bpu_cores: [0]\n#   deviceId: 0\n# Model: yolov5nu_detect_nashe_640x640_nv12\n#   priority: 66\n#   customId: 0\n#   bpu_cores: [-1]\n#   deviceId: 0\n'})}),"\n","Note: A ",(0,t.jsx)(n.code,{children:"bpu_cores"})," value of -1 indicates automatic core assignment by the scheduler."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"inference-execution-functions",children:"Inference Execution Functions"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"run(input_tensor, **kwargs)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Function Signature:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"run(input_tensor: np.ndarray, **kwargs) -> Dict[str, Dict[str, np.ndarray]]\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Functionality:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Designed for inference with a single model and a single input. The input is a NumPy array corresponding to the model's sole input tensor. When only one model is loaded, specifying the model name is optional."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Parameters:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"input_tensor"}),(0,t.jsx)(n.td,{children:"np.ndarray"}),(0,t.jsx)(n.td,{children:"Single input tensor, used only in single-model, single-input inference scenarios. The tensor shape must match the expected input shape of the model."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"kwargs"}),(0,t.jsx)(n.td,{children:"Variable keyword arguments"}),(0,t.jsxs)(n.td,{children:[(0,t.jsx)(n.code,{children:"model_name"})," (",(0,t.jsx)(n.code,{children:"str"}),"): Specifies the model name (optional if only one model is loaded; required otherwise)."]})]})]})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Return Value:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Type: Dict[str, Dict[str, np.ndarray]]"}),"\n",(0,t.jsx)(n.li,{children:"Outer dictionary keys: Model names."}),"\n",(0,t.jsx)(n.li,{children:"Inner dictionary keys: Output tensor names."}),"\n",(0,t.jsx)(n.li,{children:"Values: Corresponding NumPy output arrays."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'Example: Refer to the "Quick Start" section, specifically the part on single-model, single-input inference.'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"run(input_tensors: Dict[str, np.ndarray], **kwargs)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Function Signature:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"run(input_tensors: Dict[str, np.ndarray], **kwargs) -> Dict[str, Dict[str, np.ndarray]]\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Functionality",":Applicable"," to single-model, multi-input inference. Each input tensor is specified by its input name, consistent with the model definition. When only one model is loaded, the model name in the input can be omitted."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Parameter Description"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter Name"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"input_tensors"}),(0,t.jsx)(n.td,{children:"Dict[str, np.ndarray]"}),(0,t.jsx)(n.td,{children:"Multiple input tensors, used only in single-model multi-input inference scenarios. Keys are input tensor names, and values are corresponding NumPy arrays."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"kwargs"}),(0,t.jsx)(n.td,{children:"Variable keyword arguments"}),(0,t.jsxs)(n.td,{children:[(0,t.jsx)(n.code,{children:"model_name"})," (",(0,t.jsx)(n.code,{children:"str"}),"): Specifies the model name (can be omitted if only one model is loaded; otherwise, it must be specified)."]})]})]})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Return Value",(0,t.jsx)(n.br,{}),"\n","Same as above."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'Example: Refer to the "Quick Start" section, specifically the part on single-model multi-input inference.'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"run(multi_input_tensors: Dict[str, Dict[str, np.ndarray]], **kwargs)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Function Signature"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"run(multi_input_tensors: Dict[str, Dict[str, np.ndarray]], **kwargs) -> Dict[str, Dict[str, np.ndarray]]\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Function Description",(0,t.jsx)(n.br,{}),"\n","Applicable to scenarios involving simultaneous inference of multiple models. Each model provides its own set of multiple input tensors. There is no need to specify ",(0,t.jsx)(n.code,{children:"model_name"}),", as model names are already indicated in the dictionary keys. If a model name is explicitly specified, only that model will be executed."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Parameter Description"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter Name"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"multi_input_tensors"}),(0,t.jsx)(n.td,{children:"Dict[str, Dict[str, np.ndarray]]"}),(0,t.jsx)(n.td,{children:"Multi-model inference input. The outer dictionary keys are model names; the inner dictionaries map input names to tensors. Supports running multiple models concurrently (each model may have multiple inputs)."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"kwargs"}),(0,t.jsx)(n.td,{children:"Variable keyword arguments"}),(0,t.jsxs)(n.td,{children:[(0,t.jsx)(n.code,{children:"model_name"})," (",(0,t.jsx)(n.code,{children:"str"}),"): Specifies the model name (can be omitted if only one model is loaded; otherwise, it must be specified)."]})]})]})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Return Value",(0,t.jsx)(n.br,{}),"\n","Same as above."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom hbm_runtime import HB_HBMRuntime\n\n# Map hbDNNDataType to NumPy types\nhb_dtype_map = {\n    "F32": np.float32,\n    "F16": np.float16,\n    "S8": np.int8,\n    "U8": np.uint8,\n    "S16": np.int16,\n    "U16": np.uint16,\n    "S32": np.int32,\n    "U32": np.uint32,\n    "S64": np.int64,\n    "U64": np.uint64,\n    "BOOL8": np.bool_,\n}\n\n# Load multiple models\nmodel_files = ["/opt/hobot/model/s100/basic/lanenet256x512.hbm",\n    "/opt/hobot/model/s100/basic/yolov5x_672x672_nv12.hbm"]\n\nmodel = HB_HBMRuntime(model_files)\n\n# Print loaded model names\nprint("Loaded models:", model.model_names)\n\n# Construct multiple input tensors for each model\nmulti_input_tensors = {}\n\nfor model_name in model.model_names:\n    model_inputs = {}\n\n    for input_name in model.input_names[model_name]:\n        shape = model.input_shapes[model_name][input_name]\n        dtype_enum = model.input_dtypes[model_name][input_name]\n\n        np_dtype = hb_dtype_map.get(dtype_enum.name, np.float32)\n\n        model_inputs[input_name] = np.ones(shape, dtype=np_dtype)\n\n    multi_input_tensors[model_name] = model_inputs\n\n# Optional: Specify inference priority and BPU devices\npriority = {name: 5 for name in model.model_names}\nbpu_cores = {name: [0] for name in model.model_names}\n\nmodel.set_scheduling_params(\n    priority=priority,\n    bpu_cores=bpu_cores\n)\n\n# Perform inference\nresults = model.run(multi_input_tensors)\n\n# Output results\nfor model_name, outputs in results.items():\n    print(f"\\nModel: {model_name}")\n    for output_name, output_tensor in outputs.items():\n        print(f"  Output: {output_name}, shape={output_tensor.shape}, dtype={output_tensor.dtype}")\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Detailed Explanation of ",(0,t.jsx)(n.code,{children:"kwargs"})," Parameters"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["model_name","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Type: ",(0,t.jsx)(n.code,{children:"str"})," (model name string)"]}),"\n",(0,t.jsxs)(n.li,{children:["Description: Specifies the model to be used for inference, which must be one of the currently loaded models. In the first two ",(0,t.jsx)(n.code,{children:"run"})," methods, this parameter can be omitted if only one model is loaded; if multiple models are loaded, this parameter must be specified. In the third ",(0,t.jsx)(n.code,{children:"run"})," method, it can still be omitted\u2014in which case all models provided in ",(0,t.jsx)(n.code,{children:"multi_input_tensors"})," will be inferred; if specified, only the named model will be executed."]}),"\n",(0,t.jsxs)(n.li,{children:["Example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'outputs = model.run(input_tensor, model_name="resnet18")\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"configuration-functions",children:"Configuration Functions"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["set_scheduling_params","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Function Signature"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def set_scheduling_params(\n    priority: Optional[Dict[str, int]] = None,\n    bpu_cores: Optional[Dict[str, List[int]]] = None,\n    custom_id: Optional[Dict[str, int]] = None,\n    device_id: Optional[Dict[str, int]] = None\n) -> None\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Parameter Description"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter Name"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"priority"}),(0,t.jsx)(n.td,{children:"Optional dict (model name \u2192 int)"}),(0,t.jsx)(n.td,{children:"Sets scheduling priority for each model. Range is typically 0\u2013255; higher values indicate higher priority."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"bpu_cores"}),(0,t.jsx)(n.td,{children:"Optional dict (model name \u2192 List[int])"}),(0,t.jsx)(n.td,{children:"Specifies the list of BPU core indices to bind the model to. Default indicates automatic allocation; actual behavior depends on hardware support."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"custom_id"}),(0,t.jsx)(n.td,{children:"Optional dict (model name \u2192 int)"}),(0,t.jsxs)(n.td,{children:["Custom priority identifier (e.g., timestamp, frame ID). Lower values indicate higher priority. Priority order: ",(0,t.jsx)(n.code,{children:"priority"})," > ",(0,t.jsx)(n.code,{children:"custom_id"}),"."]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"device_id"}),(0,t.jsx)(n.td,{children:"Optional dict (model name \u2192 int)"}),(0,t.jsx)(n.td,{children:"Specifies the device ID on which the model should run."})]})]})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Return Value",(0,t.jsx)(n.br,{}),"\n","None"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Set scheduling parameters\nmodel.set_scheduling_params(\n    priority={"model1": 200, "model2": 100},\n    bpu_cores={"model1": [0, 1], "model2": [0]}\n)\n\n# Verify that settings took effect\nparams = runtime.sched_params\nprint(params["model1"].priority)   # Output: 200\nprint(params["model1"].bpu_cores)  # Output: [0, 1]\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Exception Handling","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["A ",(0,t.jsx)(n.code,{children:"ValueError"})," is raised if input tensor dimensions or data types do not match the model expectations."]}),"\n",(0,t.jsx)(n.li,{children:"If input tensors are non-contiguous (not C-style), a contiguous copy is automatically created internally."}),"\n",(0,t.jsxs)(n.li,{children:["Before inference, ensure that input tensor shapes exactly match those in ",(0,t.jsx)(n.code,{children:"input_shapes"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"quantparams-class",children:"QuantParams Class"}),"\n",(0,t.jsx)(n.p,{children:"Tensor quantization parameter object."}),"\n",(0,t.jsx)(n.h5,{id:"attributes-1",children:"Attributes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["scale: ",(0,t.jsx)(n.code,{children:"numpy.ndarray"}),", array of quantization scale factors"]}),"\n",(0,t.jsxs)(n.li,{children:["zero_point: ",(0,t.jsx)(n.code,{children:"numpy.ndarray"}),", array of zero points"]}),"\n",(0,t.jsxs)(n.li,{children:["quant_type: ",(0,t.jsx)(n.code,{children:"hbDNNQuantiType"}),", indicating the quantization mode"]}),"\n",(0,t.jsxs)(n.li,{children:["axis: ",(0,t.jsx)(n.code,{children:"int"}),", quantization axis (used in per-channel quantization)"]}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"example-2",children:"Example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'  # Retrieve quantization parameters for a specific model output\n  tensor_qparams = model.output_quants[model_name][output_name]\n  print("scale:", tensor_qparams.scale)\n  print("zero_point:", tensor_qparams.zero_point)\n  print("type:", tensor_qparams.quant_type)\n  print("axis:", tensor_qparams.axis)\n'})}),"\n",(0,t.jsx)(n.h4,{id:"schedparam-class",children:"SchedParam Class"}),"\n",(0,t.jsx)(n.p,{children:"Model scheduling parameter object, used to configure hardware-level scheduling policies (e.g., priority, core binding)."}),"\n",(0,t.jsx)(n.h5,{id:"attributes-2",children:"Attributes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["priority: ",(0,t.jsx)(n.code,{children:"Dict[str, int]"}),(0,t.jsx)(n.br,{}),"\n","Priority settings for each model. Keys are model names; values are integer priorities (higher values = higher priority, range: 0\u2013255)."]}),"\n",(0,t.jsxs)(n.li,{children:["customId: ",(0,t.jsx)(n.code,{children:"Dict[str, int]"}),(0,t.jsx)(n.br,{}),"\n","Custom priority identifiers (e.g., timestamp, frame ID). Lower values = higher priority. Priority order: ",(0,t.jsx)(n.code,{children:"priority"})," > ",(0,t.jsx)(n.code,{children:"customId"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["bpu_cores: ",(0,t.jsx)(n.code,{children:"Dict[str, List[int]]"}),(0,t.jsx)(n.br,{}),"\n","List of BPU core IDs to bind each model to. Keys are model names; values are integer lists, e.g., ",(0,t.jsx)(n.code,{children:"[0]"})," or ",(0,t.jsx)(n.code,{children:"[0, 1]"})," for binding to one or multiple cores."]}),"\n",(0,t.jsxs)(n.li,{children:["deviceId: ",(0,t.jsx)(n.code,{children:"Dict[str, int]"}),(0,t.jsx)(n.br,{}),"\n","Device ID on which each model is deployed. Keys are model names; values are device IDs."]}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"example-3",children:"Example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from hbm_runtime import HB_HBMRuntime, SchedParam\n\n# Create a scheduling parameter object\nsched = SchedParam()\nsched.priority = {"modelA": 8}\nsched.customId = {"modelA": 1001}\nsched.bpu_cores = {"modelA": [0, 1]}\nsched.deviceId = {"modelA": 0}\n\n# Apply scheduling parameters to the runtime\nmodel.set_scheduling_params(priority=sched.priority,\n                            custom_id=sched.customId,\n                            bpu_cores=sched.bpu_cores,\n                            device_id=sched.deviceId)\n'})})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}}}]);