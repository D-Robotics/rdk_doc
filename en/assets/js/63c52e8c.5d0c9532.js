"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[76698],{11072:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"Algorithm_Application/Python_Sample/Ultralytics_YOLO11","title":"Object Detection - Ultralytics YOLO11","description":"This example uses the Ultralytics YOLO11 model and leverages the hbmruntime interface to perform object detection on images. It supports image preprocessing, inference, post-processing (including decoding, confidence filtering, and NMS), and saving result images. The example code is located in the /app/pydevdemo/02detectionsample/02ultralyticsyolo11/ directory.","source":"@site/i18n/en/docusaurus-plugin-content-docs-docs_s/current/04_Algorithm_Application/02_Python_Sample/05_Ultralytics_YOLO11.md","sourceDirName":"04_Algorithm_Application/02_Python_Sample","slug":"/Algorithm_Application/Python_Sample/Ultralytics_YOLO11","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/Ultralytics_YOLO11","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767953796000,"sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Object Detection - Ultralytics YOLOv5x","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/Ultralytics_YOLOv5x"},"next":{"title":"Semantic Segmentation - UNetMobileNet","permalink":"/rdk_doc/en/rdk_s/Algorithm_Application/Python_Sample/UNetMobileNet"}}');var t=i(74848),r=i(28453);const l={sidebar_position:5},c="Object Detection - Ultralytics YOLO11",o={},d=[{value:"Model Description",id:"model-description",level:2},{value:"Functionality Description",id:"functionality-description",level:2},{value:"Environment Dependencies",id:"environment-dependencies",level:2},{value:"Directory Structure",id:"directory-structure",level:2},{value:"Parameter Description",id:"parameter-description",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Notes",id:"notes",level:2},{value:"License",id:"license",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"object-detection---ultralytics-yolo11",children:"Object Detection - Ultralytics YOLO11"})}),"\n",(0,t.jsxs)(n.p,{children:["This example uses the Ultralytics YOLO11 model and leverages the ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," interface to perform object detection on images. It supports image preprocessing, inference, post-processing (including decoding, confidence filtering, and NMS), and saving result images. The example code is located in the ",(0,t.jsx)(n.code,{children:"/app/pydev_demo/02_detection_sample/02_ultralytics_yolo11/"})," directory."]}),"\n",(0,t.jsx)(n.h2,{id:"model-description",children:"Model Description"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Overview"}),":"]}),"\n",(0,t.jsx)(n.p,{children:"Ultralytics YOLO11 is a lightweight anchor-based object detection model that integrates both anchor-free and anchor-based concepts, offering fast inference and precise localization capabilities. During regression, it adopts a discrete binning approach combined with softmax classification and a decoding mechanism to enhance localization accuracy. Ultralytics YOLO11 is suitable for deploying small models in real-time scenarios such as security surveillance and industrial inspection."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"HBM Model Name"}),": ",(0,t.jsx)(n.code,{children:"yolo11n_detect_nashe_640x640_nv12.hbm"})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Input Format"}),": NV12 format, sized at 640x640 (separate Y and UV planes)"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": Multi-scale feature maps; each scale includes a class score tensor and a discrete bounding box regression tensor. The final output consists of bounding box coordinates, class IDs, and confidence scores."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Model Download URL"})," (automatically downloaded by the program):"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"https://archive.d-robotics.cc/downloads/rdk_model_zoo/rdk_s100/ultralytics_YOLO/yolo11n_detect_nashe_640x640_nv12.hbm\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"functionality-description",children:"Functionality Description"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Model Loading"})}),"\n",(0,t.jsxs)(n.p,{children:["Load the quantized Ultralytics YOLO11 model using the ",(0,t.jsx)(n.code,{children:"hbm_runtime"})," interface, extract model metadata such as input/output names, shapes, and quantization information for subsequent inference steps."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Input Preprocessing"})}),"\n",(0,t.jsx)(n.p,{children:"Resize the original BGR image to 640\xd7640, convert it to NV12 format (separate Y and UV planes), and construct a nested dictionary of input tensors compatible with the inference interface."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Inference Execution"})}),"\n",(0,t.jsxs)(n.p,{children:["Run forward inference via the ",(0,t.jsx)(n.code,{children:".run()"})," method, optionally specifying scheduling parameters (inference priority and BPU core binding). The output includes classification and regression tensors from multiple scale branches."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Result Post-processing"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Dequantize quantized outputs back to float32;"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Filter classification scores per scale branch, retaining candidate boxes exceeding a specified confidence threshold;"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Decode bounding boxes using a multi-bin regression algorithm;"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Merge candidate boxes across all scales and apply NMS (Non-Maximum Suppression) to remove redundant detections;"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Map detected boxes from the model input coordinate system back to the original image dimensions;"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Optionally draw detection results and save the annotated image file."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"environment-dependencies",children:"Environment Dependencies"}),"\n",(0,t.jsx)(n.p,{children:"This example has no special environment requirements\u2014only ensure that dependencies listed in pydev are installed:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install -r ../../requirements.txt\n"})}),"\n",(0,t.jsx)(n.h2,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:".\n\u251c\u2500\u2500 ultralytics_yolo11.py       # Main inference script\n\u2514\u2500\u2500 README.md                   # Usage instructions\n"})}),"\n",(0,t.jsx)(n.h2,{id:"parameter-description",children:"Parameter Description"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Argument"}),(0,t.jsx)(n.th,{children:"Description"}),(0,t.jsx)(n.th,{children:"Default Value"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--model-path"})}),(0,t.jsx)(n.td,{children:"Path to the model file (.hbm format)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/opt/hobot/model/s100/basic/yolo11n_detect_nashe_640x640_nv12.hbm"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--test-img"})}),(0,t.jsx)(n.td,{children:"Path to the input test image"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/app/res/assets/kite.jpg"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--label-file"})}),(0,t.jsx)(n.td,{children:"Path to the class label file (one class name per line)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/app/res/labels/coco_classes.names"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--img-save-path"})}),(0,t.jsx)(n.td,{children:"Path to save the detection result image"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"result.jpg"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--priority"})}),(0,t.jsx)(n.td,{children:"Model scheduling priority (0\u2013255; higher values indicate higher priority)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"0"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--bpu-cores"})}),(0,t.jsxs)(n.td,{children:["List of BPU core IDs to use (e.g., ",(0,t.jsx)(n.code,{children:"--bpu-cores 0 1"}),")"]}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"[0]"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--nms-thres"})}),(0,t.jsx)(n.td,{children:"IoU threshold for Non-Maximum Suppression (NMS)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"0.45"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"--score-thres"})}),(0,t.jsx)(n.td,{children:"Confidence threshold for filtering detections (boxes below this are discarded)"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"0.25"})})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Run the Model"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["With default arguments:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python ultralytics_yolo11.py\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["With custom arguments:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python ultralytics_yolo11.py \\\n    --model-path /opt/hobot/model/s100/basic/yolo11n_detect_nashe_640x640_nv12.hbm \\\n    --test-img /app/res/assets/kite.jpg \\\n    --label-file /app/res/labels/coco_classes.names \\\n    --img-save-path result.jpg \\\n    --priority 0 \\\n    --bpu-cores 0 \\\n    --nms-thres 0.45 \\\n    --score-thres 0.25\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"View Results"})}),"\n",(0,t.jsxs)(n.p,{children:["Upon successful execution, detection bounding boxes will be drawn on the original image and saved to the path specified by ",(0,t.jsx)(n.code,{children:"--img-save-path"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"[Saved] Result saved to: result.jpg\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"If the specified model path does not exist, the program will attempt to download the model automatically."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"license",children:"License"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-license",children:"Copyright (C) 2025, XiangshunZhao D-Robotics.\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as\npublished by the Free Software Foundation, either version 3 of the\nLicense, or (at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>c});var s=i(96540);const t={},r=s.createContext(t);function l(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);