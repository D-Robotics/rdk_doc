"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[54294],{11470:(e,t,n)=>{n.d(t,{A:()=>y});var s=n(96540),o=n(34164),a=n(23104),r=n(56347),l=n(205),i=n(57485),c=n(31682),d=n(70679);function u(e){return s.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,s.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:t,children:n}=e;return(0,s.useMemo)(()=>{const e=t??function(e){return u(e).map(({props:{value:e,label:t,attributes:n,default:s}})=>({value:e,label:t,attributes:n,default:s}))}(n);return function(e){const t=(0,c.XI)(e,(e,t)=>e.value===t.value);if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,n])}function p({value:e,tabValues:t}){return t.some(t=>t.value===e)}function m({queryString:e=!1,groupId:t}){const n=(0,r.W6)(),o=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,i.aZ)(o),(0,s.useCallback)(e=>{if(!o)return;const t=new URLSearchParams(n.location.search);t.set(o,e),n.replace({...n.location,search:t.toString()})},[o,n])]}function b(e){const{defaultValue:t,queryString:n=!1,groupId:o}=e,a=h(e),[r,i]=(0,s.useState)(()=>function({defaultValue:e,tabValues:t}){if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!p({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=t.find(e=>e.default)??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:a})),[c,u]=m({queryString:n,groupId:o}),[b,g]=function({groupId:e}){const t=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,o]=(0,d.Dv)(t);return[n,(0,s.useCallback)(e=>{t&&o.set(e)},[t,o])]}({groupId:o}),f=(()=>{const e=c??b;return p({value:e,tabValues:a})?e:null})();(0,l.A)(()=>{f&&i(f)},[f]);return{selectedValue:r,selectValue:(0,s.useCallback)(e=>{if(!p({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);i(e),u(e),g(e)},[u,g,a]),tabValues:a}}var g=n(92303);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=n(74848);function v({className:e,block:t,selectedValue:n,selectValue:s,tabValues:r}){const l=[],{blockElementScrollPositionUntilNextRender:i}=(0,a.a_)(),c=e=>{const t=e.currentTarget,o=l.indexOf(t),a=r[o].value;a!==n&&(i(t),s(a))},d=e=>{let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const n=l.indexOf(e.currentTarget)+1;t=l[n]??l[0];break}case"ArrowLeft":{const n=l.indexOf(e.currentTarget)-1;t=l[n]??l[l.length-1];break}}t?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":t},e),children:r.map(({value:e,label:t,attributes:s})=>(0,x.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{l.push(e)},onKeyDown:d,onClick:c,...s,className:(0,o.A)("tabs__item",f.tabItem,s?.className,{"tabs__item--active":n===e}),children:t??e},e))})}function j({lazy:e,children:t,selectedValue:n}){const a=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const e=a.find(e=>e.props.value===n);return e?(0,s.cloneElement)(e,{className:(0,o.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:a.map((e,t)=>(0,s.cloneElement)(e,{key:t,hidden:e.props.value!==n}))})}function _(e){const t=b(e);return(0,x.jsxs)("div",{className:(0,o.A)("tabs-container",f.tabList),children:[(0,x.jsx)(v,{...t,...e}),(0,x.jsx)(j,{...t,...e})]})}function y(e){const t=(0,g.A)();return(0,x.jsx)(_,{...e,children:u(e.children)},String(t))}},19365:(e,t,n)=>{n.d(t,{A:()=>r});n(96540);var s=n(34164);const o={tabItem:"tabItem_Ymn6"};var a=n(74848);function r({children:e,hidden:t,className:n}){return(0,a.jsx)("div",{role:"tabpanel",className:(0,s.A)(o.tabItem,n),hidden:t,children:e})}},28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>l});var s=n(96540);const o={},a=s.createContext(o);function r(e){const t=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),s.createElement(a.Provider,{value:t},e.children)}},84904:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>p,frontMatter:()=>i,metadata:()=>s,toc:()=>u});const s=JSON.parse('{"id":"Robot_development/boxs/detection/yolo","title":"YOLO","description":"Introduction","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/05_Robot_development/03_boxs/detection/yolo.md","sourceDirName":"05_Robot_development/03_boxs/detection","slug":"/Robot_development/boxs/detection/yolo","permalink":"/rdk_doc/en/Robot_development/boxs/detection/yolo","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1753191447000,"sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"FCOS","permalink":"/rdk_doc/en/Robot_development/boxs/detection/fcos"},"next":{"title":"MobileNet_SSD","permalink":"/rdk_doc/en/Robot_development/boxs/detection/mobilenet"}}');var o=n(74848),a=n(28453),r=n(11470),l=n(19365);const i={sidebar_position:2},c="YOLO",d={},u=[{value:"Introduction",id:"introduction",level:2},{value:"Supported Platforms",id:"supported-platforms",level:2},{value:"Preparations",id:"preparations",level:2},{value:"RDK",id:"rdk",level:3},{value:"Usage",id:"usage",level:2},{value:"RDK",id:"rdk-1",level:3},{value:"Use MIPI Cameras to Publish Images",id:"use-mipi-cameras-to-publish-images",level:4},{value:"Use USB Camera to Publish Images",id:"use-usb-camera-to-publish-images",level:4},{value:"Use Local Data Offline",id:"use-local-data-offline",level:4},{value:"Result Analysis",id:"result-analysis",level:2},{value:"Use a Camera to Publish Images",id:"use-a-camera-to-publish-images",level:3},{value:"Use Local Data Offline",id:"use-local-data-offline-1",level:3}];function h(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"yolo",children:"YOLO"})}),"\n","\n",(0,o.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,o.jsx)(t.p,{children:"YOLO detection algorithm example uses images as input, performs algorithm inference using BPU, and publishes algorithm messages containing object categories and detection boxes. Currently, it supports four versions: YOLOv2\u3001YOLOv3\u3001Ultralytics YOLOv5\u3001YOLOv5x\u3001Ultralytics YOLOv8\u3001YOLOv10\u3001Ultralytics YOLO11\u3001YOLO12\u3001YOLO13."}),"\n",(0,o.jsxs)(t.p,{children:["Since all YOLOs after YOLOv8 are based on the Ultralytics algorithm framework, the Parser of YOLOv8 can be used. The relevant bin model can be found on GitHub\u2b50\ufe0f : Get it ",(0,o.jsx)(t.a,{href:"https://github.com/D-Robotics/rdk_model_zoo",children:"RDK_Model_Zoo"}),"."]}),"\n",(0,o.jsxs)(t.p,{children:["The model is trained using the ",(0,o.jsx)(t.a,{href:"http://cocodataset.org/",children:"COCO dataset"}),", and the supported object detection types include humans, animals, fruits, and vehicles, totaling 80 types."]}),"\n",(0,o.jsxs)(t.p,{children:["You can also use the Ultralytics software package to train on custom datasets. (",(0,o.jsx)(t.a,{href:"https://docs.ultralytics.com/zh/modes/train",children:"https://docs.ultralytics.com/zh/modes/train"}),")"]}),"\n",(0,o.jsxs)(t.p,{children:["Code repository:  (",(0,o.jsx)(t.a,{href:"https://github.com/D-Robotics/hobot_dnn",children:"https://github.com/D-Robotics/hobot_dnn"}),")"]}),"\n",(0,o.jsx)(t.p,{children:"Use cases: As a representative algorithm in single-stage object detection, the YOLO series has the advantages of fast speed and good generalization, and can be used for garbage recognition, vehicle detection, and other functions, mainly applied in autonomous driving, smart home, and other fields."}),"\n",(0,o.jsx)(t.h2,{id:"supported-platforms",children:"Supported Platforms"}),"\n",(0,o.jsxs)(t.table,{children:[(0,o.jsx)(t.thead,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.th,{children:"Platform"}),(0,o.jsx)(t.th,{children:"System"}),(0,o.jsx)(t.th,{children:"Supported Algorithms"}),(0,o.jsx)(t.th,{children:"Function"})]})}),(0,o.jsxs)(t.tbody,{children:[(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:"RDK X3, RDK X3 Module"}),(0,o.jsx)(t.td,{children:"Ubuntu 20.04 (Foxy), Ubuntu 22.04 (Humble)"}),(0,o.jsx)(t.td,{children:"yolov2/yolov3/yolov5"}),(0,o.jsxs)(t.td,{children:["\xb7 Start MIPI/USB cameras and display results through web",(0,o.jsx)("br",{}),"\xb7 Use local data offline, and save results"]})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:"RDK X5"}),(0,o.jsx)(t.td,{children:"Ubuntu 22.04 (Humble)"}),(0,o.jsx)(t.td,{children:"yolov2/yolov3/yolov5x/yolov8/yolov10"}),(0,o.jsxs)(t.td,{children:["\xb7 Start MIPI/USB cameras and display results through web",(0,o.jsx)("br",{}),"\xb7 Use local data offline, and save results"]})]})]})]}),"\n",(0,o.jsx)(t.h2,{id:"preparations",children:"Preparations"}),"\n",(0,o.jsx)(t.h3,{id:"rdk",children:"RDK"}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsxs)(t.li,{children:["\n",(0,o.jsx)(t.p,{children:"RDK has been burned with the  Ubuntu 20.04/22.04 system image provided by D-Robotics."}),"\n"]}),"\n",(0,o.jsxs)(t.li,{children:["\n",(0,o.jsx)(t.p,{children:"RDK has successfully installed TogetheROS.Bot."}),"\n"]}),"\n",(0,o.jsxs)(t.li,{children:["\n",(0,o.jsx)(t.p,{children:"RDK has installed MIPI or USB cameras. If there is no camera available, the algorithm can be experienced offline by local JPEG/PNG images or MP4, H.264, and H.265 videos."}),"\n"]}),"\n",(0,o.jsxs)(t.li,{children:["\n",(0,o.jsx)(t.p,{children:"Confirm that the PC can access the RDK through the network."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"usage",children:"Usage"}),"\n",(0,o.jsx)(t.h3,{id:"rdk-1",children:"RDK"}),"\n",(0,o.jsx)(t.h4,{id:"use-mipi-cameras-to-publish-images",children:"Use MIPI Cameras to Publish Images"}),"\n",(0,o.jsx)(t.p,{children:"YOLOv2 object detection algorithm example subscribes to images published by a MIPI camera and publish algorithm msg after inference. It displays published images and corresponding results on PC browsers through the websocket package."}),"\n",(0,o.jsxs)(r.A,{groupId:"tros-distro",children:[(0,o.jsx)(l.A,{value:"foxy",label:"Foxy",children:(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,o.jsx)(l.A,{value:"humble",label:"Humble",children:(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-shell",children:"# Configuring MIPI camera\nexport CAM_TYPE=mipi\n\n# Start the launch file\nros2 launch dnn_node_example dnn_node_example.launch.py dnn_example_config_file:=config/yolov2workconfig.json dnn_example_image_width:=480 dnn_example_image_height:=272\n"})}),"\n",(0,o.jsx)(t.h4,{id:"use-usb-camera-to-publish-images",children:"Use USB Camera to Publish Images"}),"\n",(0,o.jsx)(t.p,{children:"YOLOv2 object detection algorithm example subscribes to images published by a USB camera, publishes algorithm msg after inference, and displays published images and corresponding results on PC browsers through the websocket package."}),"\n",(0,o.jsxs)(r.A,{groupId:"tros-distro",children:[(0,o.jsx)(l.A,{value:"foxy",label:"Foxy",children:(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,o.jsx)(l.A,{value:"humble",label:"Humble",children:(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-shell",children:"# Configuring USB camera\nexport CAM_TYPE=usb\n\n# Start the launch file\nros2 launch dnn_node_example dnn_node_example.launch.py dnn_example_config_file:=config/yolov2workconfig.json dnn_example_image_width:=480 dnn_example_image_height:=272\n"})}),"\n",(0,o.jsx)(t.h4,{id:"use-local-data-offline",children:"Use Local Data Offline"}),"\n",(0,o.jsx)(t.p,{children:"YOLOv2 object detection algorithm uses local JPEG/PNG images offline. After inference, the rendered images of the results are stored in the local path."}),"\n",(0,o.jsxs)(r.A,{groupId:"tros-distro",children:[(0,o.jsx)(l.A,{value:"foxy",label:"Foxy",children:(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n"})})}),(0,o.jsx)(l.A,{value:"humble",label:"Humble",children:(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"# Configure the tros.b environment\nsource /opt/tros/humble/setup.bash\n"})})})]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-shell",children:"# Start the launch file\nros2 launch dnn_node_example dnn_node_example_feedback.launch.py dnn_example_config_file:=config/yolov2workconfig.json dnn_example_image:=config/target.jpg\n"})}),"\n",(0,o.jsxs)(t.p,{children:["In addition to the YOLOv2, YOLOv3 and YOLOv5 are also supported. The algorithm can be switched using the config_file parameter in the startup command. For example, to use the YOLOv3, the startup configuration should be ",(0,o.jsx)(t.code,{children:'dnn_example_config_file:="config/yolov3workconfig.json"'}),", and for the YOLOv5 algorithm, the startup configuration should be ",(0,o.jsx)(t.code,{children:'dnn_example_config_file:="config/yolov5workconfig.json"'}),", and for the YOLOv8 algorithm, the startup configuration should be ",(0,o.jsx)(t.code,{children:'dnn_example_config_file:="config/yolov8workconfig.json"'}),", and for the YOLOv10 algorithm, the startup configuration should be ",(0,o.jsx)(t.code,{children:'dnn_example_config_file:="config/yolov10workconfig.json"'}),"."]}),"\n",(0,o.jsx)(t.h2,{id:"result-analysis",children:"Result Analysis"}),"\n",(0,o.jsx)(t.h3,{id:"use-a-camera-to-publish-images",children:"Use a Camera to Publish Images"}),"\n",(0,o.jsx)(t.p,{children:"The terminal output during execution shows the following information:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-text",children:"[example-3] [WARN] [1655095347.608475236] [example]: Create ai msg publisher with topic_name: hobot_dnn_detection\n[example-3] [WARN] [1655095347.608640353] [example]: Create img hbmem_subscription with topic_name: /hbmem_img\n[example-3] [WARN] [1655095348.709411619] [img_sub]: Sub img fps 12.95\n[example-3] [WARN] [1655095348.887570945] [example]: Smart fps 12.10\n[example-3] [WARN] [1655095349.772225728] [img_sub]: Sub img fps 11.30\n[example-3] [WARN] [1655095349.948913662] [example]: Smart fps 11.31\n[example-3] [WARN] [1655095350.834951431] [img_sub]: Sub img fps 11.30\n[example-3] [WARN] [1655095351.011915729] [example]: Smart fps 11.30\n"})}),"\n",(0,o.jsxs)(t.p,{children:["The log shows that the topic for publishing the inference results is ",(0,o.jsx)(t.code,{children:"hobot_dnn_detection"}),", and the topic for subscribing to images is ",(0,o.jsx)(t.code,{children:"/hbmem_img"}),"."]}),"\n",(0,o.jsxs)(t.p,{children:["You can view the image and algorithm rendering effects by entering ",(0,o.jsx)(t.a,{href:"http://IP:8000",children:"http://IP:8000"})," in the browser on the PC (where IP is the IP address of the RDK):"]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/03_boxs/detection/image/box_basic/yolov2_render_web.jpeg",alt:"render_web"})}),"\n",(0,o.jsx)(t.h3,{id:"use-local-data-offline-1",children:"Use Local Data Offline"}),"\n",(0,o.jsx)(t.p,{children:"The terminal output during execution shows the following information:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-text",children:"[example-1] [INFO] [1654925067.952159234] [PostProcessBase]: out box size: 8\n[example-1] [INFO] [1654925067.952227232] [PostProcessBase]: det rect: 464.03 196.145 605.525 434.865, det type: potted plant, score:0.813219\n[example-1] [INFO] [1654925067.952319229] [PostProcessBase]: det rect: 86.5421 310.158 512.542 468.201, det type: couch, score:0.669208\n[example-1] [INFO] [1654925067.952392268] [PostProcessBase]: det rect: 198.968 399.91 273.841 421.767, det type: book, score:0.539755\n[example-1] [INFO] [1654925067.952465182] [PostProcessBase]: det rect: 159.861 370.656 217.685 417.746, det type: potted plant, score:0.480698\n[example-1] [INFO] [1654925067.952533221] [PostProcessBase]: det rect: 51.2147 321.047 84.0969 375.842, det type: vase, score:0.433644\n[example-1] [INFO] [1654925067.952607802] [PostProcessBase]: det rect: 70.0548 197.381 96.1826 221.062, det type: vase, score:0.399885\n[example-1] [INFO] [1654925067.952675924] [PostProcessBase]: det rect: 197.706 405.271 278.929 435.743, det type: book, score:0.384268\n[example-1] [INFO] [1654925067.952743463] [PostProcessBase]: det rect: 54.0955 256.68 88.6269 266.159, det type: book, score:0.307426\n"})}),"\n",(0,o.jsx)(t.p,{children:"The log shows that the algorithm infers 8 targets from the input image and outputs the coordinates of the object detection boxes (the order of the coordinates is the top-left x and y coordinates and the bottom-right x and y coordinates of the bounding box) and the object categories. The rendered image file is saved as render_feedback_0_0.jpeg, and the rendering effect is shown below:"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:"https://rdk-doc.oss-cn-beijing.aliyuncs.com/doc/img/05_Robot_development/03_boxs/detection/image/box_basic/yolov2_render_feedback.jpeg",alt:"render_feedback"})})]})}function p(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}}}]);