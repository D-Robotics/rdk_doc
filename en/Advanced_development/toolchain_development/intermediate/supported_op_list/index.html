<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Advanced_development/toolchain_development/intermediate/supported_op_list" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">supported_op_list | RDK DOC</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://developer.d-robotics.cc/rdk_doc/en/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://developer.d-robotics.cc/rdk_doc/en/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://developer.d-robotics.cc/rdk_doc/en/Advanced_development/toolchain_development/intermediate/supported_op_list"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="supported_op_list | RDK DOC"><meta data-rh="true" name="description" content="Supported Operator Lists and Restrictions"><meta data-rh="true" property="og:description" content="Supported Operator Lists and Restrictions"><link data-rh="true" rel="icon" href="/rdk_doc/en/img/logo.png"><link data-rh="true" rel="canonical" href="https://developer.d-robotics.cc/rdk_doc/en/Advanced_development/toolchain_development/intermediate/supported_op_list"><link data-rh="true" rel="alternate" href="https://developer.d-robotics.cc/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://developer.d-robotics.cc/rdk_doc/en/Advanced_development/toolchain_development/intermediate/supported_op_list" hreflang="en"><link data-rh="true" rel="alternate" href="https://developer.d-robotics.cc/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"7. Advanced Development","item":"https://developer.d-robotics.cc/rdk_doc/en/Advanced_development"},{"@type":"ListItem","position":2,"name":"7.4 Algorithm Toolchain Development Guide","item":"https://developer.d-robotics.cc/rdk_doc/en/04_toolchain_development"},{"@type":"ListItem","position":3,"name":"7.4.2 Advanced Guide","item":"https://developer.d-robotics.cc/rdk_doc/en/Advanced_development/toolchain_development/intermediate/"},{"@type":"ListItem","position":4,"name":"supported_op_list","item":"https://developer.d-robotics.cc/rdk_doc/en/Advanced_development/toolchain_development/intermediate/supported_op_list"}]}</script><script src="https://hm.baidu.com/hm.js?24dd63cad43b63889ea6bede5fd1ab9e" async></script><link rel="stylesheet" href="/rdk_doc/en/assets/css/styles.0fbd7d27.css">
<script src="/rdk_doc/en/assets/js/runtime~main.39f46c21.js" defer="defer"></script>
<script src="/rdk_doc/en/assets/js/main.e6501ff3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a href="https://d-robotics.cc/" target="_blank" rel="noopener noreferrer" class="navbar__brand"><div class="navbar__logo"><img src="/rdk_doc/en/img/logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/rdk_doc/en/img/logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">D-Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/rdk_doc/en/RDK">RDK X3 / X5</a><a class="navbar__item navbar__link" href="/rdk_doc/en/rdk_s/RDK">RDK S100</a><a href="https://developer.d-robotics.cc/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Community<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/D-Robotics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>EN</a><ul class="dropdown__menu"><li><a href="/rdk_doc/Advanced_development/toolchain_development/intermediate/supported_op_list" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-Hans">CN</a></li><li><a href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/supported_op_list" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">EN</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/rdk_doc/en/RDK">D-Robotics RDK Suite</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/en/Quick_start">1. Quick Start</a><button aria-label="Expand sidebar category &#x27;1. Quick Start&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/en/System_configuration">2. System Configuration</a><button aria-label="Expand sidebar category &#x27;2. System Configuration&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/en/Basic_Application">3. Basic Application Development</a><button aria-label="Expand sidebar category &#x27;3. Basic Application Development&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/en/Basic_Development">4. Algorithm Application Development</a><button aria-label="Expand sidebar category &#x27;4. Algorithm Application Development&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/en/Robot_development">5. Robotics Application Development</a><button aria-label="Expand sidebar category &#x27;5. Robotics Application Development&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/en/Application_case">6. Application Development Guide</a><button aria-label="Expand sidebar category &#x27;6. Application Development Guide&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/rdk_doc/en/Advanced_development">7. Advanced Development</a><button aria-label="Collapse sidebar category &#x27;7. Advanced Development&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rdk_doc/en/hardware_development">7.1 Hardware Development Guide</a><button aria-label="Expand sidebar category &#x27;7.1 Hardware Development Guide&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rdk_doc/en/linux_development">7.2. Linux Development Guide</a><button aria-label="Expand sidebar category &#x27;7.2. Linux Development Guide&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rdk_doc/en/03_multimedia_development">7.3 RDK X3 Multimedia Development Guide</a><button aria-label="Expand sidebar category &#x27;7.3 RDK X3 Multimedia Development Guide&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/rdk_doc/en/04_toolchain_development">7.4 Algorithm Toolchain Development Guide</a><button aria-label="Collapse sidebar category &#x27;7.4 Algorithm Toolchain Development Guide&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/rdk_doc/en/Advanced_development/toolchain_development/overview">7.4.1 Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/">7.4.2 Advanced Guide</a><button aria-label="Collapse sidebar category &#x27;7.4.2 Advanced Guide&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/environment_config">Environment Installation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/ptq_process">Principles and Steps of PTQ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/supported_op_list">supported_op_list</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/runtime_sample">On-board Model Application Development Guide</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rdk_doc/en/Advanced_development/toolchain_development/expert/">7.4.3 Expert Guide</a><button aria-label="Expand sidebar category &#x27;7.4.3 Expert Guide&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/en/FAQ">8. FAQs</a><button aria-label="Expand sidebar category &#x27;8. FAQs&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/rdk_doc/en/Appendix">9. Appendix</a><button aria-label="Expand sidebar category &#x27;9. Appendix&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/rdk_doc/en/Release_Note/release_note">10. Version release</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/rdk_doc/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/rdk_doc/en/Advanced_development"><span>7. Advanced Development</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/rdk_doc/en/04_toolchain_development"><span>7.4 Algorithm Toolchain Development Guide</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/"><span>7.4.2 Advanced Guide</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">supported_op_list</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>supported_op_list</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="supported_op_list_and_restrictions">Supported Operator Lists and Restrictions<a href="#supported_op_list_and_restrictions" class="hash-link" aria-label="Direct link to Supported Operator Lists and Restrictions" title="Direct link to Supported Operator Lists and Restrictions">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="limitations-and-notes">Limitations and Notes<a href="#limitations-and-notes" class="hash-link" aria-label="Direct link to Limitations and Notes" title="Direct link to Limitations and Notes">​</a></h3>
<p>This section primarily covers the operators supported by the D-Robotics Processor for both <code>Caffe</code> and <code>ONNX</code>. Operators not listed are currently unsupported due to hardware limitations on the BPU.</p>
<p><strong>Terminology:</strong></p>
<ul>
<li><strong>BPU Acceleration</strong>: Operators that the D-Robotics Processor can accelerate under certain constraints; if not met, they will be computed on the CPU.</li>
<li><strong>CPU Computation</strong>: Operators already optimized on D-Robotics&#x27;s ARM CPU, supporting ONNX opsets 10 and 11.</li>
<li><strong>CPU Computation※</strong>: Temporary CPU operators not yet integrated.</li>
</ul>
<p><strong>Additional Considerations:</strong></p>
<ul>
<li>
<p>For all BPU in RDK X3, there is a general restriction: input_batch ≤ 128.</p>
</li>
<li>
<p>On RDK Ultra BPU, restrictions apply:</p>
<ol>
<li>Input and output dimensions must be 4D; support for non-four-dimensional ops is indicated explicitly.</li>
<li>Shape: H, W, C ∈ [1, 65536], N ≤ 4096; and N x C x H x W ≤ 1GB.</li>
<li>Supports Caffe 1.0 base operators and common extended operators, as well as ONNX opsets 10 and 11. Ops not meeting BPU acceleration constraints fallback to ARM CPU.</li>
</ol>
</li>
<li>
<p>Operators like <code>Cast</code>, <code>Constant</code>, <code>Dropout</code>, <code>Reshape</code>, <code>Squeeze</code>, <code>Unsqueeze</code>, and <code>Shape</code> (OPs) cannot run directly on the BPU, but algorithmic toolchains may optimize them in some cases (e.g., constant folding) for support.</p>
</li>
<li>
<p>Operators marked as PyTorch are officially unsupported opsets 11 ops, which D-Robotics&#x27;s algorithm toolchain provides a script to export from PyTorch to custom ONNX ops.</p>
</li>
<li>
<p>Tensorflow-onnx conversion tool (<a href="https://github.com/onnx/tensorflow-onnx" target="_blank" rel="noopener noreferrer">https://github.com/onnx/tensorflow-onnx</a>) supports converting TensorFlow 1.x operators to stable ONNX opsets 6-11, but TensorFlow 2.x support is still experimental.</p>
</li>
<li>
<p><strong>Quantization Details</strong>: A compliant operator may still run on CPU due to being a passively quantized OP. The algorithm toolchain designs quantization logic based on the OP&#x27;s computation characteristics and BPU low-level logic. For more information on active, passive, and manual quantization, see the &quot;<a href="https://developer.d-robotics.cc/forumDetail/118364000835765793" target="_blank" rel="noopener noreferrer">Quantization Logic in Algorithm Toolchain</a>&quot; chapter.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-x3-list-of-supported-caffe-operators">RDK X3 List of supported Caffe operators<a href="#rdk-x3-list-of-supported-caffe-operators" class="hash-link" aria-label="Direct link to RDK X3 List of supported Caffe operators" title="Direct link to RDK X3 List of supported Caffe operators">​</a></h2>
<table><thead><tr><th><strong>Caffe Operator Name</strong></th><th><strong>CPU Computing/BPU Acceleration</strong></th><th><strong>X3 BPU Constraints</strong></th><th><strong>CPU Constraints</strong></th></tr></thead><tbody><tr><td>Convolution</td><td>BPU Acceleration</td><td>Kernel Size: HxW = [1, 7]x[1, 7] for BPU<br> <code>Channel limit: &lt;= 2048 (for non-dilated, group, depthwise conv), or &lt;= 4096 for standard convs</code><br> No stride limit<br> Dilation: only powers of 2 allowed, divisible by stride<br> <code>h_dilated &lt;= w_dilated</code><br> <code>Total kernel size: HxWxC &lt;= 32768</code><br> axis not supported (default: 1)</td><td>4D Conv only<br> auto_pad not supported<br>Type constraints: float, int32, int8<br>Pads constraint: [Hstart, Wstart, Hend, Wend] (4 elements) with Hstart == Hend and Wstart == Wend</td></tr><tr><td>Deconvolution</td><td>BPU Acceleration</td><td>Kernel Size: HxW = [2, 14]x[2, 14]<br><code>Channel limit: C &lt;= 2048</code><br>Padding: HxW = [0, (Kernel_H-1)/2]x[0, (Kernel_W-1)/2]<br><code>Stride: Stride ∈ {2, 4}, stride_h ≤ stride_w</code><br>Dilation: (1, 1)<br>No axis support</td><td>output_shape and output_padding unsupported<br>auto_pad: NOTSET only<br>No axis support</td></tr><tr><td>MaxUnpool</td><td>CPU Computing</td><td>---</td><td>from_type constraints: X - float only, I - Tensor(int64)<br>to_type constraints: float only</td></tr><tr><td>Pooling</td><td>BPU Acceleration</td><td>Four types: MaxPooling, AveragePooling, GlobalMaxPooling, GlobalAveragePooling<br>Constraints: <br><code>MaxPooling: Kernel Size = [1, 64]x[1, 64], Stride = [1, 185], Padding &gt;= 0</code><br>AveragePooling: HxW = [1, 7]x[1, 7], Stride ∈ <!-- -->185<br><code>GlobalAveragePooling: HxW &lt;= 8192 for NCHW input</code><br>GlobalMaxPooling: HxW = [1, 1024]x[1, 1024] for NCHW input</td><td>None</td></tr><tr><td>SPP</td><td>CPU Computing</td><td>Not supported</td><td><code>pyramid_height: 2^n pooling, n &lt; 7</code><br><code>pooling kernel size &lt;= 255</code><br>pool option: <!-- -->1</td></tr><tr><td>InnerProduct</td><td>BPU Acceleration</td><td>Converted to Conv<br>Constraints: <br><code>For NCHW input, if HW &lt; 7, Gemm limits same as Conv</code><br><code>H = W = 1: C limit &lt;= 16384; otherwise, C limit &lt;= 2048</code><br><code>Low-precision int8 output after BPU node: H x W/8 x C/4 ≤ 1024</code><br><code>High-precision int32 output: H x W/8 x C/4 &lt; 2048</code><br>No axis support</td><td>None</td></tr><tr><td>LRN</td><td>CPU Computing</td><td>Not supported</td><td>local_size supported<br>alpha, beta supported<br>norm_region: ACROSS_CHANNELS, WITHIN_CHANNEL (optional)<br>k supported</td></tr><tr><td>MVN</td><td>CPU Computing</td><td>Not supported</td><td><code> normalize_variance: {0, 1} (optional)</code><br><code>across_channels: {0, 1} (optional)</code><br>Float32 only</td></tr><tr><td>BatchNorm</td><td>BPU Acceleration</td><td>Unlimited</td><td>None</td></tr><tr><td>ELU</td><td>CPU Computing</td><td>Not supported</td><td>None</td></tr><tr><td>BNLL</td><td>CPU Computing</td><td>Not supported</td><td>None</td></tr><tr><td>PReLU</td><td>BPU Acceleration</td><td>Unlimited</td><td>None</td></tr><tr><td>ReLU/LeakyReLu</td><td>BPU Acceleration</td><td>Unlimited</td><td>None</td></tr><tr><td>Sigmoid</td><td>BPU Acceleration</td><td><code>For 1CHW tensor: min(8W4C-aligned shape, 32C-aligned shape) ≤ 8192</code><br>8W4C: pad W to multiples of 8, C to multiples of 4<br>32C: pad C to multiples of 32<br>Use the smaller aligned shape</td><td>None</td></tr><tr><td>TanH</td><td>BPU Acceleration</td><td>Unlimited</td><td>None</td></tr><tr><td>Eltwise</td><td>BPU Acceleration</td><td>Operation supports Add and Mul, no Sub<br><code>Add: M ≤ 2048 channels</code><br>Supported cases: <br>1. NCHW vs NCHW<br>2. NCHW vs NC11 (inputs must be op outputs)<br><code>Mul: Both inputs must be 4D, C ≤ 2048</code><br>Supported shapes: <br>1. (1xCxHxW vs 1xCxHxW)<br>2. (1xCxHxW vs 1xCx1x1)<br>3. (1xCxHxW vs 1x1x1x1)</td><td>None</td></tr><tr><td>Bias</td><td>BPU Acceleration</td><td>Refer to Eltwise (Add) constraints</td><td>None</td></tr><tr><td>Scale</td><td>BPU Acceleration</td><td>Refer to Eltwise (Mul) constraints</td><td>None</td></tr><tr><td>AbsVal</td><td>CPU Computing</td><td>Not supported</td><td>None</td></tr><tr><td>Exp</td><td>BPU Acceleration</td><td>Unlimited</td><td>None</td></tr><tr><td>Log</td><td>CPU Computing</td><td>Not supported</td><td>None</td></tr><tr><td>Power</td><td>BPU</td><td>Unlimited</td><td>None</td></tr><tr><td>Threshold</td><td>CPU</td><td>Not supported</td><td>None</td></tr><tr><td>Reduction</td><td>CPU</td><td>Not supported</td><td>Operation supports SUM, ASUM, SUMSQ, MEAN. <br>Axis supports. <br>Only supports Float32 calculations.</td></tr><tr><td>Softmax</td><td>CPU</td><td>Not supported</td><td>None</td></tr><tr><td>ArgMax</td><td>BPU</td><td><code>Only supports axis=1 and c&lt;=64.</code> <br>Does not support top_k != 1</td><td>None</td></tr><tr><td>Concat</td><td>BPU</td><td>Input/Output Channel: <code>C&lt;=2048</code></td><td>None</td></tr><tr><td>Split</td><td>BPU</td><td>Unlimited</td><td>None</td></tr><tr><td>Slice</td><td>BPU</td><td>Unlimited</td><td>None</td></tr><tr><td>Reshape</td><td>CPU</td><td>Not supported (can be fused in some scenarios)</td><td>Shape supports up to [1,4] shape_dim configurations. <br>Axis supports [-4,3]. No support for N dimensions. Default value is 0, follows Caffe rules.</td></tr><tr><td>Flatten</td><td>CPU</td><td>Not supported (can be fused in some scenarios)</td><td>Axis range [-4,3], default is 1, -4 and 0 have the same meaning. Only supports End_axis == -1.</td></tr><tr><td>Crop</td><td>CPU</td><td>Not supported</td><td>None</td></tr><tr><td>Dropout</td><td>BPU</td><td>Unlimited</td><td>None</td></tr><tr><td>LSTM</td><td>BPU</td><td>Only supports batch=1</td><td>--</td></tr><tr><td>Normalize</td><td>CPU</td><td>Not supported</td><td>Type constraint: only supports float type.</td></tr><tr><td>PassThrough</td><td>BPU</td><td>Supports mode=DCR and mode=CRD. <br>Only supports rearrangement in H and W directions with blocksize=2.</td><td>Type constraint: only supports float type.</td></tr><tr><td>CReLU</td><td>CPU</td><td>Not supported</td><td>Type constraint: only supports float type.</td></tr><tr><td>RReLU</td><td>CPU</td><td>Not supported</td><td>None</td></tr><tr><td>Permute</td><td>CPU</td><td>Not supported</td><td>- Supports nhwc2nchw, perm: [0, 3, 1, 2]. <br> - Supports nchw2nhwc, perm: [0, 2, 3, 1]. <br> - Supports specified perm dimension conversions, data types: float, int8, int32.</td></tr><tr><td>MatMul</td><td>BPU</td><td>Optimized for specific scenarios: <br>- K vs KxN, K vs 1xKxN, K vs 1x1xKxN<br>- MxK vs K, MxK vs KxN, MxK vs 1x1xKxN<br>- 1xMxK vs K, 1xMxK vs 1xKxN<br>- 1x1xMxK vs K, 1x1xMxK vs 1xKxN, 1x1xMxK vs 1x1xKxN<br>- BxMxK vs KxN (B&gt;=1)<br>- 1xBxMxK vs KxN (B&gt;=1)<br>- AxBxMxK vs KxN (A&gt;1, B&gt;1)<br>For the opposite scenario: <br>- 1xBxMxK vs 1x1xKxN (B&gt;1)<br>Optimized for two featuremaps: <br>- 1xBxMxK vs 1x1xKxN (B&gt;=1)</td><td>Type constraint: only supports float type.</td></tr><tr><td>Upsample</td><td>BPU</td><td><code>Input featuremap must be 4D NCHW, resize only on H and W dimensions, factors must be 2^N.</code> <br><code>Supports different factors for H and W, but H_factor &lt;= W_factor required.</code></td><td>None</td></tr><tr><td>ROIPooling</td><td>CPU</td><td>Not supported</td><td>None</td></tr><tr><td>PSROIPooling</td><td>CPU</td><td>Not supported</td><td>None</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-x3-list-of-supported-onnx-operators">RDK X3 List of supported ONNX operators<a href="#rdk-x3-list-of-supported-onnx-operators" class="hash-link" aria-label="Direct link to RDK X3 List of supported ONNX operators" title="Direct link to RDK X3 List of supported ONNX operators">​</a></h2>
<table><thead><tr><th><strong>ONNX Operator Name</strong></th><th><strong>CPU Computing/BPU Acceleration</strong></th><th><strong>X3 BPU Constraints</strong></th><th><strong>CPU Constraints</strong></th></tr></thead><tbody><tr><td>Abs</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>Acos</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>Acosh</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>Add</td><td>BPU Acceleration</td><td><code>M &lt;= 2048, supported cases:</code><br>1. NCHW and NCHW shapes for both inputs.<br>2. NCHW and NC11 shapes (both inputs need to be outputs of other ops).<br>3. Integrated into the previous conv in ResNet&#x27;s shortcut structure for acceleration.</td><td>- Supports same shape inputs calculation.<br>- Supports scalar input 1 or input 2 calculation.<br>- Supports broadcast calculation with a max dimension of 5.</td></tr><tr><td>And</td><td>CPU Calculation</td><td>--</td><td>- Supports same shape inputs calculation.<br>- Supports scalar input 1 or input 2 calculation.<br>- Supports broadcast calculation with a max dimension of 5.</td></tr><tr><td>ArgMax</td><td>BPU Acceleration</td><td>1. Four-dimensional input (NCHW).<br>2. Only supports argmax along the C dimension (axis=1).<br>3.<code>C &lt;= 64</code></td><td>Type constraint: only supports float type.</td></tr><tr><td>ArgMin</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>Asin</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>Asinh</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>Atan</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>Atanh</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>AveragePool</td><td>BPU Acceleration</td><td>Kernel HxW: [1, 7]x[1, 7], Stride ∈<!-- -->185</td><td>auto_pad attribute not supported.<br>Only supports four-dimensional tensors.</td></tr><tr><td>BatchNormalization</td><td>BPU Acceleration</td><td>Optimized to fuse with previous conv</td><td>Type constraint: only supports float type.<br>Supports channel-first data layout (dim=1).</td></tr><tr><td>BitShift</td><td>CPU Calculation(*)</td><td>--</td><td>--</td></tr><tr><td>Cast</td><td>CPU Calculation</td><td>--</td><td>from_type supports double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8.<br>to_type supports double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8.</td></tr><tr><td>Ceil</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>Clip</td><td>BPU Acceleration</td><td>Unlimited</td><td>Type constraint: only supports float type.<br>Default min parameter when two inputs are provided.</td></tr><tr><td>Compress</td><td>CPU Calculation(*)</td><td>--</td><td>--</td></tr><tr><td>Concat</td><td>BPU Acceleration</td><td><code>Input/Output Channel: C&lt;=2048</code></td><td>--</td></tr><tr><td>ConcatFromSequence</td><td>CPU Calculation(*)</td><td>--</td><td>--</td></tr><tr><td>Constant</td><td>BPU Acceleration</td><td>Optimized through constant folding</td><td>No support for sparse_tensor attribute.<br>Type constraint: only supports float type.</td></tr><tr><td>ConstantOfShape</td><td>BPU Acceleration</td><td>Optimized through constant folding</td><td>Supported types: float, int32, int8.</td></tr><tr><td>Conv</td><td>BPU Acceleration</td><td>Kernel HxW: [1, 7]x[1, 7].<br><code>Input/output Channel (for one group): &lt;= 2048 (relaxed to &lt;=4096 for non-dilated, group, depthwise conv).</code><br>Stride: Unrestricted (except stride=1 for Conv followed by Add in ResNet shortcut-connecting).<br>Dilation: Only powers of 2 allowed, divisible by stride.<br><code>h_dilated ≤ w_dilated.</code><br><code>Total kernel size limit: HxWxC ≤ 32768</code></td><td>Only supports 4D Convolution.<br>auto_pad attribute not supported.<br>Type constraint: float, int32, int8.<br>Pads constraint: [Hstart, Wstart, Hend, Wend] (4 elements) with Hstart==Hend and Wstart==Wend.</td></tr><tr><td>ConvInteger</td><td>CPU Calculation(*)</td><td>--</td><td>--</td></tr><tr><td>ConvTranspose</td><td>BPU Acceleration</td><td>Kernel HxW: [2, 14]x[2, 14].<br><code>Input/output Channel: C &lt;= 2048.</code><br>Padding HxW: [0,(Kernel_H-1)/2]x[0,(Kernel_W-1)/2].<br>Stride: <!-- -->4<!-- -->.<br><code>stride_h ≤ stride_w</code>.<br>Dilation: (1, 1) only</td><td>auto_pad attribute not supported.<br>Type constraint: float, int32, int8.</td></tr><tr><td>Cos</td><td>BPU Acceleration</td><td><code>Limited to CxHxW &lt;= 8192 for 1CHW tensor</code></td><td>Type constraint: only supports float type.</td></tr><tr><td>Cosh</td><td>CPU Calculation</td><td>--</td><td>Type constraint: only supports float type.</td></tr><tr><td>CumSum</td><td>CPU Calculation</td><td>--</td><td>--</td></tr></tbody></table>
<table><thead><tr><th>Operator: from_type:</th><th>Description: BPU Acceleration</th><th>Supported Modes</th><th>Input Shape Constraints</th><th>Output Type Constraints</th></tr></thead><tbody><tr><td>DepthToSpace</td><td>BPU acceleration</td><td>Supports DCR and CRD modes.</td><td>Only supports rearrangement along H and W dimensions with blockSize=2.</td><td><br>- from_type: only float types allowed.<br>- 4D Tensor computation only.<br>- to_type: only float types allowed.<br>- 4D Tensor computation only.</td></tr><tr><td>DequantizeLinear</td><td>CPU computation</td><td>--</td><td>--</td><td>--</td></tr><tr><td>Det</td><td>CPU computation※</td><td>--</td><td>--</td><td>--</td></tr><tr><td>Div</td><td>BPU acceleration</td><td>1. Supports featuremap inputs only (no constant inputs).<br>2. Input shape constraints refer to Mul operator.</td><td>- Same input shape supported.<br>- Supports scalar input1 or input2.<br>- Broadcast calculation up to 5 dimensions.</td><td></td></tr><tr><td>Dropout</td><td>BPU acceleration</td><td>Not computed in inference, removed by optimization.</td><td>--</td><td></td></tr><tr><td>Einsum</td><td>CPU computation※</td><td>--</td><td>--</td><td>--</td></tr><tr><td>Elu</td><td>CPU computation</td><td>--</td><td>Type constraint: only float types.</td><td></td></tr><tr><td>Equal</td><td>CPU computation</td><td>--</td><td>- Same input shape supported.<br>- Supports scalar input1 or input2.<br>- Broadcast calculation up to 5 dimensions.</td><td></td></tr><tr><td>Erf</td><td>CPU computation</td><td>--</td><td>Type constraint: supports float and double types.</td><td></td></tr><tr><td>Exp</td><td>BPU acceleration</td><td>--</td><td>Type constraint: only float types.</td><td></td></tr><tr><td>Expand</td><td>CPU computation</td><td>--</td><td>--</td><td></td></tr><tr><td>EyeLike</td><td>CPU computation</td><td>--</td><td>--</td><td></td></tr><tr><td>Flatten</td><td>CPU computation</td><td>--</td><td>--</td><td></td></tr><tr><td>Floor</td><td>CPU computation</td><td>--</td><td>Type constraint: only float types.</td><td></td></tr><tr><td>GRU</td><td>CPU computation</td><td>--</td><td>- direction attribute supports forward only.<br>- Type constraint: only float types.<br>- Input count must be 3, 4, or 6.<br>- Output count is 2.</td><td></td></tr><tr><td>Gather</td><td>CPU computation</td><td>--</td><td>from_type:<br>- input: types supported: float, int64, int32, int8, uint64, uint32, uint8.<br>- indices: type supported: int32, int64.<br>- to_type: types supported: float, int64, int32, int8, uint64, uint32, uint8.</td><td></td></tr><tr><td>GatherElements</td><td>CPU computation</td><td>--</td><td>--</td><td></td></tr><tr><td>GatherND</td><td>CPU computation</td><td>--</td><td>from_type:<br>- input: types supported: float, int32, int8.<br>- indices: tensor(int64).<br>- to_type: types supported: float, int32, int8.</td><td></td></tr><tr><td>Gemm</td><td>BPU acceleration</td><td>Converted to Conv implementation.</td><td><br>- <code>HW &lt;= 7 for both H and W if both are &lt;= 7.</code><br>- <code>C &lt;= 16384 if H/W = 1; otherwise, C &lt;= 2048.</code><br>- <code>Low-precision int8 output if followed by BPU-supported node: H x W/8 x C/4 &lt;= 1024.</code><br>- <code>High-precision int32 output if followed by non-BPU-supported node: H x W/8 x C/4 &lt; 2048.</code><br>- Type constraint: only float types.</td><td></td></tr><tr><td>GlobalAveragePool</td><td>BPU acceleration</td><td><code>Input HxW must be &lt;= 8192 for NCHW shape.</code></td><td>--</td><td></td></tr><tr><td>GlobalLpPool</td><td>CPU computation</td><td>--</td><td>Type constraint: supports float and double types.<br>- 4D Tensor computation only.</td><td></td></tr><tr><td>GlobalMaxPool</td><td>BPU acceleration</td><td>Input HxW range: [1, 1024]x[1, 1024] for NCHW shape.</td><td>Type constraint: only float types.<br>- 4D Tensor only.</td><td></td></tr><tr><td>Greater</td><td>CPU computation</td><td>--</td><td>- Same input shape supported.<br>- Supports scalar input1 or input2.<br>- Broadcast calculation up to 5 dimensions.</td><td></td></tr><tr><td>HardSigmoid</td><td>CPU computation</td><td>--</td><td>Type constraint: only float types.</td><td></td></tr><tr><td>Hardmax</td><td>CPU computation※</td><td>--</td><td>--</td><td></td></tr><tr><td>Identity</td><td>CPU computation</td><td>--</td><td>--</td><td></td></tr><tr><td>If</td><td>CPU computation※</td><td>--</td><td>--</td><td></td></tr><tr><td>InstanceNormalization</td><td>CPU Calculation</td><td></td><td></td><td></td></tr><tr><td>IsInf</td><td>CPU Calculation</td><td></td><td>Only supports float type.</td><td></td></tr><tr><td>IsNaN</td><td>CPU Calculation</td><td></td><td>Only supports float type.</td><td></td></tr><tr><td>LRN</td><td>CPU Calculation</td><td>Only supports 4D Tensors and float type.</td><td></td><td></td></tr><tr><td>LSTM</td><td>BPU Accelerated</td><td>Supports batch_size=1 only.</td><td>No attribute settings supported. Only supports inputs of 3, 4, or 8, and outputs of 2. Float type only.</td><td></td></tr><tr><td>LeakyRelu</td><td>BPU Accelerated</td><td>N/A</td><td>N/A</td><td></td></tr><tr><td>Less</td><td>CPU Calculation</td><td>Supports same input shape, scalar input1 or input2, and broadcast</td><td>Supports up to 5-dimensional broadcast with same input shapes, and scalar inputs.</td><td></td></tr><tr><td>LessOrEqual</td><td>CPU Calculation</td><td>Same as &#x27;Less&#x27;</td><td>Same as &#x27;Less&#x27;.</td><td></td></tr><tr><td>Log</td><td>CPU Calculation</td><td>Only supports float type.</td><td></td><td></td></tr><tr><td>LogSoftmax</td><td>CPU Calculation</td><td>Only supports float type.</td><td></td><td></td></tr><tr><td>Loop</td><td>CPU Calculation</td><td></td><td></td><td></td></tr><tr><td>LpNormalization</td><td>CPU Calculation</td><td>p-norm only supports 1 or 2, double or float type.</td><td></td><td></td></tr><tr><td>LpPool</td><td>CPU Calculation</td><td>auto_pad not supported, double or float type, and 4D computation</td><td></td><td></td></tr><tr><td>MatMulInteger</td><td>CPU Calculation</td><td></td><td></td><td></td></tr><tr><td>MatMul</td><td>BPU Accelerated</td><td>For scenarios where the two inputs are featuremap and weight, which involve element-wise multiplication between a featuremap and a constant, the following can be optimized for execution on a BPU:<br>- K vs KxN, K vs 1xKxN, K vs 1x1xKxN<br>- MxK vs K, MxK vs KxN, MxK vs 1x1xKxN<br>- 1xMxK vs K, 1xMxK vs 1xKxN<br>- 1x1xMxK vs K, 1x1xMxK vs 1xKxN, 1x1xMxK vs 1x1xKxN<br>- BxMxK vs KxN (where B &gt;= 1)<br>- 1xBxMxK vs KxN (where B &gt;= 1)<br>- AxBxMxK vs KxN (where A &gt; 1 and B &gt; 1)<br>For situations where both inputs are featuremaps (i.e., element-wise multiplication of featuremaps), the following can be optimized for the BPU:<br>- 1xBxMxK vs 1x1xKxN (where B &gt;= 1)</td><td>Only supports float type. Optimizations apply to specific input shapes: see details below.</td><td></td></tr><tr><td>Max</td><td>CPU Calculation</td><td>Supports multiple inputs, same shape, scalar inputs, and broadcast</td><td>Up to 5-dimensional broadcast, supports scalar inputs.</td><td></td></tr><tr><td>MaxPool</td><td>BPU Accelerated</td><td>Kernel size [1-64]x[1-64], stride [1-185], padding &gt;= 0, no dilation</td><td>dilation only supports 1x1, data row-major storage, no auto_pad or storage_order support, 4D Tensors only.</td><td></td></tr><tr><td>MaxRoiPool</td><td>CPU Calculation</td><td></td><td></td><td></td></tr><tr><td>Mean</td><td>CPU Calculation</td><td></td><td></td><td></td></tr><tr><td>Min</td><td>CPU Calculation</td><td>Same as &#x27;Max&#x27;</td><td></td><td></td></tr><tr><td>Mod</td><td>CPU Calculation</td><td></td><td></td><td></td></tr><tr><td>Mul</td><td>BPU Accelerated</td><td><code>4D inputs with C &lt;= 2048, specific shape rules apply</code><br>1. (1xCxHxW vs 1xCxHxW)。<br>2. (1xCxHxW vs 1xCx1x1)。<br>3. (1xCxHxW vs 1x1x1x1) 。</td><td>Same broadcast constraints as &#x27;Mul&#x27;. Input values must not be 0.</td><td></td></tr><tr><td>Multinomial</td><td>CPU Calculation</td><td></td><td></td><td></td></tr><tr><td>Neg</td><td>CPU Calculation</td><td></td><td></td><td></td></tr><tr><td>NonZero</td><td>CPU Calculation</td><td>Supports float, int32, or int8 types, 1D or 4D computations</td><td></td><td></td></tr><tr><td>Not</td><td>CPU Calculation</td><td></td><td></td><td></td></tr><tr><td>OneHot</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>Or</td><td>CPU</td><td>--</td><td>Supports same input shape calculation. <br>Supports scalar inputs. <br>Broadcasting up to 5 dimensions.</td><td></td></tr><tr><td>PRelu</td><td>BPU</td><td>- Type constraints: Only supports float type.<br>- from_type: X and slope.<br>- to_type: Y.</td><td>- X&#x27;s shape is data_shape, slope&#x27;s is slope_shape.<br>- data_shape == slope_shape.<br>- slope_shape.ProdSize() == 1.<br>- NCHW layout for 4D tensors with equal N and C dimensions.<br>- HxW with 1x1 (slope_shape).<br>- HxW with Hx1 (slope_shape).<br>- HxW with 1xW (slope_shape).<br>- Special case: 4D X and 3D slope, with data_shape[1] == slope_shape[0], slope_shape[1] == 1, slope_shape[2] == 1.</td><td></td></tr><tr><td>Pad</td><td>BPU</td><td>Supports mode=Constant. <br>Only supports padding on H, W dimensions.</td><td>Pad-10: <br>- Type constraint: float only.<br>- 4D NCHW tensors.<br>- pads constraint: len(pads) == 8, pads[i] &gt;= 0, pads[0] = pads[1] = pads[4] = pads[5] = 0.<br>Pad-11: <br>- from_type: data (float), pads (int64 tensor), optional constant_value (float).<br>- 4D tensor, 2D or 3D padding only.<br>- to_type: float only.</td><td></td></tr><tr><td>Pow</td><td>BPU</td><td>Supports exponent as a single value.</td><td>- Type constraints: double, float, int64, int32.<br>- Supports same shape, scalar inputs, and broadcasting up to 5 dimensions.<br>- X and Y must be of the same type.</td><td></td></tr><tr><td>QLinearConv</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>QLinearMatMul</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>QuantizeLinear</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>RNN</td><td>CPU</td><td>--</td><td>- Type constraint: float only.<br>- direction attribute: forward only.<br>- Input constraints: X, W, R required, B, sequence_lens, initial_h unsupported.<br>- Output constraint: Y_h output, shape [num_directions, batch_size, hidden_size].</td><td></td></tr><tr><td>RandomNormal</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>RandomNormalLike</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>RandomUniform</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>RandomUniformLike</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>Range</td><td>CPU</td><td>Type constraints: float, int64, int32, int16.</td><td>--</td><td></td></tr><tr><td>Reciprocal</td><td>BPU</td><td>--</td><td>--</td><td></td></tr><tr><td>ReduceL1</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>ReduceL2</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>ReduceLogSum</td><td>CPU</td><td>--</td><td>Only supports float, double data types.</td><td></td></tr><tr><td>ReduceLogSumExp</td><td>CPU</td><td>--</td><td>Type constraints: float, double.</td><td></td></tr><tr><td>ReduceMax</td><td>CPU</td><td>--</td><td>Axes support: 0, 1, or equal to input dimensions.</td><td></td></tr><tr><td>ReduceMean</td><td>BPU</td><td>Input featuremap must be 4D, axes=[2, 3].</td><td>Axes support: 0, 1, or equal to input dimensions.</td><td></td></tr><tr><td>ReduceMin</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>ReduceProd</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>ReduceSum</td><td>CPU</td><td>--</td><td>Axes support: 0, 1, or equal to input dimensions.</td><td></td></tr><tr><td>ReduceSumSquare</td><td>CPU</td><td>--</td><td>Axes support: 0, 1, or equal to input dimensions.</td><td></td></tr><tr><td>Relu</td><td>BPU</td><td>--</td><td>--</td><td></td></tr><tr><td>Reshape</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>Resize</td><td>BPU</td><td>1. Input must be NCHW 4D and only resize in H and W dimensions. ROI input supported in ONNX opset=11 (manual modification required for PyTorch models to add ROI input, which only accepts constant inputs and works with tf_crop_and_resize mode).<br>2. Mode supports nearest and linear.<br>3. Supports scaling up and down.<br>4. For nearest mode, scaling factors should be powers of 2 (e.g., 2, 4, 8, 16, 32) and H_factor must be less than or equal to W_factor.<br>5. coordinate_transformation_mode supports half_pixel, pytorch_half_pixel, asymmetric, align_corners, and tf_crop_and_resize. When using tf_crop_and_resize, ensure ROI input coordinates are integers.<br>resize-10<br>- Use opset10 when input is 2.<br>- Input is a 4D Tensor.<br>resize-11<br>- Use opset11 when input is greater than 2.<br>- Input is a 4D Tensor.<br>- coordinate_transformation_mode supports half_pixel, asymmetric, align_corners, and pytorch_half_pixel for nearest and linear modes, and half_pixel only for cubic mode.<br>- extrapolation_value not supported.</td><td></td><td></td></tr><tr><td>ReverseSequence</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>RoiAlign</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>Round</td><td>CPU</td><td>--</td><td>--</td><td></td></tr><tr><td>Scan</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>Scatter (deprecated)</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>ScatterElements</td><td>CPU</td><td>--</td><td>from_type: float, int32, int8<br>indices: int32 only<br>updates: float, int32, int8<br>to_type: float, int32, int8</td><td></td></tr><tr><td>ScatterND</td><td>CPU</td><td>--</td><td>from_type: float, int32, int8<br>updates: float, int32, int8<br>to_type: float, int32, int8</td><td></td></tr><tr><td>Selu</td><td>CPU</td><td>--</td><td>Only supports float types.</td><td></td></tr><tr><td>SequenceAt</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>SequenceConstruct</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>SequenceEmpty</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>SequenceErase</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>SequenceInsert</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>SequenceLength</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>Shape</td><td>BPU</td><td>Optimized to numerical storage via constant folding.</td><td>--</td><td></td></tr><tr><td>Shrink</td><td>CPU※</td><td>--</td><td>--</td><td></td></tr><tr><td>Sigmoid</td><td>BPU</td><td><code>Limited to 1CHW tensors where CxHxW &lt;= 8192.</code><br>8W4C: pad W to multiples of 8 and C to multiples of 4.<br>32C: pad C to multiples of 32.<br><code>Choose the smallest aligned shape between the two and ensure &lt;= 8192.</code></td><td>Only supports float types.</td><td></td></tr><tr><td>Sign</td><td>CPU</td><td>--</td><td>None</td><td></td></tr><tr><td>Sin</td><td>BPU</td><td><code>Limited to 1CHW tensors where CxHxW &lt;= 8192.</code></td><td>Only supports float types.</td><td></td></tr><tr><td>Sinh</td><td>CPU</td><td>--</td><td>Only supports float types.</td><td></td></tr><tr><td>Size</td><td>BPU</td><td>Optimized to numerical storage via constant folding.</td><td>--</td><td></td></tr><tr><td>Slice</td><td>BPU</td><td>Unlimited</td><td>None</td><td></td></tr><tr><td>Softmax</td><td>BPU</td><td>Runs on CPU by default. Can be set to BPU for 4D inputs with axis=1 and as model output, using run_on_bpu.</td><td>Only supports float types.</td><td></td></tr><tr><td>Softplus</td><td>BPU acceleration</td><td><code>Supports CxHxW &lt;= 8192 for a tensor of input dimension 1CHW.</code></td><td>Only supports float type.</td><td></td></tr><tr><td>Softsign</td><td>CPU computation</td><td>--</td><td>Only supports float type.</td><td></td></tr><tr><td>SpaceToDepth</td><td>BPU acceleration</td><td>Supports DCR and CRD modes. <br>Restrictions: H and W permutation, blocksize=2 only.</td><td>Only supports float type.</td><td></td></tr><tr><td>Split</td><td>BPU acceleration</td><td>Restrictions: NCHW input, divisible lengths, axis=1,2,3.</td><td>Only supports float type.</td><td></td></tr><tr><td>SplitToSequence</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr><tr><td>Sqrt</td><td>BPU acceleration</td><td><code>Supports CxHxW &lt;= 8192 for a tensor of input dimension 1CHW.</code></td><td>Only supports float type.</td><td></td></tr><tr><td>Squeeze</td><td>CPU computation</td><td>Removed by constant folding optimization if in constant substructure.</td><td>--</td><td></td></tr><tr><td>StringNormalizer</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr><tr><td>Sub</td><td>CPU computation</td><td>--</td><td>Supports same shape, scalar inputs, broadcast up to 5 dimensions.</td><td></td></tr><tr><td>Sum</td><td>BPU acceleration</td><td>Same restrictions as Add.</td><td>Only supports float type.</td><td></td></tr><tr><td>Tan</td><td>CPU computation</td><td>--</td><td>Only supports float type.</td><td></td></tr><tr><td>Tanh</td><td>BPU acceleration</td><td><code>Supports CxHxW &lt;= 8192 for a tensor of input dimension 1CHW.</code></td><td>Only supports float type.</td><td></td></tr><tr><td>TfIdfVectorizer</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr><tr><td>ThresholdedRelu</td><td>CPU computation</td><td>--</td><td>Only supports float type.</td><td></td></tr><tr><td>Tile</td><td>CPU computation</td><td>--</td><td>Supports float, int64, int32, uint64, uint32 types.</td><td></td></tr><tr><td>TopK</td><td>CPU computation</td><td>--</td><td>Only supports float type, opset-10.</td><td></td></tr><tr><td>Transpose</td><td>CPU computation</td><td>Supports nhwc2nchw, perm=[0, 3, 1, 2], nchw2nhwc, perm=[0, 2, 3, 1].</td><td>Supports float, int8, int32 types.</td><td></td></tr><tr><td>Unique</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr><tr><td>Unsqueeze</td><td>CPU computation</td><td>Removed by constant folding optimization if in constant substructure.</td><td>--</td><td></td></tr><tr><td>Upsample (replace resize)</td><td>BPU acceleration</td><td>--</td><td>Upsample-10 for input=2, 4D Tensor.<br>Upsample-11 for input&gt;2, 4D Tensor.</td><td></td></tr><tr><td>Where</td><td>CPU computation</td><td>--</td><td>Supports float and int64 types. <br>Shape constraints detailed in the description.</td><td></td></tr><tr><td>Xor</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr><tr><td>Function</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr><tr><td>Celu</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr><tr><td>DynamicQuantizeLinear</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr><tr><td>GreaterOrEqual</td><td>CPU computation</td><td>--</td><td>Supports same shape, scalar inputs, broadcast up to 5 dimensions.</td><td></td></tr><tr><td>MeanVarianceNormalization</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr><tr><td>GridSample (PyTorch)</td><td>CPU computation(*)</td><td>--</td><td>--</td><td></td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-ultra-supported-caffe-operators-list">RDK Ultra Supported Caffe Operators List<a href="#rdk-ultra-supported-caffe-operators-list" class="hash-link" aria-label="Direct link to RDK Ultra Supported Caffe Operators List" title="Direct link to RDK Ultra Supported Caffe Operators List">​</a></h2>
<table><thead><tr><th><strong>Caffe Operator Name</strong></th><th><strong>CPU Computation/BPU Acceleration</strong></th><th><strong>RDK Ultra BPU Constraints</strong></th><th><strong>CPU Constraints</strong></th></tr></thead><tbody><tr><td>Convolution</td><td>BPU Accelerated</td><td>- <code>Kernel width and height: &lt;= 32</code><br> - <code>Input/output channels (for one group): &lt;= 8192 (or &lt;= 65536 if last in quantized graph)</code><br> - <code>Stride: Unrestricted, stride for Conv followed by Add (ResNet shortcut-connection) should be {1, 2}</code><br> - <code>Dilation: &lt;= 16</code><br> - <code>Only supports dilation=1 when dilation != 1</code><br> - <code>Axis default: 1</code><br></td><td>- 4D Convolution only<br> - auto_pad attribute not supported<br> - Type constraints: float, int32, int8<br> - Pads attribute constraint: [Hstart, Wstart, Hend, Wend] (4 elements) with Hstart==Hend and Wstart==Wend.</td></tr><tr><td>Deconvolution</td><td>BPU Accelerated</td><td>- <code>kernel &gt;= stride</code><br> - <code>Input/output featuremaps &lt;= 2048</code><br> - <code>pad &lt;= kernel</code> / stride<br> - out_pad &lt; 2<br> - <code>stride: 14 &gt;= stride &gt;= 1</code>, but stride_h and stride_w cannot both be 1<br> - Axis configuration not supported</td><td>- Shape constraint: 4D Tensor computation only<br> - Type constraint: float only<br> - Attribute constraints: dilations, group, output_padding, pads, strides attributes<br> - Pads attribute constraint: [hstart, wstart, hend, wend] must satisfy (hstart==hend and wstart==wend).</td></tr><tr><td>MaxUnpool</td><td>CPU Computation</td><td>---</td><td>- from_type constraints: X - float, I - Tensor(int64)<br> - to_type constraints: float only</td></tr><tr><td>Pooling</td><td>BPU Accelerated</td><td>- Four types: MaxPooling, AveragePooling, GlobalMaxPooling, GlobalAveragePooling<br> - <code>Constraints: MaxPooling - int16 input/output, kernel &lt;= 256, stride &lt;= 256, padding &lt;= 256</code><br> - AveragePooling - same as MaxPooling<br> - GlobalAveragePooling - unlimited<br> - GlobalMaxPooling - H, W ∈ [1, 256]</td><td>None</td></tr><tr><td>SPP</td><td>CPU Computation</td><td>Not supported</td><td>- <code>Supports pyramid_height with 2^n pooling, n &lt; 7</code><br> - <code>pooling kernel &lt;= 255</code><br> - <code>pool option, configurable values: {0, 1}</code></td></tr><tr><td>InnerProduct</td><td>BPU Accelerated</td><td>Converted to Conv with Conv constraints<br> - Axis configuration not supported</td><td>None</td></tr><tr><td>LRN</td><td>CPU Computation</td><td>Not supported</td><td>- local_size supported<br> - alpha, beta, norm_region supported (configurable values: ACROSS_CHANNELS, WITHIN_CHANNEL)<br> - k supported</td></tr><tr><td>MVN</td><td>CPU Computation</td><td>Not supported</td><td>- normalize_variance: configurable values <!-- -->1<br> - across_channels: configurable values <!-- -->1<br> - Float32 computation only</td></tr><tr><td>BatchNorm</td><td>BPU Accelerated</td><td>Unlimited</td><td>None</td></tr><tr><td>ELU</td><td>BPU Accelerated</td><td>- int16 input/output support<br> - Input/output dimensions up to 10D, max dimension [1, 4096], others [1, 65536]</td><td>None</td></tr><tr><td>BNLL</td><td>CPU Computation</td><td>Not supported</td><td>None</td></tr><tr><td>PReLU</td><td>CPU Computation</td><td>- type constraint: float only<br> - from_type: X and slope<br> - to_type: Y<br> - Shape constraints: X = data_shape, slope = slope_shape<br>   - data_shape == slope_shape<br>   - slope_shape.ProdSize() == 1<br>   - 4D NCHW layout for X and slope, N, C dimensions must be equal<br>     - HxW or 1x1 for slope_shape<br>     - Hx1 or 1xH for slope_shape<br>     - 1xW or Wx1 for slope_shape<br>   - Special case: 4D X and 3D slope with data_shape[1] = slope_shape[0] and slope_shape[1] = 1, slope_shape[2] = 1</td><td>None</td></tr><tr><td>ReLU/LeakyReLU</td><td>BPU Accelerated</td><td>- int16 input/output support<br> - Input/output dimensions up to 10D, max dimension [1, 4096], others [1, 65536]</td><td>None</td></tr><tr><td>Sigmoid</td><td>BPU Accelerated</td><td>- int16 input/output support<br> - Input/output dimensions up to 10D, max dimension [1, 4096], others [1, 65536]</td><td>None</td></tr><tr><td>TanH</td><td>BPU Accelerated</td><td>- int16 input/output support<br> - Input/output dimensions up to 10D, max dimension [1, 4096], others [1, 65536]</td><td>None</td></tr><tr><td>Eltwise</td><td>BPU Accelerated</td><td>Supports Add, Sub, Mul operations<br> - int16 input/output support<br> - Feature map and constant inputs, at most one constant<br> - Broadcasting except first dimension<br> - 2D, 3D, 4D, and 5D dimensions supported, with general limitations (see notes)<br> - Different input dimensions supported, 5D inputs must meet: merge adjacent dimensions to 4D (e.g., NHWD1 and N1WDC), broadcast dimensions cannot be adjacent (e.g., NHWD1 and N11DC due to broadcast on H, W, and C)</td><td>None</td></tr><tr><td>Bias</td><td>BPU Accelerated</td><td>Refer to Eltwise (Add) constraints</td><td>None</td></tr><tr><td>Scale</td><td>BPU Accelerated</td><td>Refer to Eltwise (Mul) constraints</td><td>None</td></tr><tr><td>AbsVal</td><td>BPU Accelerated</td><td>- int16 input/output support<br> - Input/output dimensions up to 10D, max dimension [1, 4096], others [1, 65536]</td><td>None</td></tr><tr><td>Exp</td><td>BPU Accelerated</td><td>- int16 input/output support<br> - Input/output dimensions up to 10D, max dimension [1, 4096], others [1, 65536]</td><td>None</td></tr><tr><td>Log</td><td>BPU Accelerated</td><td>- int16 input/output support<br> - Input/output dimensions up to 10D, max dimension [1, 4096], others [1, 65536]</td><td>None</td></tr><tr><td>Power</td><td>BPU Op</td><td>1. Supports int16 input and output.<br>2. Input and output support up to 10 dimensions, with max dimension ∈ [1, 4096], others ∈ [1, 65536].<br>3. Second input only supports scalar.</td><td>-</td></tr><tr><td>Threshold</td><td>CPU Computation</td><td>Not supported</td><td>-</td></tr><tr><td>Reduction</td><td>CPU Computation</td><td>Not supported. Operation supports SUM, ASUM, SUMSQ, MEAN, Max, LogSum, Min, Prod; Axis supports; Only supports Float32 computation.</td><td>-</td></tr><tr><td>Softmax</td><td>BPU Op</td><td>1. Supports int16 input and output.<br>2. Defaults to CPU execution. Can run on BPU for 4D inputs with axis=1,2,3 if specified by run_on_bpu.</td><td>-</td></tr><tr><td>ArgMax</td><td>BPU Op</td><td><code>1. Only supports axis=1, c&lt;=64.</code><br><code>2. Does not support top_k ≠ 1.</code><br><code>3. Supports int16 input and output.</code></td><td>-</td></tr><tr><td>Concat</td><td>BPU Op</td><td>1. Supports int16 input and output.<br>2. Does not support N-dimensional concat.</td><td>-</td></tr><tr><td>Split</td><td>BPU Op</td><td>1. Supports int16 input and output.<br>2. Length of the original input must be a multiple of each split tensor length.<br>3. Supports any dimension except N.<br>4. Split count should be divisible.<br>5. Supports non-four-dimensional input and output.</td><td>-</td></tr><tr><td>Slice</td><td>BPU Op</td><td>1. Supports int16 input and output.<br>2. Unlimited, supports non-four-dimensional input and output.</td><td>-</td></tr><tr><td>Reshape</td><td>BPU Op</td><td>1. Supports int16 input and output.<br>2. Supports up to 10-dimensional input and output.</td><td>Shape supports [1,4] shape_dim configurations; Axis supports [-4,3], does not support N dimensions, default 0 follows Caffe rules; num_axes supports [-1,3], default -1 means all axes from axis start.</td></tr><tr><td>Flatten</td><td>CPU Computation</td><td>Not supported (can be fused in some scenarios)</td><td>Axis range [-4,3], default is 1, with -4 and 0 having the same meaning. Only supports End_axis == -1.</td></tr><tr><td>Crop</td><td>CPU Computation</td><td>Not supported</td><td>-</td></tr><tr><td>Dropout</td><td>BPU Op</td><td>Unlimited</td><td>-</td></tr><tr><td>LSTM</td><td>BPU Op</td><td>Only supports batch=1</td><td>-</td></tr><tr><td>Normalize</td><td>CPU Computation</td><td>Not supported</td><td>Type constraint: only supports float types.</td></tr><tr><td>PassThrough</td><td>BPU Op</td><td>Supports mode=DCR and mode=CRD. Only supports reordering along H and W directions with blocksize=2, e.g., NxCxHxW -&gt; Nx(4C)x(H/2)x(W/2).</td><td>Type constraint: only supports float types.</td></tr><tr><td>CReLU</td><td>CPU Computation</td><td>Not supported</td><td>Type constraint: only supports float types.</td></tr><tr><td>RReLU</td><td>CPU Computation</td><td>Not supported</td><td>None</td></tr><tr><td>Permute</td><td>BPU Op</td><td>1. Supports arbitrary input dimensions.<br>2. Supports conversion of any other dimension except batch dimension (first dimension).</td><td>- Supports nhwc2nchw, perm: [0, 3, 1, 2].<br>- Supports nchw2nhwc, perm: [0, 2, 3, 1].<br>- Supports permutation of specified dimensions, data types supported: float, int8, int32.</td></tr><tr><td>MatMul</td><td>BPU Op</td><td>C = MatMul(A, B), with dimension constraints for A and B:<br>- Both A and B can have non-four-dimensional inputs but must meet these conditions:<br>  - Dimensions of A and B must be the same.<br>  - The lowest two dimensions M, K ∈ [1, 8192], higher dimensions ∈ [1, 4096].<br>  Note: HDMK vs HDKN, MK/KN refers to the lowest two dimensions.<br>- Broadcasting is supported under these conditions:<br>  - All other dimensions than the lowest two of A and B are either 1 or do not require broadcasting.<br>    - Supported example: HDMK vs H1KN<br>    - Unsupported example: H1MK vs 1DKN<br>  - A cannot have both broadcasting and non-broadcasting values in dimensions beyond its lowest two.<br>    - Supported example: 11MK vs HDKN<br>    - Unsupported example: H1MK vs HDKN<br>  - If B has both broadcasting and non-broadcasting values in higher dimensions, non-broadcasting values must be contiguous.<br>    - Supported example: BHDMK vs B11KN<br>    - Unsupported example: BHDMK vs B1DKN<br>- Broadcasting rules:<br>- If A and B have unequal values in a given dimension, the 1 is considered the broadcasting value, and the non-1 is not.<br>- If A and B have equal values in a given dimension, both are considered non-broadcasting values (e.g., HDMK vs H1KN, 1 is the broadcasting value, H is not).</td><td>Type constraint: only supports float types.</td></tr><tr><td>Upsample</td><td>BPU Op</td><td>Requires four-dimensional NCHW input, resize only supported on H and W dimensions; factor cannot be less than 2.</td><td>-</td></tr><tr><td>ROIPooling</td><td>CPU Computation</td><td>Not supported</td><td>-</td></tr><tr><td>PSROIPooling</td><td>CPU Computation</td><td>Not supported</td><td>-</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rdk-ultra-supported-onnx-operators-list">RDK Ultra-supported ONNX Operators List<a href="#rdk-ultra-supported-onnx-operators-list" class="hash-link" aria-label="Direct link to RDK Ultra-supported ONNX Operators List" title="Direct link to RDK Ultra-supported ONNX Operators List">​</a></h2>
<table><thead><tr><th><strong>ONNX Operator Name</strong></th><th><strong>CPU/CPU Acceleration</strong></th><th><strong>RDK Ultra BPU Constraints</strong></th><th><strong>CPU Constraints</strong></th></tr></thead><tbody><tr><td>Abs</td><td>BPU Accelerated</td><td>1. Supports int16 input/output.<br>2. Input/output dimensions up to 10D, with max dimensions in [1, 4096] and others in [1, 65536].</td><td>Type constraint: only supports float types.</td></tr><tr><td>Acos</td><td>CPU Computation</td><td>--</td><td>Type constraint: only supports float types.</td></tr><tr><td>Acosh</td><td>CPU Computation</td><td>--</td><td>Type constraint: only supports float types.</td></tr><tr><td>Add</td><td>BPU Accelerated</td><td>1. Supports int16 input/output.<br>2. Input can be featuremaps or constants, with at most one constant input.<br>3. Supports broadcast except for the first dimension, including NHWC and N1WC broadcasting.<br>4. Dimensions supported: 2D, 3D, 4D, and 5D, with general restrictions (see notes).<br>5. In ResNet&#x27;s shortcut connection, Add is fused into the preceding conv for acceleration.</td><td>- Supports computation with same input shape.<br>- Supports scalar inputs as either input 1 or 2.<br>- Supports broadcast up to 5D.</td></tr><tr><td>And</td><td>CPU Computation</td><td>--</td><td>- Supports same input shape calculation.<br>- Supports scalar inputs as either input 1 or 2.<br>- Supports broadcast up to 5D.</td></tr><tr><td>ArgMax</td><td>BPU Accelerated</td><td>1. 4D input format NCHW.<br><code>2. Only supports argmax along the C axis (axis=1).&lt;br/&gt;3. C &lt;= 64.</code><br>4. Supports int16 input/output.</td><td>Type constraint: only supports float types.</td></tr><tr><td>ArgMin</td><td>BPU Accelerated</td><td>Similar to ArgMax constraints</td><td>Type constraint: only supports float types.</td></tr><tr><td>Asin</td><td>CPU Computation</td><td>--</td><td>Type constraint: only supports float types.</td></tr><tr><td>Asinh</td><td>CPU Computation</td><td>--</td><td>Type constraint: only supports float types.</td></tr><tr><td>Atan</td><td>BPU Accelerated</td><td>1. Supports int16 input/output.<br>2. Input/output dimensions up to 10D, with max dimensions in [1, 4096] and others in [1, 65536].</td><td>Type constraint: only supports float types.</td></tr><tr><td>Atanh</td><td>CPU Computation</td><td>--</td><td>Type constraint: only supports float types.</td></tr><tr><td>AveragePool</td><td>BPU Accelerated</td><td><code>Kernel &lt;= 256.</code><br><code>Stride &lt;= 256.&lt;br/&gt;Padding &lt;= 256. </code></td><td>No support for auto_pad attribute.<br>Only supports 4D Tensors.</td></tr><tr><td>BatchNormalization</td><td>BPU Accelerated</td><td>No limitations.</td><td>Type constraint: only supports float types.<br>Supports channel-first data layout (dimension 1 is channel).</td></tr><tr><td>BitShift</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>Cast</td><td>CPU Computation</td><td>--</td><td>from_type supports: double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8.<br>to_type supports: double, float, bool, int64, uint32, int32, uint16, int16, uint8, int8.</td></tr><tr><td>Ceil</td><td>BPU Accelerated</td><td>1. Supports int16 input/output.<br>2. Input/output dimensions up to 10D, with max dimensions in [1, 4096] and others in [1, 65536].</td><td>Type constraint: only supports float types.</td></tr><tr><td>Clip</td><td>BPU Accelerated</td><td>1. Supports int16 input/output.<br>2. Input/output dimensions up to 10D, with max dimensions in [1, 4096] and others in [1, 65536].<br>Opset 6: min, max as attributes, dtype only supports float.<br>Opset 11: min, max as inputs, second input is min when there are two; dtype supports float, double.</td><td></td></tr><tr><td>Compress</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>Concat</td><td>BPU Accelerated</td><td>1. Supports int16 input/output.<br>2. Does not support N-dimensional concatenation.</td><td>--</td></tr><tr><td>ConcatFromSequence</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>Constant</td><td>BPU Accelerated</td><td>Optimized via constant folding</td><td>No support for sparse_tensor attribute.</td></tr><tr><td>ConstantOfShape</td><td>BPU Accelerated</td><td>Optimized via constant folding</td><td>Supported types: float, int32, int8.</td></tr><tr><td>Conv</td><td>BPU Accelerated</td><td>Supports 4D (conv2d) and 5D (conv3d) inputs.<br>4D conv2d: Kernel size range: N,C ∈ [1, 8192]; H,W ∈ [1, 31].<br>C<em>H</em>W ≤ 65535.<br>Channel limits: 1 group, C ≤ 8192 (or 65536 if last operator in quantized graph).<br>Stride: H,W ∈ [1, 256] (except for shortcut-connected conv, stride=1,2); dilation: H,W ∈ [1, 16], with H and W factors dividing input Tensor dimensions.<br>Padding: H,W ∈ [0, 256].<br>5D conv3d: NCDHW limits: N ∈ [1, 128]; H,W,D,C ∈ [1, 65536].<br>Kernel size: N,C ∈ [1, 65536]; H,W ∈ [1, 31], D ∈ [1, 8191].<br>Padding: DHW: H,W ∈ [0, 256], D ∈ [0, kernel_d/2].<br>Stride: H, W must be 1 or 2.<br>Group and dilation not supported.<br>Size limit: 1GB; D<em>C ≤ 4096 for D</em>H<em>alignCeil(W, 256)<em>D</em>C &lt; 1GB.<br>Weight limit: D</em>C ≤ 8192.</td><td>Only supports 4D convolutions.<br>No support for auto_pad attribute.<br>Supported types: float, int32, int8.<br>Pads constraint: [Hstart, Wstart, Hend, Wend] (4 elements) with Hstart==Hend and Wstart==Wend.</td></tr><tr><td>ConvInteger</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>ConvTranspose</td><td>BPU Accelerated</td><td>Input/output featuremap limits: N ∈ [1, 128], H,W ∈ [1, 65536], C ∈ [1, 2048].<br>Size limit: 1GB.<br>Weight size limits: N,C ∈ [1, 2048], H,W ∈ [1, 14], HW ≠ 1.<br>Size: [1, 65535].<br>Padding: For odd strides, H,W ∈ [0, kernel / stride); even strides, H,W ∈ [0, kernel / stride].<br>Out_pad: H,W ∈ <!-- -->1<!-- -->.<br>Stride: 1-14, not both stride_h and stride_w equal to 1. n ∈ <!-- -->1<!-- -->.</td><td>Shape Constraint: Only supports 4D Tensors for computation.<br>Type Constraint: Only supports float types.<br>Attribute Constraints:<br>- Supports only dilations, group, output_padding, pads, and strides attributes.<br>- The pads attribute constraint is that [hstart, wstart, hend, wend] must satisfy (hstart==hend and wstart==wend).</td></tr><tr><td>Cos</td><td>BPU Acceleration</td><td>1. This operator supports int16 input and output.<br>2. Input and output support dimensions up to 10, with the highest dimension ∈ [1, 4096], and other dimensions ∈ [1, 65536].<br>Type Constraint: Only supports float types.</td><td></td></tr><tr><td>Cosh</td><td>CPU Computation</td><td>--</td><td></td></tr><tr><td>CumSum</td><td>CPU Computation</td><td>--</td><td>Axis: Type Constraint is only for int32 types.</td></tr><tr><td>DepthToSpace</td><td>BPU Acceleration</td><td>Supports modes DCR and CRD.<br>Only rearrangement of H and W directions is supported, and blocksize=2 rearrangement only.<br>Example: NxCxHxW -&gt; Nx(C/4)x(2H)x(2W), where the number of channels must be a multiple of 4.</td><td>From_Type Constraints:<br>- Type Constraint: Only supports float types.<br>- Limited to 4D Tensor computation.<br>To_Type Constraints:<br>- Type Constraint: Only supports float types.<br>- Limited to 4D Tensor computation.</td></tr><tr><td>DequantizeLinear</td><td>CPU Computation</td><td>--</td><td></td></tr><tr><td>Det</td><td>CPU Computation※</td><td>--</td><td></td></tr><tr><td>Div</td><td>BPU Acceleration</td><td>1. Only supports featuremap inputs (not constant inputs);<br>2. Input shape constraints refer to the Mul operator.<br>- Supports same-input-shape computation.<br>- Supports computation when input 1 is a scalar or input 2 is a scalar.<br>- Supports broadcast computation with a maximum dimension of 5.</td><td></td></tr><tr><td>Dropout</td><td>BPU Acceleration</td><td>Does not participate in inference computations and will be removed during optimization.</td><td></td></tr><tr><td>Einsum</td><td>CPU Computation※</td><td>--</td><td></td></tr><tr><td>Elu</td><td>BPU Acceleration</td><td>1. This operator supports int16 input and output.<br>2. Input and output support dimensions up to 10, with the highest dimension ∈ [1, 4096], and other dimensions ∈ [1, 65536].<br>Type Constraint: Only supports float types.</td><td></td></tr><tr><td>Equal</td><td>BPU Acceleration</td><td>1. Supports int16 input.<br>2. Input and output dimensions support 2-5 dimensions.<br>3. Supports broadcast across all dimensions, broadcast for fin0 or fin1 input allowed, but not mutual broadcasting. 5D broadcast has the following restrictions:<br>- Must merge adjacent dimensions to reduce to 4D (including dimension N), e.g., NHWDC and NH1D1 can merge the NH dimension.<br>- Broadcasted dimensions cannot merge with adjacent ones, e.g., NHWDC and N1W1C are unsupported due to inability to merge adjacent dimensions.<br>4. Runs on CPU by default; can be specified to run on BPU with run_on_bpu.</td><td></td></tr><tr><td>Erf</td><td>CPU Computation</td><td>--</td><td>Type Constraint: Supports float and double data types.</td></tr><tr><td>Exp</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input and output support dimensions up to 10, with the highest dimension ∈ [1, 4096], and other dimensions ∈ [1, 65536].<br>Type Constraint: Only supports float types.</td><td></td></tr><tr><td>Expand</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input and output support dimensions up to 10, with one differing dimension between input and output.<br>3. Only allows one differing dimension between input and output.</td><td></td></tr><tr><td>EyeLike</td><td>CPU Computation</td><td>--</td><td></td></tr><tr><td>Flatten</td><td>BPU Acceleration</td><td>Constraints similar to Reshape.</td><td></td></tr><tr><td>Floor</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input and output support dimensions up to 10, with the highest dimension ∈ [1, 4096], and other dimensions ∈ [1, 65536].<br>Type Constraint: Only supports float types.</td><td></td></tr><tr><td>GRU</td><td>CPU Computation</td><td>--</td><td>Direction Attribute: Only supports forward type.<br>Type Constraint: Only supports float types.</td></tr><tr><td>Gather</td><td>BPU Acceleration</td><td>1. All ranks of input/output/indices must be less than or equal to 4.<br>2. Indices support:<br>   - When indices are feature (other op outputs), type constraint is only for int32.<br>   - When indices are weight (model constants), type constraint supports int32 and int64.<br>From_Type Constraints:<br>- input: Type constraint supports float, int64, int32, int8, uint64, uint32, uint8.<br>- indices: Type constraint supports int32, int64.<br>To_Type Constraints:<br>- Type constraint supports float, int64, int32, int8, uint64, uint32, uint8.</td><td></td></tr><tr><td>GatherElements</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input/indices/output dimensions support up to 10 dimensions.<br>3. Indices type constraint supports int16/int32/int64.</td><td></td></tr><tr><td>GatherND</td><td>CPU Computation</td><td>--</td><td>From_Type Constraints:<br>- input: Type constraint supports float, int32, int8.<br>- indices: tensor(int64).<br>To_Type Constraints: Type constraint supports float, int32, int8.</td></tr><tr><td>Gemm</td><td>BPU Acceleration</td><td>Gemm will be converted to Conv implementation, with boundary constraints referring to Conv.</td><td>Type Constraint: Only supports float types.</td></tr><tr><td>GlobalAveragePool</td><td>BPU Acceleration</td><td>No limitations.</td><td>- Type Constraint: Only supports float types.<br>- Limited to 4D Tensors.</td></tr><tr><td>GlobalLpPool</td><td>CPU Computation</td><td>--</td><td>- Type Constraint: Supports float and double types.<br>- Limited to 4D Tensor computation.</td></tr><tr><td>GlobalMaxPool</td><td>BPU Acceleration</td><td>H, W ∈ [1, 256].</td><td>- Type Constraint: Only supports float types.<br>- Limited to 4D Tensors.</td></tr><tr><td>Greater</td><td>BPU Acceleration</td><td>1. Supports int16 input.<br>2. Input and output dimensions support 2-5 dimensions.<br>3. Same as Equal operator constraints.<br>4. Runs on CPU by default; can be specified to run on BPU with run_on_bpu.</td><td></td></tr><tr><td>HardSigmoid</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input and output support dimensions up to 10, with the highest dimension ∈ [1, 4096], and other dimensions ∈ [1, 65536].<br>Type Constraint: Only supports float types.</td><td></td></tr><tr><td>Hardmax</td><td>CPU Computation※</td><td>--</td><td></td></tr><tr><td>Identity</td><td>CPU Computation</td><td>--</td><td></td></tr><tr><td>If</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>InstanceNormalization</td><td>CPU Computation</td><td>--</td><td>- Type constraint only supports float types.<br>- Supports data layout with the first dimension as channels.</td></tr><tr><td>IsInf</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>IsNaN</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>LRN</td><td>CPU Computation</td><td>--</td><td>- Type constraint only supports float types.<br>- Only supports four-dimensional Tensors.</td></tr><tr><td>LSTM</td><td>BPU Acceleration</td><td>Supports batch_size=1 only. If using multiple batches, ensure LSTM&#x27;s batch is 1 during ONNX export and configure the parameter input_batch=1 in the YAML.</td><td>- Type constraint only supports float types.<br>- Attribute constraint: direction attribute only supports forward.<br>- Input constraints:<br>   - Supports X, W, R inputs;<br>   - Supports X, W, R, B inputs (sequence_lens is empty or default);<br>   - Supports X, W, R, B, sequence_lens, initial_h, initial_c, P inputs (sequence_lens is empty or default).</td></tr><tr><td>LeakyRelu</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input and output dimensions support 1-10 dimensions, with the highest dimension ∈ [1, 4096], others ∈ [1, 65536].</td><td>Type constraint: only supports float types.</td></tr><tr><td>Less</td><td>BPU Acceleration</td><td>1. Supports int16 input.<br>2. Input/output dimensions support 2-5 dimensions.<br>3. Runs on CPU by default; can be specified to run on BPU using run_on_bpu.</td><td>- Supports same shape inputs calculation.<br>- Supports scalar input1 or scalar input2 calculation.<br>- Supports broadcast calculation with a max dimension of 5.</td></tr><tr><td>LessOrEqual</td><td>BPU Acceleration</td><td>In opset11, single LessOrEqual not supported; Greater + Not operator is used instead, with the same limitations as Greater.</td><td>- Supports same shape inputs calculation.<br>- Supports scalar input1 or scalar input2 calculation.<br>- Supports broadcast calculation with a max dimension of 5.</td></tr><tr><td>Log</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input and output dimensions support 1-10 dimensions, with the highest dimension ∈ [1, 4096], others ∈ [1, 65536].</td><td>Type constraint: only supports float types.</td></tr><tr><td>LogSoftmax</td><td>CPU Computation</td><td>--</td><td>Type constraint: only supports float types.</td></tr><tr><td>Loop</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>LpNormalization</td><td>CPU Computation</td><td>--</td><td>- p-norm only supports 1 or 2.<br>- Type constraint supports double and float types.</td></tr><tr><td>LpPool</td><td>CPU Computation</td><td>--</td><td>- auto_pad attribute not supported.<br>- Type constraint supports double and float types.<br>- Limited to 4-dimensional computation.</td></tr><tr><td>MatMulInteger</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>MatMul</td><td>BPU Acceleration</td><td>C = MatMul(A, B), with input A and B dimension restrictions:<br>- Non-quadruple dimensional inputs allowed but must meet these constraints:<br>  - A and B must have identical dimensions.<br>  - The lowest two dimensions M, K ∈ [1, 8192], higher dimensions ∈ [1, 4096].<br>  Note: HDMK vs HDKN, MK/KN refers to the lowest two dimensions.<br>- Broadcast is supported under these conditions:<br>  - For A and B, all dimensions except the lowest two must be either 1 or non-broadcastable values.<br>    - Examples: HDMK vs H1KN<br>    - Counterexample: H1MK vs 1DKN<br>  - A&#x27;s higher dimensions cannot contain both broadcastable and non-broadcastable values.<br>    - Examples: 11MK vs HDKN<br>    - Counterexample: H1MK vs HDKN<br>  - If B&#x27;s higher dimensions contain both broadcastable and non-broadcastable values, non-broadcastable ones must be consecutive high dimensions.<br>    - Examples: BHDMK vs B11KN<br>    - Counterexample: BHDMK vs B1DKN<br>- Type constraint: only supports float types.</td><td></td></tr><tr><td>Max</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input/output dimensions support 2-5 dimensions.<br>3. Supports broadcast across all dimensions, broadcast for fin0 or fin1 individually, not mutual broadcast. Restrictions for 5D broadcast:<br>- Can merge adjacent dimensions to 4D (including dimension N), e.g., NHWDC and NH1D1 can merge NH.<br>- Broadcast dimensions cannot merge with adjacent ones, e.g., NHWDC and N1W1C unsupported due to no adjacent dimension merge.<br>- Other details in the documentation.</td><td>- Supports 1-∞ inputs.<br>- Supports same shape inputs calculation.<br>- Supports scalar input1 or scalar input2 calculation.<br>- Supports broadcast calculation with a max dimension of 5.</td></tr><tr><td>MaxPool</td><td>BPU Acceleration</td><td>Supports int16 input and output.<br>Kernel size ≤ 256.<br>Stride ≤ 256.<br>Padding ≤ 256.<br>MaxPool does not support dilation.</td><td>1. Dilation only supports 1x1.<br>2. Data row-major storage only.<br>3. auto_pad attribute not supported.<br>4. storage_order attribute not supported.<br>5. Limited to four-dimensional Tensor computation.</td></tr><tr><td>MaxRoiPool</td><td>CPU Computation</td><td>--</td><td>No specific constraints.</td></tr><tr><td>Mean</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>Min</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input/output dimensions support 2-5 dimensions.<br>3. Similar to Max, but with different broadcast and dimension merge rules.<br>4. Runs on CPU by default; can be moved to BPU using run_on_bpu.</td><td>- Similar to Max, but with different input constraints.</td></tr><tr><td>Mod</td><td>CPU Computation※</td><td>--</td><td>--</td></tr><tr><td>Mul</td><td>BPU Acceleration</td><td>1. Supports int16 input and output.<br>2. Input types support feature maps and constants, with at most one constant input.<br>3. Supports broadcast except the first dimension, mutual broadcast between inputs, like NH1C and N1WC.<br>4. Dimensions up to 5D, with general restrictions (see notes). Supports different input dimensions, with specific restrictions for 5D input.<br>(1) Merge adjacent dimensions to 4D, e.g., NHWD1 and N1WDC can merge W and D.<br>(2) Cannot merge broadcast dimensions with adjacent ones, e.g., NHWD1 and N11DC unsupported due to H, W, and C being broadcast dimensions.</td><td>- Supports same shape inputs calculation.<br>- Supports scalar input1 or scalar input2 calculation.<br>- Supports broadcast calculation with a max dimension of 5.</td></tr><tr><td>Multinomial</td><td>CPU Computation※</td><td>--</td><td>--</td></tr></tbody></table>
<table><thead><tr><th>Operation</th><th>Implementation</th><th>Notes</th><th>Limitations</th></tr></thead><tbody><tr><td>Neg</td><td>CPU computation</td><td></td><td></td></tr><tr><td>Not</td><td>CPU computation</td><td></td><td></td></tr><tr><td>OneHot</td><td>CPU computation</td><td></td><td></td></tr><tr><td>Or</td><td>CPU computation</td><td>- Supports same-input-shape computation.<br>- Supports when Input 1 is a scalar or Input 2 is a scalar.<br>- Supports broadcast calculation with a maximum dimension of 5.</td><td></td></tr><tr><td>PRelu</td><td>CPU computation</td><td>- Type constraint: only supports float types.<br>- from_type: X and slope.<br>- to_type: Y.<br>- Constraints for X&#x27;s shape (data_shape):<br>  - data_shape == slope_shape.<br>  - slope_shape.ProdSize() == 1.<br>  - N, C dimensions must be equal in 4D NCHW layout.<br>  - HxW with 1x1 (slope_shape), Hx1 (slope_shape), or 1xW (slope_shape).<br>- Special case: 4D X and 3D slope with data_shape[1] == slope_shape[0] == 1 and slope_shape[2] == 1.</td><td></td></tr><tr><td>Pad</td><td>BPU acceleration</td><td>1. Supports int16 input and output.<br>2. Supports mode: Constant.<br>3. Supports padding in all dimensions.</td><td><br>Pad-10:<br>  - Type constraint: float only.<br>  - 4D NCHW tensors only.<br>  - Constraint on pads attribute:<br>    - len(pads) == 8<br>    - pads[i] &gt;= 0<br>    - pads[0] == pads[1] == pads[4] == pads[5] == 0.<br>Pad-11:<br>  - from_type: data - float only.<br>  - pads: tensor(int64)<br>  - constant_value (optional) - float only.<br>  - to_type: float only.<br>  - 4D Tensor only.<br>  - Supports 2D or 3D padding only.</td></tr><tr><td>Pow</td><td>BPU acceleration</td><td>1. Supports int16 input and output.<br>2. Input/output support 1-10 dimensions, max dim ∈ [1, 4096], others ∈ [1, 65536].<br>3. Second input must be a scalar.</td><td>- Type constraints: double, float, int64, int32.<br>- Supports same-input-shape calculation.<br>- Supports scalar inputs for either Input 1 or Input 2.<br>- Supports broadcast calculation with a maximum dimension of 5.<br>- Requires X and Y to have the same type.</td></tr><tr><td>QLinearConv</td><td>CPU computation※</td><td></td><td></td></tr><tr><td>QLinearMatMul</td><td>CPU computation※</td><td></td><td></td></tr><tr><td>QuantizeLinear</td><td>CPU computation</td><td></td><td></td></tr><tr><td>RNN</td><td>CPU computation</td><td>- Type constraint: float only.<br>- Attribute constraint: direction attribute supports forward only.<br>- Input constraint: X, W, R inputs only, no optional inputs like B, sequence_lens, initial_h allowed.<br>- Output constraint: Only Y_h output supported, shape [num_directions, batch_size, hidden_size].</td><td></td></tr><tr><td>RandomNormal</td><td>CPU computation※</td><td></td><td></td></tr><tr><td>RandomNormalLike</td><td>CPU computation※</td><td></td><td></td></tr><tr><td>RandomUniform</td><td>CPU computation</td><td></td><td></td></tr><tr><td>RandomUniformLike</td><td>CPU computation</td><td></td><td></td></tr><tr><td>Range</td><td>CPU computation</td><td>Type constraints: float, int64, int32, int16.</td><td></td></tr><tr><td>Reciprocal</td><td>BPU acceleration</td><td>1. Supports int16 input and output.<br>2. Input/output support 1-10 dimensions, max dim ∈ [1, 4096], others ∈ [1, 65536].</td><td></td></tr><tr><td>ReduceL1</td><td>CPU computation</td><td></td><td></td></tr><tr><td>ReduceL2</td><td>CPU computation</td><td></td><td></td></tr><tr><td>ReduceLogSum</td><td>CPU computation</td><td></td><td></td></tr><tr><td>ReduceLogSumExp</td><td>CPU computation</td><td>Type constraints: float, double.</td><td></td></tr><tr><td>ReduceMax</td><td>BPU acceleration</td><td>1. Supports int16 input and output.<br>2. Input supports 2-5 dimensions, requires axes attribute with 1 axis, no reduction across more than 1 dimension.<br>3. Reduced dimension size ∈ [1, 8192].<br>4. keepdims == 1 only.<br></td><td>Axes supported: 0, 1, or equal to input data dimensions.</td></tr><tr><td>ReduceMean</td><td>BPU acceleration</td><td>1. Supports int16 input and output.<br>2. Input supports 2-5 dimensions, requires axes attribute with 1 axis, no reduction across more than 1 dimension.<br>3. Special case: Supports HW reduction when reduce_dim = 2.<br>4. keepdims == 1 only.<br></td><td>Axes supported: 0, 1, or equal to input data dimensions.</td></tr><tr><td>ReduceMin</td><td>CPU computation</td><td></td><td></td></tr><tr><td>ReduceProd</td><td>CPU computation</td><td></td><td></td></tr><tr><td>ReduceSum</td><td>BPU acceleration</td><td>1. Supports int16 input and output.<br>2. Input supports 2-5 dimensions, requires axes attribute with 1 axis, no reduction across more than 1 dimension.</td><td>Axes supported: 0, 1, or equal to input data dimensions.</td></tr><tr><td>ReduceSumSquare</td><td>CPU computation</td><td></td><td></td></tr><tr><td>Relu</td><td>BPU acceleration</td><td>Unlimited</td><td>Only supports float type.</td></tr><tr><td>Reshape</td><td>BPU acceleration</td><td>1. Supports int16 inputs and outputs.<br>2. Supports 1-10 dimensional inputs and outputs.</td><td>None.</td></tr><tr><td>Resize</td><td>BPU acceleration</td><td>1. NCHW input featuremaps, resize only on H and W dimensions. onnx opset=11 supports ROI input (PyTorch models need manual modification to add ROI input, which only accepts constant inputs).<br>2. Mode supports nearest and linear.<br>3. Supports scaling up or down.<br><code>4. For nearest mode, scale factors must be powers of 2 (e.g., 2, 4, 8, 16, 32) with H_factor &lt;= W_factor.</code><br>5. onnx opset=11 supports half_pixel, pytorch_half_pixel, asymmetric, align_corners, and tf_crop_and_resize. ROI input is only effective in tf_crop_and_resize mode, requiring integer boundary coordinates after conversion.<br>6. extrapolation_value not supported.</td><td></td></tr><tr><td>ReverseSequence</td><td>CPU computation</td><td>--</td><td>--</td></tr><tr><td>RoiAlign</td><td>CPU computation</td><td>--</td><td>--</td></tr><tr><td>Round</td><td>CPU computation</td><td>--</td><td>--</td></tr><tr><td>Scan</td><td>CPU computation*</td><td>--</td><td>--</td></tr><tr><td>Scatter (deprecated)</td><td>CPU computation*</td><td>--</td><td>--</td></tr><tr><td>ScatterElements</td><td>CPU computation</td><td>--</td><td>from_type: supports float, int32, int8.<br>indices: only supports int32 type.<br>updates: supports float, int32, int8.<br>to_type: supports float, int32, int8.</td></tr><tr><td>ScatterND</td><td>CPU computation</td><td>--</td><td>from_type: supports float, int32, int8.<br>updates: supports float, int32, int8.<br>to_type: supports float, int32, int8.</td></tr><tr><td>Selu</td><td>CPU computation</td><td>--</td><td>Only supports float type.</td></tr><tr><td>SequenceAt</td><td>CPU computation*</td><td>--</td><td>--</td></tr><tr><td>SequenceConstruct</td><td>CPU computation*</td><td>--</td><td>--</td></tr><tr><td>SequenceEmpty</td><td>CPU computation*</td><td>--</td><td>--</td></tr><tr><td>SequenceErase</td><td>CPU computation*</td><td>--</td><td>--</td></tr><tr><td>SequenceInsert</td><td>CPU computation*</td><td>--</td><td>--</td></tr><tr><td>SequenceLength</td><td>CPU computation*</td><td>--</td><td>--</td></tr><tr><td>Shape</td><td>BPU acceleration</td><td>Optimized through constant folding into numerical storage.</td><td>--</td></tr><tr><td>Shrink</td><td>CPU computation*</td><td>--</td><td>--</td></tr><tr><td>Sigmoid</td><td>BPU acceleration</td><td>1. Supports int16 inputs and outputs.<br>2. Supports 1-10 dimensional inputs, max dimension [1, 4096], others [1, 65536].</td><td>Only supports float type.</td></tr><tr><td>Sign</td><td>CPU computation</td><td>Only supports float type.</td><td>--</td></tr><tr><td>Sin</td><td>BPU acceleration</td><td>1. Supports int16 inputs and outputs.<br>2. Supports 1-10 dimensional inputs, max dimension [1, 4096], others [1, 65536].</td><td>Only supports float type.</td></tr><tr><td>Sinh</td><td>CPU computation</td><td>Only supports float type.</td><td>--</td></tr><tr><td>Size</td><td>BPU acceleration</td><td>Optimized through constant folding into numerical storage.</td><td>--</td></tr><tr><td>Slice</td><td>BPU acceleration</td><td>1. Supports int16 inputs and outputs.<br>2. Unlimited, supports non-four-dimensional inputs and outputs.</td><td>No constraints.</td></tr><tr><td>Softmax</td><td>BPU acceleration</td><td>- Supports int16 inputs and outputs.<br>- Runs on CPU by default, with differences between onnx::softmax and pytorch::softmax:<br>1. For onnx::softmax, can run on BPU if input is 4D and axis=3. Specify run_on_bpu.<br>2. For pytorch::softmax, can run on BPU for 4D inputs and axis=1, 2, 3. Specify run_on_bpu.<br></td><td>Only supports float type.</td></tr><tr><td>Softplus</td><td>BPU acceleration</td><td>1. Supports int16 inputs and outputs.<br>2. Supports 1-10 dimensional inputs, max dimension [1, 4096], others [1, 65536].</td><td>Only supports float type.</td></tr><tr><td>Softsign</td><td>CPU computation</td><td>--</td><td>--</td></tr></tbody></table>
<table><thead><tr><th>Operator</th><th>Acceleration</th><th>Support modes and constraints</th><th>Type constraints</th></tr></thead><tbody><tr><td>SpaceToDepth</td><td>BPU accelerated</td><td>Supports DCR and CRD modes. Only reordering along H and W dimensions is allowed, with blocksize=2.</td><td>float only</td></tr><tr><td>Split</td><td>BPU accelerated</td><td>1. Supports int16 inputs and outputs.<br>2. Input length must be a multiple of each split tensor&#x27;s length.<br>3. Supports arbitrary dimensions except N.<br>4. Split count must be divisible.<br>5. Non-four-dimensional inputs and outputs supported.</td><td>float only</td></tr><tr><td>SplitToSequence</td><td>CPU computation(*)</td><td>--</td><td>--</td></tr><tr><td>Sqrt</td><td>BPU accelerated</td><td>1. Supports int16 inputs and outputs.<br>2. Input/output supports 1-10 dimensions, with max dimension in [1, 4096] and others in [1, 65536].</td><td>float only</td></tr><tr><td>Squeeze</td><td>BPU accelerated</td><td>Converted to Reshape op. BPU constraints apply.</td><td>--</td></tr><tr><td>StringNormalizer</td><td>CPU computation(*)</td><td>--</td><td>--</td></tr><tr><td>Sub</td><td>BPU accelerated</td><td>1. Supports int16 inputs and outputs.<br>2. Feature map and constant inputs supported, up to one constant.<br>3. Broadcasting except first dimension, supports input broadcasting between NH1C and N1WC.<br>4. 2D-5D dimensions supported, with general restrictions (see notes). Supports different input dimensions; for 5D inputs, see restrictions below.<br>(1) Merge adjacent dimensions to 4D, e.g., NHWD1 and N1WDC.<br>(2) Cannot merge broadcasted dimensions with adjacent ones, e.g., NHWD1 and N11DC not supported due to H, W, and C being broadcasted dimensions.</td><td>Same shape input support<br>Scalar input support<br>Broadcasting up to 5 dimensions.</td></tr><tr><td>Sum</td><td>BPU accelerated</td><td>Constraints same as Add</td><td>float only</td></tr><tr><td>Tan</td><td>CPU computation</td><td>--</td><td>float only</td></tr><tr><td>Tanh</td><td>BPU accelerated</td><td>1. Supports int16 inputs and outputs.<br>2. Input/output supports 1-10 dimensions, with max dimension in [1, 4096] and others in [1, 65536].</td><td>float only</td></tr><tr><td>TfIdfVectorizer</td><td>CPU computation(*)</td><td>--</td><td>--</td></tr><tr><td>ThresholdedRelu</td><td>CPU computation</td><td>--</td><td>float only</td></tr><tr><td>Tile</td><td>BPU accelerated</td><td>1. Supports int16 inputs and outputs.<br>2. Only one dimension may have differing values between input and output.</td><td>float, int64, etc.</td></tr><tr><td>TopK</td><td>BPU accelerated</td><td>1. Supports int16 inputs and outputs.<br>2. Input/indices/output dimensions: 1-10.<br>3. Indices type: int16/int32/int64.<br>4. Sorted parameter supports true only.</td><td>float only</td></tr><tr><td>Transpose</td><td>BPU accelerated</td><td>1. Supports int16 inputs and outputs.<br>2. Arbitrary input dimensions.</td><td>nhwc2nchw, perm: [0, 3, 1, 2]<br>nchw2nhwc, perm: [0, 2, 3, 1]<br>Custom perm dimensions for float, int8, int32.</td></tr><tr><td>Unique</td><td>CPU computation(*)</td><td>--</td><td>--</td></tr><tr><td>Unsqueeze</td><td>BPU accelerated</td><td>Converted to Reshape op. BPU constraints apply.</td><td>--</td></tr><tr><td>Upsample (resize replacement)</td><td>BPU accelerated</td><td>--</td><td>Upsample-10<br>Input: 4D Tensor, opset10 when = 2<br>Upsample-11<br>Input: 4D Tensor, opset11 when &gt; 2<br>Coordinate transformation modes: nearest, linear (half_pixel, asymmetric, align_corners, pytorch_half_pixel), cubic (half_pixel only)<br>Extrapolation_value unsupported.</td></tr><tr><td>Where</td><td>CPU computation</td><td>--</td><td>float, int64</td></tr><tr><td>Xor</td><td>CPU computation(*)</td><td>--</td><td>--</td></tr><tr><td>Function</td><td>CPU computation(*)</td><td>--</td><td>--</td></tr><tr><td>Celu</td><td>CPU computation(*)</td><td>--</td><td>--</td></tr><tr><td>DynamicQuantizeLinear</td><td>CPU computation(*)</td><td>--</td><td>--</td></tr><tr><td>GreaterOrEqual</td><td>BPU accelerated</td><td>Opset11 doesn&#x27;t support standalone GreaterOrEqual; Less + Not on BPU for split conditions, with similar restrictions to Less.</td><td>Same shape, scalar, broadcast up to 5D.</td></tr><tr><td>MeanVarianceNormalization</td><td>CPU computation(*)</td><td>--</td><td>--</td></tr><tr><td>GridSample (PyTorch)</td><td>BPU accelerated</td><td>1. Input dimensions: 4D, N ∈ [1, 4096], C ∈ [1, 65536], H, W ∈ [1, 1024], H<em>W ≤ 720</em>1024.<br>2. Mode: bilinear, nearest.<br>3. Padding_mode: zeros, border.<br>4. Opset16 ONNX operator, exported via horizon_nn.torch.export_onnx (not opset11 native). See example below.</td><td>--</td></tr></tbody></table></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-08-14T12:54:11.000Z" itemprop="dateModified">Aug 14, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/ptq_process"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Principles and Steps of PTQ</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/rdk_doc/en/Advanced_development/toolchain_development/intermediate/runtime_sample"><div class="pagination-nav__sublabel">Next </div><div class="pagination-nav__label">On-board Model Application Development Guide</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#supported_op_list_and_restrictions" class="table-of-contents__link toc-highlight">Supported Operator Lists and Restrictions</a><ul><li><a href="#limitations-and-notes" class="table-of-contents__link toc-highlight">Limitations and Notes</a></li></ul></li><li><a href="#rdk-x3-list-of-supported-caffe-operators" class="table-of-contents__link toc-highlight">RDK X3 List of supported Caffe operators</a></li><li><a href="#rdk-x3-list-of-supported-onnx-operators" class="table-of-contents__link toc-highlight">RDK X3 List of supported ONNX operators</a></li><li><a href="#rdk-ultra-supported-caffe-operators-list" class="table-of-contents__link toc-highlight">RDK Ultra Supported Caffe Operators List</a></li><li><a href="#rdk-ultra-supported-onnx-operators-list" class="table-of-contents__link toc-highlight">RDK Ultra-supported ONNX Operators List</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.guyuehome.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">GuYueHome<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Contact US</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/D-Robotics" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@D-Robotics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Youtube<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 D-Robotics.</div></div></div></footer></div>
</body>
</html>